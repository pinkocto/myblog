[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "welcome!"
  },
  {
    "objectID": "Tip/2023-02-24-tips.html",
    "href": "Tip/2023-02-24-tips.html",
    "title": "Julia 연동",
    "section": "",
    "text": "Julia 설치\n설치된 Julia를 열어 Command창에 using Pkg 입력 + 엔터\nPkg.add(\"IJulia\") 입력 + 엔터\nJupyter notebook/lab 들어가서 확인\n\n결과\n\n\n\nimage.png"
  },
  {
    "objectID": "Tip/2023-02-20-tips.html",
    "href": "Tip/2023-02-20-tips.html",
    "title": "download files from Github",
    "section": "",
    "text": "- Github에 주피터노트북 파일 다운로드 받는 법\n\n!wget https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/STGCN/2022-12-29-STGCN-tutorial.ipynb\n\n--2023-02-20 22:35:38--  https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/STGCN/2022-12-29-STGCN-tutorial.ipynb\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1184264 (1.1M) [text/plain]\nSaving to: ‘2022-12-29-STGCN-tutorial.ipynb’\n\n2022-12-29-STGCN-tu 100%[===================>]   1.13M  --.-KB/s    in 0.03s   \n\n2023-02-20 22:35:39 (42.5 MB/s) - ‘2022-12-29-STGCN-tutorial.ipynb’ saved [1184264/1184264]\n\n\n\n좌측 사이드바를 확인해보면 원하는 주피터 파일 (2022-12-29-STGCN-tutorial.ipynb) 이 잘 다운받아진 것을 확인해볼 수 있다."
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#pyg-의-data-자료형",
    "href": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#pyg-의-data-자료형",
    "title": "STGCN 튜토리얼",
    "section": "PyG 의 Data 자료형",
    "text": "PyG 의 Data 자료형\n\nref: https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-handling-of-graphs\n\n- 자료는 PyG의 Data 오브젝트를 기반으로 한다.\n(예제) 아래와 같은 그래프자료를 고려하자.\n\n이러한 자료형은 아래와 같은 형식으로 저장한다.\n\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype=torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\ndata = Data(x=x, edge_index=edge_index) # Data는 그래프자료형을 만드는 클래스\n\n\ntype(data)\n\ntorch_geometric.data.data.Data\n\n\n\ndata.x\n\ntensor([[-1.],\n        [ 0.],\n        [ 1.]])\n\n\n\ndata.edge_index\n\ntensor([[0, 1, 1, 2],\n        [1, 0, 2, 1]])"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#pytorch-geometric-temporal-의-자료형",
    "href": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#pytorch-geometric-temporal-의-자료형",
    "title": "STGCN 튜토리얼",
    "section": "PyTorch Geometric Temporal 의 자료형",
    "text": "PyTorch Geometric Temporal 의 자료형\n\nref: PyTorch Geometric Temporal Signal\n\n아래의 클래스들중 하나를 이용하여 만든다.\n## Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n## Heterogeneous Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphStaticSignal\n이중 “Heterogeneous Temporal Signal” 은 우리가 관심이 있는 신호가 아니므로 사실상 아래의 3개만 고려하면 된다.\n\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n\n여기에서 StaticGraphTemporalSignal 는 시간에 따라서 그래프 구조가 일정한 경우, 즉 \\({\\cal G}_t=\\{{\\cal V},{\\cal E}\\}\\)와 같은 구조를 의미한다.\n(예제1) StaticGraphTemporalSignal 를 이용하여 데이터 셋 만들기\n- json data \\(\\to\\) dict\n\nimport json\nimport urllib\n\n\nurl = \"https://raw.githubusercontent.com/benedekrozemberczki/pytorch_geometric_temporal/master/dataset/chickenpox.json\"\ndata_dict = json.loads(urllib.request.urlopen(url).read())\n# data_dict 출력이 김\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n- 살펴보기\n\nnp.array(data_dict['edges']).T\n\narray([[ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,\n         3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  6,\n         6,  6,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n        10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12,\n        12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15,\n        15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18,\n        18, 18, 19, 19, 19, 19],\n       [10,  6, 13,  1,  0,  5, 16,  0, 16,  1, 14, 10,  8,  2,  5,  8,\n        15, 12,  9, 10,  3,  4, 13,  0, 10,  2,  5,  0, 16,  6, 14, 13,\n        11, 18,  7, 17, 11, 18,  3,  2, 15,  8, 10,  9, 13,  3, 12, 10,\n         5,  9,  8,  3, 10,  2, 13,  0,  6, 11,  7, 13, 18,  3,  9, 13,\n        12, 13,  9,  6,  4, 12,  0, 11, 10, 18, 19,  1, 14,  6, 16,  3,\n        15,  8, 16, 14,  1,  0,  6,  7, 19, 17, 18, 14, 18, 17,  7,  6,\n        19, 11, 18, 14, 19, 17]])\n\n\n\n\\({\\cal E} = \\{(0,10),(0,6), \\dots, (19,17)\\}\\)\n혹은 \\({\\cal E} = \\{(\\tt{BACS},\\tt{JASZ}), ({\\tt BACS},{\\tt FEJER}), \\dots, (\\tt{ZALA},\\tt{VAS})\\}\\)\n\n\ndata_dict['node_ids']\n\n{'BACS': 0,\n 'BARANYA': 1,\n 'BEKES': 2,\n 'BORSOD': 3,\n 'BUDAPEST': 4,\n 'CSONGRAD': 5,\n 'FEJER': 6,\n 'GYOR': 7,\n 'HAJDU': 8,\n 'HEVES': 9,\n 'JASZ': 10,\n 'KOMAROM': 11,\n 'NOGRAD': 12,\n 'PEST': 13,\n 'SOMOGY': 14,\n 'SZABOLCS': 15,\n 'TOLNA': 16,\n 'VAS': 17,\n 'VESZPREM': 18,\n 'ZALA': 19}\n\n\n\n\\({\\cal V}=\\{\\tt{BACS},\\tt{BARANYA} \\dots, \\tt{ZALA}\\}\\)\n\n\nnp.array(data_dict['FX']), np.array(data_dict['FX']).shape\n\n(array([[-1.08135724e-03, -7.11136085e-01, -3.22808515e+00, ...,\n          1.09445310e+00, -7.08747750e-01, -1.82280792e+00],\n        [ 2.85705967e-02, -5.98430173e-01, -2.29097341e-01, ...,\n         -1.59220988e+00, -2.24597623e-01,  7.86330575e-01],\n        [ 3.54742090e-01,  1.90511208e-01,  1.61028185e+00, ...,\n          1.38183225e-01, -7.08747750e-01, -5.61724314e-01],\n        ...,\n        [-4.75512620e-01, -1.19952837e+00, -3.89043358e-01, ...,\n         -1.00023329e+00, -1.71429032e+00,  4.70746677e-02],\n        [-2.08645035e-01,  6.03766218e-01,  1.08216835e-02, ...,\n          4.71099041e-02,  2.45684924e+00, -3.44296107e-01],\n        [ 1.21464875e+00,  7.16472130e-01,  1.29038982e+00, ...,\n          4.56939849e-01,  7.43702632e-01,  1.00375878e+00]]),\n (521, 20))\n\n\n\n\\({\\bf f}=\\begin{bmatrix} {\\bf f}_1\\\\ {\\bf f}_2\\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}=\\begin{bmatrix} f(t=1,v=\\tt{BACS}) & \\dots & f(t=1,v=\\tt{ZALA}) \\\\ f(t=2,v=\\tt{BACS}) & \\dots & f(t=2,v=\\tt{ZALA}) \\\\ \\dots & \\dots & \\dots \\\\ f(t=521,v=\\tt{BACS}) & \\dots & f(t=521,v=\\tt{ZALA}) \\end{bmatrix}\\)\n\n즉 data_dict는 아래와 같이 구성되어 있음\n\n\n\n\n\n\n\n\n\n\n수학 기호\n코드에 저장된 변수\n자료형\n차원\n설명\n\n\n\n\n\\({\\cal V}\\)\ndata_dict['node_ids']\ndict\n20\n20개의 노드에 대한 설명이 있음\n\n\n\\({\\cal E}\\)\ndata_dict['edges']\nlist (double list)\n(102,2)\n노드들에 대한 102개의 연결을 정의함\n\n\n\\({\\bf f}\\)\ndata_dict['node_ids']\ndict\n(521,20)\n\\(f(t,v)\\) for \\(v \\in {\\cal V}\\) and \\(t = 1,\\dots, T\\)\n\n\n\n- 주어진 자료를 정리하여 그래프신호 \\(\\big(\\{{\\cal V},{\\cal E},{\\bf W}\\},{\\bf f}\\big)\\)를 만들면 아래와 같다.\n\nedges = np.array(data_dict[\"edges\"]).T\nedge_weight = np.ones(edges.shape[1])\nf = np.array(data_dict[\"FX\"])\n\n\n여기에서 edges는 \\({\\cal E}\\)에 대한 정보를\nedges_weight는 \\({\\bf W}\\)에 대한 정보를\nf는 \\({\\bf f}\\)에 대한 정보를 저장한다.\n\n\nNote: 이때 \\({\\bf W}={\\bf E}\\) 로 정의한다. (하지만 꼭 이래야 하는건 아니야)\n\n- data_dict \\(\\to\\) dl\n\nlags = 4\nfeatures = [f[i : i + lags, :].T for i in range(f.shape[0] - lags)]\ntargets = [f[i + lags, :].T for i in range(f.shape[0] - lags)]\n\n\nnp.array(features).shape, np.array(targets).shape\n\n((517, 20, 4), (517, 20))\n\n\n\n\n\n\n\n\n\n설명변수\n반응변수\n\n\n\n\n\\({\\bf X} = {\\tt features} = \\begin{bmatrix} {\\bf f}_1 & {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 \\\\ {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 & {\\bf f}_5 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ {\\bf f}_{517} & {\\bf f}_{518} & {\\bf f}_{519} & {\\bf f}_{520} \\end{bmatrix}\\)\n\\({\\bf y}= {\\tt targets} = \\begin{bmatrix} {\\bf f}_5 \\\\ {\\bf f}_6 \\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}\\)\n\n\n\n\nAR 느낌으로 표현하면 AR(4) 임\n\n\ndataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(\n    edge_index= edges,\n    edge_weight = edge_weight,\n    features = features,\n    targets = targets\n)\n\n\ndataset\n\n<torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7f89e2b6e340>\n\n\n- 그런데 이 과정을 아래와 같이 할 수도 있음\n# PyTorch Geometric Temporal 공식홈페이지에 소개된 코드\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset=loader.get_dataset(lags=4)\n- dataset은 dataset[0], \\(\\dots\\) , dataset[516]과 같은 방식으로 각 시점별 자료에 접근가능\n\ndataset[0]\n\nData(x=[20, 4], edge_index=[2, 102], edge_attr=[102], y=[20])\n\n\n각 시점에 대한 자료형은 아까 살펴보았던 PyG의 Data 자료형과 같음\n\ntype(dataset[0])\n\ntorch_geometric.data.data.Data\n\n\n\ndataset[0].x \n\ntensor([[-1.0814e-03,  2.8571e-02,  3.5474e-01,  2.9544e-01],\n        [-7.1114e-01, -5.9843e-01,  1.9051e-01,  1.0922e+00],\n        [-3.2281e+00, -2.2910e-01,  1.6103e+00, -1.5487e+00],\n        [ 6.4750e-01, -2.2117e+00, -9.6858e-01,  1.1862e+00],\n        [-1.7302e-01, -9.4717e-01,  1.0347e+00, -6.3751e-01],\n        [ 3.6345e-01, -7.5468e-01,  2.9768e-01, -1.6273e-01],\n        [-3.4174e+00,  1.7031e+00, -1.6434e+00,  1.7434e+00],\n        [-1.9641e+00,  5.5208e-01,  1.1811e+00,  6.7002e-01],\n        [-2.2133e+00,  3.0492e+00, -2.3839e+00,  1.8545e+00],\n        [-3.3141e-01,  9.5218e-01, -3.7281e-01, -8.2971e-02],\n        [-1.8380e+00, -5.8728e-01, -3.5514e-02, -7.2298e-02],\n        [-3.4669e-01, -1.9827e-01,  3.9540e-01, -2.4774e-01],\n        [ 1.4219e+00, -1.3266e+00,  5.2338e-01, -1.6374e-01],\n        [-7.7044e-01,  3.2872e-01, -1.0400e+00,  3.4945e-01],\n        [-7.8061e-01, -6.5022e-01,  1.4361e+00, -1.2864e-01],\n        [-1.0993e+00,  1.2732e-01,  5.3621e-01,  1.9023e-01],\n        [ 2.4583e+00, -1.7811e+00,  5.0732e-02, -9.4371e-01],\n        [ 1.0945e+00, -1.5922e+00,  1.3818e-01,  1.1855e+00],\n        [-7.0875e-01, -2.2460e-01, -7.0875e-01,  1.5630e+00],\n        [-1.8228e+00,  7.8633e-01, -5.6172e-01,  1.2647e+00]])\n\n\n\n이 값들은 features[0]의 값들과 같음. 즉 \\([{\\bf f}_1~ {\\bf f}_2~ {\\bf f}_3~ {\\bf f}_4]\\)를 의미함\n\n\ndataset[0].y\n\ntensor([ 0.7106, -0.0725,  2.6099,  1.7870,  0.8024, -0.2614, -0.8370,  1.9674,\n        -0.4212,  0.1655,  1.2519,  2.3743,  0.7877,  0.4531, -0.1721, -0.0614,\n         1.0452,  0.3203, -1.3791,  0.0036])\n\n\n\n이 값들은 targets[0]의 값들과 같음. 즉 \\({\\bf f}_5\\)를 의미함"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#summary-of-data",
    "href": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#summary-of-data",
    "title": "STGCN 튜토리얼",
    "section": "summary of data",
    "text": "summary of data\n\n\\(T\\) = 519\n\\(N\\) = 20 # number of nodes\n\\(|{\\cal E}|\\) = 102 # edges\n\\(f(t,v)\\)의 차원? (1,)\n시간에 따라서 Number of nodes가 변하는지? False\n시간에 따라서 Number of nodes가 변하는지? False\n\\({\\bf X}\\): (20,4)\n\\({\\bf y}\\): (20,)\n예제코드적용가능여부: Yes\n\n- Nodes : 20\n\nvertices are counties\n\n-Edges : 102\n\nedges are neighbourhoods\n\n- Time : 519\n\nbetween 2004 and 2014\nper weeks\n\n\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#learn",
    "href": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#learn",
    "title": "STGCN 튜토리얼",
    "section": "learn",
    "text": "learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [01:08<00:00,  1.38s/it]"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#visualization",
    "href": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#visualization",
    "title": "STGCN 튜토리얼",
    "section": "visualization",
    "text": "visualization\n\nmodel.eval()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nV = list(data_dict['node_ids'].keys())\n\n\nfig,ax = plt.subplots(20,1,figsize=(10,50))\nfor k in range(20):\n    ax[k].plot(f[:,k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:,k],label='predicted (tr)')\n    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html",
    "href": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html",
    "title": "Toy Example",
    "section": "",
    "text": "import networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#data",
    "href": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#data",
    "title": "Toy Example",
    "section": "data",
    "text": "data\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=14)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#recurrentgcn",
    "href": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#recurrentgcn",
    "title": "Toy Example",
    "section": "RecurrentGCN",
    "text": "RecurrentGCN\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#learn",
    "href": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#learn",
    "title": "Toy Example",
    "section": "Learn",
    "text": "Learn\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=14, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [03:48<00:00,  4.57s/it]"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#예제의-차원-조사",
    "href": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#예제의-차원-조사",
    "title": "Toy Example",
    "section": "예제의 차원 조사",
    "text": "예제의 차원 조사\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1068, 14])\n\n\n\n1068: number of nodes // 1068개의 노드가 있음\n14: number of features // 하나의 노드에 맵핑된 차원의수\n\n\n_edge_index.shape\n\ntorch.Size([2, 27079])\n\n\n\n_edge_attr.shape\n\ntorch.Size([27079])\n\n\n\n_y.shape\n\ntorch.Size([1068])\n\n\n\n1068: number of nodes\n\n\n_x.shape\n\ntorch.Size([1068, 14])"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html",
    "title": "튜토리얼 따라가기1",
    "section": "",
    "text": "https://miruetoto.github.io/yechan3/posts/3_Researches/STGCN/2022-12-29-STGCN-tutorial.html\nhttps://pytorch-geometric-temporal.readthedocs.io/en/latest/"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#imports",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#imports",
    "title": "튜토리얼 따라가기1",
    "section": "imports",
    "text": "imports\n\n# 일반적인 모듈\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport networkx as nx # 그래프 시그널 시각화를 위한 모듈\nfrom tqdm import tqdm # for문의 진행 상태 확인\n\n# 파이토치 관련\nimport torch\nimport torch.nn.functional as F\n\n\n# PyG 관련\nfrom torch_geometric.data import Data # 그래프 자료를 만들기 위한 클래스\n\n\n# STGCN 관련\nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split # STGCN dataset을 train/test set으로 분리\n\n- STGCN의 학습을 위한 클래스 선언\n\n# define recurrent GCN architecture\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#notations-of-stgcn",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#notations-of-stgcn",
    "title": "튜토리얼 따라가기1",
    "section": "notations of STGCN",
    "text": "notations of STGCN\n- 시계열: each \\(t\\) 에에 대한 observation이 하나의 값 (혹은 벡터)\n\n자료: \\(X(t) \\quad \\text{for} \\quad t = 1,2,\\dots,T\\)\n\n- STGCN setting에서는 each \\(t\\) 에 대한 observation이 graph\n\n자료: \\(X(v,t) \\quad \\text{for} \\quad t = 1,2,\\dots,T \\quad \\text{and} \\quad v\\in V\\)\n주의: 이 포스트에서는 \\(X(v,t)\\)를 \\(f(v,t)\\)로 표현할 때가 있음"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#dataset-dataloaders",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#dataset-dataloaders",
    "title": "튜토리얼 따라가기1",
    "section": "dataset, dataloaders",
    "text": "dataset, dataloaders\n\nPyG의 Data 자료형\n(예제) 아래와 같은 그래프 자료를 고려하자.\nWe show a simple example of an unweighted and undirected graph with three nodes and four edges. Each node contains exactly one feature\n\n이러한 자료형은 아래와 같은 형식으로 저장한다.\n\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype = torch.long)  # 4 edges\nx  = torch.tensor([[-1], [0], [1]], dtype = torch.float) # 3 nodes\ndata = Data(x=x, edge_index=edge_index) # Data는 그래프자료형을 만드는 클래스\n\n\ndata\n\nData(x=[3, 1], edge_index=[2, 4])\n\n\n\nx : \\(3\\times1\\) 크기의 행렬 \\(\\to\\) 3개의 노드와 각 노드는 단일 값을 가진다.\nedge_index : \\(2 \\times 4\\) 크기의 행렬 \\(\\to\\) \\(4\\)개의 엣지들 (양방향 그래프)\n\n\ntype(data)\n\ntorch_geometric.data.data.Data\n\n\n\ndata.x # 노드의 특징 행렬\n\ntensor([[-1.],\n        [ 0.],\n        [ 1.]])\n\n\n\ndata.edge_index # 그래프 연결성\n\ntensor([[0, 1, 1, 2],\n        [1, 0, 2, 1]])\n\n\n\ndata.num_edges # edge 총 갯수\n\n4\n\n\n\ndata.is_directed() # 그래프 방향성 여부 확인\n\nFalse"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#pytorch-geometric-temporal-의-자료형",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#pytorch-geometric-temporal-의-자료형",
    "title": "튜토리얼 따라가기1",
    "section": "PyTorch Geometric Temporal 의 자료형",
    "text": "PyTorch Geometric Temporal 의 자료형\n\nref: PyTorch Geomatric Temporal Signal\n\n아래의 클래스들 중 하나를 이용하여 만든다.\n\n## Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n\n## Heterogeneous Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphStaticSignal\n\ntorch_geometric_temporal.signal.dynamic_hetero_graph_static_signal.DynamicHeteroGraphStaticSignal\n\n\n이 중 “Heterogeneous Temporal Signal”은 우리가 관심이 있는 신호가 아님로 사실상 아래 3가지만 고려하면 된다.\n\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n\n여기에서 StaticGraphTemporalSignal 는 시간에 따라서 그래프 구조가 일정한 경우, 즉 \\({\\cal G}_t=\\{{\\cal V},{\\cal E}\\}\\) 와 같은 구조를 의미한다.\n\n(예제1) StaticGraphTemporalSignal을 이용하여 데이터 셋 만들기\n- json data \\(\\to\\) dict\n\nimport json\nimport urllib\n\n\nurl = \"https://raw.githubusercontent.com/benedekrozemberczki/pytorch_geometric_temporal/master/dataset/chickenpox.json\"\ndata_dict = json.loads(urllib.request.urlopen(url).read())\n# data_dict 출력이 김\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n- 살펴보기\n\nnp.array(data_dict['edges']).T\n\narray([[ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,\n         3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  6,\n         6,  6,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n        10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12,\n        12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15,\n        15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18,\n        18, 18, 19, 19, 19, 19],\n       [10,  6, 13,  1,  0,  5, 16,  0, 16,  1, 14, 10,  8,  2,  5,  8,\n        15, 12,  9, 10,  3,  4, 13,  0, 10,  2,  5,  0, 16,  6, 14, 13,\n        11, 18,  7, 17, 11, 18,  3,  2, 15,  8, 10,  9, 13,  3, 12, 10,\n         5,  9,  8,  3, 10,  2, 13,  0,  6, 11,  7, 13, 18,  3,  9, 13,\n        12, 13,  9,  6,  4, 12,  0, 11, 10, 18, 19,  1, 14,  6, 16,  3,\n        15,  8, 16, 14,  1,  0,  6,  7, 19, 17, 18, 14, 18, 17,  7,  6,\n        19, 11, 18, 14, 19, 17]])\n\n\n\n\\({\\cal E} = \\{(0,10),(0,6), \\dots, (19,17)\\}\\)\n혹은 \\({\\cal E} = \\{(\\tt{BACS},\\tt{JASZ}), ({\\tt BACS},{\\tt FEJER}), \\dots, (\\tt{ZALA},\\tt{VAS})\\}\\)\n\n\ndata_dict['node_ids']\n\n{'BACS': 0,\n 'BARANYA': 1,\n 'BEKES': 2,\n 'BORSOD': 3,\n 'BUDAPEST': 4,\n 'CSONGRAD': 5,\n 'FEJER': 6,\n 'GYOR': 7,\n 'HAJDU': 8,\n 'HEVES': 9,\n 'JASZ': 10,\n 'KOMAROM': 11,\n 'NOGRAD': 12,\n 'PEST': 13,\n 'SOMOGY': 14,\n 'SZABOLCS': 15,\n 'TOLNA': 16,\n 'VAS': 17,\n 'VESZPREM': 18,\n 'ZALA': 19}\n\n\n\nlen(data_dict['node_ids']) # node 개수는 20개\n\n20\n\n\n\n\\({\\cal V}=\\{\\tt{BACS},\\tt{BARANYA} \\dots, \\tt{ZALA}\\}\\)\n\n\nlen(data_dict['edges']) # edge의 개수 102개\n\n102\n\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n\nnp.array(data_dict['FX']), np.array(data_dict['FX']).shape\n\n(array([[-1.08135724e-03, -7.11136085e-01, -3.22808515e+00, ...,\n          1.09445310e+00, -7.08747750e-01, -1.82280792e+00],\n        [ 2.85705967e-02, -5.98430173e-01, -2.29097341e-01, ...,\n         -1.59220988e+00, -2.24597623e-01,  7.86330575e-01],\n        [ 3.54742090e-01,  1.90511208e-01,  1.61028185e+00, ...,\n          1.38183225e-01, -7.08747750e-01, -5.61724314e-01],\n        ...,\n        [-4.75512620e-01, -1.19952837e+00, -3.89043358e-01, ...,\n         -1.00023329e+00, -1.71429032e+00,  4.70746677e-02],\n        [-2.08645035e-01,  6.03766218e-01,  1.08216835e-02, ...,\n          4.71099041e-02,  2.45684924e+00, -3.44296107e-01],\n        [ 1.21464875e+00,  7.16472130e-01,  1.29038982e+00, ...,\n          4.56939849e-01,  7.43702632e-01,  1.00375878e+00]]),\n (521, 20))\n\n\n\n\\({\\bf f}=\\begin{bmatrix} {\\bf f}_1\\\\ {\\bf f}_2\\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}=\\begin{bmatrix} f(t=1,v=\\tt{BACS}) & \\dots & f(t=1,v=\\tt{ZALA}) \\\\ f(t=2,v=\\tt{BACS}) & \\dots & f(t=2,v=\\tt{ZALA}) \\\\ \\dots & \\dots & \\dots \\\\ f(t=521,v=\\tt{BACS}) & \\dots & f(t=521,v=\\tt{ZALA}) \\end{bmatrix}\\)\n\n즉, data_dict는 아래와 같이 구성되어 있음\n\n\n\n\n\n\n\n\n\n\n수학 기호\n코드에 저장된 변수\n자료형\n차원\n설명\n\n\n\n\n\\({\\cal V}\\)\ndata_dict['node_ids']\ndict\n20\n20개의 노드에 대한 설명이 있음\n\n\n\\({\\cal E}\\)\ndata_dict['edges']\nlist (double list)\n(102,2)\n노드들에 대한 102개의 연결을 정의함\n\n\n\\({\\bf f}\\)\ndata_dict['node_ids']\ndict\n(521,20)\n\\(f(t,v)\\) for \\(v \\in {\\cal V}\\) and \\(t = 1,\\dots, T\\)\n\n\n\n- 주어진 자료를 정리하여 그래프신호 \\(\\big(\\{{\\cal V},{\\cal E},{\\bf W}\\},{\\bf f}\\big)\\)를 만들면 아래와 같다.\n\nedges = np.array(data_dict['edges']).T\nedge_weight = np.ones(edges.shape[1])\nf =  np.array(data_dict['FX'])\n\n\n여기에서 edges는 \\(\\cal{E}\\) 에 대한 정보들\nedges_weight는 \\(\\bf{W}\\)에 대한 정보들\nf는 \\(\\bf{f}\\)에 대한 정보를 저장한다.\n\n\nNote: 이때 \\(\\bf{W} = \\bf{E}\\)로 정의한다.\n\n- data_dict \\(\\to\\) dl\n\nlags = 4\nfeatures = [f[i : i + lags, :].T for i in range(f.shape[0] - lags)]\ntargets = [f[i + lags, :].T for i in range(f.shape[0] - lags)]\n\n\nnp.array(features).shape, np.array(targets).shape\n\n((517, 20, 4), (517, 20))\n\n\n\n\n\n\n\n\n\n설명변수\n반응변수\n\n\n\n\n\\({\\bf X} = {\\tt features} = \\begin{bmatrix} {\\bf f}_1 & {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 \\\\ {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 & {\\bf f}_5 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ {\\bf f}_{517} & {\\bf f}_{518} & {\\bf f}_{519} & {\\bf f}_{520} \\end{bmatrix}\\)\n\\({\\bf y}= {\\tt targets} = \\begin{bmatrix} {\\bf f}_5 \\\\ {\\bf f}_6 \\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}\\)\n\n\n\n\nAR 느낌으로 표현하면 AR(4) 이다.\n\n\ndataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(\n    edge_index = edges,\n    edge_weight = edge_weight,\n    features = features,\n    targets = targets)\n\n\ndataset\n\n<torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7fc4bee0a250>\n\n\n- 그런데 이 과정을 아래와 같이 할 수도있음\n\n# Pytorch Geometric Temporal 공식홈페이지에 소개된 콛,ㅡ\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset = loader.get_dataset(lags = 4)\n\n- dataset은 dataset[0],\\(\\dots\\)dataset[516]과 같은 방식으로 각 시점별 자료에 접근 가능\n\ndataset[0]\n\nData(x=[20, 4], edge_index=[2, 102], edge_attr=[102], y=[20])\n\n\n각 시점에 대한 자료형은 아까 살펴보았던 PyG의 Data 자료형과 같음\n\ntype(dataset[0])\n\ntorch_geometric.data.data.Data\n\n\n\ndataset[0].x\n\ntensor([[-1.0814e-03,  2.8571e-02,  3.5474e-01,  2.9544e-01],\n        [-7.1114e-01, -5.9843e-01,  1.9051e-01,  1.0922e+00],\n        [-3.2281e+00, -2.2910e-01,  1.6103e+00, -1.5487e+00],\n        [ 6.4750e-01, -2.2117e+00, -9.6858e-01,  1.1862e+00],\n        [-1.7302e-01, -9.4717e-01,  1.0347e+00, -6.3751e-01],\n        [ 3.6345e-01, -7.5468e-01,  2.9768e-01, -1.6273e-01],\n        [-3.4174e+00,  1.7031e+00, -1.6434e+00,  1.7434e+00],\n        [-1.9641e+00,  5.5208e-01,  1.1811e+00,  6.7002e-01],\n        [-2.2133e+00,  3.0492e+00, -2.3839e+00,  1.8545e+00],\n        [-3.3141e-01,  9.5218e-01, -3.7281e-01, -8.2971e-02],\n        [-1.8380e+00, -5.8728e-01, -3.5514e-02, -7.2298e-02],\n        [-3.4669e-01, -1.9827e-01,  3.9540e-01, -2.4774e-01],\n        [ 1.4219e+00, -1.3266e+00,  5.2338e-01, -1.6374e-01],\n        [-7.7044e-01,  3.2872e-01, -1.0400e+00,  3.4945e-01],\n        [-7.8061e-01, -6.5022e-01,  1.4361e+00, -1.2864e-01],\n        [-1.0993e+00,  1.2732e-01,  5.3621e-01,  1.9023e-01],\n        [ 2.4583e+00, -1.7811e+00,  5.0732e-02, -9.4371e-01],\n        [ 1.0945e+00, -1.5922e+00,  1.3818e-01,  1.1855e+00],\n        [-7.0875e-01, -2.2460e-01, -7.0875e-01,  1.5630e+00],\n        [-1.8228e+00,  7.8633e-01, -5.6172e-01,  1.2647e+00]])\n\n\n\n이 값들은 features[0]의 값들과 같음. 즉 \\([\\bf{f}_1, \\bf{f}_2, \\bf{f}_3, \\bf{f}_4]\\)를 의미함\n\n\ndataset[0].y\n\ntensor([ 0.7106, -0.0725,  2.6099,  1.7870,  0.8024, -0.2614, -0.8370,  1.9674,\n        -0.4212,  0.1655,  1.2519,  2.3743,  0.7877,  0.4531, -0.1721, -0.0614,\n         1.0452,  0.3203, -1.3791,  0.0036])\n\n\n\n이 값들은 targets[0]이 값들과 같음. 즉 \\(\\bf{f}_5\\)를 의미함"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#summary-of-data",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#summary-of-data",
    "title": "튜토리얼 따라가기1",
    "section": "Summary of data",
    "text": "Summary of data\n\n\\(T = 519\\)\n\\(N=20\\) # number of nodes\n\\(|\\cal{E}|=102\\) # edges\n\\(f(t,v)\\)의 차원? \\((1,)\\) # edges\n시간에 따라서 Number of nods가 변하는지? \\(\\to\\) False\n\\(\\bf{X}: (20, 4)\\)\n\\(\\bf{y}: (20, )\\)\n예제코드적용가능 여부 : Yes\n\n- Nodes : 20 - vertices are counties\n- Edges: 102 - edges are neighbourhoods\n- Time: 519 - between 2004 and 2014 - per weeks\n\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset = loader.get_dataset(lags = 4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio = 0.8)"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#learn",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#learn",
    "title": "튜토리얼 따라가기1",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features = 4, filters = 32)\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat - snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [01:08<00:00,  1.37s/it]"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#visualization",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#visualization",
    "title": "튜토리얼 따라가기1",
    "section": "Visualization",
    "text": "Visualization\n\nmodel.eval()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nV = list(data_dict['node_ids'].keys())\nV\n\n['BACS',\n 'BARANYA',\n 'BEKES',\n 'BORSOD',\n 'BUDAPEST',\n 'CSONGRAD',\n 'FEJER',\n 'GYOR',\n 'HAJDU',\n 'HEVES',\n 'JASZ',\n 'KOMAROM',\n 'NOGRAD',\n 'PEST',\n 'SOMOGY',\n 'SZABOLCS',\n 'TOLNA',\n 'VAS',\n 'VESZPREM',\n 'ZALA']\n\n\n\nfig,ax = plt.subplots(20,1,figsize=(10,50))\nfor k in range(20):\n    ax[k].plot(f[:,k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:,k],label='predicted (tr)')\n    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html",
    "href": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html",
    "title": "튜토리얼 따라가기2",
    "section": "",
    "text": "Toy Example"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#data",
    "href": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#data",
    "title": "튜토리얼 따라가기2",
    "section": "Data",
    "text": "Data\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=14)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#recurrentgcn",
    "href": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#recurrentgcn",
    "title": "튜토리얼 따라가기2",
    "section": "RecurrentGCN",
    "text": "RecurrentGCN\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n        \n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#learn",
    "href": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#learn",
    "title": "튜토리얼 따라가기2",
    "section": "Learn",
    "text": "Learn\n\n# 오래걸림 주의\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features = 14, filters = 32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat - snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [06:21<00:00,  7.63s/it]"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#예제의-차원-조사",
    "href": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#예제의-차원-조사",
    "title": "튜토리얼 따라가기2",
    "section": "예제의 차원 조사",
    "text": "예제의 차원 조사\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x\n    _edge_index = snapshot.edge_index\n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1068, 14])\n\n\n\n1068: number of nodes # 1068개의 노드가 있음\n14: number of features # 하나의 노드에 맵핑된 차원의 수\n\n\n_edge_index.shape\n\ntorch.Size([2, 27079])\n\n\n\n_edge_attr.shape\n\ntorch.Size([27079])\n\n\n\n_y.shape\n\ntorch.Size([1068])\n\n\n\n1068: number of nodes\n\n\n_x.shape\n\ntorch.Size([1068, 14])"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#우리예제",
    "href": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#우리예제",
    "title": "튜토리얼 따라가기2",
    "section": "우리예제",
    "text": "우리예제\n\nT = 100 \nN = 4 # number of nodes \nE = np.array([[0,1],[1,2],[2,3],[3,0]]).T\nV = np.array([1,2,3,4])\nAMP = np.array([3,2,1,2.2])\nt = np.arange(0,T)\nnode_features = 1 \n\n\nf = np.stack([a*np.sin(2*t**2/1000)+np.random.normal(loc=0,scale=0.2,size=T) for a in AMP],axis=1).reshape(T,N,node_features)\nf = torch.tensor(f).float()\n\n\nf.shape\n\ntorch.Size([100, 4, 1])\n\n\n\nX = f[:99,:,:]\ny = f[1:,:,:]\n\n\nplt.plot(y[:,0,0],label=\"v1\")\nplt.plot(y[:,1,0],label=\"v2\")\nplt.plot(y[:,2,0],label=\"v3\")\nplt.plot(y[:,3,0],label=\"v4\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fdca565c8e0>\n\n\n\n\n\n\nedge_index = torch.tensor(E)\nedge_attr = torch.tensor(np.array([1,1,1,1]),dtype=torch.float32)\n\n\n_ee = enumerate(zip(X,y))\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:15<00:00,  3.22it/s]\n\n\n\nyhat = torch.stack([model(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n\n\nplt.plot(y[:,0,0],label=\"y in V1\")\nplt.plot(yhat[:,0,0],label=\"yhat in V1\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fdc9c7883d0>\n\n\n\n\n\n\nplt.plot(y[:,1,0],label=\"y in V2\")\nplt.plot(yhat[:,1,0],label=\"yhat in V2\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fdc9c764e50>\n\n\n\n\n\n\nplt.plot(y[:,2,0],label=\"y in V3\")\nplt.plot(yhat[:,2,0],label=\"yhat in V3\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fdc9c6bd940>\n\n\n\n\n\n\nplt.plot(y[:,3,0],label=\"y in V4\")\nplt.plot(yhat[:,3,0],label=\"yhat in V4\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fdc9c69e8e0>"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/traffic_prediction.html",
    "href": "posts/STGCN/STGCN 공부/traffic_prediction.html",
    "title": "Traffic Forecasting review",
    "section": "",
    "text": "https://www.youtube.com/watch?v=Rws9mf1aWUs\n\n\n\n\nimport torch\nfrom IPython.display import clear_output\npt_version = torch.__version__\nprint(pt_version)\n\n1.11.0+cu113\n\n\nThis took some time for me, so be patient :)\n\n!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n!pip install torch-geometric\n!pip install torch-geometric-temporal\nclear_output()\n\n\n\n\n\nTraffic forecasting dataset based on Los Angeles Metropolitan traffic\n207 loop detectors on highways\nMarch 2012 - June 2012\nFrom the paper: Diffusion Convolutional Recurrent Neural Network\n\n\nimport numpy as np\nfrom torch_geometric_temporal.dataset import METRLADatasetLoader\nfrom torch_geometric_temporal.signal import StaticGraphTemporalSignal\n\nloader = METRLADatasetLoader()\ndataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n\nprint(\"Dataset type:  \", dataset)\nprint(\"Number of samples / sequences: \",  len(set(dataset)))\n\nDataset type:   <torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal object at 0x7f455e5315d0>\nNumber of samples / sequences:  34249\n\n\n\n\n\n207 nodes\n2 features per node (speed, time)\n12 timesteps per bucket (12 x 5 min = 60 min)\nLabels for 12 future timesteps (normalized speed) –> node regression\nEdge_attr is build based on the distances between sensors + threshold\nFurther details: https://pytorch-geometric-temporal.readthedocs.io/en/latest/_modules/torch_geometric_temporal/dataset/metr_la.html#METRLADatasetLoader\nRaw data: https://graphmining.ai/temporal_datasets/METR-LA.zip\n\n\n# Show first sample\nnext(iter(dataset))\n\nData(x=[207, 2, 12], edge_index=[2, 1722], edge_attr=[1722], y=[207, 12])\n\n\n\n# Important: It is not always like that!\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nd = ChickenpoxDatasetLoader().get_dataset(lags=4)\nnext(iter(d))\n\nData(x=[20, 4], edge_index=[2, 102], edge_attr=[102], y=[20])\n\n\nYou can always have a look at the source-code to see how a dataset is constructed. Chickenpox would be a classical “predict-next-timestep” dataset (the label is one step later than the features).\nMETR-LA would be a sequence-to-sequence prediction dataset that predicts further into the future than just the next timestep. You can also see, that the features are used as label as well.\n# >>> From the ChickenpoxDatasetLoader <<<\nself.features = [\n            stacked_target[i : i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ]\nself.targets = [\n            stacked_target[i + self.lags, :].T  \n            for i in range(stacked_target.shape[0] - self.lags)\n        ]\n\n# >>> From METRLADatasetLoader <<<\nindices = [\n            (i, i + (num_timesteps_in + num_timesteps_out))\n            for i in range(self.X.shape[2] - (num_timesteps_in + num_timesteps_out) + 1)\n        ]\nfor i, j in indices:\n            features.append((self.X[:, :, i : i + num_timesteps_in]).numpy())\n            target.append((self.X[:, 0, i + num_timesteps_in : j]).numpy())\n\nimport seaborn as sns\n# Visualize traffic over time\nsensor_number = 1\nhours = 24\nsensor_labels = [bucket.y[sensor_number][0].item() for bucket in list(dataset)[:hours]]\nsns.lineplot(data=sensor_labels)\n\n<matplotlib.axes._subplots.AxesSubplot at 0x7f455d15d310>\n\n\n\n\n\n\n\n\n\nfrom torch_geometric_temporal.signal import temporal_signal_split\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n\nprint(\"Number of train buckets: \", len(set(train_dataset)))\nprint(\"Number of test buckets: \", len(set(test_dataset)))\n\nNumber of train buckets:  27399\nNumber of test buckets:  6850\n\n\n\n\n\n\nWhich model to choose depends on which time-series task you work on.\n\nA3TGCN is an extension of TGCN that uses attention\nThe spatial aggregation uses GCN, the temporal aggregation a GRU\nWe can pass in periods to get an embedding for several timesteps\nThis embedding can be used to predict several steps into the future = output dimension\nWe could also do this in a loop and feed it again into the model (would be autoregressive)\nThere is only one block here. Other layers also allow stacking???\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import A3TGCN\n\nclass TemporalGNN(torch.nn.Module):\n    def __init__(self, node_features, periods):\n        super(TemporalGNN, self).__init__()\n        # Attention Temporal Graph Convolutional Cell\n        self.tgnn = A3TGCN(in_channels=node_features, \n                           out_channels=32, \n                           periods=periods)\n        # Equals single-shot prediction\n        self.linear = torch.nn.Linear(32, periods)\n\n    def forward(self, x, edge_index):\n        \"\"\"\n        x = Node features for T time steps\n        edge_index = Graph edge indices\n        \"\"\"\n        h = self.tgnn(x, edge_index)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\nTemporalGNN(node_features=2, periods=12)\n\nTemporalGNN(\n  (tgnn): A3TGCN(\n    (_base_tgcn): TGCN(\n      (conv_z): GCNConv(2, 32)\n      (linear_z): Linear(in_features=64, out_features=32, bias=True)\n      (conv_r): GCNConv(2, 32)\n      (linear_r): Linear(in_features=64, out_features=32, bias=True)\n      (conv_h): GCNConv(2, 32)\n      (linear_h): Linear(in_features=64, out_features=32, bias=True)\n    )\n  )\n  (linear): Linear(in_features=32, out_features=12, bias=True)\n)\n\n\n\n\n\n\nTraining on GPU didn’t bring much speed-up\nI ran into RAM issues, why I only train on a smaller subset of the data\n\n\n# GPU support\ndevice = torch.device('cpu') # cuda\nsubset = 2000\n\n# Create model and optimizers\nmodel = TemporalGNN(node_features=2, periods=12).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nprint(\"Running training...\")\nfor epoch in range(10): \n    loss = 0\n    step = 0\n    for snapshot in train_dataset:\n        snapshot = snapshot.to(device)\n        # Get model predictions\n        y_hat = model(snapshot.x, snapshot.edge_index)\n        # Mean squared error\n        loss = loss + torch.mean((y_hat-snapshot.y)**2) \n        step += 1\n        if step > subset:\n          break\n\n    loss = loss / (step + 1)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    print(\"Epoch {} train MSE: {:.4f}\".format(epoch, loss.item()))\n\nRunning training...\n\n\n\n\n\n\nLets get some sample predictions for a specific horizon (e.g. 288/12 = 24 hours)\nThe model always gets one hour and needs to predict the next hour\n\n\nmodel.eval()\nloss = 0\nstep = 0\nhorizon = 288\n\n# Store for analysis\npredictions = []\nlabels = []\n\nfor snapshot in test_dataset:\n    snapshot = snapshot.to(device)\n    # Get predictions\n    y_hat = model(snapshot.x, snapshot.edge_index)\n    # Mean squared error\n    loss = loss + torch.mean((y_hat-snapshot.y)**2)\n    # Store for analysis below\n    labels.append(snapshot.y)\n    predictions.append(y_hat)\n    step += 1\n    if step > horizon:\n          break\n\nloss = loss / (step+1)\nloss = loss.item()\nprint(\"Test MSE: {:.4f}\".format(loss))\n\n\n\n\nThe further away the point in time is, the worse the predictions get\nPredictions shape: [num_data_points, num_sensors, num_timesteps]\n\n\nimport numpy as np\n\nsensor = 123\ntimestep = 11 \npreds = np.asarray([pred[sensor][timestep].detach().cpu().numpy() for pred in predictions])\nlabs  = np.asarray([label[sensor][timestep].cpu().numpy() for label in labels])\nprint(\"Data points:,\", preds.shape)\n\nData points:, (289,)\n\n\n\nimport matplotlib.pyplot as plt \nplt.figure(figsize=(20,5))\nsns.lineplot(data=preds, label=\"pred\")\nsns.lineplot(data=labs, label=\"true\")\n\n<matplotlib.axes._subplots.AxesSubplot at 0x7f7b14858950>"
  },
  {
    "objectID": "posts/GCN/2023-02-21-gcn1.html",
    "href": "posts/GCN/2023-02-21-gcn1.html",
    "title": "Graph Convolutional Network",
    "section": "",
    "text": "GCN의 개념에 대해 학습해보자.\n\n\n\n\n\nMany important real-world datasets come in the form of graphs or networks: social networks, knowledge graphs, protein-interaction networks, the World Wide Web, etc. (just to name a few).\n\n대부분의 머신러닝 알고리즘은 입력 데이터가 유클리디안 공간 (Euclidean space)에 존재함을 가정하고 있다. 즉, 통계 데이터나 이미지처럼 입력 데이터가 벡터의 형태로 표현될 수 있어야 한다. 그러나 소셜 네트워크, 관계형 데이터베이스, 분자 구조 등과 같이 객체들과 그 객체들 간의 관계로 표현되는 데이터는 기본적으로 위와 같은 그래프로 표현된다.\n또한, 만약 사용자나 원자의 속성, 연결의 종류 등을 고려해야하는 경우에는 단순히 node와 edge로 이루어진 그래프가 아니라, node feature matrix와 edge feature matrix가 추가된 속성 그래프 (attributed graph)로 데이터를 표현해야 한다. 이러한 형태의 그래프 데이터는 유클리드 공간에 존재하지 않으며, 직접적인 방식으로 벡터의 형태로 변환하는 것 또한 불가능하다. 따라서, 벡터 형태의 입력 데이터를 가정하는 기존의 인공신경망 (Artificial Neural Network, ANN)으로는 분자 구조와 같은 그래프 형태의 데이터를 처리할 수 없다는 문제점이 존재한다.\n(+) 행동 인식 분야에서 가장 핫하게 등장하는 네트워크가 바로 GCN(Graph Convolutional Networks)이다. GCN은 쉽게 설명하자면, 어떤 그래프 구조를 이미지 convolution과 유사한 방식으로 연산해서 특징점을 추출하는 네트워크라고 보면 될 것 같다. 사람의 몸도 어떻게 보면 각 관절과 그 관절들이 연결되어있는 구조로 그래프 구조라고 볼 수 있다. 그렇기 때문에 GCN을 사용한 논문들에서도 좋은 성능을 보이고 있다.\n\nref: (AAAI-2018) Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition\n\n\n\n\n\n\nGraph는 vertex(node)와 edge로 이루어져있다. 이 때 node는 한 input data를 의미하고 edge는 두 데이터 간의 relationship을 의미한다. (어차피 같은 의미이지만 앞으로는 vertex 대신 node라는 표현을 많이 사용할 것이다.)\n\n소셜 그래프에서 node는 사람, edge는 두 사람 사이의 관계를 의미한다.\nWeighted Grapgh vs. Unweighted Graph\nDirected Graph vs. Undirected Graph\n(참고) 위의 그래프의 경우 방향성이 존재하지 않는 undirected Graph이다.\n\n\n\n\n모든 노드간의 relationship 정보를 담고있도록 data를 표현해야하므로 이 정보들은 1. Adgacency matrix로 나타낼 수 있다. 또한 노드간의 relationship정보 말고도 node 자체가 가지고 있는 feature 정보가 있으므로 이는 2. Feature matrix로 나타낸다.\n\n1 Network(Graph data) \\(\\to\\) Adjacency matrix\n\n\\(n\\) 개의 노드가 있다면 Adjacency matrix는 \\(n\\times n\\) 크기를 갖게 된다.\n\n5개의 노드가 있으므로 \\(5\\times 5\\) Adjacency matrix\n\n\\(\\bf{A}_{ij}\\) : Adjacency matrix의 \\(i\\)번째 row와 \\(j\\)번째 컬럼에 있는 값을 나타내며, \\(i\\)번째 노드와 \\(j\\)번째 노드가 서로 연결이 되어 있는지를 나타낸다.\n\n노드 사이에 엣지가 있는지? (있으면 \\(1\\), 없으면 \\(0\\))\n\n\n2 Feature matrix\n\nFeature matirx로 각 노드의 정보를 나타낸다.\n\nFeature matrix의 크기는 \\(n(\\text{노드의 수}) \\times f(\\text{feature 개수})\\) 이며, \\(f\\)는 설정함에 따라서 많아질 수도 있고 적어질 수도 있는 값이다.\nfeature matrix를 \\(\\bf{X}\\) 라고 하자, 이 때 \\(\\bf{X}_{ij}\\) 가 의미하는 것은 i번째 노드에 j번째 feature가 무엇인지 나타내는 것이다.\n\n\n\n\n\n\n\n데이터의 구조를 고려해야 한다는 점은 이미지뿐만 아니라 그래프 데이터에서도 매우 중요하기 때문에 이미지에 대한 convolution을 일반화하여 그래프 데이터에 적용하기 위한 연구가 머신러닝 분야에서 활발히 진행되었다. 그래프 합성곱 신경망 (Graph Convolutional Network, GCN)은 이미지에 대한 convolution을 그래프 데이터로 확장한 머신러닝 알고리즘이다.\n이부분에 대해 이해를 하려면 먼저 CNN에 이해가 필요할 것 같다.\n\n\n\n\n\nStanford, cs231n 2017\n\n\n\n\n\nReduce the number of parameters \\(\\to\\) less overfitting, low computational cost\nLearn local features\nTranslation invariance\n\n\n\n\n\n어쨌든 얘도 convolutional network니까 CNN을 보고 이것을 이미지가 아닌 그래프에 적용시켜본다면 구조를 어떻게 바꿔야 할지지 생각해보자.\n\nCNN updates values in activation map in each layer. Values of activation map determine the state of image.\nValues of each node feature determine the state of graph. \\(\\to\\) Make each layer of network update values of each node feature\n\n그래프의 정보를 결정하는 것은 무엇일까? 이미지는 activation map에 있는 value들이 그 이미지에 담긴 상태가 뭔지, 이미지에 담긴 정보가 뭔지를 결정을 하는 값들이었는데 그래프 같은 경우에는 각 노드에 담긴 value 즉, node feature matrix 안에 담긴 정보가 업데이트 되도록 하면 되겠다.\n결국 중요한 것은 Graph Convolutional Layer를 거치게 되면 노드 피처에 담긴 값이 업데이트가 되어야 한다는 것을 convolutional network를 통해 알 수 있었다.\n그렇다면 어떤 방식으로 업데이트를 해야 타당할까?\n어쨌든 이것도 컨볼루션이니까 컨볼루션은 어떤 작은 웨이트를 쭉 이동시키는 연산이었는데 중요한 특성은 Weight sharing을 한다는 것이었고, 어떤 로컬한 이 값 근처에 있는 값들만 weight에 들어가서 로컬한 피처를 배운다는 것이 또 하나의 특징이었다. 그래서 그 뉴런이 receptive field를 갖게 된다. (어떤 전체의 데이터에 정보를 하나의 뉴런이 다 받는게 아니라 어떤 로컬한 부분에 있는 정보를 이제 뉴런이 받게 되고 이를 receptive field 라고 한다.)\n그런 특성을 그럼 그래프에는 어떻게 적용시켜야 될까? 노드의 피처를 계쏙 업데이트 한다는 것은 각 노드의 정보를 업데이트 하는 것 그래서 노드 피처 매트릭스를 다시 그려보면 \\(n\\)개의 노드가 있는 그래프일 때 \\(n\\times f\\text{(feature 개수)}\\)의 shape을 갖고 이 matrix의 i번째 row가 의미하는 것은 i번째 노드의 피처/상태/정보를 담고있다고 앞에서 배웠다.\n아까 말했듯이 layer를 하나 거쳐서 이 node feature matrix를 업데이트 한다는 것은 이 각각의 row를 즉, 각각의 노드의 정보를 업데이트 해주면 될 것 같다.\n그럼 어떤 방식으로 업데이트를 할 거냐? convolution network 같이 그 주변에 있는 애들의 정보만 받아서 업데이트를 하자 이런식으로 생각해 볼 수 있을 것 같다.\n\n\n\n\n\n\nimage.png\n\n\n\\[H_1^{(l+1)} = \\sigma(H_1^{(l)}W^{(l)} + H_2^{(l)}W^{(l)} + H_3^{(l)}W^{(l)} + H_4^{(l)}W^{(l)} + b^{(l)})\\]\n\\[\\Rightarrow H_i^{(l+1)} = \\sigma\\Big(\\sum_{j\\in N(i)} H_j^{(l)}W^{(l)} + b^{(l)} \\Big)\\]\n\\[W: \\text{weight},\\quad W^{(l)}: l\\text{번째 layer의 weight},\\quad H:\\text{hidden state}, \\quad \\sigma: \\text{activation function}\\]\n(참고) 여기서는 node feature matrix를 hidden state라고 부를 것임\n위의 그림과 같은 그래프가 있다고 가정해보자. 그래프의 번호가 1번, 2번, 3번, 4번 이런식으로 붙여졌다고 할 때 \\(H_1^{(l+1)}\\), 즉 하나의 \\((l+1)\\)번 째 layer를 통과하게 되면 \\(H_1\\)의 정보는 자기 자신의 웨이트를 더하고, 그 다음에 연결되어 있는 \\(H_2\\)의 hidden state에 weight를 곱하고, \\(H_3\\)의 hidden state에 weight를 곱하고 \\(H_4\\)의 hidden state에 weight를 곱하고 bias를 더해서 activation을 거쳐서 다음 layer의 값을 업데이트 하면 되겠다.\n이렇게 되면 이제 convolutional layer처럼 어떤 local한 feature를 뽑아낼 수 있고, 그럼 이 다음 노드가 받은 것은 1번, 2번, 3번, 4번 노드의 정보만 받아서 다음 뉴런에 전달을 해주는 것이고, 연결되지 않은 5번, 6번, 7번에 대해서는 들어가지 않았으니까 1번 노드의 정보는 1번 노드의 근처에 있는 로컬한 정보를 뽑아냈다라고 볼 수 있다.\n또한 이 weight가 다 똑같기 때문에 weight sharing을 한다. 즉, 전체가 다 연결되어 있는게 아니라 어쨌든 얘도 어떤 노드의 정보는 그 구조가 다 비슷할 것이다. 왜냐하면 처음에 같은 이 feature의 순서가 똑같았으니까 거기에 어차피 얘들도 다 비슷한 애들이니까 같은 weight를 곱해서 general한 정보를 뽑아낼 수 있게 마치 LSTM에서 각각의 워드에 다 똑같은 weight를 곱해줬던 것 처럼(왜냐하면 이 word는 다 비슷한 특성을 가지고 있기 때문에) 얘들도 각각의 노드에 피처가 비슷한 성격을 띄고 있을 거니까 같은 weight를 sharing해서 곱해줘서 computational cost도 낮추고 efficiency도 높일 수 있겠다.\n그래서 이런식으로 업데이트 하면 아까 convolutional layer의 두 가지 특성이였던 weight sharing과 local feature를 뽑아낸다는 것 둘 다 가지고 있게 됐다.\n실질적으로 구현할 때 1번 노드에 연결되었는지 다 보고, 1번노드와 연결되어 있는 애들을 weight 타고 다 더한다음에 2번노드로 가서 2번노드에 뭐가 연결되어있는지 다 보고, 그 다음에 종합해서 업데이트 하고, 3번노드 뭐랑 연결되어있는지 다 보고,,이렇게 할 수는 없겠죠.(for문을 엄청나게 많이 사용해서 속도가 느려질 것이다.)\n그러면 우리가 graph structure를 adjacency matrix로 나타내는데 그럼 이 adjacency matrix가 결국은 connectivity를 담고있는 매트릭스이다. 그럼 이것을 어떻게 잘 활용하면 한번에 행렬연산으로 할 수 있을 것 같다. (행렬 연산은 gpu가 빠르게 잘함)\n- 예제\n자기자신과 연결되어있다고 가정, feature의 개수도 임의로 10으로 지정\n보기 쉽게 node feature matrix를 H라고 놓자. (오른쪽 matrix가 H임)\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n그 새로운 값은 각각의 노드의 근처에 있는 값들만 받아들여서 convolution 연산을 한 효과를 냈고, 그리고 그 weight들은 다 똑같다. 그 weight를 곱할때 filter마다는 다르지만 동인한 하나의 필터 내에서는 같은 weight들이 서로 다른 노드에 곱해진다.\n그래서 이런식으로 하면 weight sharing을 하고, local feature를 뽑아내는 convolutional layer의 특성을 가지면서도 for문을 돌고 하는게 아니라 행렬연산을 통해 이것을 구현 함으로써 GPU에 넣었을 때 훨씬 빠르고 gradient 계산하는 것도 병렬화되서 훨씬 빠르게 할 수 있기 떄문에 이렇게 구현하면 쓸 수 있겠다고 생각해볼 수 있다.\n타당한 structure인 것 같다.\n\\[H^{(l+1)} = \\sigma(AH^{(l)}W^{(l)}+b^{(l)})\\]\n다음 layer의 hidden state는 이전 layer의 hidden stat에 weight를 곱하고 여기에 adjacency matrix를 곱하면 그 connectivity에 들어가는 정보가 들어가서 각각의 노드가 연결되어 있는 애들의 정보만 받게되고, 이것도 어쨌든 컨볼루션을 했으니까 activation을 씌워주면 update된 값을 얻을 수 있다.\n\n\n\n\nPermutation invariance는 adjency matrix의 순서가 바뀌더라도 그 output이 변하지 않는 함수의 특성을 말한다.\n\n\\[f(PAP^{T}) = f(A)\\]\n(참고) 위 식에서 \\(\\bf{A}\\)는 adjacency matrix, \\(\\bf{P}\\)는 행과 열의 순서를 바꾸는 permutation matrix이다. 위 식은 위에서 설명한 것처럼 adjacency matrix 내의 노드의 순서가 바뀌어도 함수의 결과는 바뀌지 않는다.\n\n\n\nimage.png\n\n\n그래프를 adjacency matrix와 node feature matrix로 표현을 했는데 node feature matrix에 순서가 있다. 노드의 순서가 바뀐다고 해서 그래프가 달라지지는 않는다. 노드의 배치만 바뀌었을 뿐 노드의 특성과 엣지는 다 똑같이 연결되어 있으니까 같은 그래프이다.그런데 우리가 표현하는 node feature matrix는 바뀌게 될것이다. (row의 순서가 뒤죽박죽..)근데 결국 얘네들은 같은 그래프이니까 feature를 뽑아낼 때 같은 값이 나와야 된다. (순서가 다르게되어 있다고 다른값이 나오면 안되겠죠) 따라서 이걸 하기 위해서 Readout layer를 거치게 된다.\n이 Readout layer의 역할은 permutation invariance를 준다. 즉, permutation이 어떻게 되어있든 관계없이 invariance하게 하는 역할을 수행해준다. 다양한 방법이 있지만 가장 간단한 방법은 위와 같다.\n\n\n\n\n\n\n\nimage.png\n\n\nGCN을 거친 후 마지막에 Readout layer를 통해 최종적으로 classification 혹은 value를 regression한다. CNN에서 Conv-pool layer들을 거친 후 마지막에 모든 node들 정보를 취합하기 위해 FC-layer를 거친 후 softmax를 통해 classification작업을 수행한다.\n마찬가지로 Graph Neural Network에서도 graph convolution layer들을 거친 후 MLP로 모든 node 정보를 취합하고 최종적으로 regression 혹은 classification을 위해 어떤 값을 결정짓는 작업이 필요하다. 이를 GCN에서 readout-layer라고 한다\n\n\n\nimage.png\n\n\n\n\n\nGCN을 비롯한 graph neural network (GNN)을 직접 구현하는 것은 인접 행렬과 node feature matrix를 추출하는 것부터 여러 그래프의 batch를 만드는 것 까지 많은 어려움이 따른다. PyTorch를 기준으로는 Deep Graph Library (DGL)와 PyTorch Geometric이라는 라이브러리가 GNN과 이를 이용한 딥 러닝에 관한 여러 구현을 제공하고 있다.\n\n\n\n\nhttps://tkipf.github.io/graph-convolutional-networks/\nhttps://untitledtblog.tistory.com/152"
  },
  {
    "objectID": "posts/GCN/2023-02-27-gcn-prac.html",
    "href": "posts/GCN/2023-02-27-gcn-prac.html",
    "title": "GCN Implementation",
    "section": "",
    "text": "cora dataset\n\n\nimport torch_geometric\n\n\nfrom typing import Callable, List, Optional, Tuple\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport torch_geometric.transforms as T\nfrom torch import Tensor\nfrom torch.optim import Optimizer\nfrom torch_geometric.data import Data\nfrom torch_geometric.datasets import Planetoid\nfrom torch_geometric.nn import GCNConv\n# from torch_geometric.utils import accuracy\nfrom typing_extensions import Literal, TypedDict\n\nThe Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words.\n\ndataset = Planetoid('./cora', name='Cora')\n\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\nProcessing...\nDone!\n\n\n\nnum_nodes = dataset.data.num_nodes\nnum_edges = dataset.data.num_edges // 2\ntrain_len = dataset[0].train_mask.sum()\nval_len = dataset[0].val_mask.sum()\ntest_len = dataset[0].test_mask.sum()\nother_len = num_nodes - train_len - val_len - test_len\nprint(f'Dataset: {dataset.name}')\nprint(f'Num. nodes: {num_nodes}(train={train_len},val={val_len}, test={test_len}, other={other_len})')\nprint(f'Num. edges: {num_edges}')\nprint(f'Num. node features: {dataset.num_node_features}')\nprint(f'Num. classes: {dataset.num_classes}')\nprint(f'Dataaset len.: {dataset.len()}')\n\nDataset: Cora\nNum. nodes: 2708(train=140,val=500, test=1000, other=1068)\nNum. edges: 5278\nNum. node features: 1433\nNum. classes: 7\nDataaset len.: 1\n\n\n\nclass GCN(torch.nn.Module):\n    def __init__(\n        self,\n        num_node_features: int,\n        num_classes: int,\n        hidden_dim: int = 16,\n        dropout_rate: float = 0.5,\n    ) -> None:\n        super().__init__()\n        self.dropout1 = torch.nn.Dropout(dropout_rate)\n        self.conv1 = GCNConv(num_node_features, hidden_dim)\n        self.relu = torch.nn.ReLU(inplace=True)\n        self.dropout2 = torch.nn.Dropout(dropout_rate)\n        self.conv2 = GCNConv(hidden_dim, num_classes)\n        \n    def forward(self, x: Tensor, edge_index: Tensor) -> torch.Tensor:\n        x = self.dropout1(x)\n        x = self.conv1(x, edge_index)\n        x = self.relu(x)\n        x = self.dropout2(x)\n        x = self.conv2(x, edge_index)\n        return x\n\n\nGCN(dataset.num_node_features, dataset.num_classes, 16, 0.5)\n\nGCN(\n  (dropout1): Dropout(p=0.5, inplace=False)\n  (conv1): GCNConv(1433, 16)\n  (relu): ReLU(inplace=True)\n  (dropout2): Dropout(p=0.5, inplace=False)\n  (conv2): GCNConv(16, 7)\n)\n\n\n\ndataset = Planetoid('./cora', name='Cora')\nprint(f'Sum of row values without normalization: {dataset[0].x.sum(dim=-1)}')\n\ndataset = Planetoid('./cora', name='Cora', transform=T.NormalizeFeatures())\nprint(f'Sum of row values with normalization: {dataset[0].x.sum(dim=-1)}')\n\nSum of row values without normalization: tensor([ 9., 23., 19.,  ..., 18., 14., 13.])\nSum of row values with normalization: tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000])\n\n\n\n\n\nLossFn = Callable[[Tensor, Tensor], Tensor]\nStage  = Literal['train','val','test']\n\ndef train_step(\n    model: torch.nn.Module, date: Data, optimizer: torch.optim.Optimizer, loss_fn:LossFn\n) -> Tuple[float, float]:\n    model.train()\n    optimizer.zero_grad()\n    mask = data.train_mask\n    logits = model(data.x, data.edge_index)[mask]\n    preds = logits.argmax(dim=1)\n    y = data.y[mask]\n    loss = loss_fn(logits, y)\n    # L2 regularization to the first layer only\n    \n    acc = accuracy(preds, y)\n    loss.backward()\n    optimizer.step()\n    return loss.item(), acc\n\n@torch.no_grad()\ndef eval_step(model: torch.nn.Module, data: Data, loss_fn:LossFn, stage: Stage) -> Tuple[float,float]:\n    model.eval()\n    mask = getattr(data, f'{stage}_mask')\n    logits = model(data.x, data.edge_index)[mask]\n    preds = logits.argmax(dim=1)\n    y = data.y[mask]\n    loss = loss_fn(logits, y)\n    \n    acc = accuracy(preds, y)\n    return loss.item(), acc\n\n\nclass HistoryDict(TypedDict):\n    loss: List[float]\n    acc: List[float]\n    val_loss: List[float]\n    val_acc: List[float]\n    \ndef train(\n    model: torch.nn.Module,\n    date: Data,\n    optimizer: torch.optim.Optimizer,\n    loss_fn: LossFn = torch.nn.CrossEntropyLoss(),\n    max_epochs: int=200,\n    early_stopping: int=10,\n    print_interval: int=20,\n    verbose: bool=True,\n) -> HistoryDict:\n    history = {'loss':[], 'val_loss':[], 'acc_loss':[], 'val_acc':[]}\n    for epoch in range(max_epochs):\n        loss, acc = train_step(model, data, optimizer, loss_fn)\n        val_loss, val_acc = eval_step(model, data, loss_fn, 'val')\n        history['loss'].append(loss)\n        history['acc'].append(acc)\n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        \n        if epoch > early_stopping and val_loss > np.mean(history['val_loss'][-(early_stopping + 1):-1]):\n            if verbose:\n                print('\\nEarly stopping...')\n            break\n            \n        if verbose and epoch % print_interval == 0:\n            print(f'nEpoch: {epoch}\\n--------------')\n            print(f'Train loss: {loss:.4f} | Train acc: {acc:.4f}')\n            print(f' Val loss: {loss:.4f} | Val acc: {val_acc:.4f}')\n    \n    test_loss, test_acc = eval_step(model, data, loss_fn, 'test')\n    if verbose:\n        print(f'nEpoch: {epoch}\\n--------------')\n        print(f'Train loss: {loss:.4f} | Train acc: {acc:.4f}')\n        print(f' Val loss: {loss:.4f} | Val acc: {val_acc:.4f}')\n    return history\n        \n\n\nSEED = 42\nMAX_EPOCHS = 200\nLEARNING_RATE = 0.01\nWEIGHT_DECAY = 5e-4\nEARLY_STOPPING = 10\n\n\ntorch.manual_seed(SEED)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = GCN(dataset.num_node_features, dataset.num_classes).to(device)\ndata = dataset[0].to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\nhistory = train(model, data, optimizer, max_epochs=MAX_EPOCHS, early_stopping=EARLY_STOPPING)\n\nIndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)\n\n\n\n뭐가 문제지? ㅠㅠㅠ"
  },
  {
    "objectID": "posts/study/2023-02-25-chap12.2.html",
    "href": "posts/study/2023-02-25-chap12.2.html",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "",
    "text": "using LinearAlgebra, DSP"
  },
  {
    "objectID": "posts/study/2023-02-25-chap12.2.html#simultaneously-diagonalizable",
    "href": "posts/study/2023-02-25-chap12.2.html#simultaneously-diagonalizable",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "Simultaneously Diagonalizable",
    "text": "Simultaneously Diagonalizable\n매트릭스 \\(\\bf{A}\\)와 \\(\\bf{B}\\)가 대각화 가능하다는 것은 아래의 표현을 만족한 적당한 invertible matrix와 \\({\\bf \\Psi}_A,{\\bf \\Psi}_B\\)와 대각행렬 \\({\\bf \\Lambda}_A,{\\bf \\Lambda}_B\\)가 존재한다는 의미가 된다.\n\\[{\\bf A} = {\\bf V}_{A} {\\bf \\Lambda}_A {\\bf V}_{A}^{-1}\\]\n\\[{\\bf B} = {\\bf V}_{B} {\\bf \\Lambda}_B {\\bf V}_{B}^{-1}\\]\n그리고 만약에 \\({\\bf V}_{A}={\\bf V}_{B}\\)이라면 즉,\n\\[{\\bf A} = {\\bf V} {\\bf \\Lambda}_A {\\bf V}^{-1}\\]\n\\[{\\bf B} = {\\bf V} {\\bf \\Lambda}_B {\\bf V}^{-1}\\]\n이라면 \\(\\{{\\bf A},{\\bf B}\\}\\)가 simultaneosuly diagonalizable 하다고 표현한다."
  },
  {
    "objectID": "posts/study/2023-02-25-chap12.2.html#commute",
    "href": "posts/study/2023-02-25-chap12.2.html#commute",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "Commute",
    "text": "Commute\n두 matrix \\(\\bf{A}\\) 와 \\(\\bf{B}\\)에 대하여\n\\[{\\bf A}{\\bf B}= {\\bf B}{\\bf A}\\]\n인 관계가 성립하면 두 매트릭스가 commute한다고 표현한다. 그런데 \\({\\bf A}{\\bf B}= {\\bf B}{\\bf A}\\)의 조건은 \\(\\bf{A}, \\bf{B}\\)가 동시대각화가능할(simultaneously diagonalizable) 조건과 같다. 따라서 simultaneously diagonalizable는 commute와 같은 말이라 생각해도 무방하다."
  },
  {
    "objectID": "posts/study/2023-02-25-chap12.2.html#shift-invariant-filter",
    "href": "posts/study/2023-02-25-chap12.2.html#shift-invariant-filter",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "Shift Invariant Filter",
    "text": "Shift Invariant Filter\nDefine the matrix \\({\\bf B}\\) as periodic shift matrix such that\n\\[\n{\\bf B} = \\begin{bmatrix}\n0 & 0 & 0 & \\dots  & 0 & 1 \\\\\n1 & 0 & 0 & \\dots & 0 & 0 \\\\\n0 & 1 & 0 & \\dots & 0 & 0 \\\\\n\\dots & \\dots & \\dots & \\dots & \\dots & \\dots\\\\\n0 & 0 & \\dots & 1 & 0 & 0 \\\\\n0 & 0 & \\dots & 0 & 1 & 0 \\\\\n\\end{bmatrix}.\\]\nA generic filter \\({\\boldsymbol h}\\) is given by its \\(z\\)-transform\n\\[h(z)=h_0z^0+h_1z^{-1}+\\cdots +h_{N-1}z^{-(N-1)}\\]\nwhere \\(s_{n-1}=z^{-1}s_n\\). In vector notation, and with respect to the standard basis \\({\\bf I}\\), the filter is represented by the matrix \\({\\bf H}\\), a polynomial in the cyclic shift\n\\[{\\bf H}=h({\\bf B})=h_0{\\bf B}^0+h_1{\\bf B}^1+\\cdots+h_{N-1}{\\bf B}^{N-1}.\\]"
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "",
    "text": "using LinearAlgebra, FFTW\n\nSyntaxError: invalid syntax (<ipython-input-9-0c475c9575f9>, line 1)"
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html#cyclic-shfit-operator-bf-b",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html#cyclic-shfit-operator-bf-b",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Cyclic shfit operator \\({\\bf B}\\)",
    "text": "Cyclic shfit operator \\({\\bf B}\\)\nThe matrix \\({\\bf B}\\) representing the periodic shift is\n\nB= [0 0 0 0 1\n    1 0 0 0 0 \n    0 1 0 0 0\n    0 0 1 0 0\n    0 0 0 1 0]\n\nSyntaxError: invalid syntax (<ipython-input-8-08cf3960a9a9>, line 1)\n\n\nThis matrix is the cyclic shift.\nnote: \\({\\bf B}\\) is orthogonal matrix.\n\nB'B\n\n5×5 Matrix{Int64}:\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n 0  0  0  0  1\n\n\n(ex1) Define \\({\\bf s}\\) as\n\ns = [1,2,3,4,5]\ns\n\n5-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n\n\nObserve that\n\nB*s\n\n5-element Vector{Int64}:\n 5\n 1\n 2\n 3\n 4\n\n\n\nB^2*s\n\n5-element Vector{Int64}:\n 4\n 5\n 1\n 2\n 3\n\n\n\nB^3*s\n\n5-element Vector{Int64}:\n 3\n 4\n 5\n 1\n 2\n\n\nThus we can interprete the matrix \\({\\bf B}\\) as cyclic shift operator such that\n\\[\n{\\bf B}s_n =s_{n-1}\n\\]\nfor \\(n=1,\\dots, N-1\\) and \\({\\bf B}s_0 =s_N\\).\nnote: \\({\\bf B}\\)는 시계열에서 다루는 backshift operator 와 비슷함."
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html#dft",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html#dft",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "DFT",
    "text": "DFT\nThe matrix \\({\\bf B}\\) can be expressed as\n\\({\\bf B}={\\bf DFT}^\\ast \\cdot {\\bf \\Lambda} \\cdot {\\bf DFT}\\)\nwhere \\({\\bf DFT}\\) is unitary and symmetric matrix and \\(\\bf \\Lambda\\) is diagonal matrix.\n\nλ, Ψ = eigen(B)\n\nEigen{ComplexF64, ComplexF64, Matrix{ComplexF64}, Vector{ComplexF64}}\nvalues:\n5-element Vector{ComplexF64}:\n -0.8090169943749472 - 0.5877852522924725im\n -0.8090169943749472 + 0.5877852522924725im\n 0.30901699437494734 - 0.9510565162951536im\n 0.30901699437494734 + 0.9510565162951536im\n  0.9999999999999998 + 0.0im\nvectors:\n5×5 Matrix{ComplexF64}:\n  0.138197+0.425325im   0.138197-0.425325im  …  0.447214+0.0im\n -0.361803-0.262866im  -0.361803+0.262866im     0.447214+0.0im\n  0.447214-0.0im        0.447214+0.0im          0.447214+0.0im\n -0.361803+0.262866im  -0.361803-0.262866im     0.447214+0.0im\n  0.138197-0.425325im   0.138197+0.425325im     0.447214+0.0im\n\n\n\nB ≈ Ψ * Diagonal(λ) * Ψ'\n\ntrue\n\n\nDefine \\({\\boldsymbol \\Psi}^\\ast={\\bf DFT}\\).\n\nDFT = Ψ'\n\n5×5 adjoint(::Matrix{ComplexF64}) with eltype ComplexF64:\n  0.138197-0.425325im  -0.361803+0.262866im  …  0.138197+0.425325im\n  0.138197+0.425325im  -0.361803-0.262866im     0.138197-0.425325im\n -0.361803-0.262866im  -0.361803+0.262866im     0.138197-0.425325im\n -0.361803+0.262866im  -0.361803-0.262866im     0.138197+0.425325im\n  0.447214-0.0im        0.447214-0.0im          0.447214-0.0im\n\n\nNote that the eigenvalues are not ordered in julia.\n\nλ[5], exp(-im* 2π/5 * 0)\n\n(0.9999999999999998 + 0.0im, 1.0 - 0.0im)\n\n\n\nλ[3], exp(-im* 2π/5 * 1)\n\n(0.30901699437494734 - 0.9510565162951536im, 0.30901699437494745 - 0.9510565162951535im)\n\n\n\nλ[1], exp(-im* 2π/5 * 2)\n\n(-0.8090169943749472 - 0.5877852522924725im, -0.8090169943749473 - 0.5877852522924732im)\n\n\n\nλ[2], exp(-im* 2π/5 * 3)\n\n(-0.8090169943749472 + 0.5877852522924725im, -0.8090169943749475 + 0.587785252292473im)"
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html#spectral-components-and-frequencies",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html#spectral-components-and-frequencies",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Spectral components and Frequencies",
    "text": "Spectral components and Frequencies\nWe remark:\n(1) Spectral components: For \\(k = 0,1,2,\\dots, N-1\\), the \\(k\\)-th column of \\({\\bf DFT}^\\ast\\) is defined by\n\\[\\Psi_k:=\\frac{1}{\\sqrt{N}}\\begin{bmatrix} 1 \\\\ e^{j\\frac{2\\pi}{N}k} \\\\ e^{j\\frac{2\\pi}{N}2k} \\\\ e^{j\\frac{2\\pi}{N}3k} \\\\  \\dots \\\\ e^{j\\frac{2\\pi}{N}(N-1)k} \\end{bmatrix}.\\]\nNote that \\(\\Psi_k\\) can be also interpreted as \\(\\ell\\)-th eigenvector of \\({\\bf A}\\) correspoding \\(\\lambda_\\ell = e^{-j\\frac{2\\pi}{N}k}\\). Those eigenvectors\n\\[\\big\\{{\\bf 1},\\Psi_1,\\Psi_2, \\dots, \\Psi_{N-1}\\big\\}\\]\nform a complete orthonomal basis of \\(\\mathbb{C}^N\\). These vectors are called spectral components.\n(2) Frequencies: The diagonal entries of \\({\\bf \\Lambda}\\) are the eigenvalues of the time shift \\({\\bf B}\\). In Physics and in operator theory, these eigenvalues are the frequencies of the signal. In DSP it is more common to call frequencies\n\\[\\Omega_k=\\frac{-1}{2\\pi j}\\ln\\lambda_k=\\frac{-1}{2\\pi j}\\ln e^{-j \\frac{2\\pi}{N}k}=\\frac{k}{N}, \\quad k=0,1,2,\\dots,N-1.\\]\n\nThe \\(N\\) (time) frequencies \\(\\Omega_k\\) are all distinct, positive, equally spaced, and increasing from \\(0\\) to \\(\\frac{N-1}{N}\\). The spectral components are the complex exponential sinusiodal functions. For example, corresponding to the zero frequency is the DC spectral component (a vector whose entries are constant and all equal to \\(\\frac{1}{\\sqrt{N}}\\))."
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html#dft-1",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html#dft-1",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "DFT",
    "text": "DFT\n일반적으로 우리가 알고있는 DFT1는 아래와 같다. (이 그림은 위키피디아에서 캡쳐한 것이다)\n\n즉 DFT는 임의의 신호 \\(\\{{\\bf x}_n\\}:=x_0,x_1,\\dots,x_{N-1}\\)를 적당한 규칙2에 따라서 \\(\\{{\\bf X}_k\\}:=X_0,X_1,\\dots,X_{N-1}\\)로 바꾸는 변환을 이라고 이해할 수 있다. 이때 사용되는 적당한 규칙은 구체적으로 아래의 수식을 의미한다.\n\\[X_k = \\sum_{n=0}^{N-1}x_n\\cdot e^{-i\\frac{2\\pi}{N}kn}\\]\n그런데 매트릭스를 활용하면 위의 수식을 아래와 같이 표현할 수 있다.\n\\[\\begin{bmatrix} X_1 \\\\ X_2 \\\\ X_3 \\\\ \\dots \\\\ X_{N-1} \\end{bmatrix}\n=\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n\\end{bmatrix}\n\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ \\dots \\\\ x_{N-1} \\end{bmatrix}\\]\n편의상 \\({\\bf X}\\)와 \\({\\bf x}\\)를 \\(N \\times 1\\) col-vec이라고 생각하고 DFT를 아래와 같은 matrix로 정의하자.\n\\[{\\bf DFT} = \\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n그러면\n\\[{\\bf X} = {\\bf DFT} \\cdot {\\bf x}\\]\n와 같이 표현할 수 있고 \\({\\bf x}\\)에서 \\({\\bf X}\\)로 바꾸는 과정을 단순히 \\({\\bf DFT}\\)행렬을 \\({\\bf x}\\)의 왼쪽에 곱하는 과정으로 이해할 수 있다.\n(참고) 사실 아래와 같이 \\({\\bf DFT}\\)를 정의하는 버전도 있다. (둘이 혼용해서 쓰인다)\n\\[{\\bf DFT} = \\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n\n예제1 아래는 위키에서 긁어온 예제이다. 이 예제를 따라가보자.\n\n\n\n그림2: 위키에서 긁어온 예제이미지\n\n\n예제를 풀기위해서 우선 아래와 같은 벡터를 선언하다.\n\nx = [1, 2-im, -im, -1+2im]\n\n4-element Vector{Complex{Int64}}:\n  1 + 0im\n  2 - 1im\n  0 - 1im\n -1 + 2im\n\n\n(풀이1)\n\\(4\\times 4\\)의 크기를 가지는 DFT행렬을 선언한다.\n(step1) 아래의 매트릭스 생성\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\n_DFT\n\n4×4 Matrix{Int64}:\n 0  0  0  0\n 0  1  2  3\n 0  2  4  6\n 0  3  6  9\n\n\n(step2) _DFT의 각 원소에 함수 \\(f: x \\to \\exp(-i\\frac{2\\pi}{4}x)\\)를 취함\n\nf = x -> exp(-im * (2π/4) * x)\nDFT = _DFT .|> f\n\n4×4 Matrix{ComplexF64}:\n 1.0-0.0im           1.0-0.0im          …           1.0-0.0im\n 1.0-0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0-0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0-0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n\n\n이제 \\({\\bf X}\\)를 구하면 아래와 같다.\n\nDFT * x\n\n4-element Vector{ComplexF64}:\n                   2.0 + 0.0im\n   -1.9999999999999998 - 2.0000000000000004im\n 8.881784197001252e-16 - 1.9999999999999998im\n    3.9999999999999987 + 4.000000000000001im\n\n\n위키의 답이 잘 나옴\n(풀이2)\n참고로 아래와 같이 패키지를 이용하여 구할 수도 있다.\n\nfft(x)\n\n4-element Vector{ComplexF64}:\n  2.0 + 0.0im\n -2.0 - 2.0im\n  0.0 - 2.0im\n  4.0 + 4.0im"
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html#inverse-dft",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html#inverse-dft",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Inverse DFT",
    "text": "Inverse DFT\n앞으로는 \\({\\bf DFT}\\)를 아래와 같이 정의하자.\n\\[{\\bf DFT} = \\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n\\({\\bf DFT}\\)행렬에는 몇 가지 특징이 있다.\n특징1: 유니터리행렬이다. 즉 \\({\\bf DFT}^\\ast \\cdot {\\bf DFT} = {\\bf DFT}^\\ast \\cdot{\\bf DFT} = {\\bf I}\\) 이다.\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\nf = x -> exp(-im * (2π/4) * x)\nDFT = _DFT .|> f\nDFT # 아까의 예제의 DFT!\n\n4×4 Matrix{ComplexF64}:\n 1.0-0.0im           1.0-0.0im          …           1.0-0.0im\n 1.0-0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0-0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0-0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n\n\n\nDFT = (1/√4)*DFT # 새로운 DFT의 정의 \nDFT'DFT .|> round # 유니터리행렬임을 확인!\n\n4×4 Matrix{ComplexF64}:\n  1.0+0.0im  -0.0-0.0im   0.0-0.0im   0.0-0.0im\n -0.0+0.0im   1.0+0.0im  -0.0-0.0im   0.0-0.0im\n  0.0+0.0im  -0.0+0.0im   1.0+0.0im  -0.0-0.0im\n  0.0+0.0im   0.0+0.0im  -0.0+0.0im   1.0+0.0im\n\n\n특징2: \\({\\bf DFT}\\)는 대칭행렬이다. 따라서 이 행렬의 켤레전치는 DFT의 각 원소에서 단순히 \\(i=\\sqrt{-1}\\) 대신에 \\(-i\\) 를 넣은 것과 같다.\n특징1-2를 조합하면 아래와 같이 \\({\\bf DFT}\\)에서 \\(i\\) 대신에 \\(-i\\)를 넣은 행렬이 변환 DFT를 취소시킬 수 있음을 이해할 수 있다. 3\n\\[\\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot 1} & e^{i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot 2} & e^{i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n행렬 \\({\\bf DFT}\\)를 discrete Fourier transform으로 생각했듯이 위의 행렬을 inverse discrete Fourier transform으로 해석할 수 있다."
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html#dft의-또-다른-정의",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html#dft의-또-다른-정의",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "DFT의 또 다른 정의",
    "text": "DFT의 또 다른 정의\n이번에는 \\({\\bf DFT}\\)에 대한 다른 정의를 생각해보자. 우선 아래와 같은 행렬 \\({\\bf B}\\)를 고려하자.\n\nB= [0 0 0 1 \n    1 0 0 0 \n    0 1 0 0\n    0 0 1 0]\n\n4×4 Matrix{Int64}:\n 0  0  0  1\n 1  0  0  0\n 0  1  0  0\n 0  0  1  0\n\n\n이것은 길이가 4인 임의의 column vector를 아래로 한칸씩 이동시키는 매트릭스이다.\n\nx = [1, 2-im, -im, -1+2im]\n\n4-element Vector{Complex{Int64}}:\n  1 + 0im\n  2 - 1im\n  0 - 1im\n -1 + 2im\n\n\n\nB*x # 아래로 한칸이동 \n\n4-element Vector{Complex{Int64}}:\n -1 + 2im\n  1 + 0im\n  2 - 1im\n  0 - 1im\n\n\n\nB^2*x # 아래로 두칸이동, B^2*x = B*(Bx) 이므로 \n\n4-element Vector{Complex{Int64}}:\n  0 - 1im\n -1 + 2im\n  1 + 0im\n  2 - 1im\n\n\n한편 이 매트릭스 \\({\\bf B}\\)는 아래와 같이 고유분해가 가능하다.\n\\[ {\\bf B} = {\\bf \\Psi} {\\bf \\Lambda} {\\bf \\Psi}^\\ast\\]\n\n\\({\\bf \\Psi}\\): make \\(\\frac{1}{\\sqrt{N}}[e^{\\sqrt{-1} \\frac{2\\pi}{N} ij}~\\text{ for }~ i=0,1,2,\\dots,N-1~\\text{ for }~j=0,1,2,\\dots,N-1]\\) and apply reshape function with \\((N,N)\\).\n\\({\\bf \\Lambda}\\): make \\([e^{-\\sqrt{-1}\\frac{2\\pi}{N}i}~\\text{ for }~ i=0,1,2\\dots,N-1]\\) and apply Diagonal function.\n\n\nN = 4 \nλ = [exp(-im * (2π/N) *i) for i in 0:(N-1)]\nΛ = Diagonal(λ)\n_Ψ = 1/√N *[exp(im * (2π/N) * i*j) for i in 0:(N-1) for j in 0:(N-1)]\nΨ = reshape(_Ψ, (N,N))\nB ≈ Ψ * Λ * Ψ'\n\ntrue\n\n\n그런데 위에서 정의된 \\({\\bf \\Psi}^\\ast\\)는 우리가 그전에 정의하였던 \\({\\bf DFT}\\)의 행렬과 같다.\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\nDFT = _DFT .|> (x -> exp(-im * (2π/4) * x)) \nDFT = DFT * 1/√N\n\n4×4 Matrix{ComplexF64}:\n 0.5-0.0im           0.5-0.0im          …           0.5-0.0im\n 0.5-0.0im   3.06162e-17-0.5im             -9.18485e-17+0.5im\n 0.5-0.0im          -0.5-6.12323e-17im             -0.5-1.83697e-16im\n 0.5-0.0im  -9.18485e-17+0.5im              2.75546e-16-0.5im\n\n\n\nΨ' == DFT \n\ntrue\n\n\n결국 요약하면 길이가 \\(N\\)인 신호의 \\({\\bf DFT}\\)행렬은 아래의 과정으로 구할 수 있음을 알 수 있다.\n\nForward operator \\({\\bf A}\\)를 정의한다.\n\\({\\bf A}\\)의 고유벡터행렬 \\({\\bf \\Psi}\\)을 구한다. 4\n\\({\\bf \\Psi}\\)의 conjugate transpose matrix \\({\\bf \\Psi}^\\ast\\) 를 구한다. 이것이 \\({\\bf DFT}\\) matrix 이다. 5"
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html#spectral-component-and-frequencies",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html#spectral-component-and-frequencies",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Spectral component and Frequencies",
    "text": "Spectral component and Frequencies\n\\({\\bf A}\\)의 고유벡터 \\({\\bf \\Psi}\\)의 각 column을 spectral component라고 부른다.\n\nψ₁ = Ψ[:,1] # ψ₁ is first spectral component \nψ₂ = Ψ[:,2] # ψ₂ is seconde spectral component \nψ₃ = Ψ[:,3] # ψ₃ is third spectral component \nψ₄ = Ψ[:,4] # ψ₄ is last spectral component\n\n그리고 아래와 같은 수열을 \\(\\Omega_{k}=\\frac{k}{N}\\)을 frequency 라고 부른다.\n\nN=4 \nΩ = [k/N for k in 0:(N-1)]\nΩ\n\n4-element Vector{Float64}:\n 0.0\n 0.25\n 0.5\n 0.75"
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "",
    "text": "using LinearAlgebra, Plots, FFTW, Statistics"
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#kronecker-product",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#kronecker-product",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "Kronecker product",
    "text": "Kronecker product\n크로네커곱의 정의는 아래와 같다.\n\\[{\\bf A} \\otimes {\\bf B}\n=\\begin{bmatrix}\na_{11}{\\bf B} & a_{12}{\\bf B} & \\dots & a_{1m}{\\bf B} \\\\\na_{21}{\\bf B} & a_{22}{\\bf B} & \\dots & a_{2m}{\\bf B} \\\\\n\\dots & \\dots & \\dots & \\dots \\\\\na_{n1}{\\bf B} & a_{n2}{\\bf B} & \\dots & a_{nm}{\\bf B} \\\\\n\\end{bmatrix}\\]\n두 행렬 \\({\\bf A}_{m\\times n}\\), \\({\\bf B}_{p\\times q}\\)의 크로네커곱 \\({\\bf A}\\otimes {\\bf B}\\)의 차원은 \\(mp \\times nq\\) 가 된다. 계산예시는 아래와 같다.\n\n\n\n위키에서 긁은 예제, 글씨가 좀 작음\n\n\n크로네커곱에 대한 성질들이 위키에 많이 있으니 참고하면 좋다.\n(예제1)\n\nA= [1 2\n    3 4]\nB= [0 5\n    6 7]\nC = kron(A, B)\n\n4×4 Matrix{Int64}:\n  0   5   0  10\n  6   7  12  14\n  0  15   0  20\n 18  21  24  28\n\n\n(예제2)\n\nA= [1 -4 7; -2 3 3]\nB= [8 -9 -6 -5; 1 -3 -4 7; 2 8 -8 -3; 1 2 -5 -1]\nC = kron(A, B)\n\n8×12 Matrix{Int64}:\n   8   -9  -6   -5  -32   36   24   20  56  -63  -42  -35\n   1   -3  -4    7   -4   12   16  -28   7  -21  -28   49\n   2    8  -8   -3   -8  -32   32   12  14   56  -56  -21\n   1    2  -5   -1   -4   -8   20    4   7   14  -35   -7\n -16   18  12   10   24  -27  -18  -15  24  -27  -18  -15\n  -2    6   8  -14    3   -9  -12   21   3   -9  -12   21\n  -4  -16  16    6    6   24  -24   -9   6   24  -24   -9\n  -2   -4  10    2    3    6  -15   -3   3    6  -15   -3"
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#khatrirao-product",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#khatrirao-product",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "Khatri–Rao product",
    "text": "Khatri–Rao product\n카트리-라오곱은 매트릭스 \\({\\bf A}\\)와 \\({\\bf B}\\)가 같은 차원의 블락매트릭스로 정의될때 각 서브매트릭스의 크로네커 곱으로 정의된다. 정의와 계산예시는 아래와 같다.\n\n\n\n예시1: 위키에서 긁은 그림\n\n\n또 다른 계산예시는 아래와 같다. 이 예제는 중요하니까 구현해보자.\n\n\n\n예시2: 위키에서 긁은 그림\n\n\n(예제1)\n\nC= [1 2 3 \n    4 5 6 \n    7 8 9] \nD= [1 4 7\n    2 5 8\n    3 6 9]\n\n3×3 Matrix{Int64}:\n 1  4  7\n 2  5  8\n 3  6  9\n\n\n\nhcat([kron(C[:,i],D[:,i]) for i in 1:3]...)\n\n9×3 Matrix{Int64}:\n  1   8  21\n  2  10  24\n  3  12  27\n  4  20  42\n  8  25  48\n 12  30  54\n  7  32  63\n 14  40  72\n 21  48  81\n\n\n이건 자주 쓸일이 있을것 같으니까 함수로 저장하자.\n\ncolumnwise_kron = \n(C,D) -> hcat([kron(C[:,i],D[:,i]) for i in 1:size(C)[2]]...)\n\n#181 (generic function with 1 method)\n\n\n\ncolumnwise_kron(C,D)\n\n9×3 Matrix{Int64}:\n  1   8  21\n  2  10  24\n  3  12  27\n  4  20  42\n  8  25  48\n 12  30  54\n  7  32  63\n 14  40  72\n 21  48  81"
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#그래프-표현",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#그래프-표현",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "그래프 표현",
    "text": "그래프 표현\n아래의 그림을 살펴보자.\n\n\n\n그래프의 개념을 이해하는 필요한 그림, 일단 오른쪽의 \\({\\bf S}\\)는 무시할 것\n\n\n오른쪽의 \\({\\bf S}\\)는 무시하고 왼쪽의 그래프만 살펴보자. 이 그림에는 6개의 노드가 있고 각각의 노드는 저 마다의 연결구조를 가진다. 이러한 연결구조는 \\({\\bf G}=({\\bf N},{\\bf E})\\) 으로 표현할 수 있는데 여기에서 \\({\\bf N}\\)은 노드들의 집합이고 \\({\\bf E}\\)는 엣지들의 집합이다.1 보통 \\({\\cal E}\\)는 복잡하므로 연결정보를 매트릭스 \\({\\bf E}\\)로 표현하는데 이러한 \\({\\bf E}\\)를 인접행렬이라고 부른다. 인접행렬의 각 원소는 \\(E_{ij}= \\begin{cases} 1 & (i,j) \\in {\\cal E} \\\\ 0 & o.w \\end{cases}\\) 와 같이 정의한다. 이 그림의 경우 \\({\\cal N}\\) 와 \\({\\cal E}\\), \\({\\bf E}\\) 는 아래와 같다.\n\n\\({\\cal N}=\\{1,2,3,4,5,6\\}\\)\n\\({\\bf E}=\\begin{bmatrix} 0 & 1 & 0 & 0 & 1 & 0 \\\\ 1 & 0 & 1 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 & 1 & 1 \\\\ 1 & 1 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 & 0 & 0 \\end{bmatrix}\\)\n\\({\\cal E} = \\{(i,j) : E_{ij}=1 \\}\\)"
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#gso",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#gso",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "GSO",
    "text": "GSO\n후에 자세히 서술하겠지만 전통적인 시계열분석기법을 그래프신호로 확장하기 위해서는 단지 퓨리에변환 대신에 그래프퓨리에 변환을 사용하면 된다. 즉 퓨리에변환을 일반화한 그래프퓨리에변환을 잘 정의하면 된다.\n전통적인 신호처리 영역에서의 퓨리에변환은 시계열자료의 인접성을 의미하는 행렬 \\({\\bf B}\\)2의 고유행렬의 켤레전치로 정의할 수 있다. 이를 이용하면 그래프 퓨리에변환은 그래프자료의 인접성을 의미하는 행렬3의 고유행렬의 켤레전치로 정의할 수 있음을 유추할 수 있다. 즉 비유클리드 자료에서도 \\({\\bf B}\\)에 대응하는 어떠한 매트릭스가 정의되어야 하는데 (그리고 이 매트릭스는 그래프자료의 인접성에 대한 정보가 있어야 한다) 이 매트릭스를 \\({\\bf S}\\)라고 정의하고 grahp shift operator (GSO) 라고 이름 붙인다.\n주어진 그래프 \\({\\cal G}=({\\cal N},{\\cal E})\\) 에 대하여 GSO \\({\\bf S}\\)는 \\({\\bf E}+{\\bf I}\\)의 값이 1인 영역에만 값이 있는 어떠한 행렬이다. 다시 아래의 그림을 생각하여 보자.\n\n\n\nGSO의 개념을 이해하는데 필요한 그림\n\n\n왼쪽그래프의 GSO는 오른쪽과 같은 행렬 \\({\\bf S}\\)가 된다. 이제 \\({\\bf S}\\) 의 고유벡터행렬을 구한 뒤에 그것의 켤레전치를 \\({\\bf GFT}\\) 행렬로 정의하면 될 것 같다. 문제는 “\\({\\bf S}\\)의 고유벡터행렬이 항상 존재하는가?” 인데, 사실 이게 항상 존재한다는 보장이 없다. 즉 \\({\\bf S}\\)의 고유벡터 행렬이 존재 안할 수도 있다. 따라서 GSO \\({\\bf S}\\)가 고유분해가능하다는 조건이 추가적으로 필요한데 이러한 조건을 만족하는 GSO를 normal GSO라고 부른다. 우리는 당연히 normal GSO에 대해서만 관심이 있으므로 앞으로 특별한 언급이 없는한 GSO는 모두 normal GSO라고 가정한다."
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#periodogram-correlogram-and-ls-estimator",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#periodogram-correlogram-and-ls-estimator",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "Periodogram, correlogram, and LS estimator",
    "text": "Periodogram, correlogram, and LS estimator\nFrom \\({\\bf C}_{\\tilde{\\bf x}}:= \\mathbb{E}\\left[\\tilde{\\bf x}\\tilde{\\bf x}^H \\right]=\\mathbb{E}\\left[({\\bf V}^H{\\bf x})({\\bf V}^H{\\bf x})^H \\right]=\\text{diag}({\\bf p})\\) it follows that one may express the PSD as \\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\). That is, the PSD is given by the expected value of the squared frequency components of the random process. This leads to a natural approach for the estimation of \\({\\bf p}\\) from a finite set of \\(R\\) realizations of the process \\({\\bf x}\\). Indeed, we compute the \\({\\bf GFT} \\tilde{\\bf x}_r = {\\bf V}^H{\\bf x}_r\\) of each observed signal \\({\\bf x}_r\\) and estimate \\({\\bf p}\\) as\n\\[\n\\hat{\\bf p}_{pg}:= \\frac{1}{R}\\sum_{r=1}^R|\\tilde{\\bf x}_r|^2=\\frac{1}{R}\\sum_{r=1}^{R}|{\\bf V}^H{\\bf x}_{r}|^2.\n\\]\nThe estimator \\(\\hat{\\bf p}_{pg}\\) is termed periodogram due to its evident similarity with its homonym5 in classical estimation. It is simple to show that \\({\\bf p}_{pg}\\) is an unbiased estimator, that is, \\(\\mathbb{E}[\\hat{\\bf p}_{pg}]= {\\bf p}\\). A more detailed analysis of the performance of \\(\\hat{\\bf p}_{pg}\\), for the case where the observations are Gaussian, is given in Proposition 12.1.6\nAn alternative nonparametric estimation scheme, denominated correlogram, can be devised by starting from the definition of \\({\\bf p}\\) in\n\\[{\\bf p}:=\\text{diag}\\big({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V} \\big).\\]\nNamely, one may substitute \\({\\bf C}_{\\bf x}\\) in above equation by the sample covariance \\(\\hat{\\bf C}_{\\bf x} = \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\) computed based on the available observations to obtain\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right].\\]\nNotice that the matrix \\({\\bf V}^H\\hat{\\bf C}_{\\bf x}{\\bf V}\\) is in general, not diagonal because the eigenbasis of \\(\\hat{\\bf C}_{\\bf x}\\) differs from \\({\\bf V}\\), the eigenbasis of \\({\\bf C}_{\\bf x}\\). Nonetheless, we keep only the diagonal elements \\({\\bf v}_i^H \\hat{\\bf C}_{\\bf x}{\\bf v}_i\\) for \\(i = 1, \\dots , N\\) as our PSD estimator. It can be shown that the correlogram \\({\\bf p}_{cg}\\) and the periodogram \\({\\bf p}_{pg}\\) lead to identical estimators, as is the case in classical signal processing.\nThe correlogram can also be interpreted as an LS estimator. The decomposition in \\({\\bf C}_{\\bf x}={\\bf V}\\text{diag}({\\bf p}){\\bf V}^H\\) allows a linear parameterization of the covariance matrix \\({\\bf C}_{\\bf x}\\) as\n\\[\n{\\bf C}_{\\bf x}({\\bf p})=\\sum_{i=1}^N p_i{\\bf v}_i{\\bf v}_i^H.\n\\]\nThis linear parametrization will also be useful for the sampling schemes developed in Section 12.4. Vectorizing \\({\\bf C}_{\\bf x}\\) in \\({\\bf C}_{\\bf x}({\\bf p})=\\sum_{i=1}^N p_i{\\bf v}_i{\\bf v}_i^H\\) results in a set of \\(N^2\\) equations in \\({\\bf p}\\)\n\\[\n{\\bf c}_{\\bf x} = \\text{vec}({\\bf C}_{\\bf x})=\\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H)={\\bf G}_{np}{\\bf p},\n\\]\nwhere \\(\\text{vec}({\\bf v}_i{\\bf v}_i^H)={\\bf v}_i^\\ast \\otimes {\\bf v}_i\\). Relying on the Khatri-Rao product, we then form the \\(N^2 \\times N\\) matrix \\({\\bf G}_{np}\\) as\n\\[\n{\\bf G}_{np}:= \\left[{\\bf v}_1^\\ast \\otimes {\\bf v}_1, \\dots, {\\bf v}_N^\\ast \\otimes {\\bf v}_N \\right] = {\\bf V}^\\ast \\odot {\\bf V}.\n\\]\n\nHere \\(\\otimes\\) denote the Kronecker matrix product and \\(\\odot\\) denote the Khatri-Rao matrix product.\n\nUsing the sample covariance matrix \\(\\hat{\\bf C}_{\\bf x}\\) as an estimate of \\({\\bf C}_{\\bf x}\\), we can match the estimated covariance vector \\(\\hat{\\bf c}_{\\bf x}=\\text{vec}(\\hat{\\bf C}_{\\bf x})\\) to the true covariance vector \\({\\bf c}_{\\bf x}\\) in the LS sense as\n\\[\n\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}.\n\\]\nIn other words, the LS estimator minimizes the squared error \\(\\text{tr}\\left[\\big(\\hat{\\bf C}_{\\bf x} − \\hat{\\bf C}_{\\bf x}({\\bf p})\\big)^T \\big(\\hat{\\bf C}_{\\bf x} − \\hat{\\bf C}_{\\bf x}({\\bf p})\\big)\\right]\\). From expression \\(\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}\\) it can be shown that the \\(i\\)th element of \\(\\hat{\\bf p}_{ls}\\) is \\({\\bf v}_i^H \\hat{\\bf C}_{\\bf x} {\\bf v}_i\\). Combining this with Eq.\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right]\\]\nwe get that the LS estimator \\(\\hat{\\bf p}_{ls}\\) and the correlogram \\(\\hat{\\bf p}_{cg}\\) —and hence the periodogram as well— are all identical estimators. The estimators derived in this subsection do not assume any data distribution and are well suited for cases where the data probability density function is not available. In what follows, we provide performance bounds for these estimators under the condition that the observed signals are Gaussian."
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#정상시계열을-분석하는-두-가지-흐름-acf와-psd",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#정상시계열을-분석하는-두-가지-흐름-acf와-psd",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "정상시계열을 분석하는 두 가지 흐름, ACF와 PSD",
    "text": "정상시계열을 분석하는 두 가지 흐름, ACF와 PSD\n\n전통적인 분석방법\n클래식한 정상시계열은 유한차수의 ARMA로 근사할 수 있음이 알려져 있다7. 유한차수의 ARMA의 계수 \\(p\\),\\(q\\)를 적절하게 추정하기 위해서는 시계열 \\({\\bf x}\\)를 SACF plot 혹은 SPACF plot 을 이용하면 된다. 이때 SACF 혹은 SPACF 의 그림을 살펴보고 적절한 모형을 선택하기 위해서는 유한차수 ARMA의 이론적 ACF의 모양을 알면 되는데,8 이를 바꾸어서 말하면 결국 정상시계열 \\({\\bf x}\\)의 모든 정보는 ACF에 들어있다는 의미가 된다. 즉 정상시계열은 ACF만 잘 추정하면 모든 것이 해결된다.\n그런데 ACF의 모든 정보는 다시 아래의 행렬에 들어있다.\n\\[{\\bf C}_{\\bf x}=\\mathbb{E}[{\\bf x}{\\bf x}^T]\\]\n여기에서 \\({\\bf x}\\)는 realization이 아니라 확률벡터를 의미함을 유의하자.9 따라서 정상시계열의 경우 \\({\\bf C}_{\\bf x}\\)를 잘 추정하면 모든것이 해결된다고 생각하면 된다.\n\n참고: 정상시계열의 경우 ACF 만 정확하게 알아도 (반대로 PACF만 정확하게 알아도) 이론상 모든 모형을 특정할 수 있다. 즉 정상시계열의 모형을 특정하기 위해서는 ACF plot, PACF plot 하나만 있어도 충분하다. (Wold’s Thm은 떠올리면 모든 정상시계열은 무한MA로 유니크하게 표현할 수 있는데, 이는 PACF plot을 가지고 모든 정상시계열을 유니크하게 특정할 수 있다는 것을 의미한다) 다만 좀 더 모형을 특정하는 과정을 용이하게 하기 위해서 실전에서는 SACF plot 과 SPACF plot 을 함께 보는 것이 유리하다.\n\n(예제) AR(1) 모형\n왜 ACF의 모든정보를 \\({\\bf C}_{\\bf x}\\)로 부터 알수 있는지 코드를 통하여 실습하여 보자. (바로 이해된다면 사실 이 예제는 스킵해도 무방함) 아래와 같은 모형을 가정하자.\n\\[x_{t} = 0.5 x_{t-1} +\\epsilon_t\\]\n여기에서 \\(\\epsilon_t\\)는 서로 독립인 표준정규분포를 따른다. 이 모형에서 길이가 100인 시계열을 임의로 발생시키자.\n\nx = zeros(100*1000)\nx[1] = randn()\nfor t in 2:100\n    x[t] = 0.5*x[t-1] + randn()\nend\n\n모형에서 생성된 하나의 시계열을 시각화 하면 아래와 같다.\n\nplot(x) # 그냥 그려본것임. 별 의미는 없음\n\n\n\n\nlag=1일 경우 이 시계열의 SACF를 계산하면 아래와 같다.\n\nx[1:99] .* x[2:100]\n\n99-element Vector{Float64}:\n  1.587897526021493\n  1.130306190921068\n  0.5698214432110668\n  0.4648189302568683\n  0.3099446153360606\n  0.36362604534744775\n  0.8191871414624922\n -0.1720390842292145\n -0.06301214708310766\n  0.026414715508855904\n -0.007988283356933327\n -0.04178812545299474\n  0.22453267567940685\n  ⋮\n  3.931333581073927\n  1.315564948810858\n  0.9096080102581454\n  0.5410986320348997\n  0.29627801400693676\n  1.0673283524686212\n -1.0394649044573636\n  2.80195248208142\n  4.152973765526384\n  2.316315764368524\n  0.978758337765867\n -0.5840281943972468\n\n\n\n이 계산결과는 각 \\(t\\)에 대하여 \\(x_{t-1}x_t\\) 를 계산한 것과 같다.\n\n이 수열들의 평균은 아래와 같다.\n\nx[1:99] .* x[2:100] |> mean\n\n0.5835563885014224\n\n\n\n이 계산결과는 \\(\\frac{1}{99}\\sum_{t=2}^{100} x_{t-1}x_t\\)를 계산한 것과 같다.\n\n이론적인 값인 0.5 근처의 값이 잘 나옴을 알 수 있다.\nlag=2일 경우도 마찬가지로 구할 수 있다.\n\nx[1:98] .* x[3:100] |> mean\n\n0.38420263596668275\n\n\n이러한 숫자들은 그런데 \\({\\bf x}{\\bf x}^T\\)를 이용하여서도 구할 수 있다.10\n\nx*x'\n\n100×100 Matrix{Float64}:\n  0.760108    1.5879      0.541064   …  -1.57394    -0.472676    0.939172\n  1.5879      3.31719     1.13031       -3.28802    -0.987441    1.96197\n  0.541064    1.13031     0.385143      -1.12037    -0.336463    0.668527\n  0.800507    1.67229     0.569821      -1.65759    -0.497799    0.989089\n  0.441361    0.922022    0.314172      -0.913915   -0.274462    0.545336\n  0.533784    1.1151      0.379961   …  -1.10529    -0.331936    0.659531\n  0.517803    1.08171     0.368586      -1.0722     -0.321998    0.639786\n  1.20252     2.51212     0.855987      -2.49003    -0.747794    1.48581\n -0.108745   -0.227173   -0.0774074      0.225175    0.0676234  -0.134363\n  0.440444    0.920106    0.313519      -0.912016   -0.273892    0.544203\n  0.0455859   0.0952309   0.0324492  …  -0.0943935  -0.0283478   0.0563249\n -0.133198   -0.278257   -0.0948139      0.27581     0.0828298  -0.164577\n  0.238468    0.498169    0.169748      -0.493789   -0.148292    0.294646\n  ⋮                                  ⋱                          \n  2.04697     4.2762      1.45708       -4.2386     -1.27291     2.52919\n  0.488514    1.02053     0.347736      -1.01155    -0.303784    0.603596\n  1.41531     2.95665     1.00746    …  -2.93065    -0.880119    1.74873\n  0.290602    0.60708     0.206858      -0.601742   -0.180712    0.359062\n  0.774954    1.61891     0.551632      -1.60468    -0.481908    0.957516\n  1.04688     2.18698     0.745197      -2.16775    -0.651007    1.2935\n -0.754723   -1.57665    -0.537231       1.56279     0.469328   -0.932519\n -2.82194    -5.89516    -2.00873    …   5.84333     1.75484    -3.48673\n -1.11863    -2.33686    -0.796269       2.31632     0.695624   -1.38215\n -1.57394    -3.28802    -1.12037        3.25911     0.978758   -1.94472\n -0.472676   -0.987441   -0.336463       0.978758    0.293936   -0.584028\n  0.939172    1.96197     0.668527      -1.94472    -0.584028    1.16042\n\n\n여기에서 각 원소들이 의미하는 바는 아래와 같다.\n\n대각선의 원소: \\(x_t^2,~ t=1,2,\\dots,100\\) 을 의미\n대각선 한칸 위, 혹은 한칸 아래: \\(x_{t-1} x_t~ t=2,3,\\dots,100\\) 을 의미\n대각선 두칸 위, 혹은 두칸 아래: \\(x_{t-2} x_t~ t=3,4,\\dots,100\\) 을 의미\n\n\n\n\nx*x'의 계산결과를 캡쳐한 그림, 이것은 \\(\\hat{\\bf C}_{\\bf x}\\)를 의미함\n\n\n확인해보자.\nlag=1, 스크린샷의 노란색\n\n(x[1:99] .* x[2:100])[1:5]\n\n5-element Vector{Float64}:\n 1.587897526021493\n 1.130306190921068\n 0.5698214432110668\n 0.4648189302568683\n 0.3099446153360606\n\n\n\nlag1에 해당하는 숫자들임. 이는 스크린샷에서 노란색으로 표현된 1.589, 1.13031, 0.569821 … 등과 일치한다.\n\nlag=2, 스크린샷의 빨간색\n\n(x[1:98] .* x[3:100])[1:5]\n\n5-element Vector{Float64}:\n 0.5410642277088621\n 1.6722932576420804\n 0.3141719983177106\n 0.5621541352252872\n 0.30066534927151267\n\n\n\nlag2에 해당하는 숫자들임. 이는 스크린샷에서 빨간색으로 표현된 숫자들인 0.54164, 1.67229, 0.31417 … 등과 일치한다.\n\n\n\n스펙트럼 방법\n지금까지는 정상시계열일 경우 ACF를 이용한 간단한 분석방법을 다시 복습했다. 그리고 \\({\\bf C}_{\\bf x}\\)가 ACF를 구함에 필요한 모든정보를 가지고 있음을 이해했다. 한편 \\({\\bf C}_{\\bf x}\\)은 positive definite matrix 이므로 아래와 같이 분해가능하다.\n\\[{\\bf C}_{\\bf x} = {\\bf V} \\text{diag}({\\bf p}) {\\bf V}^H\\]\n이 수식표현을 잘 해석하면 \\({\\bf C}_{\\bf x}\\)의 모든 정보는 \\({\\bf V}\\)와 \\({\\bf p}\\)에 담겨있다는 사실을 이해할 수 있다. 그런데 정상시계열일 경우 한정하여 \\({\\bf C}_{x}\\)의 고유벡터행렬은 \\({\\bf B}\\)의 고유벡터행렬과 일치한다는 사실을 알고 있다. 따라서 \\({\\bf V}\\)는 \\({\\bf B}\\)로 부터 그냥 알 수 있는 정보이다. 따라서 \\({\\bf C}_{\\bf x}\\)의 모든 정보는 \\({\\bf p}\\)에 담겨있다는 사실을 알 수 있다. 이는 적절한 \\({\\bf p}\\)를 추정하는 일은 적절한 \\({\\bf C}_{\\bf x}\\)를 추정하는 것과 같다는 사실을 알려준다.\n요약하면 아래와 같다.\n\n임의의 정상시계열은 이론적인 ACF (혹은 PACF)를 잘 추정하면 유니크하게 특정할 수 있다. (Wold’s Thm)\nACF를 잘 추정한다는 말은 \\({\\bf C}_{\\bf x}\\)를 잘 추정한다는 의미이다.\n그런데 \\({\\bf p}\\)를 잘 추정하면 \\({\\bf C}_{\\bf x}\\)를 잘 추정하는 일이 된다.\n따라서 임의의 정상시계열은 \\({\\bf p}\\)를 잘 추정하면 유니크하게 특정할 수 있다는 결론을 얻는다.\n\n여기에서 \\({\\bf p}\\)를 power spectral density 라고 부른다. 일반적으로 정상시계열을 분석하기 위해서는 \\({\\bf C}_{\\bf x}\\)를 특정하거나, \\({\\bf p}\\)를 특정하면 되는데 여기에서 \\({\\bf p}\\)를 특정한뒤 \\({\\bf p}\\)로 부터 \\({\\bf C}\\)를 역으로 해석하는 방법론을 spectral analysis라고 부른다. 경우에 따라서 \\({\\bf C}_{\\bf x}\\)를 특정하는 것이 용이할 수도 있지만 \\({\\bf p}\\)를 특정하고 해석하는 것이 용이할 때도 있다.\n그렇다면 주어진 시계열 \\({\\bf x}\\)에 대하여 \\({\\bf p}\\)를 어떻게 구할까? 직관적으로 생각하면 단순히 아래의 알고리즘으로 구하면 된다는 것을 알 수 있다.\n\n\\({\\bf C}_{\\bf x}\\)를 알아낸다.\n\\({\\bf C}_{\\bf x}\\)를 고유분해하여 \\({\\bf p}\\)를 구한다.\n\n또 다른 방법으로는 교재에 소개된 바 있는 아래의 수식을 이용하는 것이다.11\n\\[{\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\]\n이것을 이용하면 아래와 같은 알고리즘을 떠올릴 수 있다.\n\n\\({\\bf B}\\)의 고유벡터행렬 \\({\\bf V}\\)를 구하고 \\({\\bf V}^H{\\bf x}\\)를 계산한다.\n계산된 결과를 원소별로 제곱하여 \\({\\bf p}\\)를 얻는다.\n\n그런데 \\({\\bf V}^H{\\bf x}= {\\bf DFT} \\cdot {\\bf x}\\) 이므로 1의 과정을 아래와 같이 바꾸어 서술할 수 있다.\n\n\\({\\bf x}\\)를 퓨리에변환하여 \\(\\tilde{\\bf x} = {\\bf DFT} \\cdot {\\bf x}\\) 를 계산한다.\n\\(\\tilde{\\bf x}\\)를 원소별로 제곱하여 \\({\\bf p}\\)를 얻는다.\n\n즉 임의의 시계열을 퓨리에변환한 뒤 제곱하면 \\({\\bf p}\\)를 얻을 수 있다.\n(예제2) – 하나의 realization에서 \\(\\hat{\\bf p}\\)를 구해보자.\n(예제1에 이어서) 아래의 모형에서 생성된 \\({\\bf x}\\)를 다시 고려하자.\n\\[x_{t} = 0.5 x_{t-1} +\\epsilon_t\\]\n\nplot(x)\n\n\n\n\n이 자료의 PSD \\({\\bf p}\\)는 아래와 같이 구할 수 있다.\n단계1: \\({\\bf x}\\)의 DFT를 계산\n\nx̃ = fft(x) \n\n100-element Vector{ComplexF64}:\n  -5.756917285643583 + 0.0im\n   -19.0826720904921 - 1.0178306444775302im\n  14.230506824768984 - 11.867854578089997im\n  3.8980118254428726 + 1.2603018602424614im\n -16.157973053188194 + 27.488246322270918im\n   12.32574209329046 - 1.5134316695905219im\n    3.95421224972561 + 15.369129638224624im\n   9.516938110507798 + 19.371467179753544im\n  -19.38292930624831 + 9.49506288623419im\n  -7.853934851478428 + 4.134711886071571im\n -14.072349901900408 - 5.945064076174294im\n -14.596266922162355 + 3.447776409279256im\n   5.857720447482927 + 5.738895112838594im\n                     ⋮\n   5.857720447482924 - 5.738895112838594im\n -14.596266922162352 - 3.4477764092792564im\n -14.072349901900408 + 5.945064076174294im\n   -7.85393485147843 - 4.134711886071569im\n -19.382929306248315 - 9.49506288623419im\n   9.516938110507798 - 19.37146717975354im\n  3.9542122497256105 - 15.36912963822462im\n  12.325742093290458 + 1.5134316695905206im\n -16.157973053188194 - 27.488246322270925im\n  3.8980118254428717 - 1.260301860242461im\n  14.230506824768984 + 11.867854578089993im\n -19.082672090492103 + 1.0178306444775296im\n\n\n\n\\({\\bf B}\\)를 설정하고 고유값분해 하기 귀찮아서 그냥 DFT해주는 패키지 사용함\n\n단계2: \\(\\hat{\\bf p}\\)를 계산\n\np̂ = abs.(x̃).^2\n\n100-element Vector{Float64}:\n   33.14209663374188\n  365.18435333408365\n  343.3532967764883\n   16.782856970223087\n 1016.6837790613963\n  154.21439356883184\n  251.84594035243464\n  465.8258516955045\n  465.85416770456163\n   78.78013503208902\n  233.37481863133453\n  224.93817023139349\n   67.24780595702228\n    ⋮\n   67.24780595702225\n  224.93817023139337\n  233.37481863133453\n   78.78013503208902\n  465.8541677045618\n  465.8258516955044\n  251.84594035243452\n  154.2143935688318\n 1016.6837790613968\n   16.782856970223072\n  343.3532967764882\n  365.1843533340838\n\n\n참고\nfft(x) 대신에 아래의 코드를 이용해도 된다.\n\nN = 100 \nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |> \n    x -> reshape(x,(N,N)) .|> \n    x -> exp(im * (2π/N) * x)\nV'x\n\n100-element Vector{ComplexF64}:\n  -5.756917285643587 + 0.0im\n -19.082672090492103 - 1.0178306444775291im\n   14.23050682476898 - 11.867854578090007im\n  3.8980118254428824 + 1.2603018602424476im\n  -16.15797305318818 + 27.48824632227092im\n   12.32574209329044 - 1.5134316695905325im\n  3.9542122497256385 + 15.369129638224617im\n    9.51693811050782 + 19.371467179753516im\n  -19.38292930624826 + 9.495062886234233im\n -7.8539348514784155 + 4.134711886071595im\n -14.072349901900417 - 5.945064076174276im\n -14.596266922162371 + 3.447776409279244im\n   5.857720447482956 + 5.7388951128385735im\n                     ⋮\n   5.857720447482839 - 5.738895112838781im\n -14.596266922162307 - 3.4477764092792627im\n  -14.07234990190023 + 5.945064076174198im\n  -7.853934851478599 - 4.134711886071242im\n -19.382929306248577 - 9.49506288623372im\n   9.516938110507212 - 19.371467179753736im\n  3.9542122497250025 - 15.369129638224603im\n  12.325742093290597 + 1.5134316695903638im\n  -16.15797305318867 - 27.488246322270854im\n  3.8980118254424903 - 1.2603018602428118im\n  14.230506824769146 + 11.867854578089572im\n   -19.0826720904922 + 1.0178306444775123im\n\n\n진짜 똑같은지 확인\n\nfft(x)\n\n100-element Vector{ComplexF64}:\n  -5.756917285643583 + 0.0im\n   -19.0826720904921 - 1.0178306444775302im\n  14.230506824768984 - 11.867854578089997im\n  3.8980118254428726 + 1.2603018602424614im\n -16.157973053188194 + 27.488246322270918im\n   12.32574209329046 - 1.5134316695905219im\n    3.95421224972561 + 15.369129638224624im\n   9.516938110507798 + 19.371467179753544im\n  -19.38292930624831 + 9.49506288623419im\n  -7.853934851478428 + 4.134711886071571im\n -14.072349901900408 - 5.945064076174294im\n -14.596266922162355 + 3.447776409279256im\n   5.857720447482927 + 5.738895112838594im\n                     ⋮\n   5.857720447482924 - 5.738895112838594im\n -14.596266922162352 - 3.4477764092792564im\n -14.072349901900408 + 5.945064076174294im\n   -7.85393485147843 - 4.134711886071569im\n -19.382929306248315 - 9.49506288623419im\n   9.516938110507798 - 19.37146717975354im\n  3.9542122497256105 - 15.36912963822462im\n  12.325742093290458 + 1.5134316695905206im\n -16.157973053188194 - 27.488246322270925im\n  3.8980118254428717 - 1.260301860242461im\n  14.230506824768984 + 11.867854578089993im\n -19.082672090492103 + 1.0178306444775296im\n\n\n\n\n전통적인 방법과 스펙트럼 방법의 비교\n시계열자료의 전통적인 분석과 spectral analysis는 대충 아래의 과정으로 비교 설명할 수 있다.\n\n\n\n\n\n\n\n\n단계\n전통적인 방법\n스펙트럴 분석\n\n\n\n\n1\n\\({\\bf x}\\)의 plot을 그려봄\n\\({\\bf x}\\)의 plot을 그려봄\n\n\n2\nSACF plot, SPACF plot 을 그려봄\nPSD plot을 그려봄\n\n\n3\nACF를 추정 (=ARMA(\\(p\\),\\(q\\))에 대응하는 파라메터를 추정)\n\\({\\bf p}\\)를 추정\n\n\n4\n추정된 파라메터를 바탕으로 여러가지 분석 수행\n추정된 파라메터를 바탕으로 여러가지 분석 수행\n\n\n\n눈여겨 볼 점은 PSD plot의 존재이다. 전통적인 시계열에서 SACF plot 과 비슷하게 스펙트럼 방법에서 시계열을 분석하기 위해 필요한 매우 중요한 시각화 이다. 간단하게 비교를 하면 아래와 같다.\nSACF plot\n\nx축: lag=0, lag=1, ….\ny축: lag에 대응하는 상관계수값\n\nPSD plot\n\nx축: \\(\\Omega=\\big\\{\\frac{k}{N}:~ \\text{for}~ k=0,\\dots, N-1\\big\\}\\), 정규화된 freq를 의미함\ny축: 주파수에 대응하는 power값\n\n전통적인 방법에 비하여 스펙트럴 분석이 가지는 장점은 위의 표에서 소개한 일반적인 분석루틴이 시계열이 아닌 그래프신호로 쉽게 확장가능 하다는 점이다12. 따라서 앞으로는 전통적인 시계열 분석방법 대신 스펙트럴 분석만을 다룰 것이다. 스펙트럴 분석의 핵심적인 부분은 \\({\\bf p}\\)를 추정하는 방법과 추정량의 점근적 성질들을 파악하는 것이다. 이 포스트에서는 \\({\\bf p}\\)를 추정하는 방법만을 다룬다."
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#그래프신호에서의-psd의-추정",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#그래프신호에서의-psd의-추정",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "그래프신호에서의 PSD의 추정",
    "text": "그래프신호에서의 PSD의 추정\n이제 그래프 신호에서 \\({\\bf p}\\)를 추정하는 방법에 대하여 살펴보자. 그래프이동변환 (Graph Shift Operator, GSO)13 \\({\\bf S}={\\bf V}{\\bf \\Lambda}{\\bf V}^H\\)에 대하여 정상인 시계열 \\({\\bf x}\\)를 고려한다. 이 신호의 그래프퓨리에 변환14은 아래와 같이 구할 수 있다.\n\\[\\tilde{\\bf x}={\\bf GFT} {\\bf x} = {\\bf V}^H{\\bf x}\\]\n여기에서 \\(\\tilde{\\bf x}\\)를 \\({\\bf x}\\)의 주파수응답(frequency representation)이라고 부른다.15 우리는 아래의 수식에서 \\({\\bf p}\\)의 값에 관심이 있다.\n\\[{\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\]\n여기에서 \\({\\bf p}\\)를 PSD (power spectrum density) 라고 한다. \\({\\bf p}\\)가 포함된 표현식은 위의 수식 이외에도 2개가 더 있다. 이를 모두 요약하면 아래와 같다16\n\n\\({\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\)17\n\\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\)\n\\({\\bf c}_{\\bf x} = \\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H) = {\\bf G}_{np} {\\bf p}\\)\n\n위의 표현중 3.에서 \\({\\bf c}_{\\bf x}\\)은 \\({\\bf C}_x\\)를 벡터화한 것이며 \\({\\bf G}_{np}\\)는 \\({\\bf V}^\\ast\\) 와 \\({\\bf V}\\)를 열별-크로네커곱 (column-wise Kronecker product) 이다. 이때 \\({\\bf G}_{np}\\)의 정의가 조금 생소하니 한번 계산하여 보자.\n(예제) 아래와 같은 GSO \\({\\bf B}\\)를 고려하자.\n\nB= [0 1 0 0 \n    0 0 1 0 \n    0 0 0 1 \n    1 0 0 0]\n\n4×4 Matrix{Int64}:\n 0  1  0  0\n 0  0  1  0\n 0  0  0  1\n 1  0  0  0\n\n\n이러한 GSO에 대하여 \\({\\bf G}_{np}\\)는 아래와 같이 구할 수 있다.\n(1) \\({\\bf V}\\)를 정의\n\nV = [i*j for i in 0:3 for j in 0:3] |> \n    x -> reshape(x,(4,4)) .|> \n    x -> exp(im * (2π/4) * x) \n\n4×4 Matrix{ComplexF64}:\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im          -1.0+1.22465e-16im             -1.0+3.67394e-16im\n 1.0+0.0im  -1.83697e-16-1.0im              5.51091e-16+1.0im\n\n\n(2) \\({\\bf G}_{np}={\\bf V}^{\\ast} \\odot {\\bf V}\\), 여기에서 \\(\\odot\\)은 열별-크로네커곱을 의미한다.\n\n# columnwise_kron은 위에서 정의한적 있음~\nGₙₚ = columnwise_kron(conj(V),V)\n\n16×4 Matrix{ComplexF64}:\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im          -1.0+1.22465e-16im             -1.0+3.67394e-16im\n 1.0+0.0im  -1.83697e-16-1.0im              5.51091e-16+1.0im\n 1.0+0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im          -1.0+1.22465e-16im             -1.0+3.67394e-16im\n 1.0+0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0+0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n 1.0+0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0+0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n\n\n위에서 언급한 표현식 1,2,3 을 이용하면 \\({\\bf p}\\)를 추정하는 세 가지 방법을 각각 정의할 수 있다. 하나씩 살펴보자.\n\n1. \\({\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\)\n확률과정 \\({\\bf x}\\)에서 \\(R\\)개의 realization \\(\\{{\\bf x}_1 \\dots {\\bf x}_R\\}\\) 을 관측하였다고 하자. 수식 \\({\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\)를 적당히 변형하면 아래를 얻을 수 있다.\n\\[{\\bf p}=\\text{diag}\\big({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V} \\big)\\]\n여기에서\n\\[{\\bf C}_{\\bf x}=\\mathbb{E}[{\\bf x}{\\bf x}^H]\\approx \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_t{\\bf x}_r^H\\]\n이므로 이 수식에 근거하여 \\({\\bf p}\\)을 추정한다면 아래와 같이 할 수 있다.\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right].\\]\n만약에 확률과정 \\({\\bf x}\\)에서 관측한 시계열이 \\({\\bf x}_r\\) 하나라면18, 즉 \\(R=1\\) 이라면 단순히 아래와 같이 쓸 수 있다.\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H{\\bf x}_r{\\bf x}_r^H{\\bf V} \\right].\\]\n\n주의: 여기에서 \\({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V}\\) 는 항상 대각행렬이지만 \\({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V}\\) 은 대각행렬이 아닐수도 있음을 유의하자. 즉 이론적인 모수는 대각행렬이지만 sample version은 대각행렬이 아닐 수 있다. 대각선이 아닌 원소는 버리면 된다.)\n\n\n아이디어: 혹시 대각선이 아닌 원소들을 이용하여 오차항 \\(\\epsilon_t\\)의 분산을 추정할 수도 있지 않을까? 이미 연구가 있겠지?\n\n(예제)\n\nN = 100 \nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |> \n    x -> reshape(x,(N,N)) .|> \n    x -> exp(im * (2π/N) * x)\n\n100×100 Matrix{ComplexF64}:\n 1.0+0.0im       1.0+0.0im        …       1.0+0.0im\n 1.0+0.0im  0.998027+0.0627905im     0.998027-0.0627905im\n 1.0+0.0im  0.992115+0.125333im      0.992115-0.125333im\n 1.0+0.0im  0.982287+0.187381im      0.982287-0.187381im\n 1.0+0.0im  0.968583+0.24869im       0.968583-0.24869im\n 1.0+0.0im  0.951057+0.309017im   …  0.951057-0.309017im\n 1.0+0.0im  0.929776+0.368125im      0.929776-0.368125im\n 1.0+0.0im  0.904827+0.425779im      0.904827-0.425779im\n 1.0+0.0im  0.876307+0.481754im      0.876307-0.481754im\n 1.0+0.0im  0.844328+0.535827im      0.844328-0.535827im\n 1.0+0.0im  0.809017+0.587785im   …  0.809017-0.587785im\n 1.0+0.0im  0.770513+0.637424im      0.770513-0.637424im\n 1.0+0.0im  0.728969+0.684547im      0.728969-0.684547im\n    ⋮                             ⋱  \n 1.0+0.0im  0.728969-0.684547im      0.728969+0.684547im\n 1.0+0.0im  0.770513-0.637424im      0.770513+0.637424im\n 1.0+0.0im  0.809017-0.587785im   …  0.809017+0.587785im\n 1.0+0.0im  0.844328-0.535827im      0.844328+0.535827im\n 1.0+0.0im  0.876307-0.481754im      0.876307+0.481754im\n 1.0+0.0im  0.904827-0.425779im      0.904827+0.425779im\n 1.0+0.0im  0.929776-0.368125im      0.929776+0.368125im\n 1.0+0.0im  0.951057-0.309017im   …  0.951057+0.309017im\n 1.0+0.0im  0.968583-0.24869im       0.968583+0.24869im\n 1.0+0.0im  0.982287-0.187381im      0.982287+0.187381im\n 1.0+0.0im  0.992115-0.125333im      0.992115+0.125333im\n 1.0+0.0im  0.998027-0.0627905im     0.998027+0.0627905im\n\n\n\np̂ = diag(V' * (x*x') * V)\n\n100-element Vector{ComplexF64}:\n 33.142096633741986 + 0.0im\n 365.18435333408354 + 1.5376069362644531e-13im\n  343.3532967764883 + 6.904176529646917e-14im\n 16.782856970223083 - 3.5538396658301444e-14im\n 1016.6837790613963 + 5.475049904926759e-15im\n 154.21439356883144 + 6.4512443306088e-14im\n  251.8459403524346 + 2.1316282072803006e-14im\n 465.82585169550384 + 1.816929057526117e-13im\n 465.85416770456044 + 4.1584439183295984e-14im\n    78.780135032089 + 1.3472456770553478e-14im\n 233.37481863133462 + 6.315728724701355e-14im\n 224.93817023139385 - 3.472109560086835e-14im\n  67.24780595702241 + 7.105427357601002e-14im\n                    ⋮\n   67.2478059570233 + 6.384723798533952e-14im\n 224.93817023139195 + 1.9727655769954595e-14im\n 233.37481863132837 - 2.1872689567834747e-14im\n    78.780135032089 + 1.917599080404094e-14im\n 465.85416770456294 + 4.808950231511622e-14im\n 465.82585169550094 - 4.890486289860305e-14im\n  251.8459403524291 + 2.0146681724568905e-14im\n  154.2143935688347 - 1.0948596967617507e-13im\n 1016.6837790614081 + 1.2114814701286432e-13im\n  16.78285697022108 + 2.376159104534641e-14im\n 343.35329677648286 + 1.1310381241837407e-14im\n 365.18435333408746 + 4.574214786667376e-14im\n\n\n\n\n2. \\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\)\n확률과정 \\({\\bf x}\\)에서 \\(R\\)개의 realization \\(\\{{\\bf x}_1 \\dots {\\bf x}_R\\}\\) 을 관측하였다고 하자. 아래의 수식을 관찰하자.\n\\[{\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\approx \\frac{1}{R}\\sum_{r=1}^{R} |{\\bf V}^H {\\bf x}_r|^2 \\]\n따라서 \\(\\frac{1}{R}\\sum_{r=1}^{R} |{\\bf V}^H {\\bf x}_r|^2\\) 를 PSD \\({\\bf p}\\)에 대한 추정량이라고 생각할 수 있다. 이러한 추정량을 기호로 \\(\\hat{\\bf p}_{pg}\\)라고 정의하고 periodogram이라고 부른다. 즉\n\\[\\hat{\\bf p}_{pg}=\\frac{1}{R}\\sum_{r=1}^{R} |{\\bf V}^H {\\bf x}_r|^2 \\]\n만약에 확률과정 \\({\\bf x}\\)에서 관측한 시계열이 \\({\\bf x}_r\\) 하나라면, 즉 \\(R=1\\) 이라면 단순히 아래와 같이 쓸 수 있다.\n\\[\\hat{\\bf p}_{pg}=|{\\bf V}^H {\\bf x}_r|^2 \\]\n즉 이 경우 \\(\\hat{\\bf p}_{pg}\\)는 단순히 관측시계열 \\({\\bf x}_r\\)의 그래프 퓨리에 변환 \\(\\tilde{\\bf x}={\\bf V}^H{\\bf x}_r\\) 결과에 절대값을 취하고 제곱한 것과 같다.\n(예제)\n스펙트럼방법챕터 예제2에서 이미 보여준 적 있다. 주어진 시계열 \\({\\bf x}\\)에 대하여 \\(\\hat{\\bf p}_{pg}\\)를 구하는 방법을 요약하면 아래와 같다.\n\nx̃ = fft(x) # 단계1: GFT, 이 신호는 시계열이라서 GFT대신에 DFT를 써도 된다.\np̂ = abs.(x̃).^2 # 단계2: hat p\n\n100-element Vector{Float64}:\n   33.14209663374188\n  365.18435333408365\n  343.3532967764883\n   16.782856970223087\n 1016.6837790613963\n  154.21439356883184\n  251.84594035243464\n  465.8258516955045\n  465.85416770456163\n   78.78013503208902\n  233.37481863133453\n  224.93817023139349\n   67.24780595702228\n    ⋮\n   67.24780595702225\n  224.93817023139337\n  233.37481863133453\n   78.78013503208902\n  465.8541677045618\n  465.8258516955044\n  251.84594035243452\n  154.2143935688318\n 1016.6837790613968\n   16.782856970223072\n  343.3532967764882\n  365.1843533340838\n\n\n\n\n3. \\({\\bf c}_{\\bf x} = {\\bf G}_{np} {\\bf p}\\)\n확률과정 \\({\\bf x}\\)에서 \\(R\\)개의 realization \\(\\{{\\bf x}_1 \\dots {\\bf x}_R\\}\\) 을 관측하였다고 하자. 아래의 수식을 관찰하자.\n\\[{\\bf C}_{\\bf x} = {\\bf V} \\text{diag}({\\bf p}) {\\bf V}^H\\]\n이 수식으로부터 아래를 얻을 수 있다.\n\\[{\\bf c}_{\\bf x} = \\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H) = {\\bf G}_{np} {\\bf p}\\]\n여기에서 \\({\\bf c}_{\\bf x}\\) 대신에 \\(\\hat{\\bf c}_{\\bf x}\\) 를 대입하면 아래와 같이 생각할 수 있다.\n\\[\\hat{\\bf c}_{\\bf x} \\approx  {\\bf G}_{np} {\\bf p}\\]\n이 문제는 아래와 같은 회귀모형으로 생각할 수 있다.\n\n\n\n\n\n\n\n\n\n회귀모형\n우리의 문제\n\n\n\n\n모형\n\\({\\bf y} \\approx {\\bf X}{\\boldsymbol \\beta}\\)\n\\(\\hat{\\bf c}_{\\bf x} \\approx {\\bf G}_{np}{\\bf p}\\)\n\n\n설명변수\n\\({\\bf X}\\)19\n\\({\\bf G}_{np}\\)20\n\n\n반응변수\n\\({\\bf y}\\)21\n\\(\\hat{\\bf c}_{\\bf x}\\)22\n\n\n추정하고 싶은 파라메터\n\\({\\boldsymbol \\beta}\\)23\n\\(\\hat{\\bf p}\\)24\n\n\n오차항\n대부분 정규분포를 가정\n??? 모르겠는데??\n\n\n\n회귀분석에서 아래의 수식이 익숙하다면\n\\[\n\\hat{\\boldsymbol \\beta}_{ls} = \\underset{\\boldsymbol \\beta}{\\operatorname{argmin}} \\|{\\bf y}-{\\bf X}{\\boldsymbol \\beta}\\|_2^2=({\\bf X}^T{\\bf X})^{-1}{\\bf X}^T{\\bf y}.\n\\]\n\\({\\bf p}\\)를 추정하기 위한 아래의 수식도 쉽게 이해할 수 있다. (의문: 그런데 왜 MSE를 손실함수로 쓰고 있는 거야? 오차항이 설마 정규분포?)\n\\[\n\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}.\n\\]\n(예제)\n(1) \\({\\bf V}\\)를 정의\n\nN = 100 \nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |> \n    x -> reshape(x,(N,N)) .|> \n    x -> exp(im * (2π/N) * x)\n\n100×100 Matrix{ComplexF64}:\n 1.0+0.0im       1.0+0.0im        …       1.0+0.0im\n 1.0+0.0im  0.998027+0.0627905im     0.998027-0.0627905im\n 1.0+0.0im  0.992115+0.125333im      0.992115-0.125333im\n 1.0+0.0im  0.982287+0.187381im      0.982287-0.187381im\n 1.0+0.0im  0.968583+0.24869im       0.968583-0.24869im\n 1.0+0.0im  0.951057+0.309017im   …  0.951057-0.309017im\n 1.0+0.0im  0.929776+0.368125im      0.929776-0.368125im\n 1.0+0.0im  0.904827+0.425779im      0.904827-0.425779im\n 1.0+0.0im  0.876307+0.481754im      0.876307-0.481754im\n 1.0+0.0im  0.844328+0.535827im      0.844328-0.535827im\n 1.0+0.0im  0.809017+0.587785im   …  0.809017-0.587785im\n 1.0+0.0im  0.770513+0.637424im      0.770513-0.637424im\n 1.0+0.0im  0.728969+0.684547im      0.728969-0.684547im\n    ⋮                             ⋱  \n 1.0+0.0im  0.728969-0.684547im      0.728969+0.684547im\n 1.0+0.0im  0.770513-0.637424im      0.770513+0.637424im\n 1.0+0.0im  0.809017-0.587785im   …  0.809017+0.587785im\n 1.0+0.0im  0.844328-0.535827im      0.844328+0.535827im\n 1.0+0.0im  0.876307-0.481754im      0.876307+0.481754im\n 1.0+0.0im  0.904827-0.425779im      0.904827+0.425779im\n 1.0+0.0im  0.929776-0.368125im      0.929776+0.368125im\n 1.0+0.0im  0.951057-0.309017im   …  0.951057+0.309017im\n 1.0+0.0im  0.968583-0.24869im       0.968583+0.24869im\n 1.0+0.0im  0.982287-0.187381im      0.982287+0.187381im\n 1.0+0.0im  0.992115-0.125333im      0.992115+0.125333im\n 1.0+0.0im  0.998027-0.0627905im     0.998027+0.0627905im\n\n\n(2) \\({\\bf G}_{np}={\\bf V}^{\\ast} \\odot {\\bf V}\\), 여기에서 \\(\\odot\\)은 열별-크로네커곱을 의미한다.\n\n# columnwise_kron은 위에서 정의한적 있음~\nGₙₚ = columnwise_kron(conj(V),V)\n\n10000×100 Matrix{ComplexF64}:\n 1.0+0.0im       1.0+0.0im        …       1.0+0.0im\n 1.0+0.0im  0.998027+0.0627905im     0.998027-0.0627905im\n 1.0+0.0im  0.992115+0.125333im      0.992115-0.125333im\n 1.0+0.0im  0.982287+0.187381im      0.982287-0.187381im\n 1.0+0.0im  0.968583+0.24869im       0.968583-0.24869im\n 1.0+0.0im  0.951057+0.309017im   …  0.951057-0.309017im\n 1.0+0.0im  0.929776+0.368125im      0.929776-0.368125im\n 1.0+0.0im  0.904827+0.425779im      0.904827-0.425779im\n 1.0+0.0im  0.876307+0.481754im      0.876307-0.481754im\n 1.0+0.0im  0.844328+0.535827im      0.844328-0.535827im\n 1.0+0.0im  0.809017+0.587785im   …  0.809017-0.587785im\n 1.0+0.0im  0.770513+0.637424im      0.770513-0.637424im\n 1.0+0.0im  0.728969+0.684547im      0.728969-0.684547im\n    ⋮                             ⋱  \n 1.0+0.0im  0.770513-0.637424im      0.770513+0.637424im\n 1.0+0.0im  0.809017-0.587785im      0.809017+0.587785im\n 1.0+0.0im  0.844328-0.535827im   …  0.844328+0.535827im\n 1.0+0.0im  0.876307-0.481754im      0.876307+0.481754im\n 1.0+0.0im  0.904827-0.425779im      0.904827+0.425779im\n 1.0+0.0im  0.929776-0.368125im      0.929776+0.368125im\n 1.0+0.0im  0.951057-0.309017im      0.951057+0.309017im\n 1.0+0.0im  0.968583-0.24869im    …  0.968583+0.24869im\n 1.0+0.0im  0.982287-0.187381im      0.982287+0.187381im\n 1.0+0.0im  0.992115-0.125333im      0.992115+0.125333im\n 1.0+0.0im  0.998027-0.0627905im     0.998027+0.0627905im\n 1.0+0.0im       1.0+0.0im                1.0+0.0im\n\n\n(3) \\(\\hat{\\bf p}_{ls}=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}\\)\n\nĉₓ = vec(x*x')\np̂ = inv(Gₙₚ' * Gₙₚ) * Gₙₚ' * ĉₓ \n\n100-element Vector{ComplexF64}:\n  0.003314209663374193 - 2.7356277964988863e-19im\n   0.03651843533340838 - 4.01518191768058e-18im\n   0.03433532967764885 + 2.515448157755484e-17im\n 0.0016782856970223292 - 1.0070028487673847e-17im\n   0.10166837790613971 + 3.1129277935880596e-18im\n  0.015421439356883134 + 9.403422807142065e-18im\n  0.025184594035243472 - 3.993782799800785e-18im\n   0.04658258516955039 - 1.850761436988587e-18im\n   0.04658541677045607 + 1.1559103895961936e-17im\n  0.007878013503208905 + 3.559698092088507e-18im\n  0.023337481863133468 + 2.6204945155857973e-18im\n   0.02249381702313939 + 5.304406111488559e-18im\n  0.006724780595702225 - 1.655564138463681e-17im\n                       ⋮\n  0.006724780595702329 + 1.8121162053534517e-18im\n  0.022493817023139205 - 1.0461976779111972e-17im\n   0.02333748186313285 - 6.792203007975684e-18im\n  0.007878013503208907 - 2.3575339315335667e-18im\n  0.046585416770456294 + 1.5392042695643853e-17im\n  0.046582585169550106 - 1.123245521985718e-17im\n  0.025184594035242928 + 1.1628578774983873e-18im\n  0.015421439356883466 + 5.864828990948797e-18im\n   0.10166837790614085 + 2.2712943512935246e-17im\n 0.0016782856970221013 + 4.829637376114682e-18im\n   0.03433532967764831 + 3.3208196889839756e-19im\n  0.036518435333408754 + 1.3795822112205515e-17im\n\n\n\n?? 뭔가 스케일이 안맞음\n\n\nN^2 * p̂\n\n100-element Vector{ComplexF64}:\n  33.14209663374193 - 2.7356277964988864e-15im\n 365.18435333408377 - 4.0151819176805797e-14im\n  343.3532967764885 + 2.515448157755484e-13im\n 16.782856970223293 - 1.0070028487673847e-13im\n 1016.6837790613971 + 3.1129277935880596e-14im\n 154.21439356883135 + 9.403422807142065e-14im\n 251.84594035243472 - 3.9937827998007846e-14im\n  465.8258516955039 - 1.850761436988587e-14im\n  465.8541677045607 + 1.1559103895961937e-13im\n  78.78013503208905 + 3.559698092088507e-14im\n 233.37481863133468 + 2.6204945155857973e-14im\n 224.93817023139388 + 5.304406111488559e-14im\n  67.24780595702225 - 1.655564138463681e-13im\n                    ⋮\n  67.24780595702329 + 1.8121162053534517e-14im\n 224.93817023139206 - 1.0461976779111972e-13im\n  233.3748186313285 - 6.792203007975684e-14im\n  78.78013503208906 - 2.3575339315335666e-14im\n 465.85416770456294 + 1.5392042695643854e-13im\n 465.82585169550106 - 1.123245521985718e-13im\n 251.84594035242927 + 1.1628578774983874e-14im\n 154.21439356883465 + 5.864828990948797e-14im\n 1016.6837790614085 + 2.2712943512935246e-13im\n  16.78285697022101 + 4.8296373761146824e-14im\n  343.3532967764831 + 3.3208196889839758e-15im\n  365.1843533340875 + 1.3795822112205514e-13im\n\n\n\n\\(N^2\\)를 곱해주니까 아까부터 구하던 값이 그대로 잘 나옴. (\\({\\bf DFT}\\) 혹은 \\({\\bf GFT}\\)를 정의할때 \\(\\frac{1}{\\sqrt N}\\)으로 스케일링 하느냐 마느냐 차이때문에 생기는 현상임)"
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#의문점",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#의문점",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "의문점",
    "text": "의문점\n아래의 그림을 살펴보자.\n\n\n\n그림12.3(교재에서 긁어온 그림): Power spectral density estimation. All estimators are based on the same random process defined on the Karate club network [@zachary1977information]. (A) Periodogram estimation with different numbers of observations. (B) Windowed average periodogram from a single realization and a different number of windows. (C) Windowed average periodogram for four windows and a varying number of realizations. (D) Parametric MA estimation for 1 and 10 realizations.\n\n\n이 그림은 다양한 방법으로 true PSD \\({\\bf p}\\)를 추정한 결과를 나타내는 PSD plot 이다25. 우리가 적용한 방법은 (A)에서 \\(R=1\\)일 경우이다. 보는것 처럼 true PSD 를 놀라울 정도로 제대로 추정하지 못한다26. 만약에 우리가 모형에서 하나의 시계열이 아니라 1000개의 정도의 시계열을 관측하였다면 좀 더 합리적으로 추정할 수 있다. 그런데 사실 하나의 모형에서 1000개씩이나 되는 시계열을 관측하는 일은 현실적으로 불가능하다27 따라서 우리는 비교적 적은 \\(R\\)에서 합리적인 PSD의 추정치를 이끌어내야 한다. 그림 (B),(C)는 상대적으로 적은 \\(R\\)에 대해 \\({\\bf p}\\)를 추정하는 windowed periodogram 을 이용하여 PSD를 추정한 결과이다. (C)를 살펴보면 \\(R=1\\) 일경우 \\({\\bf p}\\)를 추정한 값들이 나와있는데 (A)와 비교하면 꽤 합리적으로 보인다.\n문제는 (A)-(C)에서 제안된 방법 모두가 (D)에 제시된 전통적인 방법에 비하여 퍼포먼스가 떨어진다는 것이다. (D)는 parametric 모형을 사용한 결과이다. 파라메트릭 방법이므로 특정 모델을 한정하고 거기에 대응하는 한두개의 모수만 추정하면 되므로 추정이 잘 된다.28 반면 (A)-(C)의 경우 한 두개의 파라메터가 아니라 \\({\\bf p}\\)의 모든 원소를 추정해야하므로 추정할 파라메터가 데이터의 수 \\(N\\)과 같다29. 따라서 추정치의 분산이 크다. 사실 이것은 파라메트릭 방법과 세미파라메트릭 방법이라는 구조적인 차이때문에 어쩔 수 없는 것 같다. 그래도 세미파라메트릭 방법은 머리아프게 모델링을 할 필요가 없고30 내가 적합한 모델이 맞는지 확인할 필요도 없다31는 장점이 있다.\n아래는 나름 PSD를 추정하는 신기술인 것 같다.\n\n\n\n그림12.4(교재에서 긁어온 그림): PSD estimation from a subset of nodes. Estimators are based on a random process defined on the Karate club network [@zachary1977information]. (A) Graph sampling for nonparametric PSD estimation. Here, 20 out of 34 nodes are observed. The sampled nodes are highlighted by the circles around the nodes. (B) Nonparametric PSD estimation based on observations from 20 nodes and 100 data snapshots. (C) Graph sampling for parametric MA PSD estimation. Here, 4 out of 34 nodes are observed. (D) Parametric MA PSD estimation based on observations from 4 nodes and 100 data snapshots.\n\n\n그래프신호의 sub-sampling을 이용하는 것 같은데 교재의 뒤쪽에 서술되어있다. \\(R=100\\)임을 고려하여도 퍼포먼스가 좋은 편인듯 하다32."
  },
  {
    "objectID": "posts/study/prof/2023-01-15-Chap-12.4.html",
    "href": "posts/study/prof/2023-01-15-Chap-12.4.html",
    "title": "Chap 12.4: Node Subsampling for PSD Estimation",
    "section": "",
    "text": "using LinearAlgebra, Plots, FFTW, Statistics\n\n\ncolumnwise_kron = \n(C,D) -> hcat([kron(C[:,i],D[:,i]) for i in 1:size(C)[2]]...)\n\n#49 (generic function with 1 method)\n\n\n\n12.4.1 The Sampling Problem\n아래와 같이 길이가 \\(N=10\\) 인 신호 \\({\\bf x}\\)를 고려하자.\n\nx = rand(10)\n\n10-element Vector{Float64}:\n 0.03235208758206609\n 0.5069925854414447\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n 0.24116013388795854\n 0.8439116925218157\n 0.6362602319916778\n 0.386069828675059\n 0.5313655894235898\n\n\n여기에서 1,3,4,5 번째 원소만 추출하여길이가 \\(K=4\\) 인 신호 \\({\\bf y}\\)를 만들고 싶다.\n\ny = x[[1,3,4,5]]\n\n4-element Vector{Float64}:\n 0.03235208758206609\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n\n\n이 과정은 아래와 같이 수행할 수도 있다.\n\nΦ= [1 0 0 0 0 0 0 0 0 0\n    0 0 1 0 0 0 0 0 0 0\n    0 0 0 1 0 0 0 0 0 0\n    0 0 0 0 1 0 0 0 0 0]\n\n4×10 Matrix{Int64}:\n 1  0  0  0  0  0  0  0  0  0\n 0  0  1  0  0  0  0  0  0  0\n 0  0  0  1  0  0  0  0  0  0\n 0  0  0  0  1  0  0  0  0  0\n\n\n\nΦ*x\n\n4-element Vector{Float64}:\n 0.03235208758206609\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n\n\n즉 적당한 \\(K\\times N\\) selection matrix를 선언하여 subsampling을 수행할 수 있다. 이때 매트릭스 \\({\\bf \\Phi}\\)를 subsampling matrix 혹은 sparse sampling matrix 라고 부른다.\n\n\n12.4.2 Compressed LS Estimator\n\nN = 10\nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |> \n    x -> reshape(x,(N,N)) .|> \n    x -> exp(im * (2π/N) * x) \n\n10×10 Matrix{ComplexF64}:\n 1.0+0.0im        1.0+0.0im          …        1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0+1.22465e-16im  …       -1.0+1.10218e-15im\n 1.0+0.0im  -0.809017-0.587785im        -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n\n\n\nG = columnwise_kron(conj(V),V)\n\n100×10 Matrix{ComplexF64}:\n 1.0+0.0im        1.0+0.0im          …        1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0+1.22465e-16im  …       -1.0+1.10218e-15im\n 1.0+0.0im  -0.809017-0.587785im        -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n 1.0+0.0im   0.809017-0.587785im     …   0.809017+0.587785im\n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n    ⋮                                ⋱  \n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.809017+0.587785im     …   0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0-1.11022e-16im          -1.0+2.27596e-15im\n 1.0+0.0im  -0.809017-0.587785im     …  -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n\n\n- 방법1\n\nĉx = vec(x*x')\np̂ = inv(G' * G) * G' * ĉx\n\n10-element Vector{ComplexF64}:\n    0.25854107856772546 + 2.245922875954761e-20im\n   0.004743491121735806 - 1.3138893409553828e-18im\n   0.006946482731189413 - 9.791191432641327e-19im\n   0.001721693617954179 - 1.9827974128203887e-18im\n   0.011344167525098774 + 2.6827005818057562e-19im\n 0.00012662617844242917 - 3.748573865136995e-20im\n   0.011344167525098762 + 2.7448152053954017e-18im\n  0.0017216936179541913 - 9.35534609073096e-19im\n   0.006946482731189404 + 1.954408900185458e-18im\n   0.004743491121735756 - 2.561030398375897e-18im\n\n\n- 방법2\n\nĉy = vec(y*y')\np̂ = (kron(Φ,Φ)*G)' * ĉy\n\n10-element Vector{ComplexF64}:\n   3.759462826821233 + 0.0im\n   2.765185174577697 - 2.0816681711721685e-17im\n   1.077337414764992 + 2.7755575615628914e-17im\n 0.11594812606807317 + 2.0816681711721685e-17im\n 0.08838298603932843 + 3.903127820947816e-17im\n 0.32863702713833354 + 4.622231866529366e-33im\n 0.08838298603932859 + 9.540979117872439e-18im\n  0.1159481260680729 - 2.0816681711721685e-17im\n  1.0773374147649915 + 0.0im\n  2.7651851745776965 - 2.0816681711721685e-17im"
  },
  {
    "objectID": "posts/study/prof/2022-12-26-Chap-12.2.html",
    "href": "posts/study/prof/2022-12-26-Chap-12.2.html",
    "title": "Chap 12.2: Weakly Stationary Graph Processes",
    "section": "",
    "text": "using LinearAlgebra, DSP"
  },
  {
    "objectID": "posts/study/prof/2022-12-26-Chap-12.2.html#simultaneously-diagonalizable",
    "href": "posts/study/prof/2022-12-26-Chap-12.2.html#simultaneously-diagonalizable",
    "title": "Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Simultaneously Diagonalizable",
    "text": "Simultaneously Diagonalizable\n매트릭스 \\({\\bf A}\\)와 \\({\\bf B}\\)가 대각화 가능하다는 것은 아래의 표현을 만족하는 적당한 invertible matrix \\({\\bf \\Psi}_A\\), \\({\\bf \\Psi}_B\\)와 대각행렬 \\({\\bf \\Lambda}_A\\), \\({\\bf \\Lambda}_B\\)가 존재한다는 의미가 된다.\n\\[{\\bf A} = {\\bf V}_{A} {\\bf \\Lambda}_A {\\bf V}_{A}^{-1}\\]\n\\[{\\bf B} = {\\bf V}_{B} {\\bf \\Lambda}_B {\\bf V}_{B}^{-1}\\]\n그리고 만약에 \\({\\bf V}_{A}={\\bf V}_{B}\\)이라면 즉\n\\[{\\bf A} = {\\bf V} {\\bf \\Lambda}_A {\\bf V}^{-1}\\]\n\\[{\\bf B} = {\\bf V} {\\bf \\Lambda}_B {\\bf V}^{-1}\\]\n이라면 \\(\\{{\\bf A},{\\bf B}\\}\\)가 simultaneously diagonalzable 하다고 표현한다."
  },
  {
    "objectID": "posts/study/prof/2022-12-26-Chap-12.2.html#commute",
    "href": "posts/study/prof/2022-12-26-Chap-12.2.html#commute",
    "title": "Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Commute",
    "text": "Commute\n두 matrix \\({\\bf A}\\)와 \\({\\bf B}\\)에 대하여\n\\[{\\bf A}{\\bf B}= {\\bf B}{\\bf A}\\]\n인 관계가 성립하면 두 매트릭스가 commute 한다고 표현한다. 그런데 \\({\\bf A}{\\bf B}={\\bf A}{\\bf B}\\)의 조건은 \\({\\bf A}, {\\bf B}\\)가 동시대각화가능할 (simultaneously diagonalzable) 조건과 같다. 1 따라서 simultaneously diagonalzable 는 commute와 같은 말이라 생각해도 무방하다.\n\n참고: 위키피디아.."
  },
  {
    "objectID": "posts/study/prof/2022-12-26-Chap-12.2.html#shift-invariant-filter",
    "href": "posts/study/prof/2022-12-26-Chap-12.2.html#shift-invariant-filter",
    "title": "Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Shift Invariant Filter",
    "text": "Shift Invariant Filter\n\nref: @djuric2018cooperative Chap 8.3 의 내용 중 일부\n\nDefine the matrix \\({\\bf B}\\) as periodic shift matrix such that\n\\[\n{\\bf B} = \\begin{bmatrix}\n0 & 0 & 0 & \\dots  & 0 & 1 \\\\\n1 & 0 & 0 & \\dots & 0 & 0 \\\\\n0 & 1 & 0 & \\dots & 0 & 0 \\\\\n\\dots & \\dots & \\dots & \\dots & \\dots & \\dots\\\\\n0 & 0 & \\dots & 1 & 0 & 0 \\\\\n0 & 0 & \\dots & 0 & 1 & 0 \\\\\n\\end{bmatrix}.\\]\nA generic filter \\({\\boldsymbol h}\\) is given by its \\(z\\)-transform\n\\[h(z)=h_0z^0+h_1z^{-1}+\\cdots +h_{N-1}z^{-(N-1)}\\]\nwhere \\(s_{n-1}=z^{-1}s_n\\). In vector notation, and with respect to the standard basis \\({\\bf I}\\), the filter is represented by the matrix \\({\\bf H}\\), a polynomial in the cyclic shift\n\\[{\\bf H}=h({\\bf B})=h_0{\\bf B}^0+h_1{\\bf B}^1+\\cdots+h_{N-1}{\\bf B}^{N-1}.\\]\nFilters are shift invariant iff\n\\[z\\cdot h(z) = h(z)\\cdot z\\]\nor from the matrix representation\n\\[{\\bf B}h({\\bf B})=h({\\bf B}){\\bf B}.\\]\nExample\nLet \\({\\bf B}\\) as\n\nB= [0 1 0 0 0 0 0\n    0 0 1 0 0 0 0 \n    0 0 0 1 0 0 0 \n    0 0 0 0 1 0 0 \n    0 0 0 0 0 1 0 \n    0 0 0 0 0 0 1 \n    1 0 0 0 0 0 0]\n\n7×7 Matrix{Int64}:\n 0  1  0  0  0  0  0\n 0  0  1  0  0  0  0\n 0  0  0  1  0  0  0\n 0  0  0  0  1  0  0\n 0  0  0  0  0  1  0\n 0  0  0  0  0  0  1\n 1  0  0  0  0  0  0\n\n\nDefine \\({\\boldsymbol h}\\) as\n\nh = [1/3,1/3,1/3]\n\n3-element Vector{Float64}:\n 0.3333333333333333\n 0.3333333333333333\n 0.3333333333333333\n\n\nFurthermore define \\({\\bf H}=h({\\bf B})=h_0{\\bf B}^0+h_1{\\bf B}^1+h_2{\\bf B}^2\\)\n\nH = (1/3)*B^0 + (1/3)*B^1 + (1/3)*B^2 \n\n7×7 Matrix{Float64}:\n 0.333333  0.333333  0.333333  0.0       0.0       0.0       0.0\n 0.0       0.333333  0.333333  0.333333  0.0       0.0       0.0\n 0.0       0.0       0.333333  0.333333  0.333333  0.0       0.0\n 0.0       0.0       0.0       0.333333  0.333333  0.333333  0.0\n 0.0       0.0       0.0       0.0       0.333333  0.333333  0.333333\n 0.333333  0.0       0.0       0.0       0.0       0.333333  0.333333\n 0.333333  0.333333  0.0       0.0       0.0       0.0       0.333333\n\n\nObserve following:\n\nB*H == H*B \n\ntrue\n\n\nThus, filter \\({\\boldsymbol h}\\) is shift invariant filter and matrix \\({\\bf H}\\) is shift invariant operator.\nnote: \\({\\boldsymbol h}\\) is moving average filter.\nnote: for any \\({\\bf x}\\), \\({\\bf H}{\\bf x}\\) is definded by\n\\[\\left[\\frac{x_{n-1}+x_n+x_1}{3},\\frac{x_n+x_1+x_2}{3},\\dots,\\frac{x_{n-3}+x_{n-2}+x_n}{3}\\right].\\]\n\nx = [1,1,1,1,2,2,2]\nH*x\n\n7-element Vector{Float64}:\n 1.0\n 1.0\n 1.3333333333333333\n 1.6666666666666665\n 2.0\n 1.6666666666666665\n 1.3333333333333333\n\n\nnote: In some sense, the matrix \\({\\bf H}{\\bf x}\\) can be thought as generalized version of \\({\\boldsymbol h}\\star {\\bf x}\\) where \\(\\star\\) is convolution up to shift\n\nconv(h,x)\n\n9-element Vector{Float64}:\n 0.3333333333333334\n 0.6666666666666667\n 1.0\n 1.0\n 1.3333333333333333\n 1.6666666666666667\n 2.0\n 1.3333333333333333\n 0.6666666666666667\n\n\nFinally, we observe that, from the Cayley-Hamilton Theorem, \\({\\bf B}\\) satisfies its characteristic polynomial \\(\\Delta({\\bf B})\\), where \\(\\Delta(\\lambda)\\) is the determinant of \\(\\lambda{\\bf I}-{\\bf B}\\). The characteristic polynomial \\(\\Delta({\\bf B})\\) has degree \\(N\\), so, in DSP, as described so far, linear filters are (matrix) polynomial with degree at most \\(N-1\\).\n\n이 부분은 책에 써있길래 가져오긴 했는데, 무슨 의미인지 모르겠음"
  },
  {
    "objectID": "posts/study/prof/2022-12-26-Chap-12.2.html#coexisting-approaches",
    "href": "posts/study/prof/2022-12-26-Chap-12.2.html#coexisting-approaches",
    "title": "Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Coexisting Approaches",
    "text": "Coexisting Approaches\nStationary graph processes were first defined and analyzed in [@girault2015stationary]. The fundamental problem identified there is that GSOs do not preserve energy in general and therefore cannot be isometric [@gavili2017shift]. This problem is addressed in [@girault2015translation] with the definition of an isometric graph shift that preserves the eigenvector space of the Laplacian GSO but modifies its eigenvalues.\nA stationary graph process is then defined as one whose probability distributions are invariant with respect to multiplications with the isometric shift. One drawback of this approach is that the isometric shift is a complex-valued operator and has a sparsity structure (if any) different from \\({\\bf S}\\). By contrast, the vertex-based definition in\n\\[\\mathbb{E} \\bigg[ \\big({\\bf S}^a{\\bf x}\\big)\\Big(\\big({\\bf S}^H)^b {\\bf x}\\Big)^H  \\bigg]=\\mathbb{E}\\bigg[\\big({\\bf S}^{a+c}{\\bf x}\\big)\\Big(\\big({\\bf S}^H\\big)^{b-c}{\\bf x} \\Big)^H \\bigg]\\]\nis based on the original GSO \\({\\bf S}\\), which is local and real-valued. As a result, above Eq. provides intuition on the relations between stationarity and locality, which can be leveraged to develop stationarity tests or estimation schemes that work with local information. Graph stationarity was also studied in [@perraudin2017stationary] where the requirement of having a covariance matrix diagonalizable by the eigenvectors of the Laplacian GSO is adopted as a definition. This condition is shown to be equivalent to statistical invariance with respect to the translation operator introduced in [@shuman2016vertex]. When the shift \\({\\bf S}\\) coincides with the Laplacian of the graph and the eigenvalues of \\({\\bf S}\\) are all distinct, Definitions 12.1 and 12.2 are equivalent to those in [@girault2015stationary,@perraudin2017stationary]. Hence, the definitions presented here differ from [@perraudin2017stationary] in that we consider general normal shifts instead of Laplacians and that we see Definition 12.1 as a definition, not a property. These are mathematically minor differences that are important in practice though; see [@marques2017stationary,@segarra2017network] for more details."
  },
  {
    "objectID": "posts/study/2023-02-24-Chap8.3.html",
    "href": "posts/study/2023-02-24-Chap8.3.html",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "",
    "text": "using LinearAlgebra, FFTW"
  },
  {
    "objectID": "posts/study/2023-02-24-Chap8.3.html#cyclic-shift-operator-bfb",
    "href": "posts/study/2023-02-24-Chap8.3.html#cyclic-shift-operator-bfb",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Cyclic shift operator \\(\\bf{B}\\)",
    "text": "Cyclic shift operator \\(\\bf{B}\\)\nThe matrix \\(\\bf{B}\\) representing the periodic shift is\n\nB= [0 0 0 0 1\n    1 0 0 0 0 \n    0 1 0 0 0\n    0 0 1 0 0\n    0 0 0 1 0]\n\n5×5 Matrix{Int64}:\n 0  0  0  0  1\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n\n\nThis matrix is cyclic shift\nnote: \\(\\bf{B}\\) is orthogonal matrix (직교행렬: 전치행렬이 역행렬인 행렬 \\(\\bf{A}\\bf{A}'=\\bf{A}'\\bf{A}=\\bf{I}\\))\n\nCyclic shift가 뭔지는 모르겠지만 뭔가 모양새가 단위행렬을 한 칸씩 뒤에서 앞으로 밀어놓은 느낌이다.\n\n\nWhat is Cyclic shift?\nref: Cyclic shift의 개념\na circular shift is the operation of rearranging the entries in a tuple, either by moving the final entry to the first position, while shifting all other entries to the next position, or by performing the inverse operation. A circular shift is a special kind of cyclic permutation, which in turn is a special kind of permutation.\n위를 요약하자면 조합론에서 순환이동이란 튜플의 항목을 재정렬하는 작업이라고 한다. 마지막 element를 첫번째 위치로 이동하고 다른 모든 element들은 다음 위치로 이동하는 것.\n\n예를들어 (a, b, c, d)에 ciclic shift를 반복적으로 적용하면 다음과 같다.\n\n0 \\((a, b, c, d)\\) # before cyclic shift (origin)\n1 \\((d, a, b, c)\\) # 1step\n2 \\((c, d, a, b)\\) # 2step\n3 \\((b, c, d, a)\\) # 3step\n4 \\((a, b, c, d)\\) # 4step –> origin\n\ncyclic shift를 4번 반복하니까 원래 변환 전 원래 튜플로 돌아왔다.\n\n\n예제\n\nB # 1 cyclic shift\n\n5×5 Matrix{Int64}:\n 0  0  0  0  1\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n\n\n\nB'B # B는 orthogonal matrix니까 B'B = I일 것.\n\n5×5 Matrix{Int64}:\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n 0  0  0  0  1\n\n\n- (ex1) Define \\(s\\) as\n\ns = [1,2,3,4,5] ## origin\ns\n\n5-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n\n\n\nB*s\n\n5-element Vector{Int64}:\n 5\n 1\n 2\n 3\n 4\n\n\n결과: \\([1,2,3,4,5] \\to [5,1,2,3,4]\\)\n\n맨 뒤에 5가 앞으로 나오고 나머지 값들은 한칸씩 뒤로 밀렸다.\n위에서 배운대로라면 5번 쉬프트되면 자기자신으로 돌아오지 않을까?\n\n- \\(\\bf{B}^2\\) 에 \\(s\\)를 곱하면?\n\nB^2  # 2 cyclic shift\n\n5×5 Matrix{Int64}:\n 0  0  0  1  0\n 0  0  0  0  1\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n\n\n\nB^2*s\n\n5-element Vector{Int64}:\n 4\n 5\n 1\n 2\n 3\n\n\n결과: \\([1,2,3,4,5] \\to [5,1,2,3,4] \\to [4,5,1,2,3]\\)\n- \\(\\bf{B}^5\\)에 \\(s\\)를 곱하면?\n예상대로라면 원래 \\(s\\)인 \\([1,2,3,4,5]\\)로 돌아올 것 같다.\n\nB^5*s\n\n5-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n\n\nThus we can interprete the matrix \\(\\bf{B}\\) as cyclic shift operator such that\n\\[\\bf{B}_n = s_{n-1}\\]\nfor \\(n = 1,\\dots,N-1\\) and \\(\\bf{B}_{s_0}=s_N\\)\nnote : \\(\\bf{B}\\)는 시계열에서 다루는 backshift operator과 비슷함.\n(참고) backshift operator(후방이동) 연산자 \\(\\bf{B}\\)는 시계열 시차를 다룰 때 유용한 표기법 장치이다. (\\(B_{y_t} = y_{t-1})\\)\n시차변수 만들 때 완전 꿀팁인듯?"
  },
  {
    "objectID": "posts/study/2023-02-24-Chap8.3.html#dft",
    "href": "posts/study/2023-02-24-Chap8.3.html#dft",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "DFT",
    "text": "DFT\nThe matrix \\(\\bf{B}\\) can be expressed as\n\\(\\bf{B} = DFT^* \\cdot \\Lambda \\cdot DFT\\)\nwhere DFT is unitary and symmetric matrix and \\(\\Lambda\\) is diagonal matrix."
  },
  {
    "objectID": "posts/study/2023-02-24-Chap8.3.html#spectral-components-and-frequencies",
    "href": "posts/study/2023-02-24-Chap8.3.html#spectral-components-and-frequencies",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Spectral components and Frequencies",
    "text": "Spectral components and Frequencies\nwe remark:\n(1) Spectral components: For \\(k = 0,1,2,\\dots, N-1\\), the \\(k\\)-th column of \\({\\bf DFT}^\\ast\\) is defined by\n\\[\\Psi_k:=\\frac{1}{\\sqrt{N}}\\begin{bmatrix} 1 \\\\ e^{j\\frac{2\\pi}{N}k} \\\\ e^{j\\frac{2\\pi}{N}2k} \\\\ e^{j\\frac{2\\pi}{N}3k} \\\\  \\dots \\\\ e^{j\\frac{2\\pi}{N}(N-1)k} \\end{bmatrix}.\\]\nNote that \\(\\Psi_k\\) can be also interpreted as \\(\\ell\\)-th eigenvector of \\({\\bf A}\\) correspoding \\(\\lambda_\\ell = e^{-j\\frac{2\\pi}{N}k}\\). Those eigenvectors\n\\[\\big\\{{\\bf 1},\\Psi_1,\\Psi_2, \\dots, \\Psi_{N-1}\\big\\}\\]\nform a complete orthonomal basis of \\(\\mathbb{C}^N\\). These vectors are called spectral components.\n(2) Frequencies: The diagonal entries of \\({\\bf \\Lambda}\\) are the eigenvalues of the time shift \\({\\bf B}\\). In Physics and in operator theory, these eigenvalues are the frequencies of the signal. In DSP it is more common to call frequencies\n\\[\\Omega_k=\\frac{-1}{2\\pi j}\\ln\\lambda_k=\\frac{-1}{2\\pi j}\\ln e^{-j \\frac{2\\pi}{N}k}=\\frac{k}{N}, \\quad k=0,1,2,\\dots,N-1.\\]"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn4.html",
    "href": "posts/RNN/2023-02-28-rnn4.html",
    "title": "순환신경망 (4)",
    "section": "",
    "text": "RNN (2)-AbAcAd예제(3)"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn4.html#data",
    "href": "posts/RNN/2023-02-28-rnn4.html#data",
    "title": "순환신경망 (4)",
    "section": "data",
    "text": "data\n- 기존의 정리방식\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5], txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))).float()\n\n\nx,y\n\n(tensor([[1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         ...,\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.]]),\n tensor([[0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         ...,\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.]]))"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html",
    "href": "posts/RNN/2023-02-25-rnn2.html",
    "title": "순환신경망 (2)",
    "section": "",
    "text": "순환신경망 intro(2)- abc예제, abdc예제, AbAcAd예제(1)"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#data",
    "href": "posts/RNN/2023-02-25-rnn2.html#data",
    "title": "순환신경망 (2)",
    "section": "data",
    "text": "data\n\ntxt = list('abc')*100\ntxt[:10]\n\n['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'a']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5], txt_y[:5]\n\n(['a', 'b', 'c', 'a', 'b'], ['b', 'c', 'a', 'b', 'c'])"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#하나의-은닉노드를-이용한-풀이---억지로-성공",
    "href": "posts/RNN/2023-02-25-rnn2.html#하나의-은닉노드를-이용한-풀이---억지로-성공",
    "title": "순환신경망 (2)",
    "section": "하나의 은닉노드를 이용한 풀이 - 억지로 성공",
    "text": "하나의 은닉노드를 이용한 풀이 - 억지로 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2}\nx = torch.tensor(f(txt_x, mapping))\ny = torch.tensor(f(txt_y, mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 0, 1]), tensor([1, 2, 0, 1, 2]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=3, embedding_dim=1), # 3? -> a,b,c // 1?->은닉층의 노드개수를 1로 설정\n    torch.nn.Tanh(),\n    #==#\n    torch.nn.Linear(in_features=1, out_features=3)\n)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    ## 2\n    loss = loss_fn(net(x),y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nsoft(net(x))[:5] \n\ntensor([[7.7743e-02, 8.4444e-01, 7.7818e-02],\n        [5.2772e-05, 7.6005e-02, 9.2394e-01],\n        [9.2247e-01, 7.7472e-02, 5.5484e-05],\n        [7.7743e-02, 8.4444e-01, 7.7818e-02],\n        [5.2772e-05, 7.6005e-02, 9.2394e-01]], grad_fn=<SliceBackward0>)\n\n\n\nnet[:2]\n\nSequential(\n  (0): Embedding(3, 1)\n  (1): Tanh()\n)\n\n\n\nnet[:2](x)[:5]\n#net[:-1](x)[:5]\n#net[1](net[0](x))[:5]\n\ntensor([[-0.0147],\n        [ 0.9653],\n        [-0.9896],\n        [-0.0147],\n        [ 0.9653]], grad_fn=<SliceBackward0>)\n\n\n- 결과해석\n처음에 두 layer를 통과시킨 값들이 어떤 값을 가질지 조사해보자.\n\nhidden = net[:-1](x).data # 처음 2개의 layer 통과\nyhat = soft(net(x)).data # hidden에 softmax 취한 것.\n\n\nplt.plot(hidden[:9],'--o')\n\n\n\n\n2번째 layer(hidden layer)까지 통과하고 한번 더 linear transform을 거치게 되면 여기 있는 하나의 값이 3개로 잘라지는데 잘라진 3개를 각각 플랏하면 다음과 같다.\n\nnet(x)[:5]\n\ntensor([[-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086],\n        [ 3.0875,  0.6104, -6.6312],\n        [-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086]], grad_fn=<SliceBackward0>)\n\n\n\nplt.plot(net(x).data[:9],'--o') # 파(a)->주(b)->초(c) 순서로 값들이 나타남.\n\n\n\n\n\n\\(x= a,b,c,a,b,c\\dots\\)\n\\(y = b,c,a,b,c,a\\dots\\)\n주황색 선의 학습상태가 썩 마음에 들지 않는다. 초록색은 확실하게 초록색, 파란색은 확실하게 파란색인데 주황색은 딱히 그런게 없다.\n약간 그런느낌 파란색도 아니고 초록색도 아니니까 얘(주황)로 하지\n\n\nplt.plot(yhat[:9],'--o')\n#plt.plot(soft(net(x)).data[:9],'--o')\n\n\n\n\n\nyhat[:5] # b일확률이 84%.. (주->b일확률, 초->c일확률, 파->a일확률)\n\ntensor([[7.7743e-02, 8.4444e-01, 7.7818e-02],\n        [5.2772e-05, 7.6005e-02, 9.2394e-01],\n        [9.2247e-01, 7.7472e-02, 5.5484e-05],\n        [7.7743e-02, 8.4444e-01, 7.7818e-02],\n        [5.2772e-05, 7.6005e-02, 9.2394e-01]])\n\n\n\ny[:5]\n\ntensor([1, 2, 0, 1, 2])\n\n\n\n억지로 맞추고 있긴한데 파라메터가 부족해보인다."
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#결과시각화1-위와-똑같은-그림임",
    "href": "posts/RNN/2023-02-25-rnn2.html#결과시각화1-위와-똑같은-그림임",
    "title": "순환신경망 (2)",
    "section": "- 결과시각화1 (위와 똑같은 그림임)",
    "text": "- 결과시각화1 (위와 똑같은 그림임)\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$', size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x)(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h, net(x),\\hat{y}$\", size=20)\nplt.tight_layout()\n\n\n\n\n\nhidden[:9], (net[-1].weight).T, net[-1].bias.data\n\n(tensor([[-0.0147],\n         [ 0.9653],\n         [-0.9896],\n         [-0.0147],\n         [ 0.9653],\n         [-0.9896],\n         [-0.0147],\n         [ 0.9653],\n         [-0.9896]]),\n tensor([[-4.6804,  0.3071,  5.2894]], grad_fn=<PermuteBackward0>),\n tensor([-1.5440,  0.9143, -1.3970]))\n\n\n\n(파랑, 주황, 초록) 순서로 그려짐\n파랑 = hidden * (-4.6804) + (-1.5440)\n주황 = hidden * (0.3071) + (0.9143) ## 상대적으로 weight, bias가 어정쩡\n초록 = hidden * (5.2894) + (-1.3970)\n\n초록색과 파란색에 대한 클래스는 확실하게 특징을 파악해서 잘 학습한 것 같은데 주황색은 그냥 초록색과 파란색이 아니기 때문에 주황색인 느낌이다.\n- 내부동작을 잘 뜯어보니까 사실 엉성해. 엄청 위태위태하게 맞추고 있었음.\n\nweight: 파랑과 초록을 구분하는 역할을 함.\nweight + bias: 뭔가 교묘하게 에매한 주황값을 만들어서 에매하게 ’b’라고 나올 확률을 학습시킨다. \\(\\to\\) 사실 학습하는 것 같지 않고 때려맞추는 느낌, 쓸 수 있는 weight가 한정적이라서 생기는 현상 (양수, 음수, 0)\n\n\n참고: torch.nn.Linear()의 비밀?\n\n사실 \\(y=x\\bf{W}+b\\) 꼴에서의 \\(\\bf{W}\\)와 \\(b\\)가 저장되는게 아니다.\n\\(y =x\\bf{A}^T+b\\)꼴에서의 \\(\\bf{X}\\)와 \\(b\\)가 저장된다.\n\\(\\bf{W}=\\bf{A}^T\\) 인 관계에 있으므로 l1.weight가 우리자 생각하는 \\(\\bf{W}\\)로 해석하려면 사실 transpose를 취해줘야 한다.\n\n왜 이렇게..?\n\n계산의 효율성 때문 (numpy의 구조를 알아야함)\n\\(x,y\\)는 수학적으로는 col-vec이지만 메모리에 저장할 시에는 row-vec로 해석하는 것이 자연스럽다. (사실 메모리는 격자모양으로 되어있지 않음)"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#결과시각화2",
    "href": "posts/RNN/2023-02-25-rnn2.html#결과시각화2",
    "title": "순환신경망 (2)",
    "section": "- 결과시각화2",
    "text": "- 결과시각화2\n똑같은 내용을 다른방식으로 시각화 한 것임.\n\ncombined = torch.concat([hidden, net(x).data, yhat],axis=1)\n\n\nplt.matshow(combined[:15], vmin=-15, vmax=15, cmap='bwr')\nplt.xticks(range(7), labels=[r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$'], size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\", size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\nsoftmax를 취하기 전단계인 net(x)(2열4열)에서 가장 빨간색인 부분만 살아남아 빨간색(57열)이 되고, 나머지 부분은 흰색으로 바뀌게 된다.\n위의 그림에서 첫번째 행에서 2~4번째 열을 보면 에매한 파란색, 에매한 빨간색으로 b가 되는 느낌."
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#data-1",
    "href": "posts/RNN/2023-02-25-rnn2.html#data-1",
    "title": "순환신경망 (2)",
    "section": "data",
    "text": "data\n\ntxt = list('abcd')*100\ntxt[:10]\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'a', 'b']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5], txt_y[:5]\n\n(['a', 'b', 'c', 'd', 'a'], ['b', 'c', 'd', 'a', 'b'])"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#하나의-은닉노드를-이용한-풀이---억지로-성공-1",
    "href": "posts/RNN/2023-02-25-rnn2.html#하나의-은닉노드를-이용한-풀이---억지로-성공-1",
    "title": "순환신경망 (2)",
    "section": "하나의 은닉노드를 이용한 풀이 - 억지로 성공",
    "text": "하나의 은닉노드를 이용한 풀이 - 억지로 성공\n- 데이터 정리\n\nmapping = {'a':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))\n\n\n- 학습\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4, embedding_dim=1),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1, out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nnet[0].weight.data = torch.tensor([[-0.3333],[-2.5000],[5.0000],[0.3333]])\n\nnet[-1].weight.data = torch.tensor([[1.5000],[-6.0000],[-2.0000],[6.0000]])\nnet[-1].bias.data = torch.tensor([0.1500, -2.0000,  0.1500, -2.000])\n\n\nnet[0]\n\nEmbedding(4, 1)\n\n\n\nfor epoc in range(5000):\n    ## 1\n    ## 2\n    loss = loss_fn(net(x),y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n\n주황색과 빨간색을 특징을 잘 파악했는데 녹색과 파란색은 좀 에매하게 특징을 파악했지만 어쩌다보니 결과는 잘 나옴.\n\n\n\n- 결과시각화2\n\ncombined = torch.concat([hidden, net(x).data, yhat], axis=1)\ncombined.shape\n\ntorch.Size([399, 9])\n\n\n\nplt.matshow(combined[:15],vmin=-15,vmax=15,cmap='bwr')\nplt.xticks(range(9), labels=[r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#두개의-은닉노드를-이용한-풀이---깔끔한-성공",
    "href": "posts/RNN/2023-02-25-rnn2.html#두개의-은닉노드를-이용한-풀이---깔끔한-성공",
    "title": "순환신경망 (2)",
    "section": "두개의 은닉노드를 이용한 풀이 - 깔끔한 성공",
    "text": "두개의 은닉노드를 이용한 풀이 - 깔끔한 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=2), # 은닉노드 2개\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n(맨 왼쪽 그림) 2개의 노드를 썼으니까 파랑이와 주황색선 두개가 보인다. - h dimension \\((n,1)\\to(n,2)\\) - 주황이가 확실히 1, -1 호불호가 갈려서 학습이 된다. - 파랑이도 1, -1 두가지로 갈려서 학습이 된다.\n맨 왼쪽그림에서 적당한 선형변환을 통해 2번째 그림을 만들어야 하고, 여기서 3번째 그림을 만들어야 한다. - 가장 오른쪽 그림의 출력결과만 봐도 매우 깔끔하게 나온다! - 높은 확률로 깔끔하게 예측하고 있음을 볼 수 있다.\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([399, 10])\n\n\n\nplt.matshow(combined[:15],vmin=-7,vmax=7,cmap='bwr')\nplt.xticks(range(10), labels=[r'$h$',r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\n\nhidden layer는 \\(-1\\sim 1\\) 값을 가질 수 있다.\n\n파,빨 \\(\\to\\) b\n파,파 \\(\\to\\) c\n빨,파 \\(\\to\\) d\n빨,빨 \\(\\to\\) a\n\n\n이런식으로 hidden layer에 있는 특징들도 결과를 해석하기에 좋은 형태로 잘 학습되어 있다.\n\n빨간색일수록 근거가 뚜렷함. 특징이 그전에 비해서 굉장히 명확하게 학습이 되고 있다는 것을 알 수 있다.\n그 전에는 b와 d는 특징을 잘 파악하고 있는데 a,c는 약간 에매했지만 이번에는 a,b,c,d의 특징들을 잘 이해하고 맞추는 것처럼 느껴진다."
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#data-2",
    "href": "posts/RNN/2023-02-25-rnn2.html#data-2",
    "title": "순환신경망 (2)",
    "section": "data",
    "text": "data\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#두개의-은닉노드를-이용한-풀이---실패",
    "href": "posts/RNN/2023-02-25-rnn2.html#두개의-은닉노드를-이용한-풀이---실패",
    "title": "순환신경망 (2)",
    "section": "두개의 은닉노드를 이용한 풀이 - 실패",
    "text": "두개의 은닉노드를 이용한 풀이 - 실패\n- 데이터정리\n\nmapping = {'A':0, 'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x, mapping))\ny = torch.tensor(f(txt_y, mapping))\nx[:5], y[:5]\n\n(tensor([0, 1, 0, 2, 0]), tensor([1, 0, 2, 0, 3]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4, embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2, out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat, y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([599, 10])\n\n\n\nplt.matshow(combined[:15],vmin=-5,vmax=5,cmap='bwr')\nplt.xticks(range(10), labels=[r'$h$',r'$h$',r'$y=A?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=A)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\n\n\\(x = \\text{AbAcAd}\\dots\\)\n\\(y = \\text{bAcAdA}\\dots\\)\n\n결국 A의 자리만 잘 찾고 b,c,d끼리는 구분을 잘 못하는 느낌이다. (1/3확률로 찍는 느낌)\n히든노드를 2개로 하고 잘 한 것 같은데 왜 이런 결과가 나올까?\n\n\n\nimage.png\n\n\n데이터를 살펴보자. 보니까 A->b, A->c, A->d ??? A다음에 뭐가 나올지 맞출 수가 없다.\n\n인간은 추론해서 맞출 수 있겠지만 컴퓨터는 데이터를 바로 직전에 있는 character만 보고 다음을 예측하게끔 우리가 데이터셋을 구성해서 x,y로 줬다.\n그런데 사실은 바로 직전이 아니고 그 직전에 직전도 보고 뭔가 이렇게 좀 여러개를 이제 봐야한다는 것이다.\n해결책? 한칸을 더 보게하면 된다. but 엄밀히 말하면 해결이 아님!\n\n실패\n- 실패를 해결하는 순진한 접근방식: 위 문제를 해결하기 위해서는 아래와 같은 구조로 데이터를 다시 정리하면 될 것이다.\n\n\n\nx\ny\n\n\n\n\nA,b\nA\n\n\nb,A\nc\n\n\nA,c\nA\n\n\nc,A\nd\n\n\nA,d\nA\n\n\nd,A\nb\n\n\nA,b\nA\n\n\nb,A\nc\n\n\n\\(\\cdots\\)\n\\(\\cdots\\)\n\n\n\n- 순진한 접근방식의 비판\n\n결국 정확하게 직전 2개의 문자를 보고 다음 문제를 예측하는 구조\n만약에 직전 3개의 문자를 봐야하는 상황이 된다면 또 다시 코드를 수정해야함.\n그리고 실전에서는 직전 몇 개의 문자를 봐야하는지 모름.\n\n앞에있는 2개, 3개, 4개.. 이러한 구조를 반영할 수 있는 새로운 네트워크를 고안해냈는데 그것은 바로 순환신경망이다.\n지금까지는 순환신경망의 필요성에 대해 알아보았던 것!\n이것에 대한 해결책은 순환신경망이다.(NEXT)"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#도전1-은닉노드-2개",
    "href": "posts/RNN/2023-02-25-rnn2.html#도전1-은닉노드-2개",
    "title": "순환신경망 (2)",
    "section": "도전1 (은닉노드 2개)",
    "text": "도전1 (은닉노드 2개)\n\nmapping = {'a':0,'b':1,'c':2,'d':3,'e':4}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 4]), tensor([1, 2, 3, 4, 0]))\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=5,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=5)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([499, 12])\n\n\n\nplt.matshow(combined[:15],vmin=-7,vmax=7,cmap='bwr')\nplt.xticks(range(12), labels=[r'$h$',r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$y=d?$', r'$y=e?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$',r'$P(y=e)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\n\n실패"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#도전2-은닉노드-3개",
    "href": "posts/RNN/2023-02-25-rnn2.html#도전2-은닉노드-3개",
    "title": "순환신경망 (2)",
    "section": "도전2 ( 은닉노드 3개)",
    "text": "도전2 ( 은닉노드 3개)\n\nmapping = {'a':0,'b':1,'c':2,'d':3,'e':4}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 4]), tensor([1, 2, 3, 4, 0]))\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=5,embedding_dim=3),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=3,out_features=5)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([499, 13])\n\n\n\nplt.matshow(combined[:15],vmin=-5,vmax=5,cmap='bwr')\nplt.xticks(range(13), labels=[r'$h$',r'$h$',r'$h$',\n                              r'$y=A?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$y=e?$',\n                              r'$P(y=A)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$',r'$P(y=e)$'],size=13)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\na,b,c,d,e를 표현함에 있어서 3개의 은닉노드면 충분하다.\n\n1개의 은닉노드 \\(\\to\\) 2개의 문자를 표현할 수 있음\n2개의 은닉노드 \\(\\to\\) 4개의 문자를 표현할 수 있음\n3개의 은닉노드 \\(\\to\\) 8개의 문자를 표현할 수 있음"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn3.html",
    "href": "posts/RNN/2023-02-28-rnn3.html",
    "title": "순환신경망 (3)",
    "section": "",
    "text": "RNN1 - AbAcAd예제(2)"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn3.html#data",
    "href": "posts/RNN/2023-02-28-rnn3.html#data",
    "title": "순환신경망 (3)",
    "section": "data",
    "text": "data\n- 기존의 정리방식\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5], txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])\n\n\n\nx = torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))\n\n\nx[:8], y[:8]\n\n(tensor([0, 1, 0, 2, 0, 3, 0, 1]), tensor([1, 0, 2, 0, 3, 0, 1, 0]))\n\n\n- 이번에는 원핫인코딩 형태까지 미리 정의하자. (임베딩 레이어 안쓸예정)\n\nx= torch.nn.functional.one_hot(x).float()\ny= torch.nn.functional.one_hot(y).float()\n\n\nx, y\n\n(tensor([[1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         ...,\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.]]),\n tensor([[0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         ...,\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.]]))"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn3.html#실패했던-풀이-구현1",
    "href": "posts/RNN/2023-02-28-rnn3.html#실패했던-풀이-구현1",
    "title": "순환신경망 (3)",
    "section": "실패했던 풀이: 구현1",
    "text": "실패했던 풀이: 구현1\n- 저번시간의 실패한 풀이\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4, embedding_dim=2), ##\n    torch.nn.Tanh(), ##\n    torch.nn.Linear(in_featusre=2, out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\n네트워크 쪼개기\n- Tanh까지만 클래스로 바꾸어서 구현\n## step1. 요 두줄 따로 떼네서 요부분만 수행하는 네트워크를 따로만들고 (Hnet)\ntorch.nn.Embedding(num_embeddings=4, embedding_dim=2),\ntorch.nn.Tanh(),\n## step2. 밑에있는 linear를 수행하는 네트워크를 따로 만들 것이다.\ntorch.nn.Linear(in_featusre=2, out_features=4)\n## step3. 이렇게 2개의 네트워크를 만들고, 2개의 네트워크에 해당되는 파라미터들을 전달해서 학습을 시킬 것\n\n## + 2개의 네트워크로 쪼개서 파라미터를 각각 리스트 형태로 전달할 것이기 때문에 위에서 한 예비학습이 필요했다.\n\nclass Hnet(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의\n        self.i2h = torch.nn.Linear(in_features=4, out_features=2) # input(x) -> h\n        self.tanh = torch.nn.Tanh()\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구현할것인지 정의\n        hidden = self.tanh(self.i2h(x))\n        ## 정의 끝\n        return hidden\n\n\nhnet = Hnet()\n\n\nhnet\n\nHnet(\n  (i2h): Linear(in_features=4, out_features=2, bias=True)\n  (tanh): Tanh()\n)\n\n\n- for문 돌릴준비\n\n# 옵티마이저에 자칭 신기술 적용!!!\n\n\ntorch.manual_seed(43052) \nhnet = Hnet()\nlinr = torch.nn.Linear(in_features=2,out_features=4)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(hnet.parameters())+list(linr.parameters())) ## 학습하고 싶은 파라미터 모으기\n\n- for문 20회반복\n\nfor epoc in range(20): \n    ## 1 \n    ## 2 \n    hidden = hnet(x) \n    output = linr(hidden)\n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- linr(hnet(x)) 적합결과 <- 숫자체크\n\nlinr(hnet(x)) \n\ntensor([[-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.2912,  0.8140, -0.2032,  0.0178],\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        ...,\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.1065,  0.6307, -0.0874,  0.1821],\n        [-0.3589,  0.7921, -0.1970, -0.0302]], grad_fn=<AddmmBackward0>)"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn3.html#실패했던-풀이-구현2",
    "href": "posts/RNN/2023-02-28-rnn3.html#실패했던-풀이-구현2",
    "title": "순환신경망 (3)",
    "section": "실패했던 풀이: 구현2",
    "text": "실패했던 풀이: 구현2\n- Tanh까지 구현한 클래스\n\n# class Hnet(torch.nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.i2h = torch.nn.Linear(in_features=4,out_features=2)\n#         self.tanh = torch.nn.Tanh()\n#     def forward(self,x):\n#         hidden = self.tanh(self.i2h(x))\n#         return hidden\n\n- for문돌릴준비\n\ntorch.manual_seed(43052)\nhnet = Hnet()\nlinr = torch.nn.Linear(in_features=2, out_features=4)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(hnet.parameters()) + list(linr.parameters()))\n\n- for문: 20회반복\n\nlen(x)\n\n599\n\n\n\nhnet(x[0]), hnet(x[[0]])\n\n(tensor([-0.4504,  0.6483], grad_fn=<TanhBackward0>),\n tensor([[-0.4504,  0.6483]], grad_fn=<TanhBackward0>))\n\n\n\nT = len(x) \nfor epoc in range(20): \n    ## 1~2\n    loss = 0 \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = hnet(xt)   # hidden \n        ot = linr(ht)  # 하나의 observation에 대한 output\n        loss = loss + loss_fn(ot,yt)  # loss를 누적.\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- linr(hnet(x)) 적합결과 <- 숫자체크\n\nlinr(hnet(x))\n\ntensor([[-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.2912,  0.8140, -0.2032,  0.0178],\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        ...,\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.1065,  0.6307, -0.0874,  0.1821],\n        [-0.3589,  0.7921, -0.1970, -0.0302]], grad_fn=<AddmmBackward0>)\n\n\n\nx # n x 4\n\ntensor([[1., 0., 0., 0.],\n        [0., 1., 0., 0.],\n        [1., 0., 0., 0.],\n        ...,\n        [1., 0., 0., 0.],\n        [0., 0., 1., 0.],\n        [1., 0., 0., 0.]])"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn3.html#순환신경망의-아이디어",
    "href": "posts/RNN/2023-02-28-rnn3.html#순환신경망의-아이디어",
    "title": "순환신경망 (3)",
    "section": "순환신경망의 아이디어",
    "text": "순환신경망의 아이디어\n\n모티브\n(예비생각1) h에 대한 이해\n는 사실 문자열 ’abcd’들을 숫자로 바꾼 또 다른 형식의 숫자표현이라 해석할 수 있음. 즉 원핫인코딩과 다른 또 다른 형태의 숫자표현이라 해석할 수 있다. (사실 원핫인코딩보다 약간 더 (1) 액기스만 남은 느낌 + (2) 숙성된 느낌을 준다)\n\n(why1) h는 “학습을 용이하게 하기 위해서 x를 적당히 선형적으로 전처리한 상태”라고 이해가능\n(why2) 실제로 예시를 살펴보면 그러했다\n\n(예비생각2) 수백년전통을 이어가는 방법\n“1리터에 500만원에 낙찰된 적 있습니다.”\n“2kg에 1억원 정도 추산됩니다.”\n“20여 종 종자장을 블렌딩해 100ml에 5000만원씩 분양 예정입니다.”\n\n모두 씨간장(종자장) 가격에 관한 실제 일화다.\n\n(중략...)\n\n위스키나 와인처럼 블렌딩을 하기도 한다. \n새로 담근 간장에 씨간장을 넣거나, 씨간장독에 햇간장을 넣어 맛을 유지하기도 한다. \n이를 겹장(또는 덧장)이라 한다. \n몇몇 종갓집에선 씨간장 잇기를 몇백 년째 해오고 있다. \n매년 새로 간장을 담가야 이어갈 수 있으니 불씨 꺼트리지 않는 것처럼 굉장히 어려운 일이다.\n이렇게 하는 이유는 집집마다 내려오는 고유 장맛을 잃지 않기 위함이다. \n씨간장이란 그만큼 소중한 주방의 자산이며 정체성이다.\n덧장: 새로운 간장을 만들 때, 옛날간장을 섞어서 만듦.\n* 기존방식: \\(\\text{콩물} \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}\\)\n* 수백년 전통의 간장맛을 유지하는 방식\n\n\\(\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3\\)\n\n* 수백년 전통의 간장맛을 유지하면서 조리를 한다면?\n\n\\(\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3\\)\n\n점점 맛있는 간장계란밥이 탄생함.\n* 알고리즘 편의상 아래와 같이 생각해도 무방.\n\n\\(\\text{콩물}_1, \\text{간장}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1 ,\\quad \\text{간장}_0=\\text{맹물}\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3\\)\n\n아이디어\n* 수백년 전통의 간장맛을 유지하면서 조리하는 과정을 수식으로?\n\n\\(\\boldsymbol{x}_1, \\boldsymbol{h}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_1 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_1\\)\n\\(\\boldsymbol{x}_2, \\boldsymbol{h}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_2 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_2\\)\n\\(\\boldsymbol{x}_3, \\boldsymbol{h}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_3 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_3\\)\n\n이제 우리가 배울것은 (1)“\\(\\text{콩물}_{t}\\)”와 “\\(\\text{간장}_{t-1}\\)”로 “\\(\\text{간장}_{t}\\)”를 숙성하는 방법 (2) “\\(\\text{간장}_{t}\\)”으로 “\\(\\text{간장계란밥}_{t}\\)”을 조리하는 방법이다.\n즉 숙성담당 네트워크와 조리담당 네트워크를 각각 만들어 학습하면 된다.\n\n\n알고리즘\n세부적인 알고리즘(\\(t=0,1,2,\\dots\\)에 대하여 한줄 한줄 쓴 알고리즘)\n(1) \\(t=0\\)\n\\({\\boldsymbol h}_0=[[0,0]] \\leftarrow \\text{간장}_0\\)은 맹물로 초기화\n(2) \\(t=1\\)\n\\({\\boldsymbol h}_1= \\tanh({\\boldsymbol x}_1{\\bf W}_{ih}+{\\boldsymbol h}_0{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\)\n\n\\({\\boldsymbol x}_1: (1,4)\\)\n\\({\\bf W}_{ih}: (4,2)\\)\n\\({\\boldsymbol h}_0: (1,2)\\)\n\\({\\bf W}_hh: (2,2)\\)\n\\({\\boldsymbol b}_{ih}: (1,2)\\)\n\\({\\boldsymbol b}_{hh}: (1,2)\\)\n\n\\({\\boldsymbol o}_1= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}\\)\n\\(\\hat{\\boldsymbol y}_1 = \\text{soft}({\\boldsymbol o}_1)\\)\n\n좀 더 일반화된 알고리즘\n(ver1)\ninit \\(\\boldsymbol{h}_0\\)\nfor \\(t\\) in \\(1\\):\\(T\\)\n\n\\({\\boldsymbol h}_t= \\tanh({\\boldsymbol x}_t{\\bf W}_{ih}+{\\boldsymbol h}_{t-1}{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\)\n\\({\\boldsymbol o}_t= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}\\)\n\\(\\hat{\\boldsymbol y}_t = \\text{soft}({\\boldsymbol o}_t)\\)\n\n(ver2)\ninit hidden\n\nfor t in 1:T \n    hidden = tanh(linr(x)+linr(hidden))\n    output = linr(hidden)\n    yt_hat = soft(output)\n\n코드상으로는 \\(h_t\\)와 \\(h_{t-1}\\)의 구분이 교묘하게 사라진다. (그래서 오히려 좋아.)\n\n\n전체 알고리즘은 대충 아래와 같은 형식으로 구현될 수 있음.\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        linr1 = torch.nn.Linear(?,?) \n        linr2 = torch.nn.Linear(?,?) \n        tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = tanh(lrnr1(x)+lrnr2(hidden))\n        return hidden\n\ninit ht\nrnncell = rNNCell()\n\nfor t in 1:T \n    xt, yt = x[[t]], y[[t]] \n    ht = rnncell(xt, ht)\n    ot = linr(ht) \n    loss = loss + loss_fn(ot, yt)"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn3.html#순환신경망-구현1-with-rnncell-class-hidden-node2---성공",
    "href": "posts/RNN/2023-02-28-rnn3.html#순환신경망-구현1-with-rnncell-class-hidden-node2---성공",
    "title": "순환신경망 (3)",
    "section": "순환신경망 구현1 (with rNNCell class, hidden node2) - 성공",
    "text": "순환신경망 구현1 (with rNNCell class, hidden node2) - 성공\n(1) 숙성담당 네트워크\n\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(4,2) \n        self.h2h = torch.nn.Linear(2,2) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = self.tanh(self.i2h(x)+self.h2h(hidden))\n        return hidden\n\n\ntorch.manual_seed(43052)\nrnncell =  rNNCell() # 숙성담당 네트워크 (콩물 -> 간장), h를 만드는 네트워크.\n\n(2) 조리담당 네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수, 옵티마이저 설계\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습 (6분정도 걸림)\n\nT = len(x) \nfor epoc in range(5000): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) # 1x2 맹물벡터\n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) # 숙성된 애가 들어가서 ht가 만들어짐.\n        ot = cook(ht) # ht가 cook을 거쳐서 ot가 됨.\n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) # x에 맹물을 넣어 첫번째 간장을 만든다.\nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]]) \n\n\nyhat = soft(cook(hidden)) # 간장을 가지고 조리한 것을 softmax 취한다.\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4712e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n\nplt.matshow(yhat.data[:15]) # 앞에 15개\n\n<matplotlib.image.AxesImage at 0x7f240219a760>\n\n\n\n\n\n\n# x[:8]\ny[:8], y[-15:]\n\n(tensor([[0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.],\n         [1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.]]),\n tensor([[0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.],\n         [1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.],\n         [1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.]]))\n\n\n\nplt.matshow(yhat.data[-15:])  # 끝에 15개\n\n<matplotlib.image.AxesImage at 0x7f2401f57490>\n\n\n\n\n\n\n아주 특이한 특징: yhat[:15], yhat[-15:]의 적합결과가 다르다.\n왜? 간장계란밥은 간장이 중요한데, 간장은 시간이 갈수록 맛있어지니까..!\n\n뒤에있는 적합결과가 앞에있는 적합결과보다 더 잘맞는다.\\(\\to\\) 뒤에있는 애가 앞에있는 정보를 더 많이 활용하기 때문이다.\n\n\n첫번째 순환신경망 성공적으로 학습!!!"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn3.html#순환신경망-구현2-with-rnncell-hidden-node-2---성공",
    "href": "posts/RNN/2023-02-28-rnn3.html#순환신경망-구현2-with-rnncell-hidden-node-2---성공",
    "title": "순환신경망 (3)",
    "section": "순환신경망 구현2 (with RNNCell, hidden node 2) - 성공",
    "text": "순환신경망 구현2 (with RNNCell, hidden node 2) - 성공\n\nref: https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.ht\n\n(1) 숙성네트워크\n선언\n\nrnncell = torch.nn.RNNCell(4,2) # x: (n,4) h:(n,2) // 콩물의 dim , 간장(hidden layer)의 dim\n\n가중치초기화 (순환신경망 구현1과 동일하도록)\n\n# 비교를 위한것.\ntorch.manual_seed(43052)\n_rnncell = rNNCell()\n\n\nrnncell.weight_ih.data = _rnncell.i2h.weight.data \nrnncell.weight_hh.data = _rnncell.h2h.weight.data \nrnncell.bias_hh.data = _rnncell.h2h.bias.data \nrnncell.bias_ih.data = _rnncell.i2h.bias.data \n\n(2) 조리담당 네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수, 옵티마이저 설계\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습 (6분정도 걸림)\n\nT = len(x) \nfor epoc in range(5000): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) \n        ot = cook(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]]) \n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4712e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n\nplt.matshow(yhat.data[-15:])\n\n<matplotlib.image.AxesImage at 0x7f2401dd61f0>"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html",
    "href": "posts/RNN/2023-03-01-rnn5.html",
    "title": "순환신경망 (4)",
    "section": "",
    "text": "LSTM (1) - GPU실험, abcabC예제, abcdabcD예제"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes",
    "href": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes",
    "title": "순환신경망 (4)",
    "section": "20000 len + 20 hidden nodes",
    "text": "20000 len + 20 hidden nodes\ncpu\n\nx = torch.randn([20000,4]) \ny = torch.randn([20000,4]) \n\n\nrnn = torch.nn.RNN(4,20)\nlinr = torch.nn.Linear(20,4)\noptimizr = torch.optim.Adam(list(rnn.parameters()) + list(linr.parameters()))\nloss_fn = torch.nn.MSELoss()\n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1\n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x, _water)\n    yhat = linr(hidden)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward() ## 사실 역전파 부분이 시간을 되게 많이 잡아먹음.\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1\n\n145.73457264900208\n\n\ngpu\n\nx = torch.randn([20000,4]).to(\"cuda:0\")\ny = torch.randn([20000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward()  ## 시간차이의 이유!\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n4.398334980010986\n\n\n\n왜 빠른지? (거의 30배정도 차이)"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes-역전파주석처리",
    "href": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes-역전파주석처리",
    "title": "순환신경망 (4)",
    "section": "20000 len + 20 hidden nodes + 역전파주석처리",
    "text": "20000 len + 20 hidden nodes + 역전파주석처리\n\nx = torch.randn([20000,4]) \ny = torch.randn([20000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n28.299692392349243\n\n\ngpu\n\nx = torch.randn([20000,4]).to(\"cuda:0\")\ny = torch.randn([20000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n1.6998937129974365\n\n\n\n미분을 진행하는 과정에서 gpu의 효율이 극대화된다."
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes-1",
    "href": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes-1",
    "title": "순환신경망 (4)",
    "section": "2000 len + 20 hidden nodes",
    "text": "2000 len + 20 hidden nodes\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n10.605574131011963\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n0.4819977283477783"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes-역전파주석처리-1",
    "href": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes-역전파주석처리-1",
    "title": "순환신경망 (4)",
    "section": "2000 len + 20 hidden nodes + 역전파주석처리",
    "text": "2000 len + 20 hidden nodes + 역전파주석처리\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    # loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n3.2522189617156982\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    # loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n0.1948552131652832"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#len-1000-hidden-nodes",
    "href": "posts/RNN/2023-03-01-rnn5.html#len-1000-hidden-nodes",
    "title": "순환신경망 (4)",
    "section": "2000 len + 1000 hidden nodes",
    "text": "2000 len + 1000 hidden nodes\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,1000) \nlinr = torch.nn.Linear(1000,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n43.083815574645996\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,1000).to(\"cuda:0\")\nlinr = torch.nn.Linear(1000,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n5.486930847167969"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#len-1000-hidden-nodes-역전파주석처리",
    "href": "posts/RNN/2023-03-01-rnn5.html#len-1000-hidden-nodes-역전파주석처리",
    "title": "순환신경망 (4)",
    "section": "2000 len + 1000 hidden nodes + 역전파주석처리",
    "text": "2000 len + 1000 hidden nodes + 역전파주석처리\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,1000) \nlinr = torch.nn.Linear(1000,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    # loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n6.92149543762207\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,1000).to(\"cuda:0\")\nlinr = torch.nn.Linear(1000,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    # loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n2.9791648387908936"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#실험결과-요약",
    "href": "posts/RNN/2023-03-01-rnn5.html#실험결과-요약",
    "title": "순환신경망 (4)",
    "section": "실험결과 요약",
    "text": "실험결과 요약\n\n\n\nlen\n# of hidden ndoes\nbackward\ncpu\ngpu\nratio\n\n\n\n\n20000\n20\nO\n145.73\n4.39\n33.19\n\n\n20000\n20\nX\n28.29\n1.69\n16.73\n\n\n2000\n20\nO\n10.60\n0.48\n22.08\n\n\n2000\n20\nX\n3.25\n0.19\n17.10\n\n\n2000\n1000\nO\n43.08\n5.48\n7.86\n\n\n2000\n1000\nX\n6.92\n2.97\n2.32"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#data",
    "href": "posts/RNN/2023-03-01-rnn5.html#data",
    "title": "순환신경망 (4)",
    "section": "data",
    "text": "data\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \n\n\ntxt = list('abcabC')*100\ntxt[:8]\n\n['a', 'b', 'c', 'a', 'b', 'C', 'a', 'b']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\ntxt_x[:8], txt_y[:8]\n\n(['a', 'b', 'c', 'a', 'b', 'C', 'a', 'b'],\n ['b', 'c', 'a', 'b', 'C', 'a', 'b', 'c'])\n\n\n\nmapping = {'a':0,'b':1,'c':2,'C':3}\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx = x.to(\"cuda:0\")\ny = y.to(\"cuda:0\")\n\n- a,b,c,a,b,C - 보이는 문자수가 a,b,c,C 이므로 4개\n- a1,b1,c,a2,b2,C - 문맥까지 고려하면 6개\nhidden node의 개수를 2개로 하면 a,b,c,C 4개의 문자를 구분할 수는 있지만 문맥에 따른 차이점을 구분하기 모호할 수 있다.\n\\(\\to\\) 따라서 hidden node의 개수를 3으로 설정하자."
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#data-1",
    "href": "posts/RNN/2023-03-01-rnn5.html#data-1",
    "title": "순환신경망 (4)",
    "section": "data",
    "text": "data\n\ntxt = list('abcdabcD')*100\ntxt[:8]\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'D']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'a':0,'b':1,'c':2,'d':3,'D':4}\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx=x.to(\"cuda:0\")\ny=y.to(\"cuda:0\")"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#rnn-vs.-lstm-성능비교실헝",
    "href": "posts/RNN/2023-03-01-rnn5.html#rnn-vs.-lstm-성능비교실헝",
    "title": "순환신경망 (4)",
    "section": "RNN vs. LSTM 성능비교실헝",
    "text": "RNN vs. LSTM 성능비교실헝\n- RNN\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(5,4).to(\"cuda:0\")\n        linr = torch.nn.Linear(4,5).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,4).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-8:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$RNN$\",size=20)\nfig.tight_layout()\n\n\n\n\n성공횟수가 이전 예제보다 확실히 적어졌다.\n- LSTM\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(5,4).to(\"cuda:0\")\n        linr = torch.nn.Linear(4,5).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,4).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-8:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$LSTM$\",size=20)\nfig.tight_layout()\n\n\n\n\n\n대부분 성공\nLSTM이 해당 세팅에서도 학습이 더 잘된다는 것을 알 수 있었다.\n\n- 관찰1: LSTM이 확실히 장기기억에 강하다.\n- 관찰2: LSTM은 hidden에 0이 잘 나온다.\n\n사실 확실히 구분되는 특징을 판별할때는 -1,1로 히든레이어 값들이 설정되면 명확하다.\n히든레이어에 -1~1 사이의 값이 나온다면 애매한 판단이 내려지게 된다.\n그런데 이 애매한 판단이 어떻게 보면 문맥의 뉘앙스를 이해하는데 더 잘 맞다.\n그런데 RNN은 -1,1로 셋팅된 상황에서 -1~1로의 변화가 더디다는 것이 문제임."
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn1.html",
    "href": "posts/RNN/2023-02-25-rnn1.html",
    "title": "순환신경망 (1)",
    "section": "",
    "text": "순환신경망 intro(1)- ab예제, embedding layer"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn1.html#data",
    "href": "posts/RNN/2023-02-25-rnn1.html#data",
    "title": "순환신경망 (1)",
    "section": "data",
    "text": "data\n\ntxt = list('ab')*100\ntxt[:10]\n\n['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5], txt_y[:5]\n\n(['a', 'b', 'a', 'b', 'a'], ['b', 'a', 'b', 'a', 'b'])\n\n\nx가 네트워크의 입력이라고 생각하고 b가 네트워크의 출력이라고 생각하면 - 네트워크 입력으로 a가 들어오면 b를 뱉어내고 - 네트워크 입력으로 b가 들어오면 a를 뱉어낸다.\n\\(\\to\\) 이러한 구조를 학습하면 된다."
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn1.html#선형모형을-이용한-풀이",
    "href": "posts/RNN/2023-02-25-rnn1.html#선형모형을-이용한-풀이",
    "title": "순환신경망 (1)",
    "section": "선형모형을 이용한 풀이",
    "text": "선형모형을 이용한 풀이\n\n(풀이1) 1개의 파라메터 - 실패\n\nmapping = {'a':0, 'b':1}\nx = torch.tensor(f(txt_x, mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y, mapping)).float().reshape(-1,1)\n\n\nx[:5], y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 학습 및 결과 시각화\n\nnet = torch.nn.Linear(in_features=1, out_features=1, bias=False)\nloss_fn = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat, y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizer.step()\n    optimizer.zero_grad()\n\n\nplt.plot(y[:5], 'o')\nplt.plot(net(x).data[:5])\n\n\n\n\n\n잘 학습이 안되었다.\n\n- 학습이 잘 안된 이유\n\npd.DataFrame({'x':x[:5].reshape(-1), 'y':y[:5].reshape(-1)})\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      0.0\n      1.0\n    \n    \n      1\n      1.0\n      0.0\n    \n    \n      2\n      0.0\n      1.0\n    \n    \n      3\n      1.0\n      0.0\n    \n    \n      4\n      0.0\n      1.0\n    \n  \n\n\n\n\n현재 \\(\\hat{y}_i = \\hat{w}x_i\\) 꼴의 아키텍처이고 \\(y_i \\approx \\hat{w}x_i\\)가 되는 적당한 \\(\\hat{w}\\)를 찾아야 하는 상황 - \\((x_i, y_i) = (0, 1)\\) 이면 어떠한 \\(\\hat{w}\\) 를 선택해도 \\(y_i \\approx \\hat{w}x_i\\) 를 만드는 것이 불가능 - \\((x_i, y_i) = (1, 0)\\) 이면 \\(\\hat{w} = 0\\) 일 경우 \\(y_i \\approx \\hat{w}x_i\\)로 만드는 것이 가능\n상황을 종합해보니 \\(\\hat{w}=0\\)으로 학습되는 것이 그나마 최선\n\n\n(풀이2) 1개의 파라메터 - 성공, but 확장성이 없는 풀이\n- 0이라는 값이 문제가 되므로 인코딩방식의 변경\n\nx = torch.tensor(f(txt_x, {'a':-1,'b':1})).float().reshape(-1,1)\ny = torch.tensor(f(txt_y, {'a':-1,'b':1})).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[-1.],\n         [ 1.],\n         [-1.],\n         [ 1.],\n         [-1.]]),\n tensor([[ 1.],\n         [-1.],\n         [ 1.],\n         [-1.],\n         [ 1.]]))\n\n\n\nnet = torch.nn.Linear(in_features=1, out_features=1, bias=False)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(2000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat, y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과는 성공\n\nplt.plot(y[:5],'o')\nplt.plot(net(x).data[:5])\n\n\n\n\n딱봐도 클래스가 3개일 경우 확장이 어려워 보인다."
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn1.html#로지스틱-모형을-이용한-풀이",
    "href": "posts/RNN/2023-02-25-rnn1.html#로지스틱-모형을-이용한-풀이",
    "title": "순환신경망 (1)",
    "section": "로지스틱 모형을 이용한 풀이",
    "text": "로지스틱 모형을 이용한 풀이\n\n(풀이1) 1개의 파라메터 - 실패\n- 데이터를 다시 a=0, b=1로 정의\n\nmapping = {'a':0, 'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5], y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 학습\n\nnet = torch.nn.Linear(in_features = 1, out_features = 1, bias = False)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat, y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과\n\nplt.plot(y[:10], 'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 결과해석: 예상되었던 실패임\n\n아키텍처는 \\(\\hat{y}_i = \\text{sig}(\\hat{w}x_i)\\) 꼴이다.\n\\((x_i, y_i) = (0,1)\\) 이라면 어떠한 \\(\\hat{w}\\) 를 선택해도 \\(\\hat{w}x_i=0\\)이다. 이 경우 \\(\\hat{y}_i = sig(0) = 0.5\\) 가 된다.\n\\((x_i, y_i) = (1,0)\\) 이라면 \\(\\hat{w} = -5\\)와 같은 값으로 선택하면 \\(sig(-5)\\approx - = y_i\\)와 같이 만들 수 있다.\n상황을 종합해보면 net이 weight는 \\(sig(\\hat{w}x_i)\\approx 0\\)이 되도록 적당한 음수로 학습되는 것이 최선임을 알 수 있다.\n\n\nnet.weight # 적당한 음수값으로 학습되어있음을 확인\n\nParameter containing:\ntensor([[-2.4571]], requires_grad=True)\n\n\n\n\n(풀이2) 2개의 파라메터 + 좋은 초기값 - 성공\n2개의 파라메터를 쓴다는 것은 weight와 bias를 쓴다는 것.\n- 동일하게 a=0,b=1로 맵핑\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 네트워크에서 bias를 넣기로 결정함\n\nnet = torch.nn.Linear(in_features=1, out_features=1, bias=True)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- net의 초기값을 설정 (이것은 좋은 초기값임)\n\\(y = sig(-5x + 2.5)\\)\n\n\\(x=0 \\to sig(2.5) \\to y\\text{는 1근처}\\)\n\\(x=1 \\to sig(-2.5) \\to y\\text{는 0근처}\\)\n\n(참고) \\(sig(x) = \\frac{1}{1+e^{-x}}\\)\n\nimport numpy as np\n1/(1+np.exp(-2.5)) , 1/(1+np.exp(2.5))\n\n(0.9241418199787566, 0.07585818002124355)\n\n\n\nnet.weight.data = torch.tensor([[-5.00]])\nnet.bias.data = torch.tensor([+2.500])\n\n\nnet(x)[:10]\n\ntensor([[ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000]], grad_fn=<SliceBackward0>)\n\n\n- 학습 전 결과\n\nplt.plot(y[:10], 'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 학습 후 결과\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat, y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n\n\n(풀이3) 2개의 파라메터 + 나쁜 초기값 - 성공\n- a=0,b=1\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 이전과 동일하게 바이어스가 포함된 네트워크 설정\n\nnet = torch.nn.Linear(in_features=1, out_features=1,bias=True)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- 초기값 설정 (이 초기값은 나쁜 초기값임)\n\nnet.weight.data = torch.tensor([[+5.00]])\nnet.bias.data = torch.tensor([-2.500])\n\n\nnet(x)[:10]\n\ntensor([[-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000]], grad_fn=<SliceBackward0>)\n\n\n- 학습전상태: 반대모양으로 되어있다.\n\nplt.plot(y[:10], 'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 학습\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat, y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n\n될 것 같긴한데 느릴것 같다..결국 수렴하긴 할듯.\n\n\n\n(풀이4) 3개의 파라메터를 쓴다면?\n- a=0, b=1로 코딩\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 3개의 파라메터를 사용하기 위해서 아래와 같은 구조를 생각하자.\n## 파라메터 3개를 줄 수 있는 방법\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1, bias=True),  ## 파라메터 2개\n    torch.nn.ACTIVATION_FUNCTION(),   ## activation 걸기  ## 파라메터 0개\n    torch.nn.Linear(in_features=1, out_features=1, bias=False) ## 파라메터 1개\n)\n위와 같은 네트워크를 설정하면 3개의 파라메터를 사용할 수 있다. 적절한 ACTIVATION_FUNCTION을 골라야하는데 실험적으로 tanh가 적절하다고 알려져있다. (\\(\\to\\) 그래서 우리도 실험적으로 이해해보자.)\n순환신경망에서 activation으로 tanh를 많이 사용한다. 이를 증명하기 위해서 실험을 해보자.\n\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features = 1, out_features = 1, bias = True),  ## 2개\n    torch.nn.ReLU(), ## 0개 \n    torch.nn.Linear(in_features = 1, out_features = 1, bias = False) ## 1개\n)\n\nSequential(\n  (0): Linear(in_features=1, out_features=1, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=1, out_features=1, bias=False)\n)\n\n\n\n(예비학습1) net(x)와 사실 net.forward(x)는 같다.\n\nnet(x)[:5] # 풀이3에서 학습한 네트워크임\n\ntensor([[-0.1584],\n        [ 0.1797],\n        [-0.1584],\n        [ 0.1797],\n        [-0.1584]], grad_fn=<SliceBackward0>)\n\n\n\nnet.forward(x)[:5] # 풀이3에서 학습한 네트워크임\n\ntensor([[-0.1584],\n        [ 0.1797],\n        [-0.1584],\n        [ 0.1797],\n        [-0.1584]], grad_fn=<SliceBackward0>)\n\n\n그래서 net.forward를 재정의하면 net(x)의 기능을 재정의 할 수 있다.\n\nnet.forward = lambda x: 1\n\n\n“lambda x:1”은 입력이 x, 출력이 1인 함수를 의미한다. (즉, 입력값에 상관없이 항상 1을 출력하는 함수)\n“net.forward = lambda x:1”이라고 새롭게 선언하였으므로 앞으로는 net.forward(), net(x)도 입력값에 상관없이 항상 1을 출력하게 될 것임.\n\n\nnet(x)\n\n1\n\n\n(예비학습2) torch.nn.Module을 상속받아서 네트워크를 만들면 (=’classXXX(torch.nn.Module):“와 같은 방식으로 클래스를 선언하면) 약속된 아키텍처를 가진 네트워크를 찍어내는 함수를 만들 수 있다.\n(예시1)\n\n## 클래스는 인스턴스를 만드는 틀같은 걸로 생각.\n\n\nclass Mynet1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.Sigmoid()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\n\nnet = Mynet1()\n\n는 아래와 같은 효과를 가진다.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1, bias=True),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(in_features=1, out_features=1, bias=False)\n)\n\n(예시2)\n\nclass Mynet2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1, out_features=1, bias=True)\n        self.a1 = torch.nn.ReLU()\n        self.l2 = torch.nn.Linear(in_features=1, out_features=1, bias=False)\n    def forward(self, x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\n\nnet = Mynet2()\n\n는 아래와 같은 효과를 가진다.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1, bias=True),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=1, out_features=1, bias=False)\n)\n\n(예시3)\n\nclass Mynet3(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1, out_features=1, bias=True)\n        self.a1 = torch.nn.Tanh()\n        self.l2 = torch.nn.Linear(in_features=1, out_features=1, bias=False)\n    def forward(self, x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\n\nnet = Mynet3()\n\n는 아래와 같은 효과를 가진다.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1, bias=True),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1, out_features=1, bias=False)\n)\n\n\n클래스에 대한 이해가 부족한 학생을 위한 암기방법\nstep1: 아래의 코드를 복사하여 틀을 만든다. (무조건 고정임, XXXX자리는 원하는 이름을 넣는다.)\n\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의\n        \n        ## 레이어 정의 끝\n    def forward(self, x):\n        ## yhat을 어떻게 구할것인지 정의\n        \n        ## 정의 끝\n        return yhat\n\n\nnet(x)에 사용하는 x임, yhat은 net.forward(x)의 리턴값임.\n사실, x,yhat은 다른 변수로 써도 무방하나 (예를들어 input/output 이라든지) 설명의 편의상 x와 yhat을 고정한다.\n\nstpe2: def __init__(self)에 사용할 레이어를 정의하고 이름을 붙인다. 이름은 항상 self.xxx와 같은 식으로 정의한다.\n\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return yhat\n\nstep3: def forward:에 “x->yhat”으로 가는 과정을묘사한 코드를 작성하고 yhat을 리턴하도록 한다.\n\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        u = self.xxx1(x)\n        v = self.xxx2(u)\n        yhat = self.xxx3(v)\n        ## 정의 끝\n        return yhat\n\n예비학습 끝\n\n- 우리가 하려고 했던 것 : 아래의 아키텍처에서\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1, bias=True),\n    torch.nn.ACTIVATION_FUNCTION(),\n    torch.nn.Linear(in_features=1, out_features=1, bias=False)\n)\nACTIVATION의 자리에 tanh가 왜 적절한지 직관을 얻어보자.\n\n\n- 실험결과1(Sig): Sigmoid activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet1()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_1(x):=Sigmoid(x)$\",size=20)\nfig.tight_layout()\n\n\n\n\n\n\n- 실험결과2(ReLU): ReLU activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet2()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_2(x):=ReLU(x)$\",size=20)\nfig.tight_layout()\n\n\n\n\n\n\n- 실험결과3(Tanh): Tanh activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet3()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_2(x):=Tanh(x)$\",size=20)        \nfig.tight_layout()\n\n\n\n\n\n\n- 실험해석\n\nSig: 주항색선의 변동폭이 작음 + 항상 \\(0.5\\) 근처로 머무는 적합값이 존재\nReLU: 주황색선의 변동폭이 큼 + 항상 \\(0.5\\) 근처로 머무는 적합값이 존재\nTanh: 주황색선의 변동폭이 큼 + \\(0.5\\) 근처로 머무는 적합값이 존재X\n\n실험해보니까 Tanh가 우수한 것 같다. \\(\\to\\) 앞으로는 Tanh를 쓰자."
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn1.html#소프트맥스로-확장",
    "href": "posts/RNN/2023-02-25-rnn1.html#소프트맥스로-확장",
    "title": "순환신경망 (1)",
    "section": "소프트맥스로 확장",
    "text": "소프트맥스로 확장\n\n(풀이1) 로지스틱모형에서 3개의 파라메터 버전을 그대로 확장\n\nmapping = {'a':[1,0], 'b':[0,1]}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,2)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,2)\nx[:5], y[:5]\n\n(tensor([[1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [0., 1.],\n         [1., 0.]]),\n tensor([[0., 1.],\n         [1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [0., 1.]]))\n\n\n\n[1, 0] -> a\n[0, 1] -> b\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=2, out_features=1), # x의 shape이 2 -> in_features=2\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1, out_features=2, bias=False) # y의 shape이 2 -> out_features=2\n)    \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat, y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5][:,1]\n\ntensor([1., 0., 1., 0., 1.])\n\n\n\nsoft(net(x))[:5][:,1]\n\ntensor([0.9952, 0.0049, 0.9952, 0.0049, 0.9952], grad_fn=<SelectBackward0>)\n\n\n\nplt.plot(y[:5][:,1],'o') ## y\nplt.plot(soft(net(x[:5]))[:,1].data,'--r') ## 예측한 값.\n\n\n\n\n\nfig,ax = plt.subplots(1,2)\nax[0].imshow(y[:5])\nax[1].imshow(soft(net(x[:5])).data)\n\n<matplotlib.image.AxesImage at 0x7f66535be9a0>\n\n\n\n\n\n모양이 똑같이 나왔으니까 예측이 잘 되었다고 판단."
  },
  {
    "objectID": "etc/2023-02-28.html",
    "href": "etc/2023-02-28.html",
    "title": "클래스 암기",
    "section": "",
    "text": "클래스 헷갈리는 개념모음\n\n\n파이썬 iterable object\n\n파이썬의 모든 것은 오브젝트이다. \n함수도 오브젝트이고\n리스트도 오브젝트이다..\n\n\n\n\n\n_lst= [1,2,3]\nfor i in _lst:\n    print(i)\n\n1\n2\n3\n\n\n\n_iterator = _lst.__iter__() # __iter__()라는 함수를 쓰면 iterator가 만들어진다.\n\n\niterator에는 __next__ 라는 기능이 있다.\niterable object에는 __next__라는 기능이 없다.\n이것이 iterator(=jenerator)와 iterable object와의 차이\n\niterable object는 결국 iterator로 만들 수 있는 오브젝트라는 것\n\n_iterator.__next__()\n\n1\n\n\n\n_iterator.__next__()\n\n2\n\n\n\n_iterator.__next__()\n\n3\n\n\n\n_iterator.__next__() # 에러 나는게 당연! 다음에 꺼낼게 없으니까...\n\nStopIteration: \n\n\n\nset(dir(_lst)) & {'__next__', '__iter__'} # 얘는 iterable object\n\n{'__iter__'}\n\n\n\nset(dir(_iterator)) & {'__next__', '__iter__'} # 얘는 iterator (=generator)\n\n{'__iter__', '__next__'}\n\n\n다시 정리\n\ndir()로 확인했을 때 __iter__ 만 있으면 iterable object\n\niterable object에는 __iter__ 라는 숨겨진 기능이 있음.\n\n\n__iter__와 __next__ 둘 다 있으면 iterator!!\n\n\n\n\n\nimport torch\n\n\nnet = torch.nn.Linear(in_features = 1, out_features=1)\nnet.weight\n\nParameter containing:\ntensor([[-0.9288]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([0.1182], requires_grad=True)\n\n\n\nfor param in net.parameters():\n    print(param)\n\nParameter containing:\ntensor([[-0.9288]], requires_grad=True)\nParameter containing:\ntensor([0.1182], requires_grad=True)\n\n\nnet.parameters()는 net오브젝트에서 학습할 파라메터를 모두 모아 리스트 같은 iterable object로 만드는 함수라 이해할 수 있다.\n\n\n\n\nstep1: 아래의 코드를 복사하여 틀을 만든다. (무조건 고정임, XXXX자리는 원하는 이름을 넣는다.)\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의\n        \n        ## 레이어 정의 끝\n    def forward(self, x):\n        ## yhat을 어떻게 구할것인지 정의\n        \n        ## 정의 끝\n        return yhat\n\nnet(x)에 사용하는 x임, yhat은 net.forward(x)의 리턴값임.\n사실, x,yhat은 다른 변수로 써도 무방하나 (예를들어 input/output 이라든지) 설명의 편의상 x와 yhat을 고정한다.\n\nstpe2: def __init__(self)에 사용할 레이어를 정의하고 이름을 붙인다. 이름은 항상 self.xxx와 같은 식으로 정의한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return yhat\nstep3: def forward:에 “x->yhat”으로 가는 과정을묘사한 코드를 작성하고 yhat을 리턴하도록 한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        u = self.xxx1(x)\n        v = self.xxx2(u)\n        yhat = self.xxx3(v)\n        ## 정의 끝\n        return yhat"
  },
  {
    "objectID": "etc/2023-02-01-memo.html#st-gcn",
    "href": "etc/2023-02-01-memo.html#st-gcn",
    "title": "메모장",
    "section": "01. ST-GCN",
    "text": "01. ST-GCN\n\ntemporal signal vs. static signals\nstatic graph vs. dynamic graph\nedge index? edge feature matrix (node feature matrix는 알겠는데ㅠㅠ엣지 매트릭스는 뭐야)\nRecurrent GNN\n\n얘가 GNN의 시초라는데?\n\nGNN, Recurrent GNN, GCN, ST-GCN 순서가 어떻게 되는지 헷갈린다..\nGRU\nspectral gcn\n\n\n\n\nimage.png\n\n\n\nGNN 정리 블로그\nML with Graphs 강의영상"
  },
  {
    "objectID": "etc/2023-02-01-memo.html#gnn",
    "href": "etc/2023-02-01-memo.html#gnn",
    "title": "메모장",
    "section": "02. GNN",
    "text": "02. GNN\n\n왜 순환신경망일까? 왜 순환이지???\n03/01 DNN 2강까지\n03/01 RNN 6강까지"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "myblog",
    "section": "",
    "text": "순환신경망 (4)\n\n\n\n\n\n\n\nDL2022\n\n\nRNN\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n순환신경망 (3)\n\n\n\n\n\n\n\nDL2022\n\n\nRNN\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n순환신경망 (4)\n\n\n\n\n\n\n\nDL2022\n\n\nRNN\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGCN Implementation\n\n\n\n\n\n\n\nGCN\n\n\nImplementation\n\n\n\n\n\n\n\n\n\n\n\nFeb 27, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n  \n\n\n\n\n순환신경망 (2)\n\n\n\n\n\n\n\nDL2022\n\n\nRNN\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n순환신경망 (1)\n\n\n\n\n\n\n\nDL2022\n\n\nRNN\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChap 12.2: Weakly Stationary Graph process\n\n\n\n\n\n\n\nCGSP\n\n\nstudy\n\n\n\n\n\n\n\n\n\n\n\nFeb 24, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n  \n\n\n\n\nChap 8.3: Discrete Fourier Transform\n\n\n\n\n\n\n\nCGSP\n\n\nstudy\n\n\n\n\n\n\n\n\n\n\n\nFeb 24, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n튜토리얼 따라가기2\n\n\n\n\n\n\n\nSTGCN\n\n\nBASIC\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraffic Forecasting review\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n  \n\n\n\n\nGraph Convolutional Network\n\n\n\n\n\n\n\nGCN\n\n\nBASIC\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n  \n\n\n\n\n튜토리얼 따라가기1\n\n\n\n\n\n\n\nSTGCN\n\n\nBASIC\n\n\n\n\n\n\n\n\n\n\n\nFeb 20, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChap 12.4: Node Subsampling for PSD Estimation\n\n\n\n\n\n\n\n\n\n\n\n\nJan 15, 2023\n\n\n신록예찬\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToy Example\n\n\n\n\n\n\n\nSTGCN\n\n\nPytorch\n\n\n\n\n\n\n\n\n\n\n\nDec 30, 2022\n\n\n신록예찬\n\n\n\n\n\n\n  \n\n\n\n\nSTGCN 튜토리얼\n\n\n\n\n\n\n\n\n\n\n\n\nDec 29, 2022\n\n\n신록예찬, 최서연\n\n\n\n\n\n\n  \n\n\n\n\nChap 12.2 ~ 3: Power Spectral Density and its Estimators\n\n\n\n\n\n\n\n\n\n\n\n\nDec 27, 2022\n\n\n신록예찬\n\n\n\n\n\n\n  \n\n\n\n\nChap 12.2: Weakly Stationary Graph Processes\n\n\n\n\n\n\n\n\n\n\n\n\nDec 26, 2022\n\n\n신록예찬\n\n\n\n\n\n\n  \n\n\n\n\nChap 8.3: Discrete Fourier Transform\n\n\n\n\n\n\n\n\n\n\n\n\nDec 24, 2022\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  }
]