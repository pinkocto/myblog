[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "welcome!"
  },
  {
    "objectID": "Tip/2023-02-28-link.html",
    "href": "Tip/2023-02-28-link.html",
    "title": "some links",
    "section": "",
    "text": "Aligning equations with amsmath"
  },
  {
    "objectID": "Tip/2023-02-24-tips.html",
    "href": "Tip/2023-02-24-tips.html",
    "title": "Julia 연동",
    "section": "",
    "text": "Julia 설치\n설치된 Julia를 열어 Command창에 using Pkg 입력 + 엔터\nPkg.add(\"IJulia\") 입력 + 엔터\nJupyter notebook/lab 들어가서 확인\n\n결과\n\n\n\nimage.png"
  },
  {
    "objectID": "Tip/2023-02-20-tips.html",
    "href": "Tip/2023-02-20-tips.html",
    "title": "download files from Github",
    "section": "",
    "text": "- Github에 주피터노트북 파일 다운로드 받는 법\n\n!wget https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/STGCN/2022-12-29-STGCN-tutorial.ipynb\n\n--2023-02-20 22:35:38--  https://raw.githubusercontent.com/miruetoto/yechan3/main/posts/3_Researches/STGCN/2022-12-29-STGCN-tutorial.ipynb\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1184264 (1.1M) [text/plain]\nSaving to: ‘2022-12-29-STGCN-tutorial.ipynb’\n\n2022-12-29-STGCN-tu 100%[===================>]   1.13M  --.-KB/s    in 0.03s   \n\n2023-02-20 22:35:39 (42.5 MB/s) - ‘2022-12-29-STGCN-tutorial.ipynb’ saved [1184264/1184264]\n\n\n\n좌측 사이드바를 확인해보면 원하는 주피터 파일 (2022-12-29-STGCN-tutorial.ipynb) 이 잘 다운받아진 것을 확인해볼 수 있다."
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#pyg-의-data-자료형",
    "href": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#pyg-의-data-자료형",
    "title": "STGCN 튜토리얼",
    "section": "PyG 의 Data 자료형",
    "text": "PyG 의 Data 자료형\n\nref: https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-handling-of-graphs\n\n- 자료는 PyG의 Data 오브젝트를 기반으로 한다.\n(예제) 아래와 같은 그래프자료를 고려하자.\n\n이러한 자료형은 아래와 같은 형식으로 저장한다.\n\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype=torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\ndata = Data(x=x, edge_index=edge_index) # Data는 그래프자료형을 만드는 클래스\n\n\ntype(data)\n\ntorch_geometric.data.data.Data\n\n\n\ndata.x\n\ntensor([[-1.],\n        [ 0.],\n        [ 1.]])\n\n\n\ndata.edge_index\n\ntensor([[0, 1, 1, 2],\n        [1, 0, 2, 1]])"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#pytorch-geometric-temporal-의-자료형",
    "href": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#pytorch-geometric-temporal-의-자료형",
    "title": "STGCN 튜토리얼",
    "section": "PyTorch Geometric Temporal 의 자료형",
    "text": "PyTorch Geometric Temporal 의 자료형\n\nref: PyTorch Geometric Temporal Signal\n\n아래의 클래스들중 하나를 이용하여 만든다.\n## Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n## Heterogeneous Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphStaticSignal\n이중 “Heterogeneous Temporal Signal” 은 우리가 관심이 있는 신호가 아니므로 사실상 아래의 3개만 고려하면 된다.\n\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n\n여기에서 StaticGraphTemporalSignal 는 시간에 따라서 그래프 구조가 일정한 경우, 즉 \\({\\cal G}_t=\\{{\\cal V},{\\cal E}\\}\\)와 같은 구조를 의미한다.\n(예제1) StaticGraphTemporalSignal 를 이용하여 데이터 셋 만들기\n- json data \\(\\to\\) dict\n\nimport json\nimport urllib\n\n\nurl = \"https://raw.githubusercontent.com/benedekrozemberczki/pytorch_geometric_temporal/master/dataset/chickenpox.json\"\ndata_dict = json.loads(urllib.request.urlopen(url).read())\n# data_dict 출력이 김\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n- 살펴보기\n\nnp.array(data_dict['edges']).T\n\narray([[ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,\n         3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  6,\n         6,  6,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n        10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12,\n        12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15,\n        15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18,\n        18, 18, 19, 19, 19, 19],\n       [10,  6, 13,  1,  0,  5, 16,  0, 16,  1, 14, 10,  8,  2,  5,  8,\n        15, 12,  9, 10,  3,  4, 13,  0, 10,  2,  5,  0, 16,  6, 14, 13,\n        11, 18,  7, 17, 11, 18,  3,  2, 15,  8, 10,  9, 13,  3, 12, 10,\n         5,  9,  8,  3, 10,  2, 13,  0,  6, 11,  7, 13, 18,  3,  9, 13,\n        12, 13,  9,  6,  4, 12,  0, 11, 10, 18, 19,  1, 14,  6, 16,  3,\n        15,  8, 16, 14,  1,  0,  6,  7, 19, 17, 18, 14, 18, 17,  7,  6,\n        19, 11, 18, 14, 19, 17]])\n\n\n\n\\({\\cal E} = \\{(0,10),(0,6), \\dots, (19,17)\\}\\)\n혹은 \\({\\cal E} = \\{(\\tt{BACS},\\tt{JASZ}), ({\\tt BACS},{\\tt FEJER}), \\dots, (\\tt{ZALA},\\tt{VAS})\\}\\)\n\n\ndata_dict['node_ids']\n\n{'BACS': 0,\n 'BARANYA': 1,\n 'BEKES': 2,\n 'BORSOD': 3,\n 'BUDAPEST': 4,\n 'CSONGRAD': 5,\n 'FEJER': 6,\n 'GYOR': 7,\n 'HAJDU': 8,\n 'HEVES': 9,\n 'JASZ': 10,\n 'KOMAROM': 11,\n 'NOGRAD': 12,\n 'PEST': 13,\n 'SOMOGY': 14,\n 'SZABOLCS': 15,\n 'TOLNA': 16,\n 'VAS': 17,\n 'VESZPREM': 18,\n 'ZALA': 19}\n\n\n\n\\({\\cal V}=\\{\\tt{BACS},\\tt{BARANYA} \\dots, \\tt{ZALA}\\}\\)\n\n\nnp.array(data_dict['FX']), np.array(data_dict['FX']).shape\n\n(array([[-1.08135724e-03, -7.11136085e-01, -3.22808515e+00, ...,\n          1.09445310e+00, -7.08747750e-01, -1.82280792e+00],\n        [ 2.85705967e-02, -5.98430173e-01, -2.29097341e-01, ...,\n         -1.59220988e+00, -2.24597623e-01,  7.86330575e-01],\n        [ 3.54742090e-01,  1.90511208e-01,  1.61028185e+00, ...,\n          1.38183225e-01, -7.08747750e-01, -5.61724314e-01],\n        ...,\n        [-4.75512620e-01, -1.19952837e+00, -3.89043358e-01, ...,\n         -1.00023329e+00, -1.71429032e+00,  4.70746677e-02],\n        [-2.08645035e-01,  6.03766218e-01,  1.08216835e-02, ...,\n          4.71099041e-02,  2.45684924e+00, -3.44296107e-01],\n        [ 1.21464875e+00,  7.16472130e-01,  1.29038982e+00, ...,\n          4.56939849e-01,  7.43702632e-01,  1.00375878e+00]]),\n (521, 20))\n\n\n\n\\({\\bf f}=\\begin{bmatrix} {\\bf f}_1\\\\ {\\bf f}_2\\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}=\\begin{bmatrix} f(t=1,v=\\tt{BACS}) & \\dots & f(t=1,v=\\tt{ZALA}) \\\\ f(t=2,v=\\tt{BACS}) & \\dots & f(t=2,v=\\tt{ZALA}) \\\\ \\dots & \\dots & \\dots \\\\ f(t=521,v=\\tt{BACS}) & \\dots & f(t=521,v=\\tt{ZALA}) \\end{bmatrix}\\)\n\n즉 data_dict는 아래와 같이 구성되어 있음\n\n\n\n\n\n\n\n\n\n\n수학 기호\n코드에 저장된 변수\n자료형\n차원\n설명\n\n\n\n\n\\({\\cal V}\\)\ndata_dict['node_ids']\ndict\n20\n20개의 노드에 대한 설명이 있음\n\n\n\\({\\cal E}\\)\ndata_dict['edges']\nlist (double list)\n(102,2)\n노드들에 대한 102개의 연결을 정의함\n\n\n\\({\\bf f}\\)\ndata_dict['node_ids']\ndict\n(521,20)\n\\(f(t,v)\\) for \\(v \\in {\\cal V}\\) and \\(t = 1,\\dots, T\\)\n\n\n\n- 주어진 자료를 정리하여 그래프신호 \\(\\big(\\{{\\cal V},{\\cal E},{\\bf W}\\},{\\bf f}\\big)\\)를 만들면 아래와 같다.\n\nedges = np.array(data_dict[\"edges\"]).T\nedge_weight = np.ones(edges.shape[1])\nf = np.array(data_dict[\"FX\"])\n\n\n여기에서 edges는 \\({\\cal E}\\)에 대한 정보를\nedges_weight는 \\({\\bf W}\\)에 대한 정보를\nf는 \\({\\bf f}\\)에 대한 정보를 저장한다.\n\n\nNote: 이때 \\({\\bf W}={\\bf E}\\) 로 정의한다. (하지만 꼭 이래야 하는건 아니야)\n\n- data_dict \\(\\to\\) dl\n\nlags = 4\nfeatures = [f[i : i + lags, :].T for i in range(f.shape[0] - lags)]\ntargets = [f[i + lags, :].T for i in range(f.shape[0] - lags)]\n\n\nnp.array(features).shape, np.array(targets).shape\n\n((517, 20, 4), (517, 20))\n\n\n\n\n\n\n\n\n\n설명변수\n반응변수\n\n\n\n\n\\({\\bf X} = {\\tt features} = \\begin{bmatrix} {\\bf f}_1 & {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 \\\\ {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 & {\\bf f}_5 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ {\\bf f}_{517} & {\\bf f}_{518} & {\\bf f}_{519} & {\\bf f}_{520} \\end{bmatrix}\\)\n\\({\\bf y}= {\\tt targets} = \\begin{bmatrix} {\\bf f}_5 \\\\ {\\bf f}_6 \\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}\\)\n\n\n\n\nAR 느낌으로 표현하면 AR(4) 임\n\n\ndataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(\n    edge_index= edges,\n    edge_weight = edge_weight,\n    features = features,\n    targets = targets\n)\n\n\ndataset\n\n<torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7f89e2b6e340>\n\n\n- 그런데 이 과정을 아래와 같이 할 수도 있음\n# PyTorch Geometric Temporal 공식홈페이지에 소개된 코드\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset=loader.get_dataset(lags=4)\n- dataset은 dataset[0], \\(\\dots\\) , dataset[516]과 같은 방식으로 각 시점별 자료에 접근가능\n\ndataset[0]\n\nData(x=[20, 4], edge_index=[2, 102], edge_attr=[102], y=[20])\n\n\n각 시점에 대한 자료형은 아까 살펴보았던 PyG의 Data 자료형과 같음\n\ntype(dataset[0])\n\ntorch_geometric.data.data.Data\n\n\n\ndataset[0].x \n\ntensor([[-1.0814e-03,  2.8571e-02,  3.5474e-01,  2.9544e-01],\n        [-7.1114e-01, -5.9843e-01,  1.9051e-01,  1.0922e+00],\n        [-3.2281e+00, -2.2910e-01,  1.6103e+00, -1.5487e+00],\n        [ 6.4750e-01, -2.2117e+00, -9.6858e-01,  1.1862e+00],\n        [-1.7302e-01, -9.4717e-01,  1.0347e+00, -6.3751e-01],\n        [ 3.6345e-01, -7.5468e-01,  2.9768e-01, -1.6273e-01],\n        [-3.4174e+00,  1.7031e+00, -1.6434e+00,  1.7434e+00],\n        [-1.9641e+00,  5.5208e-01,  1.1811e+00,  6.7002e-01],\n        [-2.2133e+00,  3.0492e+00, -2.3839e+00,  1.8545e+00],\n        [-3.3141e-01,  9.5218e-01, -3.7281e-01, -8.2971e-02],\n        [-1.8380e+00, -5.8728e-01, -3.5514e-02, -7.2298e-02],\n        [-3.4669e-01, -1.9827e-01,  3.9540e-01, -2.4774e-01],\n        [ 1.4219e+00, -1.3266e+00,  5.2338e-01, -1.6374e-01],\n        [-7.7044e-01,  3.2872e-01, -1.0400e+00,  3.4945e-01],\n        [-7.8061e-01, -6.5022e-01,  1.4361e+00, -1.2864e-01],\n        [-1.0993e+00,  1.2732e-01,  5.3621e-01,  1.9023e-01],\n        [ 2.4583e+00, -1.7811e+00,  5.0732e-02, -9.4371e-01],\n        [ 1.0945e+00, -1.5922e+00,  1.3818e-01,  1.1855e+00],\n        [-7.0875e-01, -2.2460e-01, -7.0875e-01,  1.5630e+00],\n        [-1.8228e+00,  7.8633e-01, -5.6172e-01,  1.2647e+00]])\n\n\n\n이 값들은 features[0]의 값들과 같음. 즉 \\([{\\bf f}_1~ {\\bf f}_2~ {\\bf f}_3~ {\\bf f}_4]\\)를 의미함\n\n\ndataset[0].y\n\ntensor([ 0.7106, -0.0725,  2.6099,  1.7870,  0.8024, -0.2614, -0.8370,  1.9674,\n        -0.4212,  0.1655,  1.2519,  2.3743,  0.7877,  0.4531, -0.1721, -0.0614,\n         1.0452,  0.3203, -1.3791,  0.0036])\n\n\n\n이 값들은 targets[0]의 값들과 같음. 즉 \\({\\bf f}_5\\)를 의미함"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#summary-of-data",
    "href": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#summary-of-data",
    "title": "STGCN 튜토리얼",
    "section": "summary of data",
    "text": "summary of data\n\n\\(T\\) = 519\n\\(N\\) = 20 # number of nodes\n\\(|{\\cal E}|\\) = 102 # edges\n\\(f(t,v)\\)의 차원? (1,)\n시간에 따라서 Number of nodes가 변하는지? False\n시간에 따라서 Number of nodes가 변하는지? False\n\\({\\bf X}\\): (20,4)\n\\({\\bf y}\\): (20,)\n예제코드적용가능여부: Yes\n\n- Nodes : 20\n\nvertices are counties\n\n-Edges : 102\n\nedges are neighbourhoods\n\n- Time : 519\n\nbetween 2004 and 2014\nper weeks\n\n\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset = loader.get_dataset(lags=4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#learn",
    "href": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#learn",
    "title": "STGCN 튜토리얼",
    "section": "learn",
    "text": "learn\n\nmodel = RecurrentGCN(node_features=4, filters=32)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [01:08<00:00,  1.38s/it]"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#visualization",
    "href": "posts/STGCN/튜토리얼/2022-12-29-STGCN-tutorial.html#visualization",
    "title": "STGCN 튜토리얼",
    "section": "visualization",
    "text": "visualization\n\nmodel.eval()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nV = list(data_dict['node_ids'].keys())\n\n\nfig,ax = plt.subplots(20,1,figsize=(10,50))\nfor k in range(20):\n    ax[k].plot(f[:,k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:,k],label='predicted (tr)')\n    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html",
    "href": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html",
    "title": "Toy Example",
    "section": "",
    "text": "import networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#data",
    "href": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#data",
    "title": "Toy Example",
    "section": "data",
    "text": "data\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=14)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#recurrentgcn",
    "href": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#recurrentgcn",
    "title": "Toy Example",
    "section": "RecurrentGCN",
    "text": "RecurrentGCN\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#learn",
    "href": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#learn",
    "title": "Toy Example",
    "section": "Learn",
    "text": "Learn\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=14, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [03:48<00:00,  4.57s/it]"
  },
  {
    "objectID": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#예제의-차원-조사",
    "href": "posts/STGCN/튜토리얼/2022-12-30-STGCN-Toy Example.html#예제의-차원-조사",
    "title": "Toy Example",
    "section": "예제의 차원 조사",
    "text": "예제의 차원 조사\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x \n    _edge_index = snapshot.edge_index \n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1068, 14])\n\n\n\n1068: number of nodes // 1068개의 노드가 있음\n14: number of features // 하나의 노드에 맵핑된 차원의수\n\n\n_edge_index.shape\n\ntorch.Size([2, 27079])\n\n\n\n_edge_attr.shape\n\ntorch.Size([27079])\n\n\n\n_y.shape\n\ntorch.Size([1068])\n\n\n\n1068: number of nodes\n\n\n_x.shape\n\ntorch.Size([1068, 14])"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html",
    "title": "튜토리얼 따라가기1",
    "section": "",
    "text": "https://miruetoto.github.io/yechan3/posts/3_Researches/STGCN/2022-12-29-STGCN-tutorial.html\nhttps://pytorch-geometric-temporal.readthedocs.io/en/latest/"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#imports",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#imports",
    "title": "튜토리얼 따라가기1",
    "section": "imports",
    "text": "imports\n\n# 일반적인 모듈\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport networkx as nx # 그래프 시그널 시각화를 위한 모듈\nfrom tqdm import tqdm # for문의 진행 상태 확인\n\n# 파이토치 관련\nimport torch\nimport torch.nn.functional as F\n\n\n# PyG 관련\nfrom torch_geometric.data import Data # 그래프 자료를 만들기 위한 클래스\n\n\n# STGCN 관련\nimport torch_geometric_temporal\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\nfrom torch_geometric_temporal.signal import temporal_signal_split # STGCN dataset을 train/test set으로 분리\n\n- STGCN의 학습을 위한 클래스 선언\n\n# define recurrent GCN architecture\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#notations-of-stgcn",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#notations-of-stgcn",
    "title": "튜토리얼 따라가기1",
    "section": "notations of STGCN",
    "text": "notations of STGCN\n- 시계열: each \\(t\\) 에에 대한 observation이 하나의 값 (혹은 벡터)\n\n자료: \\(X(t) \\quad \\text{for} \\quad t = 1,2,\\dots,T\\)\n\n- STGCN setting에서는 each \\(t\\) 에 대한 observation이 graph\n\n자료: \\(X(v,t) \\quad \\text{for} \\quad t = 1,2,\\dots,T \\quad \\text{and} \\quad v\\in V\\)\n주의: 이 포스트에서는 \\(X(v,t)\\)를 \\(f(v,t)\\)로 표현할 때가 있음"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#dataset-dataloaders",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#dataset-dataloaders",
    "title": "튜토리얼 따라가기1",
    "section": "dataset, dataloaders",
    "text": "dataset, dataloaders\n\nPyG의 Data 자료형\n(예제) 아래와 같은 그래프 자료를 고려하자.\nWe show a simple example of an unweighted and undirected graph with three nodes and four edges. Each node contains exactly one feature\n\n이러한 자료형은 아래와 같은 형식으로 저장한다.\n\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype = torch.long)  # 4 edges\nx  = torch.tensor([[-1], [0], [1]], dtype = torch.float) # 3 nodes\ndata = Data(x=x, edge_index=edge_index) # Data는 그래프자료형을 만드는 클래스\n\n\ndata\n\nData(x=[3, 1], edge_index=[2, 4])\n\n\n\nx : \\(3\\times1\\) 크기의 행렬 \\(\\to\\) 3개의 노드와 각 노드는 단일 값을 가진다.\nedge_index : \\(2 \\times 4\\) 크기의 행렬 \\(\\to\\) \\(4\\)개의 엣지들 (양방향 그래프)\n\n\ntype(data)\n\ntorch_geometric.data.data.Data\n\n\n\ndata.x # 노드의 특징 행렬\n\ntensor([[-1.],\n        [ 0.],\n        [ 1.]])\n\n\n\ndata.edge_index # 그래프 연결성\n\ntensor([[0, 1, 1, 2],\n        [1, 0, 2, 1]])\n\n\n\ndata.num_edges # edge 총 갯수\n\n4\n\n\n\ndata.is_directed() # 그래프 방향성 여부 확인\n\nFalse"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#pytorch-geometric-temporal-의-자료형",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#pytorch-geometric-temporal-의-자료형",
    "title": "튜토리얼 따라가기1",
    "section": "PyTorch Geometric Temporal 의 자료형",
    "text": "PyTorch Geometric Temporal 의 자료형\n\nref: PyTorch Geomatric Temporal Signal\n\n아래의 클래스들 중 하나를 이용하여 만든다.\n\n## Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n\n## Heterogeneous Temporal Signal Iterators\ntorch_geometric_temporal.signal.StaticHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicHeteroGraphStaticSignal\n\ntorch_geometric_temporal.signal.dynamic_hetero_graph_static_signal.DynamicHeteroGraphStaticSignal\n\n\n이 중 “Heterogeneous Temporal Signal”은 우리가 관심이 있는 신호가 아님로 사실상 아래 3가지만 고려하면 된다.\n\ntorch_geometric_temporal.signal.StaticGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphTemporalSignal\ntorch_geometric_temporal.signal.DynamicGraphStaticSignal\n\n여기에서 StaticGraphTemporalSignal 는 시간에 따라서 그래프 구조가 일정한 경우, 즉 \\({\\cal G}_t=\\{{\\cal V},{\\cal E}\\}\\) 와 같은 구조를 의미한다.\n\n(예제1) StaticGraphTemporalSignal을 이용하여 데이터 셋 만들기\n- json data \\(\\to\\) dict\n\nimport json\nimport urllib\n\n\nurl = \"https://raw.githubusercontent.com/benedekrozemberczki/pytorch_geometric_temporal/master/dataset/chickenpox.json\"\ndata_dict = json.loads(urllib.request.urlopen(url).read())\n# data_dict 출력이 김\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n- 살펴보기\n\nnp.array(data_dict['edges']).T\n\narray([[ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,\n         3,  3,  3,  3,  3,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  6,\n         6,  6,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,\n        10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12,\n        12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15,\n        15, 15, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18, 18,\n        18, 18, 19, 19, 19, 19],\n       [10,  6, 13,  1,  0,  5, 16,  0, 16,  1, 14, 10,  8,  2,  5,  8,\n        15, 12,  9, 10,  3,  4, 13,  0, 10,  2,  5,  0, 16,  6, 14, 13,\n        11, 18,  7, 17, 11, 18,  3,  2, 15,  8, 10,  9, 13,  3, 12, 10,\n         5,  9,  8,  3, 10,  2, 13,  0,  6, 11,  7, 13, 18,  3,  9, 13,\n        12, 13,  9,  6,  4, 12,  0, 11, 10, 18, 19,  1, 14,  6, 16,  3,\n        15,  8, 16, 14,  1,  0,  6,  7, 19, 17, 18, 14, 18, 17,  7,  6,\n        19, 11, 18, 14, 19, 17]])\n\n\n\n\\({\\cal E} = \\{(0,10),(0,6), \\dots, (19,17)\\}\\)\n혹은 \\({\\cal E} = \\{(\\tt{BACS},\\tt{JASZ}), ({\\tt BACS},{\\tt FEJER}), \\dots, (\\tt{ZALA},\\tt{VAS})\\}\\)\n\n\ndata_dict['node_ids']\n\n{'BACS': 0,\n 'BARANYA': 1,\n 'BEKES': 2,\n 'BORSOD': 3,\n 'BUDAPEST': 4,\n 'CSONGRAD': 5,\n 'FEJER': 6,\n 'GYOR': 7,\n 'HAJDU': 8,\n 'HEVES': 9,\n 'JASZ': 10,\n 'KOMAROM': 11,\n 'NOGRAD': 12,\n 'PEST': 13,\n 'SOMOGY': 14,\n 'SZABOLCS': 15,\n 'TOLNA': 16,\n 'VAS': 17,\n 'VESZPREM': 18,\n 'ZALA': 19}\n\n\n\nlen(data_dict['node_ids']) # node 개수는 20개\n\n20\n\n\n\n\\({\\cal V}=\\{\\tt{BACS},\\tt{BARANYA} \\dots, \\tt{ZALA}\\}\\)\n\n\nlen(data_dict['edges']) # edge의 개수 102개\n\n102\n\n\n\ndata_dict.keys()\n\ndict_keys(['edges', 'node_ids', 'FX'])\n\n\n\nnp.array(data_dict['FX']), np.array(data_dict['FX']).shape\n\n(array([[-1.08135724e-03, -7.11136085e-01, -3.22808515e+00, ...,\n          1.09445310e+00, -7.08747750e-01, -1.82280792e+00],\n        [ 2.85705967e-02, -5.98430173e-01, -2.29097341e-01, ...,\n         -1.59220988e+00, -2.24597623e-01,  7.86330575e-01],\n        [ 3.54742090e-01,  1.90511208e-01,  1.61028185e+00, ...,\n          1.38183225e-01, -7.08747750e-01, -5.61724314e-01],\n        ...,\n        [-4.75512620e-01, -1.19952837e+00, -3.89043358e-01, ...,\n         -1.00023329e+00, -1.71429032e+00,  4.70746677e-02],\n        [-2.08645035e-01,  6.03766218e-01,  1.08216835e-02, ...,\n          4.71099041e-02,  2.45684924e+00, -3.44296107e-01],\n        [ 1.21464875e+00,  7.16472130e-01,  1.29038982e+00, ...,\n          4.56939849e-01,  7.43702632e-01,  1.00375878e+00]]),\n (521, 20))\n\n\n\n\\({\\bf f}=\\begin{bmatrix} {\\bf f}_1\\\\ {\\bf f}_2\\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}=\\begin{bmatrix} f(t=1,v=\\tt{BACS}) & \\dots & f(t=1,v=\\tt{ZALA}) \\\\ f(t=2,v=\\tt{BACS}) & \\dots & f(t=2,v=\\tt{ZALA}) \\\\ \\dots & \\dots & \\dots \\\\ f(t=521,v=\\tt{BACS}) & \\dots & f(t=521,v=\\tt{ZALA}) \\end{bmatrix}\\)\n\n즉, data_dict는 아래와 같이 구성되어 있음\n\n\n\n\n\n\n\n\n\n\n수학 기호\n코드에 저장된 변수\n자료형\n차원\n설명\n\n\n\n\n\\({\\cal V}\\)\ndata_dict['node_ids']\ndict\n20\n20개의 노드에 대한 설명이 있음\n\n\n\\({\\cal E}\\)\ndata_dict['edges']\nlist (double list)\n(102,2)\n노드들에 대한 102개의 연결을 정의함\n\n\n\\({\\bf f}\\)\ndata_dict['node_ids']\ndict\n(521,20)\n\\(f(t,v)\\) for \\(v \\in {\\cal V}\\) and \\(t = 1,\\dots, T\\)\n\n\n\n- 주어진 자료를 정리하여 그래프신호 \\(\\big(\\{{\\cal V},{\\cal E},{\\bf W}\\},{\\bf f}\\big)\\)를 만들면 아래와 같다.\n\nedges = np.array(data_dict['edges']).T\nedge_weight = np.ones(edges.shape[1])\nf =  np.array(data_dict['FX'])\n\n\n여기에서 edges는 \\(\\cal{E}\\) 에 대한 정보들\nedges_weight는 \\(\\bf{W}\\)에 대한 정보들\nf는 \\(\\bf{f}\\)에 대한 정보를 저장한다.\n\n\nNote: 이때 \\(\\bf{W} = \\bf{E}\\)로 정의한다.\n\n- data_dict \\(\\to\\) dl\n\nlags = 4\nfeatures = [f[i : i + lags, :].T for i in range(f.shape[0] - lags)]\ntargets = [f[i + lags, :].T for i in range(f.shape[0] - lags)]\n\n\nnp.array(features).shape, np.array(targets).shape\n\n((517, 20, 4), (517, 20))\n\n\n\n\n\n\n\n\n\n설명변수\n반응변수\n\n\n\n\n\\({\\bf X} = {\\tt features} = \\begin{bmatrix} {\\bf f}_1 & {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 \\\\ {\\bf f}_2 & {\\bf f}_3 & {\\bf f}_4 & {\\bf f}_5 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ {\\bf f}_{517} & {\\bf f}_{518} & {\\bf f}_{519} & {\\bf f}_{520} \\end{bmatrix}\\)\n\\({\\bf y}= {\\tt targets} = \\begin{bmatrix} {\\bf f}_5 \\\\ {\\bf f}_6 \\\\ \\dots \\\\ {\\bf f}_{521} \\end{bmatrix}\\)\n\n\n\n\nAR 느낌으로 표현하면 AR(4) 이다.\n\n\ndataset = torch_geometric_temporal.signal.StaticGraphTemporalSignal(\n    edge_index = edges,\n    edge_weight = edge_weight,\n    features = features,\n    targets = targets)\n\n\ndataset\n\n<torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7fc4bee0a250>\n\n\n- 그런데 이 과정을 아래와 같이 할 수도있음\n\n# Pytorch Geometric Temporal 공식홈페이지에 소개된 콛,ㅡ\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset = loader.get_dataset(lags = 4)\n\n- dataset은 dataset[0],\\(\\dots\\)dataset[516]과 같은 방식으로 각 시점별 자료에 접근 가능\n\ndataset[0]\n\nData(x=[20, 4], edge_index=[2, 102], edge_attr=[102], y=[20])\n\n\n각 시점에 대한 자료형은 아까 살펴보았던 PyG의 Data 자료형과 같음\n\ntype(dataset[0])\n\ntorch_geometric.data.data.Data\n\n\n\ndataset[0].x\n\ntensor([[-1.0814e-03,  2.8571e-02,  3.5474e-01,  2.9544e-01],\n        [-7.1114e-01, -5.9843e-01,  1.9051e-01,  1.0922e+00],\n        [-3.2281e+00, -2.2910e-01,  1.6103e+00, -1.5487e+00],\n        [ 6.4750e-01, -2.2117e+00, -9.6858e-01,  1.1862e+00],\n        [-1.7302e-01, -9.4717e-01,  1.0347e+00, -6.3751e-01],\n        [ 3.6345e-01, -7.5468e-01,  2.9768e-01, -1.6273e-01],\n        [-3.4174e+00,  1.7031e+00, -1.6434e+00,  1.7434e+00],\n        [-1.9641e+00,  5.5208e-01,  1.1811e+00,  6.7002e-01],\n        [-2.2133e+00,  3.0492e+00, -2.3839e+00,  1.8545e+00],\n        [-3.3141e-01,  9.5218e-01, -3.7281e-01, -8.2971e-02],\n        [-1.8380e+00, -5.8728e-01, -3.5514e-02, -7.2298e-02],\n        [-3.4669e-01, -1.9827e-01,  3.9540e-01, -2.4774e-01],\n        [ 1.4219e+00, -1.3266e+00,  5.2338e-01, -1.6374e-01],\n        [-7.7044e-01,  3.2872e-01, -1.0400e+00,  3.4945e-01],\n        [-7.8061e-01, -6.5022e-01,  1.4361e+00, -1.2864e-01],\n        [-1.0993e+00,  1.2732e-01,  5.3621e-01,  1.9023e-01],\n        [ 2.4583e+00, -1.7811e+00,  5.0732e-02, -9.4371e-01],\n        [ 1.0945e+00, -1.5922e+00,  1.3818e-01,  1.1855e+00],\n        [-7.0875e-01, -2.2460e-01, -7.0875e-01,  1.5630e+00],\n        [-1.8228e+00,  7.8633e-01, -5.6172e-01,  1.2647e+00]])\n\n\n\n이 값들은 features[0]의 값들과 같음. 즉 \\([\\bf{f}_1, \\bf{f}_2, \\bf{f}_3, \\bf{f}_4]\\)를 의미함\n\n\ndataset[0].y\n\ntensor([ 0.7106, -0.0725,  2.6099,  1.7870,  0.8024, -0.2614, -0.8370,  1.9674,\n        -0.4212,  0.1655,  1.2519,  2.3743,  0.7877,  0.4531, -0.1721, -0.0614,\n         1.0452,  0.3203, -1.3791,  0.0036])\n\n\n\n이 값들은 targets[0]이 값들과 같음. 즉 \\(\\bf{f}_5\\)를 의미함"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#summary-of-data",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#summary-of-data",
    "title": "튜토리얼 따라가기1",
    "section": "Summary of data",
    "text": "Summary of data\n\n\\(T = 519\\)\n\\(N=20\\) # number of nodes\n\\(|\\cal{E}|=102\\) # edges\n\\(f(t,v)\\)의 차원? \\((1,)\\) # edges\n시간에 따라서 Number of nods가 변하는지? \\(\\to\\) False\n\\(\\bf{X}: (20, 4)\\)\n\\(\\bf{y}: (20, )\\)\n예제코드적용가능 여부 : Yes\n\n- Nodes : 20 - vertices are counties\n- Edges: 102 - edges are neighbourhoods\n- Time: 519 - between 2004 and 2014 - per weeks\n\nloader = torch_geometric_temporal.dataset.ChickenpoxDatasetLoader()\ndataset = loader.get_dataset(lags = 4)\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio = 0.8)"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#learn",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#learn",
    "title": "튜토리얼 따라가기1",
    "section": "Learn",
    "text": "Learn\n\nmodel = RecurrentGCN(node_features = 4, filters = 32)\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for t, snapshot in enumerate(train_dataset):\n        yt_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((yt_hat - snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [01:08<00:00,  1.37s/it]"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#visualization",
    "href": "posts/STGCN/STGCN 공부/2023-02-21-STGCN-tutorial1.html#visualization",
    "title": "튜토리얼 따라가기1",
    "section": "Visualization",
    "text": "Visualization\n\nmodel.eval()\n\nRecurrentGCN(\n  (recurrent): GConvGRU(\n    (conv_x_z): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_r): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n    (conv_x_h): ChebConv(4, 32, K=2, normalization=sym)\n    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n  )\n  (linear): Linear(in_features=32, out_features=1, bias=True)\n)\n\n\n\nyhat_train = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in train_dataset]).detach().numpy()\nyhat_test = torch.stack([model(snapshot.x,snapshot.edge_index, snapshot.edge_attr) for snapshot in test_dataset]).detach().numpy()\n\n\nV = list(data_dict['node_ids'].keys())\nV\n\n['BACS',\n 'BARANYA',\n 'BEKES',\n 'BORSOD',\n 'BUDAPEST',\n 'CSONGRAD',\n 'FEJER',\n 'GYOR',\n 'HAJDU',\n 'HEVES',\n 'JASZ',\n 'KOMAROM',\n 'NOGRAD',\n 'PEST',\n 'SOMOGY',\n 'SZABOLCS',\n 'TOLNA',\n 'VAS',\n 'VESZPREM',\n 'ZALA']\n\n\n\nfig,ax = plt.subplots(20,1,figsize=(10,50))\nfor k in range(20):\n    ax[k].plot(f[:,k],'--',alpha=0.5,label='observed')\n    ax[k].set_title('node: {}'.format(V[k]))\n    ax[k].plot(yhat_train[:,k],label='predicted (tr)')\n    ax[k].plot(range(yhat_train.shape[0],yhat_train.shape[0]+yhat_test.shape[0]),yhat_test[:,k],label='predicted (test)')\n    ax[k].legend()\nfig.tight_layout()"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html",
    "href": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html",
    "title": "튜토리얼 따라가기2",
    "section": "",
    "text": "Toy Example"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#data",
    "href": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#data",
    "title": "튜토리얼 따라가기2",
    "section": "Data",
    "text": "Data\n\nfrom torch_geometric_temporal.dataset import WikiMathsDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n\nloader = WikiMathsDatasetLoader()\n\ndataset = loader.get_dataset(lags=14)\n\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.5)"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#recurrentgcn",
    "href": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#recurrentgcn",
    "title": "튜토리얼 따라가기2",
    "section": "RecurrentGCN",
    "text": "RecurrentGCN\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import GConvGRU\n\nclass RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = GConvGRU(node_features, filters, 2)\n        self.linear = torch.nn.Linear(filters, 1)\n        \n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#learn",
    "href": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#learn",
    "title": "튜토리얼 따라가기2",
    "section": "Learn",
    "text": "Learn\n\n# 오래걸림 주의\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features = 14, filters = 32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat - snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [06:21<00:00,  7.63s/it]"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#예제의-차원-조사",
    "href": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#예제의-차원-조사",
    "title": "튜토리얼 따라가기2",
    "section": "예제의 차원 조사",
    "text": "예제의 차원 조사\n\nfor time, snapshot in enumerate(train_dataset):\n    _x = snapshot.x\n    _edge_index = snapshot.edge_index\n    _edge_attr = snapshot.edge_attr\n    _y = snapshot.y\n    break\n\n\n_x.shape\n\ntorch.Size([1068, 14])\n\n\n\n1068: number of nodes # 1068개의 노드가 있음\n14: number of features # 하나의 노드에 맵핑된 차원의 수\n\n\n_edge_index.shape\n\ntorch.Size([2, 27079])\n\n\n\n_edge_attr.shape\n\ntorch.Size([27079])\n\n\n\n_y.shape\n\ntorch.Size([1068])\n\n\n\n1068: number of nodes\n\n\n_x.shape\n\ntorch.Size([1068, 14])"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#우리예제",
    "href": "posts/STGCN/STGCN 공부/2023-02-23-stgcn-tutorial2.html#우리예제",
    "title": "튜토리얼 따라가기2",
    "section": "우리예제",
    "text": "우리예제\n\nT = 100 \nN = 4 # number of nodes \nE = np.array([[0,1],[1,2],[2,3],[3,0]]).T\nV = np.array([1,2,3,4])\nAMP = np.array([3,2,1,2.2])\nt = np.arange(0,T)\nnode_features = 1 \n\n\nf = np.stack([a*np.sin(2*t**2/1000)+np.random.normal(loc=0,scale=0.2,size=T) for a in AMP],axis=1).reshape(T,N,node_features)\nf = torch.tensor(f).float()\n\n\nf.shape\n\ntorch.Size([100, 4, 1])\n\n\n\nX = f[:99,:,:]\ny = f[1:,:,:]\n\n\nplt.plot(y[:,0,0],label=\"v1\")\nplt.plot(y[:,1,0],label=\"v2\")\nplt.plot(y[:,2,0],label=\"v3\")\nplt.plot(y[:,3,0],label=\"v4\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fdca565c8e0>\n\n\n\n\n\n\nedge_index = torch.tensor(E)\nedge_attr = torch.tensor(np.array([1,1,1,1]),dtype=torch.float32)\n\n\n_ee = enumerate(zip(X,y))\n\n\nfrom tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=1, filters=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nmodel.train()\n\nfor epoch in tqdm(range(50)):\n    for time, (xt,yt) in enumerate(zip(X,y)):\n        y_hat = model(xt, edge_index, edge_attr)\n        cost = torch.mean((y_hat-yt)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n100%|██████████| 50/50 [00:15<00:00,  3.22it/s]\n\n\n\nyhat = torch.stack([model(xt, edge_index, edge_attr) for xt in X]).detach().numpy()\n\n\nplt.plot(y[:,0,0],label=\"y in V1\")\nplt.plot(yhat[:,0,0],label=\"yhat in V1\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fdc9c7883d0>\n\n\n\n\n\n\nplt.plot(y[:,1,0],label=\"y in V2\")\nplt.plot(yhat[:,1,0],label=\"yhat in V2\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fdc9c764e50>\n\n\n\n\n\n\nplt.plot(y[:,2,0],label=\"y in V3\")\nplt.plot(yhat[:,2,0],label=\"yhat in V3\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fdc9c6bd940>\n\n\n\n\n\n\nplt.plot(y[:,3,0],label=\"y in V4\")\nplt.plot(yhat[:,3,0],label=\"yhat in V4\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fdc9c69e8e0>"
  },
  {
    "objectID": "posts/STGCN/STGCN 공부/traffic_prediction.html",
    "href": "posts/STGCN/STGCN 공부/traffic_prediction.html",
    "title": "Traffic Forecasting review",
    "section": "",
    "text": "https://www.youtube.com/watch?v=Rws9mf1aWUs\n\n\n\n\nimport torch\nfrom IPython.display import clear_output\npt_version = torch.__version__\nprint(pt_version)\n\n1.11.0+cu113\n\n\nThis took some time for me, so be patient :)\n\n!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n!pip install torch-geometric\n!pip install torch-geometric-temporal\nclear_output()\n\n\n\n\n\nTraffic forecasting dataset based on Los Angeles Metropolitan traffic\n207 loop detectors on highways\nMarch 2012 - June 2012\nFrom the paper: Diffusion Convolutional Recurrent Neural Network\n\n\nimport numpy as np\nfrom torch_geometric_temporal.dataset import METRLADatasetLoader\nfrom torch_geometric_temporal.signal import StaticGraphTemporalSignal\n\nloader = METRLADatasetLoader()\ndataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n\nprint(\"Dataset type:  \", dataset)\nprint(\"Number of samples / sequences: \",  len(set(dataset)))\n\nDataset type:   <torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal object at 0x7f455e5315d0>\nNumber of samples / sequences:  34249\n\n\n\n\n\n207 nodes\n2 features per node (speed, time)\n12 timesteps per bucket (12 x 5 min = 60 min)\nLabels for 12 future timesteps (normalized speed) –> node regression\nEdge_attr is build based on the distances between sensors + threshold\nFurther details: https://pytorch-geometric-temporal.readthedocs.io/en/latest/_modules/torch_geometric_temporal/dataset/metr_la.html#METRLADatasetLoader\nRaw data: https://graphmining.ai/temporal_datasets/METR-LA.zip\n\n\n# Show first sample\nnext(iter(dataset))\n\nData(x=[207, 2, 12], edge_index=[2, 1722], edge_attr=[1722], y=[207, 12])\n\n\n\n# Important: It is not always like that!\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nd = ChickenpoxDatasetLoader().get_dataset(lags=4)\nnext(iter(d))\n\nData(x=[20, 4], edge_index=[2, 102], edge_attr=[102], y=[20])\n\n\nYou can always have a look at the source-code to see how a dataset is constructed. Chickenpox would be a classical “predict-next-timestep” dataset (the label is one step later than the features).\nMETR-LA would be a sequence-to-sequence prediction dataset that predicts further into the future than just the next timestep. You can also see, that the features are used as label as well.\n# >>> From the ChickenpoxDatasetLoader <<<\nself.features = [\n            stacked_target[i : i + self.lags, :].T\n            for i in range(stacked_target.shape[0] - self.lags)\n        ]\nself.targets = [\n            stacked_target[i + self.lags, :].T  \n            for i in range(stacked_target.shape[0] - self.lags)\n        ]\n\n# >>> From METRLADatasetLoader <<<\nindices = [\n            (i, i + (num_timesteps_in + num_timesteps_out))\n            for i in range(self.X.shape[2] - (num_timesteps_in + num_timesteps_out) + 1)\n        ]\nfor i, j in indices:\n            features.append((self.X[:, :, i : i + num_timesteps_in]).numpy())\n            target.append((self.X[:, 0, i + num_timesteps_in : j]).numpy())\n\nimport seaborn as sns\n# Visualize traffic over time\nsensor_number = 1\nhours = 24\nsensor_labels = [bucket.y[sensor_number][0].item() for bucket in list(dataset)[:hours]]\nsns.lineplot(data=sensor_labels)\n\n<matplotlib.axes._subplots.AxesSubplot at 0x7f455d15d310>\n\n\n\n\n\n\n\n\n\nfrom torch_geometric_temporal.signal import temporal_signal_split\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n\nprint(\"Number of train buckets: \", len(set(train_dataset)))\nprint(\"Number of test buckets: \", len(set(test_dataset)))\n\nNumber of train buckets:  27399\nNumber of test buckets:  6850\n\n\n\n\n\n\nWhich model to choose depends on which time-series task you work on.\n\nA3TGCN is an extension of TGCN that uses attention\nThe spatial aggregation uses GCN, the temporal aggregation a GRU\nWe can pass in periods to get an embedding for several timesteps\nThis embedding can be used to predict several steps into the future = output dimension\nWe could also do this in a loop and feed it again into the model (would be autoregressive)\nThere is only one block here. Other layers also allow stacking???\n\n\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric_temporal.nn.recurrent import A3TGCN\n\nclass TemporalGNN(torch.nn.Module):\n    def __init__(self, node_features, periods):\n        super(TemporalGNN, self).__init__()\n        # Attention Temporal Graph Convolutional Cell\n        self.tgnn = A3TGCN(in_channels=node_features, \n                           out_channels=32, \n                           periods=periods)\n        # Equals single-shot prediction\n        self.linear = torch.nn.Linear(32, periods)\n\n    def forward(self, x, edge_index):\n        \"\"\"\n        x = Node features for T time steps\n        edge_index = Graph edge indices\n        \"\"\"\n        h = self.tgnn(x, edge_index)\n        h = F.relu(h)\n        h = self.linear(h)\n        return h\n\nTemporalGNN(node_features=2, periods=12)\n\nTemporalGNN(\n  (tgnn): A3TGCN(\n    (_base_tgcn): TGCN(\n      (conv_z): GCNConv(2, 32)\n      (linear_z): Linear(in_features=64, out_features=32, bias=True)\n      (conv_r): GCNConv(2, 32)\n      (linear_r): Linear(in_features=64, out_features=32, bias=True)\n      (conv_h): GCNConv(2, 32)\n      (linear_h): Linear(in_features=64, out_features=32, bias=True)\n    )\n  )\n  (linear): Linear(in_features=32, out_features=12, bias=True)\n)\n\n\n\n\n\n\nTraining on GPU didn’t bring much speed-up\nI ran into RAM issues, why I only train on a smaller subset of the data\n\n\n# GPU support\ndevice = torch.device('cpu') # cuda\nsubset = 2000\n\n# Create model and optimizers\nmodel = TemporalGNN(node_features=2, periods=12).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.train()\n\nprint(\"Running training...\")\nfor epoch in range(10): \n    loss = 0\n    step = 0\n    for snapshot in train_dataset:\n        snapshot = snapshot.to(device)\n        # Get model predictions\n        y_hat = model(snapshot.x, snapshot.edge_index)\n        # Mean squared error\n        loss = loss + torch.mean((y_hat-snapshot.y)**2) \n        step += 1\n        if step > subset:\n          break\n\n    loss = loss / (step + 1)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    print(\"Epoch {} train MSE: {:.4f}\".format(epoch, loss.item()))\n\nRunning training...\n\n\n\n\n\n\nLets get some sample predictions for a specific horizon (e.g. 288/12 = 24 hours)\nThe model always gets one hour and needs to predict the next hour\n\n\nmodel.eval()\nloss = 0\nstep = 0\nhorizon = 288\n\n# Store for analysis\npredictions = []\nlabels = []\n\nfor snapshot in test_dataset:\n    snapshot = snapshot.to(device)\n    # Get predictions\n    y_hat = model(snapshot.x, snapshot.edge_index)\n    # Mean squared error\n    loss = loss + torch.mean((y_hat-snapshot.y)**2)\n    # Store for analysis below\n    labels.append(snapshot.y)\n    predictions.append(y_hat)\n    step += 1\n    if step > horizon:\n          break\n\nloss = loss / (step+1)\nloss = loss.item()\nprint(\"Test MSE: {:.4f}\".format(loss))\n\n\n\n\nThe further away the point in time is, the worse the predictions get\nPredictions shape: [num_data_points, num_sensors, num_timesteps]\n\n\nimport numpy as np\n\nsensor = 123\ntimestep = 11 \npreds = np.asarray([pred[sensor][timestep].detach().cpu().numpy() for pred in predictions])\nlabs  = np.asarray([label[sensor][timestep].cpu().numpy() for label in labels])\nprint(\"Data points:,\", preds.shape)\n\nData points:, (289,)\n\n\n\nimport matplotlib.pyplot as plt \nplt.figure(figsize=(20,5))\nsns.lineplot(data=preds, label=\"pred\")\nsns.lineplot(data=labs, label=\"true\")\n\n<matplotlib.axes._subplots.AxesSubplot at 0x7f7b14858950>"
  },
  {
    "objectID": "posts/GNN/2023-03-04-gnn-intro.html",
    "href": "posts/GNN/2023-03-04-gnn-intro.html",
    "title": "1 GNN tuto1",
    "section": "",
    "text": "Zachary’s karate club network example\n\nRecently, deep learning on graphs has emerged to one of the hottest research fields in the deep learning community. Here, Graph Neural Networks (GNNs) aim to generalize classical deep learning concepts to irregular structured data (in contrast to images or texts) and to enable neural networks to reason about objects and their relations.\nThis is done by following a simple neural message passing scheme, where node features \\(\\mathbf{x}_v^{(\\ell)}\\) of all nodes \\(v \\in \\mathcal{V}\\) in a graph \\(\\mathcal{G} = (\\mathcal{V}, \\mathcal{E})\\) are iteratively updated by aggregating localized information from their neighbors \\(\\mathcal{N}(v)\\):\n\\[\n\\mathbf{x}_v^{(\\ell + 1)} = f^{(\\ell + 1)}_{\\theta} \\left( \\mathbf{x}_v^{(\\ell)}, \\left\\{ \\mathbf{x}_w^{(\\ell)} : w \\in \\mathcal{N}(v) \\right\\} \\right)\n\\]\n\n(참고): PyTorch Geometric is an extension library to the popular deep learning framework PyTorch, and consists of various methods and utilities to ease the implementation of Graph Neural Networks.\n\n\n\nZachary’s karate club network : This graph describes a social network of 34 members of a karate club and documents links between members who interacted outside the club. Here, we are interested in detecting communities that arise from the member’s interaction.\n\nimport os\nimport torch\n\n# helper function for visualization\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n\ndef visualize_graph(G, color):\n    plt.figure(figsize=(7,7))\n    plt.xticks([])\n    plt.yticks([])\n    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n                     node_color=color, cmap=\"Set2\")\n    plt.show()\n    \ndef visualize_embedding(h, color, epoch=None, loss=None):\n    plt.figure(figsize=(7,7))\n    plt.xticks([])\n    plt.yticks([])\n    h = h.detach().cpu().numpy()\n    plt.scatter(h[:,0],h[:,1], s=140, c=color, cmap=\"Set2\")\n    if epoch is not None and loss is not None:\n        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n    plt.show()\n\n\n# PyTorch Geometric provides an easy access to this dataset via the torch_geometric.datasets subpackage\nfrom torch_geometric.datasets import KarateClub\n\ndataset = KarateClub()\nprint(f'Dataset: {dataset}:')\nprint('=========================')\nprint(f'Number of graphs: {len(dataset)}')\nprint(f'Number of features: {dataset.num_features}')\nprint(f'Number of classes: {dataset.num_classes}')\n\nDataset: KarateClub():\n=========================\nNumber of graphs: 1\nNumber of features: 34\nNumber of classes: 4\n\n\n\n\n\n\ndataset[0]\n\nData(x=[34, 34], edge_index=[2, 156], y=[34], train_mask=[34])\n\n\n해당 데이터셋은 정확히 하나의 그래프를 포함한다.\n\ndataset[1] # 에러나는게 당연함.\n\nIndexError: range object index out of range\n\n\n\ndata = dataset[0]  # Get the first graph object.\n\nprint(data)\nprint('==============================================================')\n\n# Gather some statistics about the graph.\nprint(f'Number of nodes: {data.num_nodes}')\nprint(f'Number of edges: {data.num_edges}')\nprint(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\nprint(f'Number of training nodes: {data.train_mask.sum()}')\nprint(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\nprint(f'Has isolated nodes: {data.has_isolated_nodes()}')\nprint(f'Has self-loops: {data.has_self_loops()}')\nprint(f'Is undirected: {data.is_undirected()}')\n\nData(x=[34, 34], edge_index=[2, 156], y=[34], train_mask=[34])\n==============================================================\nNumber of nodes: 34\nNumber of edges: 156\nAverage node degree: 4.59\nNumber of training nodes: 4\nTraining node label rate: 0.12\nHas isolated nodes: False\nHas self-loops: False\nIs undirected: True\n\n\n- print(data)\n\n# print data object -> recieve a short summary about its attributes and their shape\nprint(data)\n\nData(x=[34, 34], edge_index=[2, 156], y=[34], train_mask=[34])\n\n\n\nPytorch Geometric에는 Data 오브젝트가 있다. print(data)를 통해 데이터의 오브젝트를 출력할 수 있다.\ndata 오브젝트에는 4개의 속성이 있음.\n\n\nedge_index\n\n\nx ( node features)\n\n\ny (node label)\n\n\ntrain_mask\n\n\n\n\n\n\nedge_index = data.edge_index\nprint(edge_index.t()[:10])\nprint(edge_index.t().shape)\n\ntensor([[ 0,  1],\n        [ 0,  2],\n        [ 0,  3],\n        [ 0,  4],\n        [ 0,  5],\n        [ 0,  6],\n        [ 0,  7],\n        [ 0,  8],\n        [ 0, 10],\n        [ 0, 11]])\ntorch.Size([156, 2])\n\n\n\nedge_index 는 graph connectivity에 대한 정보를 갖고 있으며 두 노드 인덱스의 튜플 형태로 저장되어 있음.\n(first node index, second node index) = (source node index, destination node index) 이런꼴\nPyG에서는 directed graphs와 undirected graphs를 구별하지 않는다. undirected 그래프를 directed 그래프의 특수케이스로 취급(directed graph edge_index의 모든 항목에 대해 inverse edge가 존재하는 경우)\n\n\n\n\n\ndata.x, data.x.shape # node featurs matrix\n\n(tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n         [0., 1., 0.,  ..., 0., 0., 0.],\n         [0., 0., 1.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 1., 0., 0.],\n         [0., 0., 0.,  ..., 0., 1., 0.],\n         [0., 0., 0.,  ..., 0., 0., 1.]]),\n torch.Size([34, 34]))\n\n\n\nkarate club dataset의 각 노드에 karate club 구성원을 고유하게 설명하는 34차원 feature vector가 할당되어 있다.\n\n\n\n\n\ndata.y # node labels\n\ntensor([1, 1, 1, 1, 3, 3, 3, 1, 0, 1, 3, 1, 1, 1, 0, 0, 3, 1, 0, 1, 0, 1, 0, 0,\n        2, 2, 0, 0, 2, 0, 0, 2, 0, 0])\n\n\n\n그래프에는 각 노드가 속한 커뮤니티를 나타내는 4개의 클래스가 있음.\n\n\n\n\n\ndata.train_mask # describes for which nodes we already know their community assigments\n\ntensor([ True, False, False, False,  True, False, False, False,  True, False,\n        False, False, False, False, False, False, False, False, False, False,\n        False, False, False, False,  True, False, False, False, False, False,\n        False, False, False, False])\n\n\n\ntrain_mask라는 속성은 정답을 알고있는지의 여부를 나타낸다. 여기서 정답이란, 각 구성원들의 커뮤니티 소속이라고 보면 된다. (4class니까 4개의 커뮤니티 중 하나겠지)\n\n\n(data.train_mask).sum() # 정답을 알고있는 노드의 수 \n\ntensor(4)\n\n\n\ndata.num_nodes\n\n34\n\n\n\nround(4/34,2) # training node label ratio\n\n0.12\n\n\n\n총 34개의 노드 중 정답을 알고있는 노드의 수는 4개이다. 우리의 목표는 나머지 30개의 노드의 소속된 커뮤니티를 맞추는 것\n\n\n\n\n\n\n# 위에서 정의한 그래프 시각화를 위한 함수..\ndef visualize_graph(G, color):\n    plt.figure(figsize=(7,7))\n    plt.xticks([])\n    plt.yticks([])\n    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=True,\n                     node_color=color, cmap=\"Set2\")\n    plt.show()\n\n\nnx?\n\n\nType:        module\nString form: <module 'networkx' from '/home/hankang07/anaconda3/envs/py38/lib/python3.8/site-packages/networkx/__init__.py'>\nFile:        ~/anaconda3/envs/py38/lib/python3.8/site-packages/networkx/__init__.py\nDocstring:  \nNetworkX\n========\nNetworkX is a Python package for the creation, manipulation, and study of the\nstructure, dynamics, and functions of complex networks.\nSee https://networkx.org for complete documentation.\n\n\n\n\n#nx.spring_layout?\n\n\n#nx.draw_networkx?\n\n\nfrom torch_geometric.utils import to_networkx\n\nG = to_networkx(data, to_undirected=True) # 무방향 그래프\nvisualize_graph(G, color = data.y)\n\n\n\n\n(참고) 그래프를 networkx 라이브러리 형식으로 변환하면 그래프 시각화를 위한 많은 기능(그래프 조작 등.)을 사용할 수 있음.\n\n\n\nWe will use on of the most simple GNN operators, the GCN layer (Kipf et al. (2017)), which is defined as\n\\[\n\\mathbf{x}_v^{(\\ell + 1)} = \\mathbf{W}^{(\\ell + 1)} \\sum_{w \\in \\mathcal{N}(v) \\, \\cup \\, \\{ v \\}} \\frac{1}{c_{w,v}} \\cdot \\mathbf{x}_w^{(\\ell)}\n\\]\nwhere \\(\\mathbf{W}^{(\\ell + 1)}\\) denotes a trainable weight matrix of shape [num_output_features, num_input_features] and \\(c_{w,v}\\) refers to a fixed normalization coefficient for each edge.\nPyG implements this layer via GCNConv, which can be executed by passing in the node feature representation x and the COO graph connectivity representation edge_index.\nWith this, we are ready to create our first Graph Neural Network by defining our network architecture in a torch.nn.Module class:\n\n# create GNN by defining our network architecture in a 'torch.nn.Mudule' class\nimport torch\nfrom torch.nn import Linear\nfrom torch_geometric.nn import GCNConv\n\n\nclass GCN(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        # 우리가 사용할 레이어 정의\n        torch.manual_seed(1234)\n        self.conv1 = GCNConv(dataset.num_features, 4)\n        self.conv2 = GCNConv(4, 4)\n        self.conv3 = GCNConv(4, 2)\n        self.classifier = Linear(2, dataset.num_classes)\n        # 레이어 정의 끝\n        \n    def forward(self, x, edge_index):\n        # yhat(output)을 어떻게 구할 것인지 정의\n        h = self.conv1(x, edge_index)\n        h = h.tanh()\n        h = self.conv2(h, edge_index)\n        h = h.tanh()\n        h = self.conv3(h, edge_index)\n        h = h.tanh()  # Final GNN embedding space.\n        \n        # Apply a final (linear) classifier.\n        out = self.classifier(h)\n        \n        # 정의 끝\n        return out, h\n\nmodel = GCN()\nprint(model)\n\nGCN(\n  (conv1): GCNConv(34, 4)\n  (conv2): GCNConv(4, 4)\n  (conv3): GCNConv(4, 2)\n  (classifier): Linear(in_features=2, out_features=4, bias=True)\n)\n\n\n\nprint(data)\n\nData(x=[34, 34], edge_index=[2, 156], y=[34], train_mask=[34])\n\n\n\nWe first define and stack three graph convolution layers, which corresponds to aggregating 3-hop neighborhood information around each node (all nodes up to 3 “hops” away). In addition, the GCNConv layers reduce the node feature dimensionality to \\(2\\) , i.e., \\(34→4→4→2\\) . Each GCNConv layer is enhanced by a tanh non-linearity.\n\n\n\n\nLet’s take a look at the node embeddings produced by our GNN. Here, we pass in the initial node features x and the graph connectivity information edge_index to the model, and visualize its 2-dimensional embedding.\n\ndef visualize_embedding(h, color, epoch=None, loss=None):\n    plt.figure(figsize=(7,7))\n    plt.xticks([])\n    plt.yticks([])\n    h = h.detach().cpu().numpy()\n    plt.scatter(h[:,0],h[:,1], s=140, c=color, cmap=\"Set2\")\n    if epoch is not None and loss is not None:\n        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n    plt.show()\n\n\nmodel = GCN()\n\n_, h = model(data.x, data.edge_index)\nprint(f'Embedding shape: {list(h.shape)}')\n\nvisualize_embedding(h, color=data.y)\n\nEmbedding shape: [34, 2]\n\n\n\n\n\nRemarkably, even before training the weights of our model, the model produces an embedding of nodes that closely resembles the community-structure of the graph. Nodes of the same color (community) are already closely clustered together in the embedding space, although the weights of our model are initialized completely at random and we have not yet performed any training so far! This leads to the conclusion that GNNs introduce a strong inductive bias, leading to similar embeddings for nodes that are close to each other in the input graph.\n\n\n\nBut can we do better? Let’s look at an example on how to train our network parameters based on the knowledge of the community assignments of 4 nodes in the graph (one for each community):\nSince everything in our model is differentiable and parameterized, we can add some labels, train the model and observse how the embeddings react. Here, we make use of a semi-supervised or transductive learning procedure: We simply train against one node per class, but are allowed to make use of the complete input graph data.\nTraining our model is very similar to any other PyTorch model. In addition to defining our network architecture, we define a loss critertion (here, CrossEntropyLoss) and initialize a stochastic gradient optimizer (here, Adam). After that, we perform multiple rounds of optimization, where each round consists of a forward and backward pass to compute the gradients of our model parameters w.r.t. to the loss derived from the forward pass. If you are not new to PyTorch, this scheme should appear familar to you.\n\n(참고) a good introduction on how to train a neural network in PyTorch.\n\n\nimport time\n\nmodel = GCN()\nloss_fn = torch.nn.CrossEntropyLoss()  # Define loss criterion.\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01)  # Define optimizer.\n\ndef train(data):\n    optimizer.zero_grad()  # Clear gradients.\n    out, h = model(data.x, data.edge_index)  # Perform a single forward pass.\n    loss = loss_fn(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n    loss.backward()  # Derive gradients.\n    optimizr.step()  # Update parameters based on gradients.\n    return loss, h\n\nfor epoc in range(401):\n    loss, h = train(data)\n    if epoch % 10 == 0:\n        visualize_embedding(h, color=data.y, epoch=epoc, loss=loss)\n        time.sleep(0.3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis concludes the first introduction into the world of GNNs and PyTorch Geometric. In the follow-up sessions, you will learn how to achieve state-of-the-art classification results on a number of real-world graph datasets."
  },
  {
    "objectID": "posts/GNN/2023-03-03-gnn1.html",
    "href": "posts/GNN/2023-03-03-gnn1.html",
    "title": "0 Introductino to GNN",
    "section": "",
    "text": "The GNN is designed specifically to handle graph-structured data, such as social networks, molecular structures, knowledge graphs, etc.\n\n\n\n\nCNN1 은 GNN의 계기가 됐다. CNN은 여러 단계의 지역화된 공간특징을 추출하고 재구성해 표현력이 높다. 그 결과 거의 모든 머신러닝 영역에서 돌파구가 됐고 딥러닝의 혁명을 가져왔다. graphs와 CNN을 깊이 파다보면 그래프에서 잘 사용될 수 있는 기술들이 이미 CNN에 있음을 알 수 있다.\n\n\ngraphs are the most typical locally connected structure.\n\n\nshared weights reduce the computational cost compared with traditional spectral graph theory2\n\n\nmulti-layer structure structure is the key to deal with hierarchical patterns, which captures the features of various sizes.\n\n\nHowever, CNNs can only operate on regular Euclidean data like images (2D grid) and text (1D sequence), which can also be regarded as instances of graphs. Therefore, it is straightforward to think of finding the generalization of CNNs to graphs. But, it is hard to define localized convolutional filters and pooling operators, which hinders the transformation of CNN from Euclidean to non-Euclidean domain\n(동기1): CNN을 확장해 그래프에 적용할 수도 있지않을까 생각해볼 수도 있지만 CNN은 이미지(2D grid), 텍스트(1D sequence) 등 일반적인 유클리드 데이터에서만 작동할 수 있다.\n\n(localized convolutional filters와 pooling 작업을 정의하기 어려워서 CNN을 “Euclidean \\(\\to\\)non-Euclidean domain” 로의 확장은 힘들다.)\n\n\n\n\nThe other motivation comes from graph embedding3, which learns to represent graph nodes, edges, or subgraphs in low-dimensional vectors.\nIn graph analysis, traditional machine learning approaches usually rely on hand-engineered features and are limited by its inflexibility and high cost. Following the idea of representation learning and the success of word embedding4, DeepWalk5, which is regarded as the first graph embedding method based on representation learning, applies SkipGram model6 on the generated random walks. Similar approaches such as node2vec7, LINE8, and TADW9 also achieved breakthroughs. However, these methods suffer from two severe drawbacks10.\n\nFirst, no parameters are shared between nodes in the encoder, which leads to computational inefficiency, since it means the number of parameters grows linearly with the number of nodes.\nSecond, the direct embedding methods lack the ability of generalization, which means they cannot deal with dynamic graphs or be generalized to new graphs.\n\n(동기2): 그래프의 node, edges, subgraphs를 낮은차원의 벡터로 표현하는 그래프 임베딩 문제. (계산 비효율적, 확장성 부족)\n\n. Wu et al. [2019c] categorize GNNs into four groups: recurrent graph neural networks (RecGNNs), convolutional graph neural networks (ConvGNNs), graph auto-encoders (GAEs), and spatial-temporal graph neural networks (STGNNs).\n\n\n\n\n\n\n\nThe concept of GNN was first proposed in Gori 11. For simplicity, we will talk about the model proposed in Scarselli12, which aims to extend existing neural networks for processing graph-structured data.\nA node is naturally defined by its features and related nodes in the graph. The target of GNN is to learn a state embedding \\(h_v \\in \\mathbb{R}^s\\) , which encodes the information of the neighborhood, for each node. The state embedding hv is used to produce an output ov, such as the distribution of the predicted node label. In Scarselli13, a typical graph is illustrated in Figure 4.1. The vanilla GNN model deals with the undirected homogeneous graph where each node in the graph has its input features \\(x_v\\) and each edge may also have its features. The paper uses \\(co[v]\\) and \\(ne[v]\\) to denote the set of edges and neighbors of node \\(v\\). For processing other more complicated graphs such as heterogeneous graphs, the corresponding variants of GNNs could be found in later chapter\nGNN의 개념은 Gori14 와 Scarselli15 가 제안했다. 여기서는 앞으로 소개할 모델로의 확장이 자연스러운 Scarselli16 의 모델을 대표로 설명한다.\n\nGNN의 최종목표는 각 노드의 state embedding \\(\\bf{h}_v \\in \\mathbb{R}^2\\)를 학습하는 것!\nstate embedding \\(\\bf{h}_v\\)는 해당노드와 주변노드의 정보를 포함하고 있으며, node \\(v\\)의 출력값인 \\(\\bf{o}_v\\)를 얻을 때 사용한다.\n(참고) 기본 그래프 신경망은 무향 동종 그래프이며, 각 노드는 input features \\(\\bf{x}_v\\) 가 있고, edge도 features를 가질 수 있다.\n\n\n\n\nGiven the input features of nodes and edges, next we will talk about how the model obtains the node embedding hv and the output embedding \\(o_v\\).\n\n\n\nAn example of the graph based on Scarselli et al.[2009]\n\n\n\\[\\bf{h}_v = f(\\bf{x}_v,\\bf{x}_{co[v]}, \\bf{h}_{ne[v]}, \\bf{x}_{ne[v]})\\]\n\\[\\bf{o}_v = g(\\bf{h}_v,\\bf{x}_v)\\]\n\n\\(\\bf{x}\\) : input feature\n\\(\\bf{h}\\) : hidden state\n\\(co[v]\\) : the set of edges connected to node \\(v\\) (node \\(v\\) 에 연결된 edge 집합)\n\\(ne[v]\\) : set of neighbors of node \\(v\\) (node \\(v\\)에 인접한 노드 집합)\n\\(f\\) : local transition function (이웃으로부터 node state를 업데이트 하기 위해 노드들끼리 공유하는 함수)\n\\(g\\) : local output function (노드의 출력값을 계산하기 위한 함수)\n\n\\(\\bf{x}_v, \\bf{x}_{co[v]}, \\bf{h}_{ne[v]}, \\bf{x}_{ne[v]}\\) are the feature of \\(v\\), the state and the feature of the node in the neighborhood of \\(v\\), respectively.\n\\[\\bf{H} = F(\\bf{H}, \\bf{X})\\] \\[\\bf{O} = G(\\bf{H}, \\bf{X}_N)\\]\n여기서 \\(F\\)와 \\(G\\)는 모든 노드에 대한 local transition function \\(f\\)와 local output function \\(g\\)를 쌓은 버전이라고 생각하면 된다. \\(\\bf{H}\\)는 fixed point이며, \\(F\\)가 contraction map이라면 유일하게 정의된다. <- 이게 무슨소리지?\nBanach’s fixed point theorem17 를 바탕으로 GNN은 다음과 같은 고전적인 반복 계산법을 사용한다.\n\\[\\bf{H}^{t+1} = F(\\bf{H}^t,\\bf{X})\\]\n\n\\(\\bf{H}^t\\): \\(\\bf{H}\\)를 \\(t\\)번 반복한 결과값.\n임의의 초깃값 \\(\\bf{H}^0\\)에 대해 \\(\\bf{H}^{t+1} = F(\\bf{H}^t,\\bf{X})\\)는 기하급수적으로 빠르게 \\(\\bf{H} = F(\\bf{H}, \\bf{X})\\)의 해에 수렴한다.\n(참고) \\(f\\), \\(g\\)를 통하는 계산을 FNN이라고 해석될 수 있다.\n\n\n\n\nAfter the introduction of the framework of GNN, the next question is how to learn the parameters of the local transition function \\(f\\) and local output function \\(g\\). With the target information (\\(t_v\\) for a specific node) for the supervision, the loss can be written as:\n\\[loss =\\sum_{i=1}^p(t_i - o_i)\\]\nwhere \\(p\\) is the number of supervised nodes.\nThe learning algorithm is based on a gradient descent strategy and is composed of the following steps.\n\nstep1. : The states \\(\\bf{h}_v^t\\) are iteratively updated by \\(\\bf{h}_v = f(\\bf{x}_v,\\bf{x}_{co[v]}, \\bf{h}_{ne[v]}, \\bf{x}_{ne[v]})\\) until a time step \\(T\\). Then we obtain an approximation fixed point solution \\(\\bf{H} = F(\\bf{H}, \\bf{X}): \\space\\space \\bf{H}(T)\\approx \\bf{H}\\).\nstep2.: The gradient of weights \\(\\bf{W}\\) is computed from the loss\nstep3.: The weights \\(\\bf{W}\\) are updated according to the gradient computed in the last step.\n\nAfter running the algorithm, we can get a model trained for a specific supervised/semi\u0002supervised task as well as hidden states of nodes in the graph. The vanilla GNN model provides an effective way to model graphic data and it is the first step toward incorporating neural net\u0002works into graph domain.\n\n\n\nThough experimental results showed that GNN is a powerful architecture for modeling struc\u0002tural data, there are still several limitations of the vanilla GNN.\n\n1. it is computationally inefficient to update the hidden states of nodes iteratively to get the fixed point. The model needs T steps of computation to approximate the fixed point. If relaxing the assumption of the fixed point, we can design a multi-layer GNN to get a stable representation of the node and its neighborhood.\n2. vanilla GNN uses the same parameters in the iteration while most popular neural networks use different parameters in different layers, which serves as a hierarchical feature extraction method. Moreover, the update of node hidden states is a sequential process which can benefit from the RNN kernels like GRU and LSTM\n3. Third, there are also some informative features on the edges which cannot be effectively modeled in the vanilla GNN. For example, the edges in the knowledge graph have the type of relations and the message propagation through different edges should be differ\u0002ent according to their types. Besides, how to learn the hidden states of edges is also an important problem.\n4. Last, if T is pretty large, it is unsuitable to use the fixed points if we focus on the repre\u0002sentation of nodes instead of graphs because the distribution of representation in the fixed point will be much more smooth in value and less informative for distinguishing each node.\n\nBeyond the vanilla GNN, several variants are proposed to release these limitations. For example, Gated Graph Neural Network (GGNN)18 is proposed to solve the first problem. Relational GCN (R-GCN)19 is proposed to deal with directed graphs. More details could be found in the following chapters\n\n\n\n\nWe will talk about graph convolutional networks (GCNs), which aim to generalize convolutions to the graph domain. As convolutional neural networks (CNNs) have achieved great success in the area of deep learning, it is intuitive to define the convolution operation on graphs. Advances in this direction are often categorized as spectral approaches and spatial approaches. As there may have vast variants in each direction, we only list several classic models in this chapter.\n\n\nSpectral approaches work with a spectral representation of the graphs. In this section we will talk about four classic models (Spectral Network, ChebNet, GCN, and AGCN).\n\nSpectral network\nChebNet\nGCN\nAGCN\n\n\n\n\n\nNeural FPs\nPATCHY-SAN\nDCNN\nDGCN\nLGCN\nMoNet\nGraphSAGE"
  },
  {
    "objectID": "posts/GNN/2023-03-04-gnn2.html",
    "href": "posts/GNN/2023-03-04-gnn2.html",
    "title": "2 GNN tuto2",
    "section": "",
    "text": "Node calssification with GNN (Cora dataset)\n\nThis tutorial will teach you how to apply Graph Neural Networks (GNNs) to the task of node classification. Here, we are given the ground-truth labels of only a small subset of nodes, and want to infer the labels for all the remaining nodes (transductive learning).\n\n\nTo demonstrate, we make use of the Cora dataset, which is a citation network where nodes represent documents. Each node is described by a 1433-dimensional bag-of-words feature vector. Two documents are connected if there exists a citation link between them. The task is to infer the category of each document (7 in total).\nThis dataset was first introduced by Yang et al. (2016)1 as one of the datasets of the Planetoid benchmark suite. We again can make use PyTorch Geometric for an easy access to this dataset via torch_geometric.datasets.Planetoid2:\n\nimport os\nimport torch\n\n# helper function for visualization\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\n\nimport torch\nfrom torch.nn import Linear\nimport torch.nn.functional as F\n\n\ndef visualize(h, color):\n    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n\n    plt.figure(figsize=(10,10))\n    plt.xticks([])\n    plt.yticks([])\n\n    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n    plt.show()\n\n\nfrom torch_geometric.datasets import Planetoid\nfrom torch_geometric.transforms import NormalizeFeatures\n\ndataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n\nprint()\nprint(f'Dataset: {dataset}:')\nprint('======================')\nprint(f'Number of graphs: {len(dataset)}')\nprint(f'Number of features: {dataset.num_features}')\nprint(f'Number of classes: {dataset.num_classes}')\n\n\nDataset: Cora():\n======================\nNumber of graphs: 1\nNumber of features: 1433\nNumber of classes: 7\n\n\n\ndata = dataset[0]  # Get the first graph object.\nprint()\nprint(data)\nprint('===========================================================================================================')\n\n\nData(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n===========================================================================================================\n\n\n\n# Gather some statistics about the graph.\nprint(f'Number of nodes: {data.num_nodes}')\nprint(f'Number of edges: {data.num_edges}')\nprint(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\nprint(f'Number of training nodes: {data.train_mask.sum()}')\nprint(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\nprint(f'Has isolated nodes: {data.has_isolated_nodes()}')\nprint(f'Has self-loops: {data.has_self_loops()}')\nprint(f'Is undirected: {data.is_undirected()}')\n\nNumber of nodes: 2708\nNumber of edges: 10556\nAverage node degree: 3.90\nNumber of training nodes: 140\nTraining node label rate: 0.05\nHas isolated nodes: False\nHas self-loops: False\nIs undirected: True\n\n\n\ndata.y.unique()\n\ntensor([0, 1, 2, 3, 4, 5, 6])\n\n\n\n각 클래스 당 20개씩 정답을 알고 있음.\ntraining node label rate = \\(5\\%\\) (학습을 위한 노드는 전체의 5% 밖에 안된다..)\n\nthis network is undirected, and that there exists no isolated nodes (each document has at least one citation).\n\n\n\nn theory, we should be able to infer the category of a document solely based on its content, i.e. its bag-of-words feature representation, without taking any relational information into account.\nLet’s verify that by constructing a simple MLP that solely operates on input node features (using shared weights across all nodes):\n\nimport torch\nfrom torch.nn import Linear\nimport torch.nn.functional as F\n\n\nclass MLP(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        ## 우리가 사용할 레이어 정의\n        torch.manual_seed(12345)\n        self.lin1 = Linear(dataset.num_features, hidden_channels)\n        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n        ## 레이어 정의 끝!\n        \n    def forward(self, x):\n        ## yhat을 어떻게 구할것인지 정의\n        x = self.lin1(x)\n        x = x.relu()\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.lin2(x)\n        ## 정의 끝!\n        return x\n\nmodel = MLP(hidden_channels=16)\nprint(model)\n\nMLP(\n  (lin1): Linear(in_features=1433, out_features=16, bias=True)\n  (lin2): Linear(in_features=16, out_features=7, bias=True)\n)\n\n\n\nmodel = MLP(hidden_channels=16)\nloss_fn = torch.nn.CrossEntropyLoss()  # Define loss criterion.\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Define optimizer.\n\n\ndata.test_mask.sum()\n\ntensor(1000)\n\n\n\ndef train():\n      model.train()\n      optimizr.zero_grad()  # Clear gradients. <-- 앞에 나와도 상관없는건가??\n      out = model(data.x)  # Perform a single forward pass.\n      loss = loss_fn(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n      loss.backward()  # Derive gradients.\n      optimizr.step()  # Update parameters based on gradients.\n      return loss\n\ndef test():\n      model.eval()\n      out = model(data.x)\n      pred = out.argmax(dim=1)  # Use the class with highest probability.\n      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n      return test_acc\n\nfor epoch in range(1, 201):\n    loss = train()\n    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n\nEpoch: 001, Loss: 1.9615\nEpoch: 002, Loss: 1.9557\nEpoch: 003, Loss: 1.9505\nEpoch: 004, Loss: 1.9423\nEpoch: 005, Loss: 1.9327\nEpoch: 006, Loss: 1.9279\nEpoch: 007, Loss: 1.9144\nEpoch: 008, Loss: 1.9087\nEpoch: 009, Loss: 1.9023\nEpoch: 010, Loss: 1.8893\nEpoch: 011, Loss: 1.8776\nEpoch: 012, Loss: 1.8594\nEpoch: 013, Loss: 1.8457\nEpoch: 014, Loss: 1.8365\nEpoch: 015, Loss: 1.8280\nEpoch: 016, Loss: 1.7965\nEpoch: 017, Loss: 1.7984\nEpoch: 018, Loss: 1.7832\nEpoch: 019, Loss: 1.7495\nEpoch: 020, Loss: 1.7441\nEpoch: 021, Loss: 1.7188\nEpoch: 022, Loss: 1.7124\nEpoch: 023, Loss: 1.6785\nEpoch: 024, Loss: 1.6660\nEpoch: 025, Loss: 1.6119\nEpoch: 026, Loss: 1.6236\nEpoch: 027, Loss: 1.5827\nEpoch: 028, Loss: 1.5784\nEpoch: 029, Loss: 1.5524\nEpoch: 030, Loss: 1.5020\nEpoch: 031, Loss: 1.5065\nEpoch: 032, Loss: 1.4742\nEpoch: 033, Loss: 1.4581\nEpoch: 034, Loss: 1.4246\nEpoch: 035, Loss: 1.4131\nEpoch: 036, Loss: 1.4112\nEpoch: 037, Loss: 1.3923\nEpoch: 038, Loss: 1.3055\nEpoch: 039, Loss: 1.2982\nEpoch: 040, Loss: 1.2543\nEpoch: 041, Loss: 1.2244\nEpoch: 042, Loss: 1.2331\nEpoch: 043, Loss: 1.1984\nEpoch: 044, Loss: 1.1796\nEpoch: 045, Loss: 1.1093\nEpoch: 046, Loss: 1.1284\nEpoch: 047, Loss: 1.1229\nEpoch: 048, Loss: 1.0383\nEpoch: 049, Loss: 1.0439\nEpoch: 050, Loss: 1.0563\nEpoch: 051, Loss: 0.9893\nEpoch: 052, Loss: 1.0508\nEpoch: 053, Loss: 0.9343\nEpoch: 054, Loss: 0.9639\nEpoch: 055, Loss: 0.8929\nEpoch: 056, Loss: 0.8705\nEpoch: 057, Loss: 0.9176\nEpoch: 058, Loss: 0.9239\nEpoch: 059, Loss: 0.8641\nEpoch: 060, Loss: 0.8578\nEpoch: 061, Loss: 0.7908\nEpoch: 062, Loss: 0.7856\nEpoch: 063, Loss: 0.7683\nEpoch: 064, Loss: 0.7816\nEpoch: 065, Loss: 0.7356\nEpoch: 066, Loss: 0.6951\nEpoch: 067, Loss: 0.7300\nEpoch: 068, Loss: 0.6939\nEpoch: 069, Loss: 0.7550\nEpoch: 070, Loss: 0.6864\nEpoch: 071, Loss: 0.7094\nEpoch: 072, Loss: 0.7238\nEpoch: 073, Loss: 0.7150\nEpoch: 074, Loss: 0.6191\nEpoch: 075, Loss: 0.6770\nEpoch: 076, Loss: 0.6487\nEpoch: 077, Loss: 0.6258\nEpoch: 078, Loss: 0.5821\nEpoch: 079, Loss: 0.5637\nEpoch: 080, Loss: 0.6368\nEpoch: 081, Loss: 0.6333\nEpoch: 082, Loss: 0.6434\nEpoch: 083, Loss: 0.5974\nEpoch: 084, Loss: 0.6176\nEpoch: 085, Loss: 0.5972\nEpoch: 086, Loss: 0.4690\nEpoch: 087, Loss: 0.6362\nEpoch: 088, Loss: 0.6118\nEpoch: 089, Loss: 0.5248\nEpoch: 090, Loss: 0.5520\nEpoch: 091, Loss: 0.6130\nEpoch: 092, Loss: 0.5361\nEpoch: 093, Loss: 0.5594\nEpoch: 094, Loss: 0.5049\nEpoch: 095, Loss: 0.5043\nEpoch: 096, Loss: 0.5235\nEpoch: 097, Loss: 0.5451\nEpoch: 098, Loss: 0.5329\nEpoch: 099, Loss: 0.5008\nEpoch: 100, Loss: 0.5350\nEpoch: 101, Loss: 0.5343\nEpoch: 102, Loss: 0.5138\nEpoch: 103, Loss: 0.5377\nEpoch: 104, Loss: 0.5353\nEpoch: 105, Loss: 0.5176\nEpoch: 106, Loss: 0.5229\nEpoch: 107, Loss: 0.4558\nEpoch: 108, Loss: 0.4883\nEpoch: 109, Loss: 0.4659\nEpoch: 110, Loss: 0.4908\nEpoch: 111, Loss: 0.4966\nEpoch: 112, Loss: 0.4725\nEpoch: 113, Loss: 0.4787\nEpoch: 114, Loss: 0.4390\nEpoch: 115, Loss: 0.4199\nEpoch: 116, Loss: 0.4810\nEpoch: 117, Loss: 0.4484\nEpoch: 118, Loss: 0.5080\nEpoch: 119, Loss: 0.4241\nEpoch: 120, Loss: 0.4745\nEpoch: 121, Loss: 0.4651\nEpoch: 122, Loss: 0.4652\nEpoch: 123, Loss: 0.5580\nEpoch: 124, Loss: 0.4861\nEpoch: 125, Loss: 0.4405\nEpoch: 126, Loss: 0.4292\nEpoch: 127, Loss: 0.4409\nEpoch: 128, Loss: 0.3575\nEpoch: 129, Loss: 0.4468\nEpoch: 130, Loss: 0.4603\nEpoch: 131, Loss: 0.4108\nEpoch: 132, Loss: 0.4601\nEpoch: 133, Loss: 0.4258\nEpoch: 134, Loss: 0.3852\nEpoch: 135, Loss: 0.4028\nEpoch: 136, Loss: 0.4245\nEpoch: 137, Loss: 0.4300\nEpoch: 138, Loss: 0.4693\nEpoch: 139, Loss: 0.4314\nEpoch: 140, Loss: 0.4031\nEpoch: 141, Loss: 0.4290\nEpoch: 142, Loss: 0.4110\nEpoch: 143, Loss: 0.3863\nEpoch: 144, Loss: 0.4215\nEpoch: 145, Loss: 0.4519\nEpoch: 146, Loss: 0.3940\nEpoch: 147, Loss: 0.4429\nEpoch: 148, Loss: 0.3527\nEpoch: 149, Loss: 0.4390\nEpoch: 150, Loss: 0.4212\nEpoch: 151, Loss: 0.4128\nEpoch: 152, Loss: 0.3779\nEpoch: 153, Loss: 0.4801\nEpoch: 154, Loss: 0.4130\nEpoch: 155, Loss: 0.3962\nEpoch: 156, Loss: 0.4262\nEpoch: 157, Loss: 0.4210\nEpoch: 158, Loss: 0.4081\nEpoch: 159, Loss: 0.4066\nEpoch: 160, Loss: 0.3782\nEpoch: 161, Loss: 0.3836\nEpoch: 162, Loss: 0.4172\nEpoch: 163, Loss: 0.3993\nEpoch: 164, Loss: 0.4477\nEpoch: 165, Loss: 0.3714\nEpoch: 166, Loss: 0.3610\nEpoch: 167, Loss: 0.4546\nEpoch: 168, Loss: 0.4387\nEpoch: 169, Loss: 0.3793\nEpoch: 170, Loss: 0.3704\nEpoch: 171, Loss: 0.4286\nEpoch: 172, Loss: 0.4131\nEpoch: 173, Loss: 0.3795\nEpoch: 174, Loss: 0.4230\nEpoch: 175, Loss: 0.4139\nEpoch: 176, Loss: 0.3586\nEpoch: 177, Loss: 0.3588\nEpoch: 178, Loss: 0.3911\nEpoch: 179, Loss: 0.3810\nEpoch: 180, Loss: 0.4203\nEpoch: 181, Loss: 0.3583\nEpoch: 182, Loss: 0.3690\nEpoch: 183, Loss: 0.4025\nEpoch: 184, Loss: 0.3920\nEpoch: 185, Loss: 0.4369\nEpoch: 186, Loss: 0.4317\nEpoch: 187, Loss: 0.4911\nEpoch: 188, Loss: 0.3369\nEpoch: 189, Loss: 0.4945\nEpoch: 190, Loss: 0.3912\nEpoch: 191, Loss: 0.3824\nEpoch: 192, Loss: 0.3479\nEpoch: 193, Loss: 0.3798\nEpoch: 194, Loss: 0.3799\nEpoch: 195, Loss: 0.4015\nEpoch: 196, Loss: 0.3615\nEpoch: 197, Loss: 0.3985\nEpoch: 198, Loss: 0.4664\nEpoch: 199, Loss: 0.3714\nEpoch: 200, Loss: 0.3810\n\n\n\n# unseen labels에 대한 성능\ntest_acc = test()\nprint(f'Test Accuracy: {test_acc:.4f}')\n\nTest Accuracy: 0.5900\n\n\n\n1/7\n\n0.14285714285714285\n\n\n\nMLP \\(\\to\\) \\(59\\%\\) test accuracy (그냥 찍는 것보다는 낫지만 성능이 별로임)\n\n- 문제1 - 심각한 오버피팅때문에 성능이 안좋게 나오는 것. - 그렇다면 왜 오버피팅이 될까? \\(\\to\\) 학습에 사용되는 training 노드수가 너무 작아 모르는 노드에 대해 일반화 하기 어렵다.\n- 문제2 - MLP 모델은 중요한 bias가 반영이 안된다. (인용된 논문은 문서의 카테고리와 관련이 있을 가능성이 매우매우 높지만 이런것들이 반영이 안된다는 점)\nGraph Neural Network를 사용해서 모델 성능을 높일수 있을 것 같다.\n\n\n\nWe can easily convert our MLP to a GNN by swapping the torch.nn.Linear layers with PyG’s GNN operators.\nFollowing-up on the first part of this tutorial, we replace the linear layers by the GCNConv module. To recap, the GCN layer (Kipf et al. (2017)) is defined as\n\\[\n\\mathbf{x}_v^{(\\ell + 1)} = \\mathbf{W}^{(\\ell + 1)} \\sum_{w \\in \\mathcal{N}(v) \\, \\cup \\, \\{ v \\}} \\frac{1}{c_{w,v}} \\cdot \\mathbf{x}_w^{(\\ell)}\n\\]\n\n\\(\\bf{W}^{l+1}\\) : a trainable weight matrix of shape of shape [num_output_features, num_input_features]\n\\(c_{w,v}\\): fixed normalization coefficient for each node.\n\nin contrast, a single Linear layer is defined as\n\\[\\bf{x}_v^{l+1} = \\bf{W}^{l+1}\\bf{x}_v^{l}\\]\nwhich does not make use of neighboring node information.\n\ndataset.num_features, dataset.num_classes\n\n(1433, 7)\n\n\n\nfrom torch_geometric.nn import GCNConv\n\n\nclass GCN(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        ## 우리가 사용할 레이어 정의\n        torch.manual_seed(1234567)\n        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n        ## 레이어 정의 끝!\n        \n    def forward(self, x, edge_index):\n        ## yhat을 어떻게 구할것인지 정의\n        x = self.conv1(x, edge_index)\n        x = x.relu()\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.conv2(x, edge_index)\n        ## 정의 끝!\n        return x\n\nmodel = GCN(hidden_channels=16)\nprint(model)\n\nGCN(\n  (conv1): GCNConv(1433, 16)\n  (conv2): GCNConv(16, 7)\n)\n\n\n\n\nwe make use of TSNE to embed our 7-dimensional node embeddings onto a 2D plane.\n\nmodel = GCN(hidden_channels=16)\nmodel.eval()\n\nout = model(data.x, data.edge_index)\nvisualize(out, color=data.y)\n\n\n\n\nWe certainly can do better by training our model. The training and testing procedure is once again the same, but this time we make use of the node features x and the graph connectivity edge_index as input to our GCN model.\n\nmodel = GCN(hidden_channels=16)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\ndef train():\n      model.train()\n      optimizr.zero_grad()  # Clear gradients.\n      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n      loss = loss_fn(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n      loss.backward()  # Derive gradients.\n      optimizr.step()  # Update parameters based on gradients.\n      return loss\n\ndef test():\n      model.eval()\n      out = model(data.x, data.edge_index)\n      pred = out.argmax(dim=1)  # Use the class with highest probability.\n      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n      return test_acc\n\n\nfor epoch in range(1, 101):\n    loss = train()\n    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test: {test_acc:.4f}')\n\nEpoch: 001, Loss: 1.9463, Test: 0.8020\nEpoch: 002, Loss: 1.9409, Test: 0.8020\nEpoch: 003, Loss: 1.9343, Test: 0.8020\nEpoch: 004, Loss: 1.9275, Test: 0.8020\nEpoch: 005, Loss: 1.9181, Test: 0.8020\nEpoch: 006, Loss: 1.9086, Test: 0.8020\nEpoch: 007, Loss: 1.9015, Test: 0.8020\nEpoch: 008, Loss: 1.8933, Test: 0.8020\nEpoch: 009, Loss: 1.8808, Test: 0.8020\nEpoch: 010, Loss: 1.8685, Test: 0.8020\nEpoch: 011, Loss: 1.8598, Test: 0.8020\nEpoch: 012, Loss: 1.8482, Test: 0.8020\nEpoch: 013, Loss: 1.8290, Test: 0.8020\nEpoch: 014, Loss: 1.8233, Test: 0.8020\nEpoch: 015, Loss: 1.8057, Test: 0.8020\nEpoch: 016, Loss: 1.7966, Test: 0.8020\nEpoch: 017, Loss: 1.7825, Test: 0.8020\nEpoch: 018, Loss: 1.7617, Test: 0.8020\nEpoch: 019, Loss: 1.7491, Test: 0.8020\nEpoch: 020, Loss: 1.7310, Test: 0.8020\nEpoch: 021, Loss: 1.7147, Test: 0.8020\nEpoch: 022, Loss: 1.7056, Test: 0.8020\nEpoch: 023, Loss: 1.6954, Test: 0.8020\nEpoch: 024, Loss: 1.6697, Test: 0.8020\nEpoch: 025, Loss: 1.6538, Test: 0.8020\nEpoch: 026, Loss: 1.6312, Test: 0.8020\nEpoch: 027, Loss: 1.6161, Test: 0.8020\nEpoch: 028, Loss: 1.5899, Test: 0.8020\nEpoch: 029, Loss: 1.5711, Test: 0.8020\nEpoch: 030, Loss: 1.5576, Test: 0.8020\nEpoch: 031, Loss: 1.5393, Test: 0.8020\nEpoch: 032, Loss: 1.5137, Test: 0.8020\nEpoch: 033, Loss: 1.4948, Test: 0.8020\nEpoch: 034, Loss: 1.4913, Test: 0.8020\nEpoch: 035, Loss: 1.4698, Test: 0.8020\nEpoch: 036, Loss: 1.3998, Test: 0.8020\nEpoch: 037, Loss: 1.4041, Test: 0.8020\nEpoch: 038, Loss: 1.3761, Test: 0.8020\nEpoch: 039, Loss: 1.3631, Test: 0.8020\nEpoch: 040, Loss: 1.3258, Test: 0.8020\nEpoch: 041, Loss: 1.3030, Test: 0.8020\nEpoch: 042, Loss: 1.3119, Test: 0.8020\nEpoch: 043, Loss: 1.2519, Test: 0.8020\nEpoch: 044, Loss: 1.2530, Test: 0.8020\nEpoch: 045, Loss: 1.2492, Test: 0.8020\nEpoch: 046, Loss: 1.2205, Test: 0.8020\nEpoch: 047, Loss: 1.2037, Test: 0.8020\nEpoch: 048, Loss: 1.1571, Test: 0.8020\nEpoch: 049, Loss: 1.1700, Test: 0.8020\nEpoch: 050, Loss: 1.1296, Test: 0.8020\nEpoch: 051, Loss: 1.0860, Test: 0.8020\nEpoch: 052, Loss: 1.1080, Test: 0.8020\nEpoch: 053, Loss: 1.0564, Test: 0.8020\nEpoch: 054, Loss: 1.0157, Test: 0.8020\nEpoch: 055, Loss: 1.0362, Test: 0.8020\nEpoch: 056, Loss: 1.0328, Test: 0.8020\nEpoch: 057, Loss: 1.0058, Test: 0.8020\nEpoch: 058, Loss: 0.9865, Test: 0.8020\nEpoch: 059, Loss: 0.9667, Test: 0.8020\nEpoch: 060, Loss: 0.9741, Test: 0.8020\nEpoch: 061, Loss: 0.9769, Test: 0.8020\nEpoch: 062, Loss: 0.9122, Test: 0.8020\nEpoch: 063, Loss: 0.8993, Test: 0.8020\nEpoch: 064, Loss: 0.8769, Test: 0.8020\nEpoch: 065, Loss: 0.8575, Test: 0.8020\nEpoch: 066, Loss: 0.8897, Test: 0.8020\nEpoch: 067, Loss: 0.8312, Test: 0.8020\nEpoch: 068, Loss: 0.8262, Test: 0.8020\nEpoch: 069, Loss: 0.8511, Test: 0.8020\nEpoch: 070, Loss: 0.7711, Test: 0.8020\nEpoch: 071, Loss: 0.8012, Test: 0.8020\nEpoch: 072, Loss: 0.7529, Test: 0.8020\nEpoch: 073, Loss: 0.7525, Test: 0.8020\nEpoch: 074, Loss: 0.7689, Test: 0.8020\nEpoch: 075, Loss: 0.7553, Test: 0.8020\nEpoch: 076, Loss: 0.7032, Test: 0.8020\nEpoch: 077, Loss: 0.7326, Test: 0.8020\nEpoch: 078, Loss: 0.7122, Test: 0.8020\nEpoch: 079, Loss: 0.7090, Test: 0.8020\nEpoch: 080, Loss: 0.6755, Test: 0.8020\nEpoch: 081, Loss: 0.6666, Test: 0.8020\nEpoch: 082, Loss: 0.6679, Test: 0.8020\nEpoch: 083, Loss: 0.7037, Test: 0.8020\nEpoch: 084, Loss: 0.6752, Test: 0.8020\nEpoch: 085, Loss: 0.6266, Test: 0.8020\nEpoch: 086, Loss: 0.6564, Test: 0.8020\nEpoch: 087, Loss: 0.6266, Test: 0.8020\nEpoch: 088, Loss: 0.6411, Test: 0.8020\nEpoch: 089, Loss: 0.6226, Test: 0.8020\nEpoch: 090, Loss: 0.6535, Test: 0.8020\nEpoch: 091, Loss: 0.6317, Test: 0.8020\nEpoch: 092, Loss: 0.5741, Test: 0.8020\nEpoch: 093, Loss: 0.5572, Test: 0.8020\nEpoch: 094, Loss: 0.5710, Test: 0.8020\nEpoch: 095, Loss: 0.5816, Test: 0.8020\nEpoch: 096, Loss: 0.5745, Test: 0.8020\nEpoch: 097, Loss: 0.5547, Test: 0.8020\nEpoch: 098, Loss: 0.5989, Test: 0.8020\nEpoch: 099, Loss: 0.6021, Test: 0.8020\nEpoch: 100, Loss: 0.5799, Test: 0.8020\n\n\n\ntest_acc = test()\nprint(f'Test Accuracy: {test_acc:.4f}')\n\nTest Accuracy: 0.8150\n\n\n\nGNN \\(\\to 81.5\\%\\) test accuracy!!!\n\nThere it is! By simply swapping the linear layers with GNN layers, we can reach 81.5% of test accuracy!\n\n\n\n\nmodel.eval()\n\nout = model(data.x, data.edge_index)\nvisualize(out, color=data.y)\n\n\n\n\n\n카테고리별로 군집이 어느정도 잘 나눠진 느낌\n\n\n\n\n\n\ndata.val_mask.sum()\n\ntensor(500)\n\n\n\ndata.test_mask.sum()\n\ntensor(1000)\n\n\nfrom torch_geometric.nn import GCNConv\n\n\nclass GCN(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        ## 우리가 사용할 레이어 정의\n        torch.manual_seed(1234567)\n        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n        ## 레이어 정의 끝!\n        \n    def forward(self, x, edge_index):\n        ## yhat을 어떻게 구할것인지 정의\n        x = self.conv1(x, edge_index)\n        x = x.relu()\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.conv2(x, edge_index)\n        ## 정의 끝!\n        return x\n\nmodel = GCN(hidden_channels=16)\nprint(model)\n\n# model = GCN(hidden_channels=16)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\ndef train():\n      model.train()\n      optimizr.zero_grad()  # Clear gradients.\n      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n      loss = loss_fn(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n      loss.backward()  # Derive gradients.\n      optimizr.step()  # Update parameters based on gradients.\n      return loss\n\ndef test():\n      model.eval()\n      out = model(data.x, data.edge_index)\n      pred = out.argmax(dim=1)  # Use the class with highest probability.\n      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n      return test_acc\n\ndef val():\n      model.eval()\n      out = model(data.x, data.edge_index)\n      pred = out.argmax(dim=1)  # Use the class with highest probability.\n      val_correct = pred[data.val_mask] == data.y[data.val_mask]  # Check against ground-truth labels.\n      val_acc = int(val_correct.sum()) / int(data.val_mask.sum())  # Derive ratio of correct predictions.\n      return val_acc\n\n\n\n\nmodel = GCN(hidden_channels=16)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\nfor epoch in range(1, 101):\n    loss = train()\n    val_acc = val()\n    test_acc = test()\n    print(f'에폭: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n\n에폭: 001, Loss: 1.9463, Val: 0.2880, Test: 0.2700\n에폭: 002, Loss: 1.9409, Val: 0.2580, Test: 0.2910\n에폭: 003, Loss: 1.9343, Val: 0.2560, Test: 0.2910\n에폭: 004, Loss: 1.9275, Val: 0.2640, Test: 0.3210\n에폭: 005, Loss: 1.9181, Val: 0.3220, Test: 0.3630\n에폭: 006, Loss: 1.9086, Val: 0.4000, Test: 0.4120\n에폭: 007, Loss: 1.9015, Val: 0.3900, Test: 0.4010\n에폭: 008, Loss: 1.8933, Val: 0.3900, Test: 0.4020\n에폭: 009, Loss: 1.8808, Val: 0.4220, Test: 0.4180\n에폭: 010, Loss: 1.8685, Val: 0.4560, Test: 0.4470\n에폭: 011, Loss: 1.8598, Val: 0.4760, Test: 0.4680\n에폭: 012, Loss: 1.8482, Val: 0.5120, Test: 0.5180\n에폭: 013, Loss: 1.8290, Val: 0.5380, Test: 0.5440\n에폭: 014, Loss: 1.8233, Val: 0.5580, Test: 0.5720\n에폭: 015, Loss: 1.8057, Val: 0.5820, Test: 0.5910\n에폭: 016, Loss: 1.7966, Val: 0.6060, Test: 0.6080\n에폭: 017, Loss: 1.7825, Val: 0.6200, Test: 0.6300\n에폭: 018, Loss: 1.7617, Val: 0.6280, Test: 0.6450\n에폭: 019, Loss: 1.7491, Val: 0.6280, Test: 0.6520\n에폭: 020, Loss: 1.7310, Val: 0.6320, Test: 0.6560\n에폭: 021, Loss: 1.7147, Val: 0.6360, Test: 0.6570\n에폭: 022, Loss: 1.7056, Val: 0.6420, Test: 0.6640\n에폭: 023, Loss: 1.6954, Val: 0.6720, Test: 0.6770\n에폭: 024, Loss: 1.6697, Val: 0.6920, Test: 0.6950\n에폭: 025, Loss: 1.6538, Val: 0.7080, Test: 0.7140\n에폭: 026, Loss: 1.6312, Val: 0.7160, Test: 0.7150\n에폭: 027, Loss: 1.6161, Val: 0.7160, Test: 0.7170\n에폭: 028, Loss: 1.5899, Val: 0.7200, Test: 0.7230\n에폭: 029, Loss: 1.5711, Val: 0.7160, Test: 0.7220\n에폭: 030, Loss: 1.5576, Val: 0.7220, Test: 0.7210\n에폭: 031, Loss: 1.5393, Val: 0.7260, Test: 0.7280\n에폭: 032, Loss: 1.5137, Val: 0.7340, Test: 0.7370\n에폭: 033, Loss: 1.4948, Val: 0.7340, Test: 0.7380\n에폭: 034, Loss: 1.4913, Val: 0.7360, Test: 0.7430\n에폭: 035, Loss: 1.4698, Val: 0.7400, Test: 0.7510\n에폭: 036, Loss: 1.3998, Val: 0.7520, Test: 0.7570\n에폭: 037, Loss: 1.4041, Val: 0.7540, Test: 0.7600\n에폭: 038, Loss: 1.3761, Val: 0.7560, Test: 0.7640\n에폭: 039, Loss: 1.3631, Val: 0.7620, Test: 0.7700\n에폭: 040, Loss: 1.3258, Val: 0.7620, Test: 0.7800\n에폭: 041, Loss: 1.3030, Val: 0.7640, Test: 0.7810\n에폭: 042, Loss: 1.3119, Val: 0.7600, Test: 0.7760\n에폭: 043, Loss: 1.2519, Val: 0.7580, Test: 0.7760\n에폭: 044, Loss: 1.2530, Val: 0.7600, Test: 0.7790\n에폭: 045, Loss: 1.2492, Val: 0.7660, Test: 0.7800\n에폭: 046, Loss: 1.2205, Val: 0.7640, Test: 0.7790\n에폭: 047, Loss: 1.2037, Val: 0.7620, Test: 0.7850\n에폭: 048, Loss: 1.1571, Val: 0.7660, Test: 0.7900\n에폭: 049, Loss: 1.1700, Val: 0.7620, Test: 0.7920\n에폭: 050, Loss: 1.1296, Val: 0.7600, Test: 0.7940\n에폭: 051, Loss: 1.0860, Val: 0.7600, Test: 0.7930\n에폭: 052, Loss: 1.1080, Val: 0.7600, Test: 0.7910\n에폭: 053, Loss: 1.0564, Val: 0.7580, Test: 0.7930\n에폭: 054, Loss: 1.0157, Val: 0.7560, Test: 0.7930\n에폭: 055, Loss: 1.0362, Val: 0.7580, Test: 0.7920\n에폭: 056, Loss: 1.0328, Val: 0.7660, Test: 0.7980\n에폭: 057, Loss: 1.0058, Val: 0.7680, Test: 0.8000\n에폭: 058, Loss: 0.9865, Val: 0.7680, Test: 0.7970\n에폭: 059, Loss: 0.9667, Val: 0.7700, Test: 0.8010\n에폭: 060, Loss: 0.9741, Val: 0.7680, Test: 0.8000\n에폭: 061, Loss: 0.9769, Val: 0.7700, Test: 0.8030\n에폭: 062, Loss: 0.9122, Val: 0.7720, Test: 0.8040\n에폭: 063, Loss: 0.8993, Val: 0.7760, Test: 0.8050\n에폭: 064, Loss: 0.8769, Val: 0.7760, Test: 0.8050\n에폭: 065, Loss: 0.8575, Val: 0.7800, Test: 0.8060\n에폭: 066, Loss: 0.8897, Val: 0.7760, Test: 0.8030\n에폭: 067, Loss: 0.8312, Val: 0.7720, Test: 0.8060\n에폭: 068, Loss: 0.8262, Val: 0.7680, Test: 0.8030\n에폭: 069, Loss: 0.8511, Val: 0.7660, Test: 0.8070\n에폭: 070, Loss: 0.7711, Val: 0.7700, Test: 0.8070\n에폭: 071, Loss: 0.8012, Val: 0.7680, Test: 0.8080\n에폭: 072, Loss: 0.7529, Val: 0.7740, Test: 0.8080\n에폭: 073, Loss: 0.7525, Val: 0.7740, Test: 0.8070\n에폭: 074, Loss: 0.7689, Val: 0.7740, Test: 0.8110\n에폭: 075, Loss: 0.7553, Val: 0.7760, Test: 0.8140\n에폭: 076, Loss: 0.7032, Val: 0.7780, Test: 0.8120\n에폭: 077, Loss: 0.7326, Val: 0.7800, Test: 0.8110\n에폭: 078, Loss: 0.7122, Val: 0.7840, Test: 0.8120\n에폭: 079, Loss: 0.7090, Val: 0.7880, Test: 0.8110\n에폭: 080, Loss: 0.6755, Val: 0.7800, Test: 0.8130\n에폭: 081, Loss: 0.6666, Val: 0.7780, Test: 0.8070\n에폭: 082, Loss: 0.6679, Val: 0.7700, Test: 0.8080\n에폭: 083, Loss: 0.7037, Val: 0.7700, Test: 0.8100\n에폭: 084, Loss: 0.6752, Val: 0.7700, Test: 0.8070\n에폭: 085, Loss: 0.6266, Val: 0.7680, Test: 0.8100\n에폭: 086, Loss: 0.6564, Val: 0.7660, Test: 0.8080\n에폭: 087, Loss: 0.6266, Val: 0.7660, Test: 0.8090\n에폭: 088, Loss: 0.6411, Val: 0.7660, Test: 0.8080\n에폭: 089, Loss: 0.6226, Val: 0.7700, Test: 0.8100\n에폭: 090, Loss: 0.6535, Val: 0.7780, Test: 0.8130\n에폭: 091, Loss: 0.6317, Val: 0.7820, Test: 0.8140\n에폭: 092, Loss: 0.5741, Val: 0.7840, Test: 0.8120\n에폭: 093, Loss: 0.5572, Val: 0.7860, Test: 0.8140\n에폭: 094, Loss: 0.5710, Val: 0.7820, Test: 0.8120\n에폭: 095, Loss: 0.5816, Val: 0.7820, Test: 0.8140\n에폭: 096, Loss: 0.5745, Val: 0.7780, Test: 0.8140\n에폭: 097, Loss: 0.5547, Val: 0.7740, Test: 0.8150\n에폭: 098, Loss: 0.5989, Val: 0.7800, Test: 0.8160\n에폭: 099, Loss: 0.6021, Val: 0.7720, Test: 0.8160\n에폭: 100, Loss: 0.5799, Val: 0.7780, Test: 0.8150\n\n\n\n\n\n\nmodel = GCN(hidden_channels=256)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\nfor epoch in range(1, 101):\n    loss = train()\n    val_acc = val()\n    test_acc = test()\n    print(f'에폭: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n\n에폭: 001, Loss: 1.9448, Val: 0.2460, Test: 0.2360\n에폭: 002, Loss: 1.9221, Val: 0.3020, Test: 0.3060\n에폭: 003, Loss: 1.8922, Val: 0.3200, Test: 0.3270\n에폭: 004, Loss: 1.8556, Val: 0.3940, Test: 0.4060\n에폭: 005, Loss: 1.8123, Val: 0.4800, Test: 0.4960\n에폭: 006, Loss: 1.7614, Val: 0.5400, Test: 0.5510\n에폭: 007, Loss: 1.7012, Val: 0.5900, Test: 0.6140\n에폭: 008, Loss: 1.6528, Val: 0.6440, Test: 0.6740\n에폭: 009, Loss: 1.5808, Val: 0.6740, Test: 0.7130\n에폭: 010, Loss: 1.5118, Val: 0.7080, Test: 0.7390\n에폭: 011, Loss: 1.4335, Val: 0.7220, Test: 0.7500\n에폭: 012, Loss: 1.3561, Val: 0.7400, Test: 0.7590\n에폭: 013, Loss: 1.2777, Val: 0.7500, Test: 0.7660\n에폭: 014, Loss: 1.2094, Val: 0.7560, Test: 0.7750\n에폭: 015, Loss: 1.1225, Val: 0.7680, Test: 0.7820\n에폭: 016, Loss: 1.0417, Val: 0.7720, Test: 0.7920\n에폭: 017, Loss: 0.9676, Val: 0.7800, Test: 0.7990\n에폭: 018, Loss: 0.9025, Val: 0.7900, Test: 0.8060\n에폭: 019, Loss: 0.8258, Val: 0.7920, Test: 0.8100\n에폭: 020, Loss: 0.7598, Val: 0.7940, Test: 0.8150\n에폭: 021, Loss: 0.7166, Val: 0.7920, Test: 0.8140\n에폭: 022, Loss: 0.6533, Val: 0.7920, Test: 0.8130\n에폭: 023, Loss: 0.6075, Val: 0.7880, Test: 0.8100\n에폭: 024, Loss: 0.5647, Val: 0.7900, Test: 0.8140\n에폭: 025, Loss: 0.5216, Val: 0.7940, Test: 0.8160\n에폭: 026, Loss: 0.4843, Val: 0.7960, Test: 0.8170\n에폭: 027, Loss: 0.4597, Val: 0.7960, Test: 0.8210\n에폭: 028, Loss: 0.4341, Val: 0.8040, Test: 0.8240\n에폭: 029, Loss: 0.3999, Val: 0.8040, Test: 0.8310\n에폭: 030, Loss: 0.3885, Val: 0.8000, Test: 0.8310\n에폭: 031, Loss: 0.3755, Val: 0.7980, Test: 0.8290\n에폭: 032, Loss: 0.3532, Val: 0.7960, Test: 0.8240\n에폭: 033, Loss: 0.3327, Val: 0.7940, Test: 0.8220\n에폭: 034, Loss: 0.3176, Val: 0.7960, Test: 0.8180\n에폭: 035, Loss: 0.3280, Val: 0.7960, Test: 0.8190\n에폭: 036, Loss: 0.3020, Val: 0.7980, Test: 0.8200\n에폭: 037, Loss: 0.3077, Val: 0.7960, Test: 0.8140\n에폭: 038, Loss: 0.3007, Val: 0.7980, Test: 0.8140\n에폭: 039, Loss: 0.2771, Val: 0.8000, Test: 0.8190\n에폭: 040, Loss: 0.2912, Val: 0.8020, Test: 0.8190\n에폭: 041, Loss: 0.2674, Val: 0.8020, Test: 0.8170\n에폭: 042, Loss: 0.2737, Val: 0.7920, Test: 0.8110\n에폭: 043, Loss: 0.2506, Val: 0.7960, Test: 0.8070\n에폭: 044, Loss: 0.2429, Val: 0.7960, Test: 0.8070\n에폭: 045, Loss: 0.2518, Val: 0.7940, Test: 0.8110\n에폭: 046, Loss: 0.2412, Val: 0.7880, Test: 0.8090\n에폭: 047, Loss: 0.2537, Val: 0.7980, Test: 0.8010\n에폭: 048, Loss: 0.2303, Val: 0.7960, Test: 0.8030\n에폭: 049, Loss: 0.2341, Val: 0.7900, Test: 0.8090\n에폭: 050, Loss: 0.2295, Val: 0.7960, Test: 0.8050\n에폭: 051, Loss: 0.2180, Val: 0.7940, Test: 0.8060\n에폭: 052, Loss: 0.2149, Val: 0.7940, Test: 0.8040\n에폭: 053, Loss: 0.2350, Val: 0.7920, Test: 0.8040\n에폭: 054, Loss: 0.2234, Val: 0.7980, Test: 0.7990\n에폭: 055, Loss: 0.2126, Val: 0.7940, Test: 0.8040\n에폭: 056, Loss: 0.2107, Val: 0.7920, Test: 0.8120\n에폭: 057, Loss: 0.2117, Val: 0.7940, Test: 0.8080\n에폭: 058, Loss: 0.2034, Val: 0.7920, Test: 0.8110\n에폭: 059, Loss: 0.2032, Val: 0.7940, Test: 0.8080\n에폭: 060, Loss: 0.2053, Val: 0.8000, Test: 0.8030\n에폭: 061, Loss: 0.2004, Val: 0.7980, Test: 0.7990\n에폭: 062, Loss: 0.1933, Val: 0.7980, Test: 0.8050\n에폭: 063, Loss: 0.1882, Val: 0.7960, Test: 0.8120\n에폭: 064, Loss: 0.1891, Val: 0.7960, Test: 0.8150\n에폭: 065, Loss: 0.1982, Val: 0.7960, Test: 0.8080\n에폭: 066, Loss: 0.1794, Val: 0.7900, Test: 0.8050\n에폭: 067, Loss: 0.1883, Val: 0.7940, Test: 0.8010\n에폭: 068, Loss: 0.1840, Val: 0.7900, Test: 0.8010\n에폭: 069, Loss: 0.1801, Val: 0.7900, Test: 0.8030\n에폭: 070, Loss: 0.1845, Val: 0.7960, Test: 0.8070\n에폭: 071, Loss: 0.1839, Val: 0.7920, Test: 0.8120\n에폭: 072, Loss: 0.1820, Val: 0.7980, Test: 0.8080\n에폭: 073, Loss: 0.1787, Val: 0.7940, Test: 0.8000\n에폭: 074, Loss: 0.1813, Val: 0.7920, Test: 0.8060\n에폭: 075, Loss: 0.1793, Val: 0.7860, Test: 0.8050\n에폭: 076, Loss: 0.1785, Val: 0.7960, Test: 0.8070\n에폭: 077, Loss: 0.1644, Val: 0.7980, Test: 0.8090\n에폭: 078, Loss: 0.1687, Val: 0.7940, Test: 0.8090\n에폭: 079, Loss: 0.1673, Val: 0.7880, Test: 0.8080\n에폭: 080, Loss: 0.1705, Val: 0.7960, Test: 0.8140\n에폭: 081, Loss: 0.1713, Val: 0.7900, Test: 0.8070\n에폭: 082, Loss: 0.1720, Val: 0.7940, Test: 0.8080\n에폭: 083, Loss: 0.1683, Val: 0.7940, Test: 0.8040\n에폭: 084, Loss: 0.1672, Val: 0.7880, Test: 0.8080\n에폭: 085, Loss: 0.1657, Val: 0.7900, Test: 0.8140\n에폭: 086, Loss: 0.1592, Val: 0.7940, Test: 0.8060\n에폭: 087, Loss: 0.1635, Val: 0.8000, Test: 0.8100\n에폭: 088, Loss: 0.1593, Val: 0.7920, Test: 0.8090\n에폭: 089, Loss: 0.1666, Val: 0.7900, Test: 0.8040\n에폭: 090, Loss: 0.1593, Val: 0.7940, Test: 0.7980\n에폭: 091, Loss: 0.1669, Val: 0.7940, Test: 0.8010\n에폭: 092, Loss: 0.1540, Val: 0.7900, Test: 0.8010\n에폭: 093, Loss: 0.1513, Val: 0.7940, Test: 0.8100\n에폭: 094, Loss: 0.1569, Val: 0.7940, Test: 0.8150\n에폭: 095, Loss: 0.1561, Val: 0.7880, Test: 0.8080\n에폭: 096, Loss: 0.1497, Val: 0.7840, Test: 0.8020\n에폭: 097, Loss: 0.1497, Val: 0.7880, Test: 0.8000\n에폭: 098, Loss: 0.1559, Val: 0.7920, Test: 0.8020\n에폭: 099, Loss: 0.1493, Val: 0.7940, Test: 0.8090\n에폭: 100, Loss: 0.1488, Val: 0.8000, Test: 0.8090\n\n\n\ntest_acc = test()\ntest_acc\n\n0.809\n\n\n\n\n\n\nmodel = GCN(hidden_channels=256)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\nfor epoch in range(1, 101):\n    loss = train()\n    val_acc = val()\n    test_acc = test()\n    print(f'에폭: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n\n에폭: 001, Loss: 1.9448, Val: 0.2460, Test: 0.2360\n에폭: 002, Loss: 1.9221, Val: 0.3020, Test: 0.3060\n에폭: 003, Loss: 1.8922, Val: 0.3200, Test: 0.3270\n에폭: 004, Loss: 1.8556, Val: 0.3940, Test: 0.4060\n에폭: 005, Loss: 1.8123, Val: 0.4800, Test: 0.4960\n에폭: 006, Loss: 1.7614, Val: 0.5400, Test: 0.5510\n에폭: 007, Loss: 1.7012, Val: 0.5900, Test: 0.6140\n에폭: 008, Loss: 1.6528, Val: 0.6440, Test: 0.6740\n에폭: 009, Loss: 1.5808, Val: 0.6740, Test: 0.7130\n에폭: 010, Loss: 1.5118, Val: 0.7080, Test: 0.7390\n에폭: 011, Loss: 1.4335, Val: 0.7220, Test: 0.7500\n에폭: 012, Loss: 1.3561, Val: 0.7400, Test: 0.7590\n에폭: 013, Loss: 1.2777, Val: 0.7500, Test: 0.7660\n에폭: 014, Loss: 1.2094, Val: 0.7560, Test: 0.7750\n에폭: 015, Loss: 1.1225, Val: 0.7680, Test: 0.7820\n에폭: 016, Loss: 1.0417, Val: 0.7720, Test: 0.7920\n에폭: 017, Loss: 0.9676, Val: 0.7800, Test: 0.7990\n에폭: 018, Loss: 0.9025, Val: 0.7900, Test: 0.8060\n에폭: 019, Loss: 0.8258, Val: 0.7920, Test: 0.8100\n에폭: 020, Loss: 0.7598, Val: 0.7940, Test: 0.8150\n에폭: 021, Loss: 0.7166, Val: 0.7920, Test: 0.8140\n에폭: 022, Loss: 0.6533, Val: 0.7920, Test: 0.8130\n에폭: 023, Loss: 0.6075, Val: 0.7880, Test: 0.8100\n에폭: 024, Loss: 0.5647, Val: 0.7900, Test: 0.8140\n에폭: 025, Loss: 0.5216, Val: 0.7940, Test: 0.8160\n에폭: 026, Loss: 0.4843, Val: 0.7960, Test: 0.8170\n에폭: 027, Loss: 0.4597, Val: 0.7960, Test: 0.8210\n에폭: 028, Loss: 0.4341, Val: 0.8040, Test: 0.8240\n에폭: 029, Loss: 0.3999, Val: 0.8040, Test: 0.8310\n에폭: 030, Loss: 0.3885, Val: 0.8000, Test: 0.8310\n에폭: 031, Loss: 0.3755, Val: 0.7980, Test: 0.8290\n에폭: 032, Loss: 0.3532, Val: 0.7960, Test: 0.8240\n에폭: 033, Loss: 0.3327, Val: 0.7940, Test: 0.8220\n에폭: 034, Loss: 0.3176, Val: 0.7960, Test: 0.8180\n에폭: 035, Loss: 0.3280, Val: 0.7960, Test: 0.8190\n에폭: 036, Loss: 0.3020, Val: 0.7980, Test: 0.8200\n에폭: 037, Loss: 0.3077, Val: 0.7960, Test: 0.8140\n에폭: 038, Loss: 0.3007, Val: 0.7980, Test: 0.8140\n에폭: 039, Loss: 0.2771, Val: 0.8000, Test: 0.8190\n에폭: 040, Loss: 0.2912, Val: 0.8020, Test: 0.8190\n에폭: 041, Loss: 0.2674, Val: 0.8020, Test: 0.8170\n에폭: 042, Loss: 0.2737, Val: 0.7920, Test: 0.8110\n에폭: 043, Loss: 0.2506, Val: 0.7960, Test: 0.8070\n에폭: 044, Loss: 0.2429, Val: 0.7960, Test: 0.8070\n에폭: 045, Loss: 0.2518, Val: 0.7940, Test: 0.8110\n에폭: 046, Loss: 0.2412, Val: 0.7880, Test: 0.8090\n에폭: 047, Loss: 0.2537, Val: 0.7980, Test: 0.8010\n에폭: 048, Loss: 0.2303, Val: 0.7960, Test: 0.8030\n에폭: 049, Loss: 0.2341, Val: 0.7900, Test: 0.8090\n에폭: 050, Loss: 0.2295, Val: 0.7960, Test: 0.8050\n에폭: 051, Loss: 0.2180, Val: 0.7940, Test: 0.8060\n에폭: 052, Loss: 0.2149, Val: 0.7940, Test: 0.8040\n에폭: 053, Loss: 0.2350, Val: 0.7920, Test: 0.8040\n에폭: 054, Loss: 0.2234, Val: 0.7980, Test: 0.7990\n에폭: 055, Loss: 0.2126, Val: 0.7940, Test: 0.8040\n에폭: 056, Loss: 0.2107, Val: 0.7920, Test: 0.8120\n에폭: 057, Loss: 0.2117, Val: 0.7940, Test: 0.8080\n에폭: 058, Loss: 0.2034, Val: 0.7920, Test: 0.8110\n에폭: 059, Loss: 0.2032, Val: 0.7940, Test: 0.8080\n에폭: 060, Loss: 0.2053, Val: 0.8000, Test: 0.8030\n에폭: 061, Loss: 0.2004, Val: 0.7980, Test: 0.7990\n에폭: 062, Loss: 0.1933, Val: 0.7980, Test: 0.8050\n에폭: 063, Loss: 0.1882, Val: 0.7960, Test: 0.8120\n에폭: 064, Loss: 0.1891, Val: 0.7960, Test: 0.8150\n에폭: 065, Loss: 0.1982, Val: 0.7960, Test: 0.8080\n에폭: 066, Loss: 0.1794, Val: 0.7900, Test: 0.8050\n에폭: 067, Loss: 0.1883, Val: 0.7940, Test: 0.8010\n에폭: 068, Loss: 0.1840, Val: 0.7900, Test: 0.8010\n에폭: 069, Loss: 0.1801, Val: 0.7900, Test: 0.8030\n에폭: 070, Loss: 0.1845, Val: 0.7960, Test: 0.8070\n에폭: 071, Loss: 0.1839, Val: 0.7920, Test: 0.8120\n에폭: 072, Loss: 0.1820, Val: 0.7980, Test: 0.8080\n에폭: 073, Loss: 0.1787, Val: 0.7940, Test: 0.8000\n에폭: 074, Loss: 0.1813, Val: 0.7920, Test: 0.8060\n에폭: 075, Loss: 0.1793, Val: 0.7860, Test: 0.8050\n에폭: 076, Loss: 0.1785, Val: 0.7960, Test: 0.8070\n에폭: 077, Loss: 0.1644, Val: 0.7980, Test: 0.8090\n에폭: 078, Loss: 0.1687, Val: 0.7940, Test: 0.8090\n에폭: 079, Loss: 0.1673, Val: 0.7880, Test: 0.8080\n에폭: 080, Loss: 0.1705, Val: 0.7960, Test: 0.8140\n에폭: 081, Loss: 0.1713, Val: 0.7900, Test: 0.8070\n에폭: 082, Loss: 0.1720, Val: 0.7940, Test: 0.8080\n에폭: 083, Loss: 0.1683, Val: 0.7940, Test: 0.8040\n에폭: 084, Loss: 0.1672, Val: 0.7880, Test: 0.8080\n에폭: 085, Loss: 0.1657, Val: 0.7900, Test: 0.8140\n에폭: 086, Loss: 0.1592, Val: 0.7940, Test: 0.8060\n에폭: 087, Loss: 0.1635, Val: 0.8000, Test: 0.8100\n에폭: 088, Loss: 0.1593, Val: 0.7920, Test: 0.8090\n에폭: 089, Loss: 0.1666, Val: 0.7900, Test: 0.8040\n에폭: 090, Loss: 0.1593, Val: 0.7940, Test: 0.7980\n에폭: 091, Loss: 0.1669, Val: 0.7940, Test: 0.8010\n에폭: 092, Loss: 0.1540, Val: 0.7900, Test: 0.8010\n에폭: 093, Loss: 0.1513, Val: 0.7940, Test: 0.8100\n에폭: 094, Loss: 0.1569, Val: 0.7940, Test: 0.8150\n에폭: 095, Loss: 0.1561, Val: 0.7880, Test: 0.8080\n에폭: 096, Loss: 0.1497, Val: 0.7840, Test: 0.8020\n에폭: 097, Loss: 0.1497, Val: 0.7880, Test: 0.8000\n에폭: 098, Loss: 0.1559, Val: 0.7920, Test: 0.8020\n에폭: 099, Loss: 0.1493, Val: 0.7940, Test: 0.8090\n에폭: 100, Loss: 0.1488, Val: 0.8000, Test: 0.8090\n\n\n\n올라가야하는데 오히려 떨어졌는데?? (에폭수 늘려봐도 똑같다..)\n\n\n\n\n\n\nfrom torch_geometric.nn import GCNConv\n\n\nclass GCN(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        ## 우리가 사용할 레이어 정의\n        torch.manual_seed(1234567)\n        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n        ## 레이어 정의 끝!\n        \n    def forward(self, x, edge_index):\n        ## yhat을 어떻게 구할것인지 정의\n        x = self.conv1(x, edge_index)\n        x = x.relu()\n        x = F.dropout(x, p=0.3, training=self.training)\n        x = self.conv2(x, edge_index)\n        ## 정의 끝!\n        return x\n\nmodel = GCN(hidden_channels=16)\nprint(model)\n\nGCN(\n  (conv1): GCNConv(1433, 16)\n  (conv2): GCNConv(16, 7)\n)\n\n\n\nmodel = GCN(hidden_channels=16)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\nfor epoch in range(1, 101):\n    loss = train()\n    val_acc = val()\n    test_acc = test()\n    print(f'에폭: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n\n에폭: 001, Loss: 1.9464, Val: 0.2780, Test: 0.2740\n에폭: 002, Loss: 1.9407, Val: 0.4700, Test: 0.4760\n에폭: 003, Loss: 1.9337, Val: 0.2860, Test: 0.3320\n에폭: 004, Loss: 1.9258, Val: 0.2960, Test: 0.3550\n에폭: 005, Loss: 1.9156, Val: 0.3040, Test: 0.3420\n에폭: 006, Loss: 1.9056, Val: 0.3220, Test: 0.3490\n에폭: 007, Loss: 1.8976, Val: 0.3720, Test: 0.3790\n에폭: 008, Loss: 1.8855, Val: 0.3900, Test: 0.3810\n에폭: 009, Loss: 1.8749, Val: 0.4040, Test: 0.4030\n에폭: 010, Loss: 1.8610, Val: 0.4240, Test: 0.4150\n에폭: 011, Loss: 1.8510, Val: 0.4460, Test: 0.4290\n에폭: 012, Loss: 1.8393, Val: 0.4700, Test: 0.4650\n에폭: 013, Loss: 1.8186, Val: 0.4920, Test: 0.4850\n에폭: 014, Loss: 1.8061, Val: 0.5000, Test: 0.5010\n에폭: 015, Loss: 1.7972, Val: 0.5120, Test: 0.5220\n에폭: 016, Loss: 1.7835, Val: 0.5160, Test: 0.5360\n에폭: 017, Loss: 1.7636, Val: 0.5440, Test: 0.5580\n에폭: 018, Loss: 1.7460, Val: 0.5580, Test: 0.5740\n에폭: 019, Loss: 1.7369, Val: 0.5640, Test: 0.5900\n에폭: 020, Loss: 1.7162, Val: 0.5800, Test: 0.6060\n에폭: 021, Loss: 1.6970, Val: 0.5940, Test: 0.6260\n에폭: 022, Loss: 1.6831, Val: 0.6080, Test: 0.6390\n에폭: 023, Loss: 1.6674, Val: 0.6420, Test: 0.6470\n에폭: 024, Loss: 1.6391, Val: 0.6480, Test: 0.6610\n에폭: 025, Loss: 1.6216, Val: 0.6600, Test: 0.6730\n에폭: 026, Loss: 1.6116, Val: 0.6680, Test: 0.6860\n에폭: 027, Loss: 1.5808, Val: 0.6800, Test: 0.6940\n에폭: 028, Loss: 1.5628, Val: 0.6880, Test: 0.7000\n에폭: 029, Loss: 1.5349, Val: 0.7000, Test: 0.7040\n에폭: 030, Loss: 1.5208, Val: 0.7100, Test: 0.7100\n에폭: 031, Loss: 1.4980, Val: 0.7300, Test: 0.7130\n에폭: 032, Loss: 1.4797, Val: 0.7360, Test: 0.7190\n에폭: 033, Loss: 1.4533, Val: 0.7400, Test: 0.7330\n에폭: 034, Loss: 1.4457, Val: 0.7420, Test: 0.7400\n에폭: 035, Loss: 1.3973, Val: 0.7380, Test: 0.7480\n에폭: 036, Loss: 1.3577, Val: 0.7380, Test: 0.7570\n에폭: 037, Loss: 1.3596, Val: 0.7480, Test: 0.7600\n에폭: 038, Loss: 1.3399, Val: 0.7500, Test: 0.7630\n에폭: 039, Loss: 1.3004, Val: 0.7480, Test: 0.7640\n에폭: 040, Loss: 1.2785, Val: 0.7600, Test: 0.7660\n에폭: 041, Loss: 1.2550, Val: 0.7640, Test: 0.7710\n에폭: 042, Loss: 1.2501, Val: 0.7640, Test: 0.7750\n에폭: 043, Loss: 1.1990, Val: 0.7680, Test: 0.7800\n에폭: 044, Loss: 1.1957, Val: 0.7640, Test: 0.7810\n에폭: 045, Loss: 1.1835, Val: 0.7620, Test: 0.7840\n에폭: 046, Loss: 1.1654, Val: 0.7620, Test: 0.7860\n에폭: 047, Loss: 1.1340, Val: 0.7680, Test: 0.7850\n에폭: 048, Loss: 1.0928, Val: 0.7640, Test: 0.7870\n에폭: 049, Loss: 1.0673, Val: 0.7620, Test: 0.7890\n에폭: 050, Loss: 1.0424, Val: 0.7600, Test: 0.7950\n에폭: 051, Loss: 1.0307, Val: 0.7700, Test: 0.7960\n에폭: 052, Loss: 1.0354, Val: 0.7700, Test: 0.7960\n에폭: 053, Loss: 0.9902, Val: 0.7680, Test: 0.7960\n에폭: 054, Loss: 0.9670, Val: 0.7660, Test: 0.7990\n에폭: 055, Loss: 0.9509, Val: 0.7720, Test: 0.8010\n에폭: 056, Loss: 0.9346, Val: 0.7720, Test: 0.7990\n에폭: 057, Loss: 0.9241, Val: 0.7720, Test: 0.8010\n에폭: 058, Loss: 0.9048, Val: 0.7700, Test: 0.8060\n에폭: 059, Loss: 0.8751, Val: 0.7760, Test: 0.8070\n에폭: 060, Loss: 0.8744, Val: 0.7760, Test: 0.8070\n에폭: 061, Loss: 0.8741, Val: 0.7760, Test: 0.8060\n에폭: 062, Loss: 0.8382, Val: 0.7760, Test: 0.8060\n에폭: 063, Loss: 0.8386, Val: 0.7760, Test: 0.8050\n에폭: 064, Loss: 0.8064, Val: 0.7740, Test: 0.8050\n에폭: 065, Loss: 0.7937, Val: 0.7700, Test: 0.8050\n에폭: 066, Loss: 0.7756, Val: 0.7700, Test: 0.8060\n에폭: 067, Loss: 0.7719, Val: 0.7740, Test: 0.8060\n에폭: 068, Loss: 0.7680, Val: 0.7760, Test: 0.8080\n에폭: 069, Loss: 0.7578, Val: 0.7740, Test: 0.8060\n에폭: 070, Loss: 0.6947, Val: 0.7760, Test: 0.8060\n에폭: 071, Loss: 0.6947, Val: 0.7740, Test: 0.8060\n에폭: 072, Loss: 0.7084, Val: 0.7800, Test: 0.8090\n에폭: 073, Loss: 0.6902, Val: 0.7820, Test: 0.8110\n에폭: 074, Loss: 0.6982, Val: 0.7840, Test: 0.8120\n에폭: 075, Loss: 0.6644, Val: 0.7860, Test: 0.8130\n에폭: 076, Loss: 0.6464, Val: 0.7840, Test: 0.8140\n에폭: 077, Loss: 0.6493, Val: 0.7820, Test: 0.8110\n에폭: 078, Loss: 0.6318, Val: 0.7820, Test: 0.8090\n에폭: 079, Loss: 0.6261, Val: 0.7820, Test: 0.8100\n에폭: 080, Loss: 0.6206, Val: 0.7840, Test: 0.8090\n에폭: 081, Loss: 0.6000, Val: 0.7820, Test: 0.8080\n에폭: 082, Loss: 0.5981, Val: 0.7820, Test: 0.8050\n에폭: 083, Loss: 0.6003, Val: 0.7840, Test: 0.8070\n에폭: 084, Loss: 0.5982, Val: 0.7780, Test: 0.8070\n에폭: 085, Loss: 0.5790, Val: 0.7780, Test: 0.8090\n에폭: 086, Loss: 0.5735, Val: 0.7760, Test: 0.8100\n에폭: 087, Loss: 0.5556, Val: 0.7700, Test: 0.8110\n에폭: 088, Loss: 0.5661, Val: 0.7720, Test: 0.8090\n에폭: 089, Loss: 0.5532, Val: 0.7720, Test: 0.8090\n에폭: 090, Loss: 0.5643, Val: 0.7720, Test: 0.8110\n에폭: 091, Loss: 0.5254, Val: 0.7800, Test: 0.8120\n에폭: 092, Loss: 0.5273, Val: 0.7800, Test: 0.8120\n에폭: 093, Loss: 0.4899, Val: 0.7800, Test: 0.8120\n에폭: 094, Loss: 0.5018, Val: 0.7840, Test: 0.8120\n에폭: 095, Loss: 0.5108, Val: 0.7820, Test: 0.8100\n에폭: 096, Loss: 0.4899, Val: 0.7800, Test: 0.8090\n에폭: 097, Loss: 0.5016, Val: 0.7780, Test: 0.8080\n에폭: 098, Loss: 0.5214, Val: 0.7800, Test: 0.8110\n에폭: 099, Loss: 0.5047, Val: 0.7820, Test: 0.8130\n에폭: 100, Loss: 0.5089, Val: 0.7820, Test: 0.8120\n\n\n\ntest_acc = test()\ntest_acc\n\n0.812\n\n\n\n\n\n\nfrom torch_geometric.nn import GCNConv\n\n\nclass GCN(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        ## 우리가 사용할 레이어 정의\n        torch.manual_seed(1234567)\n        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n        ## 레이어 정의 끝!\n        \n    def forward(self, x, edge_index):\n        ## yhat을 어떻게 구할것인지 정의\n        x = self.conv1(x, edge_index)\n        x = x.relu()\n        x = F.dropout(x, p=0.1, training=self.training)\n        x = self.conv2(x, edge_index)\n        ## 정의 끝!\n        return x\n\nmodel = GCN(hidden_channels=16)\nprint(model)\n\nGCN(\n  (conv1): GCNConv(1433, 16)\n  (conv2): GCNConv(16, 7)\n)\n\n\n\nmodel = GCN(hidden_channels=16)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\nfor epoch in range(1, 201):\n    loss = train()\n    val_acc = val()\n    test_acc = test()\n    print(f'에폭: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n\n에폭: 001, Loss: 1.9464, Val: 0.2780, Test: 0.2690\n에폭: 002, Loss: 1.9400, Val: 0.3480, Test: 0.3900\n에폭: 003, Loss: 1.9326, Val: 0.3080, Test: 0.3470\n에폭: 004, Loss: 1.9237, Val: 0.3320, Test: 0.3570\n에폭: 005, Loss: 1.9150, Val: 0.3480, Test: 0.3900\n에폭: 006, Loss: 1.9046, Val: 0.3740, Test: 0.4190\n에폭: 007, Loss: 1.8929, Val: 0.3680, Test: 0.4050\n에폭: 008, Loss: 1.8826, Val: 0.3600, Test: 0.3880\n에폭: 009, Loss: 1.8704, Val: 0.3540, Test: 0.3780\n에폭: 010, Loss: 1.8585, Val: 0.3600, Test: 0.3810\n에폭: 011, Loss: 1.8438, Val: 0.3800, Test: 0.3860\n에폭: 012, Loss: 1.8324, Val: 0.4120, Test: 0.4050\n에폭: 013, Loss: 1.8152, Val: 0.4520, Test: 0.4360\n에폭: 014, Loss: 1.7987, Val: 0.4760, Test: 0.4750\n에폭: 015, Loss: 1.7910, Val: 0.4880, Test: 0.5050\n에폭: 016, Loss: 1.7717, Val: 0.5140, Test: 0.5240\n에폭: 017, Loss: 1.7569, Val: 0.5320, Test: 0.5470\n에폭: 018, Loss: 1.7395, Val: 0.5380, Test: 0.5630\n에폭: 019, Loss: 1.7258, Val: 0.5440, Test: 0.5700\n에폭: 020, Loss: 1.7043, Val: 0.5580, Test: 0.5800\n에폭: 021, Loss: 1.6870, Val: 0.5660, Test: 0.5930\n에폭: 022, Loss: 1.6703, Val: 0.5880, Test: 0.6060\n에폭: 023, Loss: 1.6519, Val: 0.6040, Test: 0.6180\n에폭: 024, Loss: 1.6270, Val: 0.6140, Test: 0.6310\n에폭: 025, Loss: 1.6076, Val: 0.6300, Test: 0.6520\n에폭: 026, Loss: 1.5909, Val: 0.6440, Test: 0.6650\n에폭: 027, Loss: 1.5703, Val: 0.6620, Test: 0.6770\n에폭: 028, Loss: 1.5411, Val: 0.6680, Test: 0.6800\n에폭: 029, Loss: 1.5178, Val: 0.6840, Test: 0.6820\n에폭: 030, Loss: 1.5052, Val: 0.6980, Test: 0.6950\n에폭: 031, Loss: 1.4801, Val: 0.7100, Test: 0.7120\n에폭: 032, Loss: 1.4611, Val: 0.7220, Test: 0.7220\n에폭: 033, Loss: 1.4331, Val: 0.7300, Test: 0.7290\n에폭: 034, Loss: 1.4049, Val: 0.7320, Test: 0.7370\n에폭: 035, Loss: 1.3814, Val: 0.7320, Test: 0.7430\n에폭: 036, Loss: 1.3534, Val: 0.7320, Test: 0.7460\n에폭: 037, Loss: 1.3392, Val: 0.7360, Test: 0.7500\n에폭: 038, Loss: 1.3111, Val: 0.7420, Test: 0.7550\n에폭: 039, Loss: 1.2872, Val: 0.7440, Test: 0.7590\n에폭: 040, Loss: 1.2524, Val: 0.7440, Test: 0.7650\n에폭: 041, Loss: 1.2334, Val: 0.7520, Test: 0.7670\n에폭: 042, Loss: 1.2059, Val: 0.7580, Test: 0.7670\n에폭: 043, Loss: 1.1807, Val: 0.7600, Test: 0.7710\n에폭: 044, Loss: 1.1772, Val: 0.7640, Test: 0.7720\n에폭: 045, Loss: 1.1379, Val: 0.7640, Test: 0.7740\n에폭: 046, Loss: 1.1219, Val: 0.7640, Test: 0.7740\n에폭: 047, Loss: 1.0842, Val: 0.7620, Test: 0.7790\n에폭: 048, Loss: 1.0544, Val: 0.7640, Test: 0.7830\n에폭: 049, Loss: 1.0447, Val: 0.7600, Test: 0.7820\n에폭: 050, Loss: 1.0195, Val: 0.7640, Test: 0.7840\n에폭: 051, Loss: 1.0132, Val: 0.7640, Test: 0.7830\n에폭: 052, Loss: 0.9956, Val: 0.7680, Test: 0.7860\n에폭: 053, Loss: 0.9449, Val: 0.7700, Test: 0.7880\n에폭: 054, Loss: 0.9339, Val: 0.7680, Test: 0.7890\n에폭: 055, Loss: 0.9095, Val: 0.7700, Test: 0.7940\n에폭: 056, Loss: 0.8824, Val: 0.7720, Test: 0.7980\n에폭: 057, Loss: 0.8770, Val: 0.7660, Test: 0.8020\n에폭: 058, Loss: 0.8491, Val: 0.7700, Test: 0.8010\n에폭: 059, Loss: 0.8406, Val: 0.7700, Test: 0.7990\n에폭: 060, Loss: 0.8326, Val: 0.7660, Test: 0.8030\n에폭: 061, Loss: 0.8064, Val: 0.7680, Test: 0.8000\n에폭: 062, Loss: 0.7896, Val: 0.7700, Test: 0.7980\n에폭: 063, Loss: 0.7920, Val: 0.7780, Test: 0.7990\n에폭: 064, Loss: 0.7561, Val: 0.7780, Test: 0.8010\n에폭: 065, Loss: 0.7494, Val: 0.7760, Test: 0.8010\n에폭: 066, Loss: 0.7280, Val: 0.7720, Test: 0.8030\n에폭: 067, Loss: 0.7121, Val: 0.7740, Test: 0.8050\n에폭: 068, Loss: 0.7002, Val: 0.7740, Test: 0.8070\n에폭: 069, Loss: 0.6942, Val: 0.7740, Test: 0.8110\n에폭: 070, Loss: 0.6777, Val: 0.7700, Test: 0.8090\n에폭: 071, Loss: 0.6598, Val: 0.7720, Test: 0.8110\n에폭: 072, Loss: 0.6473, Val: 0.7820, Test: 0.8080\n에폭: 073, Loss: 0.6488, Val: 0.7800, Test: 0.8050\n에폭: 074, Loss: 0.6491, Val: 0.7800, Test: 0.8040\n에폭: 075, Loss: 0.6071, Val: 0.7800, Test: 0.8050\n에폭: 076, Loss: 0.6019, Val: 0.7820, Test: 0.8080\n에폭: 077, Loss: 0.5906, Val: 0.7800, Test: 0.8090\n에폭: 078, Loss: 0.5825, Val: 0.7820, Test: 0.8100\n에폭: 079, Loss: 0.5755, Val: 0.7820, Test: 0.8120\n에폭: 080, Loss: 0.5750, Val: 0.7840, Test: 0.8120\n에폭: 081, Loss: 0.5544, Val: 0.7820, Test: 0.8120\n에폭: 082, Loss: 0.5467, Val: 0.7760, Test: 0.8110\n에폭: 083, Loss: 0.5502, Val: 0.7760, Test: 0.8090\n에폭: 084, Loss: 0.5462, Val: 0.7760, Test: 0.8050\n에폭: 085, Loss: 0.5186, Val: 0.7860, Test: 0.8060\n에폭: 086, Loss: 0.5396, Val: 0.7880, Test: 0.8080\n에폭: 087, Loss: 0.5158, Val: 0.7880, Test: 0.8090\n에폭: 088, Loss: 0.5236, Val: 0.7840, Test: 0.8130\n에폭: 089, Loss: 0.5042, Val: 0.7840, Test: 0.8130\n에폭: 090, Loss: 0.5049, Val: 0.7820, Test: 0.8130\n에폭: 091, Loss: 0.4941, Val: 0.7800, Test: 0.8090\n에폭: 092, Loss: 0.4815, Val: 0.7860, Test: 0.8080\n에폭: 093, Loss: 0.4546, Val: 0.7860, Test: 0.8100\n에폭: 094, Loss: 0.4762, Val: 0.7860, Test: 0.8100\n에폭: 095, Loss: 0.4845, Val: 0.7960, Test: 0.8070\n에폭: 096, Loss: 0.4559, Val: 0.7960, Test: 0.8100\n에폭: 097, Loss: 0.4512, Val: 0.7940, Test: 0.8080\n에폭: 098, Loss: 0.4589, Val: 0.7880, Test: 0.8100\n에폭: 099, Loss: 0.4549, Val: 0.7780, Test: 0.8100\n에폭: 100, Loss: 0.4531, Val: 0.7780, Test: 0.8110\n에폭: 101, Loss: 0.4394, Val: 0.7780, Test: 0.8120\n에폭: 102, Loss: 0.4359, Val: 0.7760, Test: 0.8110\n에폭: 103, Loss: 0.4360, Val: 0.7800, Test: 0.8110\n에폭: 104, Loss: 0.4213, Val: 0.7900, Test: 0.8090\n에폭: 105, Loss: 0.4442, Val: 0.7980, Test: 0.8100\n에폭: 106, Loss: 0.4131, Val: 0.7960, Test: 0.8130\n에폭: 107, Loss: 0.4266, Val: 0.7920, Test: 0.8120\n에폭: 108, Loss: 0.4158, Val: 0.7880, Test: 0.8130\n에폭: 109, Loss: 0.4077, Val: 0.7900, Test: 0.8110\n에폭: 110, Loss: 0.3960, Val: 0.7880, Test: 0.8080\n에폭: 111, Loss: 0.4049, Val: 0.7900, Test: 0.8110\n에폭: 112, Loss: 0.3819, Val: 0.7880, Test: 0.8120\n에폭: 113, Loss: 0.3931, Val: 0.7860, Test: 0.8110\n에폭: 114, Loss: 0.3862, Val: 0.7860, Test: 0.8110\n에폭: 115, Loss: 0.3649, Val: 0.7920, Test: 0.8130\n에폭: 116, Loss: 0.3774, Val: 0.7880, Test: 0.8110\n에폭: 117, Loss: 0.3580, Val: 0.7880, Test: 0.8090\n에폭: 118, Loss: 0.3820, Val: 0.7900, Test: 0.8140\n에폭: 119, Loss: 0.3640, Val: 0.7920, Test: 0.8150\n에폭: 120, Loss: 0.3648, Val: 0.7920, Test: 0.8140\n에폭: 121, Loss: 0.3477, Val: 0.7920, Test: 0.8110\n에폭: 122, Loss: 0.3689, Val: 0.7960, Test: 0.8120\n에폭: 123, Loss: 0.3664, Val: 0.7980, Test: 0.8080\n에폭: 124, Loss: 0.3627, Val: 0.7920, Test: 0.8050\n에폭: 125, Loss: 0.3612, Val: 0.7880, Test: 0.8100\n에폭: 126, Loss: 0.3507, Val: 0.7860, Test: 0.8100\n에폭: 127, Loss: 0.3329, Val: 0.7880, Test: 0.8130\n에폭: 128, Loss: 0.3505, Val: 0.7920, Test: 0.8110\n에폭: 129, Loss: 0.3464, Val: 0.7960, Test: 0.8100\n에폭: 130, Loss: 0.3310, Val: 0.7960, Test: 0.8110\n에폭: 131, Loss: 0.3384, Val: 0.7960, Test: 0.8100\n에폭: 132, Loss: 0.3405, Val: 0.7940, Test: 0.8110\n에폭: 133, Loss: 0.3313, Val: 0.7920, Test: 0.8100\n에폭: 134, Loss: 0.3211, Val: 0.7940, Test: 0.8130\n에폭: 135, Loss: 0.3281, Val: 0.7940, Test: 0.8120\n에폭: 136, Loss: 0.3299, Val: 0.7900, Test: 0.8130\n에폭: 137, Loss: 0.3133, Val: 0.7920, Test: 0.8130\n에폭: 138, Loss: 0.3328, Val: 0.7940, Test: 0.8150\n에폭: 139, Loss: 0.3331, Val: 0.7940, Test: 0.8180\n에폭: 140, Loss: 0.3145, Val: 0.7980, Test: 0.8160\n에폭: 141, Loss: 0.3150, Val: 0.7940, Test: 0.8120\n에폭: 142, Loss: 0.3036, Val: 0.7920, Test: 0.8120\n에폭: 143, Loss: 0.3115, Val: 0.7940, Test: 0.8110\n에폭: 144, Loss: 0.3078, Val: 0.8000, Test: 0.8110\n에폭: 145, Loss: 0.3058, Val: 0.7980, Test: 0.8120\n에폭: 146, Loss: 0.3015, Val: 0.7980, Test: 0.8090\n에폭: 147, Loss: 0.3093, Val: 0.7940, Test: 0.8100\n에폭: 148, Loss: 0.2789, Val: 0.7920, Test: 0.8110\n에폭: 149, Loss: 0.2946, Val: 0.7880, Test: 0.8100\n에폭: 150, Loss: 0.2950, Val: 0.7900, Test: 0.8130\n에폭: 151, Loss: 0.3160, Val: 0.7860, Test: 0.8110\n에폭: 152, Loss: 0.3075, Val: 0.7880, Test: 0.8120\n에폭: 153, Loss: 0.3057, Val: 0.7920, Test: 0.8130\n에폭: 154, Loss: 0.2921, Val: 0.7980, Test: 0.8120\n에폭: 155, Loss: 0.2911, Val: 0.8000, Test: 0.8130\n에폭: 156, Loss: 0.2857, Val: 0.7980, Test: 0.8140\n에폭: 157, Loss: 0.2865, Val: 0.7980, Test: 0.8170\n에폭: 158, Loss: 0.2816, Val: 0.7960, Test: 0.8160\n에폭: 159, Loss: 0.2919, Val: 0.7960, Test: 0.8170\n에폭: 160, Loss: 0.2773, Val: 0.7980, Test: 0.8170\n에폭: 161, Loss: 0.2636, Val: 0.7960, Test: 0.8160\n에폭: 162, Loss: 0.3004, Val: 0.7960, Test: 0.8170\n에폭: 163, Loss: 0.2888, Val: 0.7900, Test: 0.8110\n에폭: 164, Loss: 0.2830, Val: 0.7900, Test: 0.8110\n에폭: 165, Loss: 0.2694, Val: 0.7980, Test: 0.8150\n에폭: 166, Loss: 0.2709, Val: 0.8000, Test: 0.8090\n에폭: 167, Loss: 0.2705, Val: 0.8000, Test: 0.8110\n에폭: 168, Loss: 0.2637, Val: 0.7940, Test: 0.8120\n에폭: 169, Loss: 0.2624, Val: 0.7940, Test: 0.8120\n에폭: 170, Loss: 0.2652, Val: 0.7980, Test: 0.8140\n에폭: 171, Loss: 0.2639, Val: 0.7960, Test: 0.8150\n에폭: 172, Loss: 0.2690, Val: 0.7880, Test: 0.8180\n에폭: 173, Loss: 0.2571, Val: 0.7880, Test: 0.8150\n에폭: 174, Loss: 0.2543, Val: 0.7880, Test: 0.8090\n에폭: 175, Loss: 0.2559, Val: 0.7940, Test: 0.8100\n에폭: 176, Loss: 0.2633, Val: 0.7980, Test: 0.8090\n에폭: 177, Loss: 0.2767, Val: 0.7980, Test: 0.8140\n에폭: 178, Loss: 0.2646, Val: 0.7920, Test: 0.8130\n에폭: 179, Loss: 0.2710, Val: 0.7960, Test: 0.8100\n에폭: 180, Loss: 0.2645, Val: 0.7940, Test: 0.8120\n에폭: 181, Loss: 0.2671, Val: 0.7940, Test: 0.8140\n에폭: 182, Loss: 0.2565, Val: 0.8000, Test: 0.8130\n에폭: 183, Loss: 0.2512, Val: 0.7980, Test: 0.8120\n에폭: 184, Loss: 0.2589, Val: 0.7920, Test: 0.8080\n에폭: 185, Loss: 0.2543, Val: 0.7900, Test: 0.8080\n에폭: 186, Loss: 0.2638, Val: 0.7920, Test: 0.8070\n에폭: 187, Loss: 0.2497, Val: 0.7960, Test: 0.8080\n에폭: 188, Loss: 0.2348, Val: 0.7960, Test: 0.8100\n에폭: 189, Loss: 0.2536, Val: 0.7960, Test: 0.8100\n에폭: 190, Loss: 0.2623, Val: 0.7960, Test: 0.8100\n에폭: 191, Loss: 0.2347, Val: 0.7940, Test: 0.8130\n에폭: 192, Loss: 0.2558, Val: 0.7960, Test: 0.8110\n에폭: 193, Loss: 0.2516, Val: 0.7900, Test: 0.8100\n에폭: 194, Loss: 0.2312, Val: 0.7860, Test: 0.8080\n에폭: 195, Loss: 0.2466, Val: 0.7900, Test: 0.8120\n에폭: 196, Loss: 0.2486, Val: 0.7960, Test: 0.8130\n에폭: 197, Loss: 0.2334, Val: 0.7960, Test: 0.8140\n에폭: 198, Loss: 0.2431, Val: 0.7960, Test: 0.8120\n에폭: 199, Loss: 0.2470, Val: 0.7960, Test: 0.8130\n에폭: 200, Loss: 0.2428, Val: 0.7960, Test: 0.8150\n\n\n\ntest_acc\n\n0.815\n\n\n\n\n\n\n# def train():\n#       model.train()\n#       optimizr.zero_grad()  # Clear gradients.\n#       out = model(data.x, data.edge_index)  # Perform a single forward pass.\n#       loss = loss_fn(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n#       loss.backward()  # Derive gradients.\n#       optimizr.step()  # Update parameters based on gradients.\n#       return loss\n\n\nclass EarlyStopping:\n    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n        \"\"\"\n        Args:\n            patience (int): validation loss가 개선된 후 기다리는 기간\n                            Default: 7\n            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n                            Default: False\n            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n                            Default: 0\n            path (str): checkpoint저장 경로\n                            Default: 'checkpoint.pt'\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n    def save_checkpoint(self, val_loss, model):\n        '''validation loss가 감소하면 모델을 저장한다.'''\n        if self.verbose:\n            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss\n\n\nimport numpy as np \n\ndef train_model(model, patience, n_epochs): # remove batch_size\n\n    # 모델이 학습되는 동안 trainning loss를 track\n    train_losses = []\n    # 모델이 학습되는 동안 validation loss를 track\n    valid_losses = []\n    # epoch당 average training loss를 track\n    avg_train_losses = []\n    # epoch당 average validation loss를 track\n    avg_valid_losses = []\n    test_accs = []\n    # epoch당 test accuracy를 track\n    # test_accs = []\n    # avg_test_accs = []\n\n    # early_stopping object의 초기화\n    early_stopping = EarlyStopping(patience = patience, verbose = True)\n\n    for epoch in range(1, n_epochs + 1):\n\n        ###################\n        # train the model #\n        ###################\n        model.train() # prep model for training\n        # for batch, (data, target) in enumerate(train_loader, 1):\n        #     # clear the gradients of all optimized variables\n        #     optimizer.zero_grad()    \n        #     # forward pass: 입력된 값을 모델로 전달하여 예측 출력 계산\n        #     output = model(data)\n        #     # calculate the loss\n        #     loss = loss_fn(output, target)\n        #     # backward pass: 모델의 파라미터와 관련된 loss의 그래디언트 계산\n        #     loss.backward()\n        #     # perform a single optimization step (parameter update)\n        #     optimizer.step()\n        #     # record training loss\n        #     train_losses.append(loss.item())\n\n        # model.train()\n        optimizr.zero_grad()  # Clear gradients.\n        output = model(data.x, data.edge_index)  # Perform a single forward pass.\n        loss = loss_fn(output[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n        loss.backward()  # Derive gradients.\n        optimizr.step()  # Update parameters based on gradients.\n        # return loss\n        train_losses.append(loss.item())\n            \n            \n\n        ######################    \n        # validate the model #\n        ######################\n        model.eval() # prep model for evaluation\n        # for data , target in valid_loader :\n        #     # forward pass: 입력된 값을 모델로 전달하여 예측 출력 계산\n        #     output = model(data)\n        #     # calculate the loss\n        #     loss = loss_fn(output, target)\n        #     # record validation loss\n        #     valid_losses.append(loss.item())\n        output = model(data.x, data.edge_index)\n        loss = loss_fn(output[data.val_mask], data.y[data.val_mask])\n        # test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n        # return test_acc\n        valid_losses.append(loss.item())\n        \n        \n        \n        #########################\n        #     test acc          #\n        #########################\n        model.eval()\n        output = model(data.x, data.edge_index)\n        pred = output.argmax(dim=1)\n        test_correct = pred[data.test_mask] == data.y[data.test_mask]\n        test_acc = int(test_correct.sum()) / int(data.test_mask.sum())\n        test_accs.append(test_acc)\n        \n\n        # print 학습/검증 statistics\n        # epoch당 평균 loss 계산\n        train_loss = np.average(train_losses)\n        valid_loss = np.average(valid_losses)\n        # test_accs_ = np.average(test_accs)\n        avg_train_losses.append(train_loss)\n        avg_valid_losses.append(valid_loss)\n        # avg_test_accs.append(test_accs_)\n \n\n        epoch_len = len(str(n_epochs))\n\n\n        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n                     f'train_loss: {train_loss:.5f} ' +\n                     f'valid_loss: {valid_loss:.5f} ' +\n                     f'test_acc: {test_acc:.5f}') #                      f'test_acc: {test_acc:.5f}'\n\n        print(print_msg)\n\n        # clear lists to track next epoch\n        train_losses = []\n        valid_losses = []\n        # test_accs = []\n\n        # early_stopping는 validation loss가 감소하였는지 확인이 필요하며,\n        # 만약 감소하였을경우 현제 모델을 checkpoint로 만든다.\n        early_stopping(valid_loss, model)\n\n        if early_stopping.early_stop:\n            print(\"Early stopping\")\n            break\n\n   # best model이 저장되어있는 last checkpoint를 로드한다.\n    model.load_state_dict(torch.load('checkpoint.pt'))\n\n    return  model, avg_train_losses, avg_valid_losses\n\n\n# batch_size = 256\nn_epochs = 200\n\n# train_loader, test_loader, valid_loader = create_datasets(batch_size)\n\n# early stopping patience;\n# validation loss가 개선된 마지막 시간 이후로 얼마나 기다릴지 지정\npatience = 7\n\nmodel, train_loss, valid_loss = train_model(model, patience, n_epochs) \n\n[  1/200] train_loss: 0.13977 valid_loss: 0.71796 test_acc: 0.81400\nValidation loss decreased (inf --> 0.717956).  Saving model ...\n[  2/200] train_loss: 0.14062 valid_loss: 0.72924 test_acc: 0.81000\nEarlyStopping counter: 1 out of 7\n[  3/200] train_loss: 0.13907 valid_loss: 0.74173 test_acc: 0.80100\nEarlyStopping counter: 2 out of 7\n[  4/200] train_loss: 0.13587 valid_loss: 0.74482 test_acc: 0.80000\nEarlyStopping counter: 3 out of 7\n[  5/200] train_loss: 0.13762 valid_loss: 0.73790 test_acc: 0.80600\nEarlyStopping counter: 4 out of 7\n[  6/200] train_loss: 0.14008 valid_loss: 0.72733 test_acc: 0.80600\nEarlyStopping counter: 5 out of 7\n[  7/200] train_loss: 0.13915 valid_loss: 0.71572 test_acc: 0.81300\nValidation loss decreased (0.717956 --> 0.715715).  Saving model ...\n[  8/200] train_loss: 0.14486 valid_loss: 0.70914 test_acc: 0.82000\nValidation loss decreased (0.715715 --> 0.709141).  Saving model ...\n[  9/200] train_loss: 0.13368 valid_loss: 0.70767 test_acc: 0.81900\nValidation loss decreased (0.709141 --> 0.707673).  Saving model ...\n[ 10/200] train_loss: 0.14246 valid_loss: 0.70954 test_acc: 0.81900\nEarlyStopping counter: 1 out of 7\n[ 11/200] train_loss: 0.13961 valid_loss: 0.71373 test_acc: 0.81600\nEarlyStopping counter: 2 out of 7\n[ 12/200] train_loss: 0.12674 valid_loss: 0.71963 test_acc: 0.81200\nEarlyStopping counter: 3 out of 7\n[ 13/200] train_loss: 0.13681 valid_loss: 0.72552 test_acc: 0.81100\nEarlyStopping counter: 4 out of 7\n[ 14/200] train_loss: 0.13652 valid_loss: 0.72897 test_acc: 0.81200\nEarlyStopping counter: 5 out of 7\n[ 15/200] train_loss: 0.13501 valid_loss: 0.72768 test_acc: 0.80900\nEarlyStopping counter: 6 out of 7\n[ 16/200] train_loss: 0.13654 valid_loss: 0.71993 test_acc: 0.81300\nEarlyStopping counter: 7 out of 7\nEarly stopping\n\n\n\nimport matplotlib.pyplot as plt\n\n# 훈련이 진행되는 과정에 따라 loss를 시각화\nfig = plt.figure(figsize=(10,8))\nplt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\nplt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n# plt.plot(range(1,len(test_acc)+1), test_acc, label='Test accuracy')\n\n# validation loss의 최저값 지점을 찾기\nminposs = valid_loss.index(min(valid_loss))+1\nplt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.ylim(0, 1.0) # 일정한 scale\nplt.xlim(0, len(train_loss)+1) # 일정한 scale\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\nfig.savefig('loss_plot.png', bbox_inches = 'tight')\n\n\n\n\n\n왜 이따구야…\n\n\n\n\n\n\n\n\nmodel = GCN(hidden_channels=32)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\ndef train():\n      model.train()\n      optimizr.zero_grad()  # Clear gradients.\n      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n      loss = loss_fn(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n      loss.backward()  # Derive gradients.\n      optimizr.step()  # Update parameters based on gradients.\n      return loss\n\n# def test(mask):\n#       model.eval()\n#       out = model(data.x, data.edge_index)\n#       pred = out.argmax(dim=1)  # Use the class with highest probability.\n#       correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n#       acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n#       return acc\ndef test(mask):\n      model.eval()\n      out = model(data.x, data.edge_index)\n      pred = out.argmax(dim=1)  # Use the class with highest probability.\n      correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n      acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n      return acc\n\n\n_out = model(data.x, data.edge_index)\n\n\n_out\n\ntorch.Size([2708, 7])\n\n\n\nfor epoch in range(1, 101):\n    loss = train()\n    val_acc = test(data.val_mask)\n    test_acc = test(data.test_mask)\n    print(f'에폭: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n\n에폭: 001, Loss: 1.9455, Val: 0.2040, Test: 0.2490\n에폭: 002, Loss: 1.9400, Val: 0.4880, Test: 0.4600\n에폭: 003, Loss: 1.9309, Val: 0.4900, Test: 0.4740\n에폭: 004, Loss: 1.9180, Val: 0.4220, Test: 0.4570\n에폭: 005, Loss: 1.9058, Val: 0.3940, Test: 0.4240\n에폭: 006, Loss: 1.8934, Val: 0.3840, Test: 0.4230\n에폭: 007, Loss: 1.8779, Val: 0.4000, Test: 0.4390\n에폭: 008, Loss: 1.8592, Val: 0.4200, Test: 0.4470\n에폭: 009, Loss: 1.8494, Val: 0.4120, Test: 0.4300\n에폭: 010, Loss: 1.8245, Val: 0.4220, Test: 0.4290\n에폭: 011, Loss: 1.8075, Val: 0.4180, Test: 0.4250\n에폭: 012, Loss: 1.7893, Val: 0.4440, Test: 0.4480\n에폭: 013, Loss: 1.7692, Val: 0.4700, Test: 0.4770\n에폭: 014, Loss: 1.7412, Val: 0.4940, Test: 0.4980\n에폭: 015, Loss: 1.7192, Val: 0.5360, Test: 0.5290\n에폭: 016, Loss: 1.6908, Val: 0.5800, Test: 0.5700\n에폭: 017, Loss: 1.6828, Val: 0.6000, Test: 0.6080\n에폭: 018, Loss: 1.6326, Val: 0.6220, Test: 0.6360\n에폭: 019, Loss: 1.6089, Val: 0.6500, Test: 0.6640\n에폭: 020, Loss: 1.5959, Val: 0.6840, Test: 0.6810\n에폭: 021, Loss: 1.5634, Val: 0.7060, Test: 0.7000\n에폭: 022, Loss: 1.5426, Val: 0.7140, Test: 0.7090\n에폭: 023, Loss: 1.4932, Val: 0.7220, Test: 0.7160\n에폭: 024, Loss: 1.4759, Val: 0.7300, Test: 0.7190\n에폭: 025, Loss: 1.4473, Val: 0.7360, Test: 0.7320\n에폭: 026, Loss: 1.4263, Val: 0.7360, Test: 0.7430\n에폭: 027, Loss: 1.3863, Val: 0.7360, Test: 0.7450\n에폭: 028, Loss: 1.3437, Val: 0.7400, Test: 0.7480\n에폭: 029, Loss: 1.3084, Val: 0.7460, Test: 0.7570\n에폭: 030, Loss: 1.2828, Val: 0.7500, Test: 0.7610\n에폭: 031, Loss: 1.2385, Val: 0.7600, Test: 0.7620\n에폭: 032, Loss: 1.2029, Val: 0.7660, Test: 0.7680\n에폭: 033, Loss: 1.1789, Val: 0.7660, Test: 0.7720\n에폭: 034, Loss: 1.1715, Val: 0.7680, Test: 0.7770\n에폭: 035, Loss: 1.1197, Val: 0.7660, Test: 0.7790\n에폭: 036, Loss: 1.0807, Val: 0.7680, Test: 0.7810\n에폭: 037, Loss: 1.0921, Val: 0.7700, Test: 0.7870\n에폭: 038, Loss: 1.0493, Val: 0.7760, Test: 0.7920\n에폭: 039, Loss: 1.0141, Val: 0.7760, Test: 0.7940\n에폭: 040, Loss: 0.9605, Val: 0.7780, Test: 0.7970\n에폭: 041, Loss: 0.9411, Val: 0.7800, Test: 0.8010\n에폭: 042, Loss: 0.9093, Val: 0.7780, Test: 0.8000\n에폭: 043, Loss: 0.8912, Val: 0.7780, Test: 0.8030\n에폭: 044, Loss: 0.8661, Val: 0.7780, Test: 0.8010\n에폭: 045, Loss: 0.8743, Val: 0.7760, Test: 0.7990\n에폭: 046, Loss: 0.7827, Val: 0.7740, Test: 0.8000\n에폭: 047, Loss: 0.8070, Val: 0.7740, Test: 0.7990\n에폭: 048, Loss: 0.7631, Val: 0.7760, Test: 0.7980\n에폭: 049, Loss: 0.7676, Val: 0.7760, Test: 0.7930\n에폭: 050, Loss: 0.7429, Val: 0.7740, Test: 0.7960\n에폭: 051, Loss: 0.7164, Val: 0.7800, Test: 0.7960\n에폭: 052, Loss: 0.7005, Val: 0.7820, Test: 0.8010\n에폭: 053, Loss: 0.6526, Val: 0.7840, Test: 0.8040\n에폭: 054, Loss: 0.6508, Val: 0.7840, Test: 0.8070\n에폭: 055, Loss: 0.6600, Val: 0.7860, Test: 0.8080\n에폭: 056, Loss: 0.6504, Val: 0.7800, Test: 0.8090\n에폭: 057, Loss: 0.6144, Val: 0.7820, Test: 0.8130\n에폭: 058, Loss: 0.5991, Val: 0.7880, Test: 0.8150\n에폭: 059, Loss: 0.5760, Val: 0.7900, Test: 0.8150\n에폭: 060, Loss: 0.5802, Val: 0.7840, Test: 0.8190\n에폭: 061, Loss: 0.5780, Val: 0.7840, Test: 0.8170\n에폭: 062, Loss: 0.5314, Val: 0.7820, Test: 0.8170\n에폭: 063, Loss: 0.5477, Val: 0.7800, Test: 0.8140\n에폭: 064, Loss: 0.5201, Val: 0.7800, Test: 0.8140\n에폭: 065, Loss: 0.5152, Val: 0.7780, Test: 0.8170\n에폭: 066, Loss: 0.5426, Val: 0.7820, Test: 0.8150\n에폭: 067, Loss: 0.5077, Val: 0.7820, Test: 0.8090\n에폭: 068, Loss: 0.4977, Val: 0.7840, Test: 0.8080\n에폭: 069, Loss: 0.4940, Val: 0.7860, Test: 0.8100\n에폭: 070, Loss: 0.4645, Val: 0.7840, Test: 0.8070\n에폭: 071, Loss: 0.4631, Val: 0.7860, Test: 0.8080\n에폭: 072, Loss: 0.4483, Val: 0.7820, Test: 0.8130\n에폭: 073, Loss: 0.4633, Val: 0.7820, Test: 0.8140\n에폭: 074, Loss: 0.4798, Val: 0.7840, Test: 0.8130\n에폭: 075, Loss: 0.4621, Val: 0.7840, Test: 0.8120\n에폭: 076, Loss: 0.4268, Val: 0.7840, Test: 0.8130\n에폭: 077, Loss: 0.4374, Val: 0.7840, Test: 0.8160\n에폭: 078, Loss: 0.4206, Val: 0.7860, Test: 0.8160\n에폭: 079, Loss: 0.4502, Val: 0.7840, Test: 0.8140\n에폭: 080, Loss: 0.4283, Val: 0.7840, Test: 0.8120\n에폭: 081, Loss: 0.4543, Val: 0.7860, Test: 0.8140\n에폭: 082, Loss: 0.4022, Val: 0.7860, Test: 0.8130\n에폭: 083, Loss: 0.3963, Val: 0.7900, Test: 0.8120\n에폭: 084, Loss: 0.4181, Val: 0.7900, Test: 0.8100\n에폭: 085, Loss: 0.4002, Val: 0.7860, Test: 0.8080\n에폭: 086, Loss: 0.3945, Val: 0.7880, Test: 0.8090\n에폭: 087, Loss: 0.3902, Val: 0.7860, Test: 0.8100\n에폭: 088, Loss: 0.3878, Val: 0.7880, Test: 0.8090\n에폭: 089, Loss: 0.3852, Val: 0.7880, Test: 0.8100\n에폭: 090, Loss: 0.3613, Val: 0.7840, Test: 0.8110\n에폭: 091, Loss: 0.3955, Val: 0.7920, Test: 0.8120\n에폭: 092, Loss: 0.3529, Val: 0.7880, Test: 0.8120\n에폭: 093, Loss: 0.3688, Val: 0.7900, Test: 0.8110\n에폭: 094, Loss: 0.3735, Val: 0.7900, Test: 0.8080\n에폭: 095, Loss: 0.3563, Val: 0.7860, Test: 0.8070\n에폭: 096, Loss: 0.3598, Val: 0.7860, Test: 0.8090\n에폭: 097, Loss: 0.3641, Val: 0.7840, Test: 0.8090\n에폭: 098, Loss: 0.3614, Val: 0.7860, Test: 0.8100\n에폭: 099, Loss: 0.3512, Val: 0.7860, Test: 0.8110\n에폭: 100, Loss: 0.3392, Val: 0.7800, Test: 0.8110\n\n\n\ntest_acc = test(data.test_mask)\ntest_acc\n\n0.811\n\n\n\n\n\n\nmodel = GCN(hidden_channels=64)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\ndef train():\n      model.train()\n      optimizr.zero_grad()  # Clear gradients.\n      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n      loss = loss_fn(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n      loss.backward()  # Derive gradients.\n      optimizr.step()  # Update parameters based on gradients.\n      return loss\n\ndef test(mask):\n      model.eval()\n      out = model(data.x, data.edge_index)\n      pred = out.argmax(dim=1)  # Use the class with highest probability.\n      correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n      acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n      return acc\n\n\nfor epoch in range(1, 101):\n    loss = train()\n    val_acc = test(data.val_mask)\n    test_acc = test(data.test_mask)\n    print(f'에폭: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n\n에폭: 001, Loss: 1.9461, Val: 0.2280, Test: 0.2530\n에폭: 002, Loss: 1.9347, Val: 0.3720, Test: 0.3930\n에폭: 003, Loss: 1.9207, Val: 0.6560, Test: 0.6540\n에폭: 004, Loss: 1.9041, Val: 0.7480, Test: 0.7320\n에폭: 005, Loss: 1.8870, Val: 0.7380, Test: 0.7490\n에폭: 006, Loss: 1.8686, Val: 0.7600, Test: 0.7750\n에폭: 007, Loss: 1.8476, Val: 0.7760, Test: 0.7890\n에폭: 008, Loss: 1.8169, Val: 0.7800, Test: 0.7860\n에폭: 009, Loss: 1.7975, Val: 0.7720, Test: 0.7830\n에폭: 010, Loss: 1.7649, Val: 0.7700, Test: 0.7740\n에폭: 011, Loss: 1.7330, Val: 0.7560, Test: 0.7750\n에폭: 012, Loss: 1.7101, Val: 0.7640, Test: 0.7780\n에폭: 013, Loss: 1.6784, Val: 0.7680, Test: 0.7790\n에폭: 014, Loss: 1.6361, Val: 0.7720, Test: 0.7800\n에폭: 015, Loss: 1.6086, Val: 0.7780, Test: 0.7840\n에폭: 016, Loss: 1.5724, Val: 0.7820, Test: 0.7930\n에폭: 017, Loss: 1.5306, Val: 0.7840, Test: 0.8000\n에폭: 018, Loss: 1.4846, Val: 0.7900, Test: 0.8000\n에폭: 019, Loss: 1.4324, Val: 0.8000, Test: 0.8030\n에폭: 020, Loss: 1.4128, Val: 0.8020, Test: 0.8010\n에폭: 021, Loss: 1.3664, Val: 0.7960, Test: 0.8020\n에폭: 022, Loss: 1.3191, Val: 0.7980, Test: 0.7990\n에폭: 023, Loss: 1.2794, Val: 0.7980, Test: 0.8010\n에폭: 024, Loss: 1.2395, Val: 0.7900, Test: 0.8020\n에폭: 025, Loss: 1.2056, Val: 0.7940, Test: 0.8000\n에폭: 026, Loss: 1.1459, Val: 0.7900, Test: 0.7970\n에폭: 027, Loss: 1.1225, Val: 0.7900, Test: 0.7970\n에폭: 028, Loss: 1.0561, Val: 0.7940, Test: 0.8030\n에폭: 029, Loss: 1.0305, Val: 0.7980, Test: 0.8080\n에폭: 030, Loss: 0.9678, Val: 0.8000, Test: 0.8110\n에폭: 031, Loss: 0.9440, Val: 0.7960, Test: 0.8110\n에폭: 032, Loss: 0.9190, Val: 0.7940, Test: 0.8140\n에폭: 033, Loss: 0.8733, Val: 0.7980, Test: 0.8120\n에폭: 034, Loss: 0.8455, Val: 0.8020, Test: 0.8170\n에폭: 035, Loss: 0.7919, Val: 0.8020, Test: 0.8170\n에폭: 036, Loss: 0.7638, Val: 0.8000, Test: 0.8160\n에폭: 037, Loss: 0.7554, Val: 0.8020, Test: 0.8140\n에폭: 038, Loss: 0.7256, Val: 0.8040, Test: 0.8220\n에폭: 039, Loss: 0.6891, Val: 0.8040, Test: 0.8190\n에폭: 040, Loss: 0.6443, Val: 0.7980, Test: 0.8190\n에폭: 041, Loss: 0.6405, Val: 0.8020, Test: 0.8230\n에폭: 042, Loss: 0.6302, Val: 0.7980, Test: 0.8200\n에폭: 043, Loss: 0.5836, Val: 0.7980, Test: 0.8130\n에폭: 044, Loss: 0.5620, Val: 0.7920, Test: 0.8140\n에폭: 045, Loss: 0.5484, Val: 0.8000, Test: 0.8170\n에폭: 046, Loss: 0.5387, Val: 0.8000, Test: 0.8200\n에폭: 047, Loss: 0.5254, Val: 0.8040, Test: 0.8250\n에폭: 048, Loss: 0.5036, Val: 0.8020, Test: 0.8230\n에폭: 049, Loss: 0.4968, Val: 0.8020, Test: 0.8270\n에폭: 050, Loss: 0.5090, Val: 0.7980, Test: 0.8280\n에폭: 051, Loss: 0.4719, Val: 0.7960, Test: 0.8250\n에폭: 052, Loss: 0.4537, Val: 0.7940, Test: 0.8260\n에폭: 053, Loss: 0.4421, Val: 0.7860, Test: 0.8200\n에폭: 054, Loss: 0.4380, Val: 0.7940, Test: 0.8190\n에폭: 055, Loss: 0.4082, Val: 0.8000, Test: 0.8160\n에폭: 056, Loss: 0.3956, Val: 0.8040, Test: 0.8210\n에폭: 057, Loss: 0.4172, Val: 0.8000, Test: 0.8220\n에폭: 058, Loss: 0.4053, Val: 0.7960, Test: 0.8250\n에폭: 059, Loss: 0.4049, Val: 0.7980, Test: 0.8250\n에폭: 060, Loss: 0.4005, Val: 0.7940, Test: 0.8170\n에폭: 061, Loss: 0.3776, Val: 0.7880, Test: 0.8150\n에폭: 062, Loss: 0.3655, Val: 0.7840, Test: 0.8100\n에폭: 063, Loss: 0.3504, Val: 0.7840, Test: 0.8090\n에폭: 064, Loss: 0.3473, Val: 0.7880, Test: 0.8110\n에폭: 065, Loss: 0.3726, Val: 0.7880, Test: 0.8140\n에폭: 066, Loss: 0.3532, Val: 0.7860, Test: 0.8150\n에폭: 067, Loss: 0.3520, Val: 0.7900, Test: 0.8200\n에폭: 068, Loss: 0.3481, Val: 0.7900, Test: 0.8210\n에폭: 069, Loss: 0.3543, Val: 0.7940, Test: 0.8180\n에폭: 070, Loss: 0.3482, Val: 0.7920, Test: 0.8230\n에폭: 071, Loss: 0.3228, Val: 0.7980, Test: 0.8170\n에폭: 072, Loss: 0.3726, Val: 0.7940, Test: 0.8130\n에폭: 073, Loss: 0.3259, Val: 0.8000, Test: 0.8080\n에폭: 074, Loss: 0.3051, Val: 0.8020, Test: 0.8070\n에폭: 075, Loss: 0.3152, Val: 0.7980, Test: 0.8090\n에폭: 076, Loss: 0.3163, Val: 0.7960, Test: 0.8140\n에폭: 077, Loss: 0.3005, Val: 0.7900, Test: 0.8140\n에폭: 078, Loss: 0.3089, Val: 0.7900, Test: 0.8180\n에폭: 079, Loss: 0.3017, Val: 0.7920, Test: 0.8150\n에폭: 080, Loss: 0.2835, Val: 0.7880, Test: 0.8190\n에폭: 081, Loss: 0.2895, Val: 0.7940, Test: 0.8170\n에폭: 082, Loss: 0.2775, Val: 0.7940, Test: 0.8120\n에폭: 083, Loss: 0.2926, Val: 0.7960, Test: 0.8110\n에폭: 084, Loss: 0.2832, Val: 0.7940, Test: 0.8070\n에폭: 085, Loss: 0.2879, Val: 0.7900, Test: 0.8060\n에폭: 086, Loss: 0.2579, Val: 0.7940, Test: 0.8070\n에폭: 087, Loss: 0.2768, Val: 0.7880, Test: 0.8070\n에폭: 088, Loss: 0.2832, Val: 0.7920, Test: 0.8060\n에폭: 089, Loss: 0.2625, Val: 0.7940, Test: 0.8090\n에폭: 090, Loss: 0.2670, Val: 0.7920, Test: 0.8140\n에폭: 091, Loss: 0.2810, Val: 0.7920, Test: 0.8110\n에폭: 092, Loss: 0.2622, Val: 0.7920, Test: 0.8140\n에폭: 093, Loss: 0.2512, Val: 0.7920, Test: 0.8130\n에폭: 094, Loss: 0.2469, Val: 0.7920, Test: 0.8130\n에폭: 095, Loss: 0.2359, Val: 0.7920, Test: 0.8110\n에폭: 096, Loss: 0.2657, Val: 0.7900, Test: 0.8090\n에폭: 097, Loss: 0.2554, Val: 0.7900, Test: 0.8090\n에폭: 098, Loss: 0.2496, Val: 0.7920, Test: 0.8080\n에폭: 099, Loss: 0.2493, Val: 0.7960, Test: 0.8100\n에폭: 100, Loss: 0.2593, Val: 0.7960, Test: 0.8130\n\n\n\ntest_acc = test(data.test_mask)\ntest_acc\n\n0.813\n\n\n진짜 마지막\n\n\n\n\nmodel = GCN(hidden_channels=128)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\ndef train():\n      model.train()\n      optimizr.zero_grad()  # Clear gradients.\n      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n      loss = loss_fn(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n      loss.backward()  # Derive gradients.\n      optimizr.step()  # Update parameters based on gradients.\n      return loss\n\ndef test(mask):\n      model.eval()\n      out = model(data.x, data.edge_index)\n      pred = out.argmax(dim=1)  # Use the class with highest probability.\n      correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n      acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n      return acc\n\n\nfor epoch in range(1, 101):\n    loss = train()\n    val_acc = test(data.val_mask)\n    test_acc = test(data.test_mask)\n    print(f'에폭: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n\n에폭: 001, Loss: 1.9459, Val: 0.2920, Test: 0.3330\n에폭: 002, Loss: 1.9297, Val: 0.2880, Test: 0.3140\n에폭: 003, Loss: 1.9134, Val: 0.3860, Test: 0.3930\n에폭: 004, Loss: 1.8888, Val: 0.4760, Test: 0.4990\n에폭: 005, Loss: 1.8626, Val: 0.5580, Test: 0.5820\n에폭: 006, Loss: 1.8336, Val: 0.6280, Test: 0.6420\n에폭: 007, Loss: 1.7979, Val: 0.6580, Test: 0.6730\n에폭: 008, Loss: 1.7657, Val: 0.6700, Test: 0.6910\n에폭: 009, Loss: 1.7229, Val: 0.6840, Test: 0.7180\n에폭: 010, Loss: 1.6762, Val: 0.7000, Test: 0.7250\n에폭: 011, Loss: 1.6376, Val: 0.7080, Test: 0.7370\n에폭: 012, Loss: 1.5870, Val: 0.7300, Test: 0.7650\n에폭: 013, Loss: 1.5326, Val: 0.7380, Test: 0.7740\n에폭: 014, Loss: 1.4731, Val: 0.7520, Test: 0.7770\n에폭: 015, Loss: 1.4370, Val: 0.7560, Test: 0.7840\n에폭: 016, Loss: 1.3767, Val: 0.7660, Test: 0.7910\n에폭: 017, Loss: 1.3069, Val: 0.7800, Test: 0.7910\n에폭: 018, Loss: 1.2643, Val: 0.7820, Test: 0.8020\n에폭: 019, Loss: 1.1892, Val: 0.7820, Test: 0.8040\n에폭: 020, Loss: 1.1427, Val: 0.7860, Test: 0.8080\n에폭: 021, Loss: 1.0830, Val: 0.7840, Test: 0.8090\n에폭: 022, Loss: 1.0314, Val: 0.7840, Test: 0.8080\n에폭: 023, Loss: 0.9648, Val: 0.7840, Test: 0.8100\n에폭: 024, Loss: 0.9281, Val: 0.7840, Test: 0.8110\n에폭: 025, Loss: 0.8805, Val: 0.7880, Test: 0.8120\n에폭: 026, Loss: 0.8167, Val: 0.7940, Test: 0.8150\n에폭: 027, Loss: 0.8019, Val: 0.7940, Test: 0.8140\n에폭: 028, Loss: 0.7399, Val: 0.7940, Test: 0.8160\n에폭: 029, Loss: 0.7001, Val: 0.7940, Test: 0.8180\n에폭: 030, Loss: 0.6684, Val: 0.7980, Test: 0.8230\n에폭: 031, Loss: 0.6249, Val: 0.8020, Test: 0.8230\n에폭: 032, Loss: 0.5802, Val: 0.8000, Test: 0.8220\n에폭: 033, Loss: 0.5604, Val: 0.8020, Test: 0.8250\n에폭: 034, Loss: 0.5569, Val: 0.8000, Test: 0.8280\n에폭: 035, Loss: 0.4827, Val: 0.7980, Test: 0.8270\n에폭: 036, Loss: 0.4973, Val: 0.7960, Test: 0.8250\n에폭: 037, Loss: 0.4821, Val: 0.7980, Test: 0.8280\n에폭: 038, Loss: 0.4444, Val: 0.7960, Test: 0.8290\n에폭: 039, Loss: 0.4423, Val: 0.7940, Test: 0.8280\n에폭: 040, Loss: 0.4391, Val: 0.7940, Test: 0.8220\n에폭: 041, Loss: 0.4209, Val: 0.7940, Test: 0.8200\n에폭: 042, Loss: 0.4060, Val: 0.7920, Test: 0.8210\n에폭: 043, Loss: 0.3860, Val: 0.7940, Test: 0.8210\n에폭: 044, Loss: 0.3712, Val: 0.7900, Test: 0.8230\n에폭: 045, Loss: 0.3680, Val: 0.7920, Test: 0.8240\n에폭: 046, Loss: 0.3541, Val: 0.7940, Test: 0.8200\n에폭: 047, Loss: 0.3426, Val: 0.7960, Test: 0.8220\n에폭: 048, Loss: 0.3309, Val: 0.7940, Test: 0.8190\n에폭: 049, Loss: 0.3434, Val: 0.7920, Test: 0.8230\n에폭: 050, Loss: 0.3195, Val: 0.7880, Test: 0.8190\n에폭: 051, Loss: 0.3153, Val: 0.7900, Test: 0.8220\n에폭: 052, Loss: 0.3199, Val: 0.7920, Test: 0.8230\n에폭: 053, Loss: 0.3043, Val: 0.7920, Test: 0.8210\n에폭: 054, Loss: 0.3003, Val: 0.7960, Test: 0.8170\n에폭: 055, Loss: 0.3075, Val: 0.7940, Test: 0.8160\n에폭: 056, Loss: 0.2846, Val: 0.7940, Test: 0.8160\n에폭: 057, Loss: 0.2740, Val: 0.7940, Test: 0.8150\n에폭: 058, Loss: 0.2864, Val: 0.7980, Test: 0.8100\n에폭: 059, Loss: 0.2695, Val: 0.7960, Test: 0.8110\n에폭: 060, Loss: 0.2758, Val: 0.7960, Test: 0.8130\n에폭: 061, Loss: 0.2689, Val: 0.7920, Test: 0.8110\n에폭: 062, Loss: 0.2551, Val: 0.7940, Test: 0.8100\n에폭: 063, Loss: 0.2599, Val: 0.7940, Test: 0.8040\n에폭: 064, Loss: 0.2571, Val: 0.7940, Test: 0.8030\n에폭: 065, Loss: 0.2597, Val: 0.7880, Test: 0.8010\n에폭: 066, Loss: 0.2536, Val: 0.7900, Test: 0.8000\n에폭: 067, Loss: 0.2444, Val: 0.8000, Test: 0.8070\n에폭: 068, Loss: 0.2524, Val: 0.7940, Test: 0.8080\n에폭: 069, Loss: 0.2539, Val: 0.7940, Test: 0.8090\n에폭: 070, Loss: 0.2463, Val: 0.7900, Test: 0.8130\n에폭: 071, Loss: 0.2359, Val: 0.7940, Test: 0.8080\n에폭: 072, Loss: 0.2504, Val: 0.7960, Test: 0.8020\n에폭: 073, Loss: 0.2226, Val: 0.7960, Test: 0.7970\n에폭: 074, Loss: 0.2196, Val: 0.7980, Test: 0.8000\n에폭: 075, Loss: 0.2296, Val: 0.8020, Test: 0.8010\n에폭: 076, Loss: 0.2369, Val: 0.8020, Test: 0.8020\n에폭: 077, Loss: 0.2375, Val: 0.7980, Test: 0.8070\n에폭: 078, Loss: 0.2348, Val: 0.7940, Test: 0.8030\n에폭: 079, Loss: 0.2251, Val: 0.7860, Test: 0.8090\n에폭: 080, Loss: 0.2125, Val: 0.7840, Test: 0.8070\n에폭: 081, Loss: 0.2132, Val: 0.7900, Test: 0.8050\n에폭: 082, Loss: 0.2095, Val: 0.7940, Test: 0.8060\n에폭: 083, Loss: 0.2157, Val: 0.7940, Test: 0.8060\n에폭: 084, Loss: 0.2067, Val: 0.7960, Test: 0.8040\n에폭: 085, Loss: 0.2076, Val: 0.7980, Test: 0.8050\n에폭: 086, Loss: 0.2017, Val: 0.7980, Test: 0.8050\n에폭: 087, Loss: 0.2083, Val: 0.8000, Test: 0.8050\n에폭: 088, Loss: 0.1889, Val: 0.8000, Test: 0.8070\n에폭: 089, Loss: 0.2043, Val: 0.7960, Test: 0.8070\n에폭: 090, Loss: 0.2090, Val: 0.7920, Test: 0.8080\n에폭: 091, Loss: 0.1975, Val: 0.7940, Test: 0.8030\n에폭: 092, Loss: 0.1983, Val: 0.7920, Test: 0.8020\n에폭: 093, Loss: 0.2047, Val: 0.7900, Test: 0.8080\n에폭: 094, Loss: 0.2028, Val: 0.7940, Test: 0.8040\n에폭: 095, Loss: 0.1916, Val: 0.7940, Test: 0.8050\n에폭: 096, Loss: 0.1996, Val: 0.7960, Test: 0.8060\n에폭: 097, Loss: 0.1867, Val: 0.7920, Test: 0.8030\n에폭: 098, Loss: 0.1803, Val: 0.7960, Test: 0.8030\n에폭: 099, Loss: 0.1878, Val: 0.7960, Test: 0.8000\n에폭: 100, Loss: 0.1855, Val: 0.7960, Test: 0.8020\n\n\n\ntest_acc = test(data.test_mask)\ntest_acc\n\n0.802\n\n\n실패: hidden channels=16일때가 제일 좋았다..\n\n\n\n\n\n\n\n\nfrom torch_geometric.nn import GCNConv\n\n\nclass GCN(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        ## 우리가 사용할 레이어 정의\n        torch.manual_seed(1234567)\n        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, 32)\n        self.conv3 = GCNConv(32, dataset.num_classes)\n        ## 레이어 정의 끝!\n        \n    def forward(self, x, edge_index):\n        ## yhat을 어떻게 구할것인지 정의\n        x = self.conv1(x, edge_index)\n        x = x.relu()\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.conv2(x, edge_index)\n        x = x.relu()\n        x = F.dropout(x, p = 0.5, training=self.training)\n        x = self.conv3(x, edge_index)\n        ## 정의 끝!\n        return x\n\nmodel = GCN(hidden_channels=16)\nprint(model)\n\nGCN(\n  (conv1): GCNConv(1433, 16)\n  (conv2): GCNConv(16, 32)\n  (conv3): GCNConv(32, 7)\n)\n\n\n\nmodel = GCN(hidden_channels=16)  ## 다시 처음처럼\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\ndef train():\n      model.train()\n      optimizr.zero_grad()  # Clear gradients.\n      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n      loss = loss_fn(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n      loss.backward()  # Derive gradients.\n      optimizr.step()  # Update parameters based on gradients.\n      return loss\n\ndef test(mask):\n      model.eval()\n      out = model(data.x, data.edge_index)\n      pred = out.argmax(dim=1)  # Use the class with highest probability.\n      correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n      acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n      return acc\n\n\nfor epoch in range(1, 101):\n    loss = train()\n    val_acc = test(data.val_mask)\n    test_acc = test(data.test_mask)\n    print(f'에폭: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n\n에폭: 001, Loss: 1.9463, Val: 0.0600, Test: 0.0680\n에폭: 002, Loss: 1.9436, Val: 0.0960, Test: 0.1230\n에폭: 003, Loss: 1.9410, Val: 0.1840, Test: 0.1940\n에폭: 004, Loss: 1.9393, Val: 0.1920, Test: 0.2000\n에폭: 005, Loss: 1.9353, Val: 0.2100, Test: 0.2140\n에폭: 006, Loss: 1.9314, Val: 0.2380, Test: 0.2490\n에폭: 007, Loss: 1.9273, Val: 0.2720, Test: 0.2650\n에폭: 008, Loss: 1.9238, Val: 0.2940, Test: 0.2740\n에폭: 009, Loss: 1.9072, Val: 0.3440, Test: 0.3270\n에폭: 010, Loss: 1.9020, Val: 0.4120, Test: 0.4070\n에폭: 011, Loss: 1.8989, Val: 0.4620, Test: 0.4510\n에폭: 012, Loss: 1.8787, Val: 0.5180, Test: 0.5020\n에폭: 013, Loss: 1.8766, Val: 0.5260, Test: 0.5140\n에폭: 014, Loss: 1.8677, Val: 0.4820, Test: 0.4820\n에폭: 015, Loss: 1.8441, Val: 0.4420, Test: 0.4530\n에폭: 016, Loss: 1.8193, Val: 0.4100, Test: 0.4130\n에폭: 017, Loss: 1.8285, Val: 0.4140, Test: 0.4190\n에폭: 018, Loss: 1.7950, Val: 0.4480, Test: 0.4840\n에폭: 019, Loss: 1.7566, Val: 0.5000, Test: 0.5160\n에폭: 020, Loss: 1.7496, Val: 0.5560, Test: 0.5420\n에폭: 021, Loss: 1.7091, Val: 0.5600, Test: 0.5580\n에폭: 022, Loss: 1.6968, Val: 0.5760, Test: 0.5710\n에폭: 023, Loss: 1.6870, Val: 0.5600, Test: 0.5620\n에폭: 024, Loss: 1.6368, Val: 0.5660, Test: 0.5620\n에폭: 025, Loss: 1.6025, Val: 0.5720, Test: 0.5690\n에폭: 026, Loss: 1.5775, Val: 0.5700, Test: 0.5680\n에폭: 027, Loss: 1.5343, Val: 0.5720, Test: 0.5700\n에폭: 028, Loss: 1.4857, Val: 0.6200, Test: 0.5940\n에폭: 029, Loss: 1.4279, Val: 0.6340, Test: 0.6280\n에폭: 030, Loss: 1.4115, Val: 0.6720, Test: 0.6680\n에폭: 031, Loss: 1.3927, Val: 0.7060, Test: 0.7100\n에폭: 032, Loss: 1.3441, Val: 0.7160, Test: 0.7300\n에폭: 033, Loss: 1.3032, Val: 0.7220, Test: 0.7410\n에폭: 034, Loss: 1.2482, Val: 0.7320, Test: 0.7390\n에폭: 035, Loss: 1.1926, Val: 0.7320, Test: 0.7280\n에폭: 036, Loss: 1.1531, Val: 0.7400, Test: 0.7300\n에폭: 037, Loss: 1.1780, Val: 0.7440, Test: 0.7370\n에폭: 038, Loss: 1.0796, Val: 0.7520, Test: 0.7440\n에폭: 039, Loss: 1.0631, Val: 0.7540, Test: 0.7510\n에폭: 040, Loss: 0.9750, Val: 0.7540, Test: 0.7520\n에폭: 041, Loss: 0.9219, Val: 0.7500, Test: 0.7530\n에폭: 042, Loss: 0.9419, Val: 0.7640, Test: 0.7520\n에폭: 043, Loss: 0.8603, Val: 0.7680, Test: 0.7540\n에폭: 044, Loss: 0.8931, Val: 0.7640, Test: 0.7500\n에폭: 045, Loss: 0.7922, Val: 0.7660, Test: 0.7490\n에폭: 046, Loss: 0.8802, Val: 0.7740, Test: 0.7590\n에폭: 047, Loss: 0.8179, Val: 0.7500, Test: 0.7700\n에폭: 048, Loss: 0.7274, Val: 0.7340, Test: 0.7650\n에폭: 049, Loss: 0.7752, Val: 0.7460, Test: 0.7660\n에폭: 050, Loss: 0.6349, Val: 0.7700, Test: 0.7740\n에폭: 051, Loss: 0.6551, Val: 0.7640, Test: 0.7660\n에폭: 052, Loss: 0.7158, Val: 0.7560, Test: 0.7620\n에폭: 053, Loss: 0.5738, Val: 0.7500, Test: 0.7640\n에폭: 054, Loss: 0.5982, Val: 0.7520, Test: 0.7670\n에폭: 055, Loss: 0.5448, Val: 0.7620, Test: 0.7680\n에폭: 056, Loss: 0.5286, Val: 0.7600, Test: 0.7630\n에폭: 057, Loss: 0.5853, Val: 0.7560, Test: 0.7600\n에폭: 058, Loss: 0.5214, Val: 0.7560, Test: 0.7590\n에폭: 059, Loss: 0.5056, Val: 0.7620, Test: 0.7560\n에폭: 060, Loss: 0.4689, Val: 0.7620, Test: 0.7680\n에폭: 061, Loss: 0.5076, Val: 0.7600, Test: 0.7740\n에폭: 062, Loss: 0.4237, Val: 0.7580, Test: 0.7780\n에폭: 063, Loss: 0.4444, Val: 0.7540, Test: 0.7780\n에폭: 064, Loss: 0.4448, Val: 0.7620, Test: 0.7800\n에폭: 065, Loss: 0.4126, Val: 0.7640, Test: 0.7730\n에폭: 066, Loss: 0.4183, Val: 0.7620, Test: 0.7660\n에폭: 067, Loss: 0.3891, Val: 0.7560, Test: 0.7550\n에폭: 068, Loss: 0.3522, Val: 0.7480, Test: 0.7500\n에폭: 069, Loss: 0.3471, Val: 0.7520, Test: 0.7510\n에폭: 070, Loss: 0.4018, Val: 0.7440, Test: 0.7540\n에폭: 071, Loss: 0.3704, Val: 0.7480, Test: 0.7570\n에폭: 072, Loss: 0.3627, Val: 0.7540, Test: 0.7580\n에폭: 073, Loss: 0.3264, Val: 0.7440, Test: 0.7660\n에폭: 074, Loss: 0.3125, Val: 0.7580, Test: 0.7730\n에폭: 075, Loss: 0.3847, Val: 0.7580, Test: 0.7770\n에폭: 076, Loss: 0.3563, Val: 0.7640, Test: 0.7810\n에폭: 077, Loss: 0.3036, Val: 0.7560, Test: 0.7780\n에폭: 078, Loss: 0.3413, Val: 0.7560, Test: 0.7770\n에폭: 079, Loss: 0.2660, Val: 0.7560, Test: 0.7700\n에폭: 080, Loss: 0.2901, Val: 0.7520, Test: 0.7610\n에폭: 081, Loss: 0.3114, Val: 0.7540, Test: 0.7580\n에폭: 082, Loss: 0.2800, Val: 0.7560, Test: 0.7710\n에폭: 083, Loss: 0.3129, Val: 0.7520, Test: 0.7750\n에폭: 084, Loss: 0.2437, Val: 0.7540, Test: 0.7770\n에폭: 085, Loss: 0.2357, Val: 0.7580, Test: 0.7820\n에폭: 086, Loss: 0.2883, Val: 0.7620, Test: 0.7830\n에폭: 087, Loss: 0.2879, Val: 0.7600, Test: 0.7810\n에폭: 088, Loss: 0.2974, Val: 0.7540, Test: 0.7800\n에폭: 089, Loss: 0.2173, Val: 0.7560, Test: 0.7780\n에폭: 090, Loss: 0.3087, Val: 0.7620, Test: 0.7800\n에폭: 091, Loss: 0.2438, Val: 0.7560, Test: 0.7790\n에폭: 092, Loss: 0.2548, Val: 0.7600, Test: 0.7790\n에폭: 093, Loss: 0.2634, Val: 0.7560, Test: 0.7780\n에폭: 094, Loss: 0.2814, Val: 0.7580, Test: 0.7780\n에폭: 095, Loss: 0.2191, Val: 0.7600, Test: 0.7790\n에폭: 096, Loss: 0.2393, Val: 0.7740, Test: 0.7770\n에폭: 097, Loss: 0.2537, Val: 0.7680, Test: 0.7780\n에폭: 098, Loss: 0.2113, Val: 0.7660, Test: 0.7810\n에폭: 099, Loss: 0.2402, Val: 0.7700, Test: 0.7790\n에폭: 100, Loss: 0.2013, Val: 0.7660, Test: 0.7770\n\n\n\ntest_acc = test(data.test_mask)\ntest_acc\n\n0.777\n\n\n층을 늘려봐도 test accuracy가 더 떨어진다.\n\n\n\nGCNConv 인스턴스를 attention을 이용한 GATConv로 바꿔보자.\n\nfrom torch_geometric.nn import GATConv\n\n\nclass GAT(torch.nn.Module):\n    def __init__(self, hidden_channels, heads):\n        super().__init__()\n        torch.manual_seed(1234567)\n        self.conv1 = GATConv(...)  # TODO\n        self.conv2 = GATConv(...)  # TODO\n\n    def forward(self, x, edge_index):\n        x = F.dropout(x, p=0.6, training=self.training)\n        x = self.conv1(x, edge_index)\n        x = F.elu(x)\n        x = F.dropout(x, p=0.6, training=self.training)\n        x = self.conv2(x, edge_index)\n        return x\n\n\n관련논문3\n\n\n\n\nIn this chapter, you have seen how to apply GNNs to real-world problems, and, in particular, how they can effectively be used for boosting a model’s performance. In the next section, we will look into how GNNs can be used for the task of graph classification."
  },
  {
    "objectID": "posts/GNN/2023-03-04-gnn2_guebin.html",
    "href": "posts/GNN/2023-03-04-gnn2_guebin.html",
    "title": "2 GNN tuto2",
    "section": "",
    "text": "Node calssification with GNN (Cora dataset)\n\nThis tutorial will teach you how to apply Graph Neural Networks (GNNs) to the task of node classification. Here, we are given the ground-truth labels of only a small subset of nodes, and want to infer the labels for all the remaining nodes (transductive learning).\n\n\nTo demonstrate, we make use of the Cora dataset, which is a citation network where nodes represent documents. Each node is described by a 1433-dimensional bag-of-words feature vector. Two documents are connected if there exists a citation link between them. The task is to infer the category of each document (7 in total).\nThis dataset was first introduced by Yang et al. (2016)1 as one of the datasets of the Planetoid benchmark suite. We again can make use PyTorch Geometric for an easy access to this dataset via torch_geometric.datasets.Planetoid2:\n\nimport os\nimport torch\n\n# helper function for visualization\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\n\nimport torch\nfrom torch.nn import Linear\nimport torch.nn.functional as F\n\n/home/hankang07/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\ndef visualize(h, color):\n    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n\n    plt.figure(figsize=(10,10))\n    plt.xticks([])\n    plt.yticks([])\n\n    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n    plt.show()\n\n\nfrom torch_geometric.datasets import Planetoid\nfrom torch_geometric.transforms import NormalizeFeatures\n\ndataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n\nprint()\nprint(f'Dataset: {dataset}:')\nprint('======================')\nprint(f'Number of graphs: {len(dataset)}')\nprint(f'Number of features: {dataset.num_features}')\nprint(f'Number of classes: {dataset.num_classes}')\n\n\nDataset: Cora():\n======================\nNumber of graphs: 1\nNumber of features: 1433\nNumber of classes: 7\n\n\n\ndata = dataset[0]  # Get the first graph object.\nprint()\nprint(data)\nprint('===========================================================================================================')\n\n\nData(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n===========================================================================================================\n\n\n\n# Gather some statistics about the graph.\nprint(f'Number of nodes: {data.num_nodes}')\nprint(f'Number of edges: {data.num_edges}')\nprint(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\nprint(f'Number of training nodes: {data.train_mask.sum()}')\nprint(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\nprint(f'Has isolated nodes: {data.has_isolated_nodes()}')\nprint(f'Has self-loops: {data.has_self_loops()}')\nprint(f'Is undirected: {data.is_undirected()}')\n\nNumber of nodes: 2708\nNumber of edges: 10556\nAverage node degree: 3.90\nNumber of training nodes: 140\nTraining node label rate: 0.05\nHas isolated nodes: False\nHas self-loops: False\nIs undirected: True\n\n\n\ndata.y.unique()\n\ntensor([0, 1, 2, 3, 4, 5, 6])\n\n\n\n각 클래스 당 20개씩 정답을 알고 있음.\ntraining node label rate = \\(5\\%\\) (학습을 위한 노드는 전체의 5% 밖에 안된다..)\n\nthis network is undirected, and that there exists no isolated nodes (each document has at least one citation).\n\n\n\nn theory, we should be able to infer the category of a document solely based on its content, i.e. its bag-of-words feature representation, without taking any relational information into account.\nLet’s verify that by constructing a simple MLP that solely operates on input node features (using shared weights across all nodes):\n\nimport torch\nfrom torch.nn import Linear\nimport torch.nn.functional as F\n\n\nclass MLP(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        ## 우리가 사용할 레이어 정의\n        torch.manual_seed(12345)\n        self.lin1 = Linear(dataset.num_features, hidden_channels)\n        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n        ## 레이어 정의 끝!\n        \n    def forward(self, x):\n        ## yhat을 어떻게 구할것인지 정의\n        x = self.lin1(x)\n        x = x.relu()\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.lin2(x)\n        ## 정의 끝!\n        return x\n\nmodel = MLP(hidden_channels=16)\nprint(model)\n\nMLP(\n  (lin1): Linear(in_features=1433, out_features=16, bias=True)\n  (lin2): Linear(in_features=16, out_features=7, bias=True)\n)\n\n\n\nmodel = MLP(hidden_channels=16)\nloss_fn = torch.nn.CrossEntropyLoss()  # Define loss criterion.\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Define optimizer.\n\n\ndata.test_mask.sum()\n\ntensor(1000)\n\n\n\ndef train():\n      model.train()\n      optimizr.zero_grad()  # Clear gradients. <-- 앞에 나와도 상관없는건가??\n      out = model(data.x)  # Perform a single forward pass.\n      loss = loss_fn(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n      loss.backward()  # Derive gradients.\n      optimizr.step()  # Update parameters based on gradients.\n      return loss\n\ndef test():\n      model.eval()\n      out = model(data.x)\n      pred = out.argmax(dim=1)  # Use the class with highest probability.\n      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n      return test_acc\n\nfor epoch in range(1, 201):\n    loss = train()\n    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n\nEpoch: 001, Loss: 1.9615\nEpoch: 002, Loss: 1.9557\nEpoch: 003, Loss: 1.9505\nEpoch: 004, Loss: 1.9423\nEpoch: 005, Loss: 1.9327\nEpoch: 006, Loss: 1.9279\nEpoch: 007, Loss: 1.9144\nEpoch: 008, Loss: 1.9087\nEpoch: 009, Loss: 1.9023\nEpoch: 010, Loss: 1.8893\nEpoch: 011, Loss: 1.8776\nEpoch: 012, Loss: 1.8594\nEpoch: 013, Loss: 1.8457\nEpoch: 014, Loss: 1.8365\nEpoch: 015, Loss: 1.8280\nEpoch: 016, Loss: 1.7965\nEpoch: 017, Loss: 1.7984\nEpoch: 018, Loss: 1.7832\nEpoch: 019, Loss: 1.7495\nEpoch: 020, Loss: 1.7441\nEpoch: 021, Loss: 1.7188\nEpoch: 022, Loss: 1.7124\nEpoch: 023, Loss: 1.6785\nEpoch: 024, Loss: 1.6660\nEpoch: 025, Loss: 1.6119\nEpoch: 026, Loss: 1.6236\nEpoch: 027, Loss: 1.5827\nEpoch: 028, Loss: 1.5784\nEpoch: 029, Loss: 1.5524\nEpoch: 030, Loss: 1.5020\nEpoch: 031, Loss: 1.5065\nEpoch: 032, Loss: 1.4742\nEpoch: 033, Loss: 1.4581\nEpoch: 034, Loss: 1.4246\nEpoch: 035, Loss: 1.4131\nEpoch: 036, Loss: 1.4112\nEpoch: 037, Loss: 1.3923\nEpoch: 038, Loss: 1.3055\nEpoch: 039, Loss: 1.2982\nEpoch: 040, Loss: 1.2543\nEpoch: 041, Loss: 1.2244\nEpoch: 042, Loss: 1.2331\nEpoch: 043, Loss: 1.1984\nEpoch: 044, Loss: 1.1796\nEpoch: 045, Loss: 1.1093\nEpoch: 046, Loss: 1.1284\nEpoch: 047, Loss: 1.1229\nEpoch: 048, Loss: 1.0383\nEpoch: 049, Loss: 1.0439\nEpoch: 050, Loss: 1.0563\nEpoch: 051, Loss: 0.9893\nEpoch: 052, Loss: 1.0508\nEpoch: 053, Loss: 0.9343\nEpoch: 054, Loss: 0.9639\nEpoch: 055, Loss: 0.8929\nEpoch: 056, Loss: 0.8705\nEpoch: 057, Loss: 0.9176\nEpoch: 058, Loss: 0.9239\nEpoch: 059, Loss: 0.8641\nEpoch: 060, Loss: 0.8578\nEpoch: 061, Loss: 0.7908\nEpoch: 062, Loss: 0.7856\nEpoch: 063, Loss: 0.7683\nEpoch: 064, Loss: 0.7816\nEpoch: 065, Loss: 0.7356\nEpoch: 066, Loss: 0.6951\nEpoch: 067, Loss: 0.7300\nEpoch: 068, Loss: 0.6939\nEpoch: 069, Loss: 0.7550\nEpoch: 070, Loss: 0.6864\nEpoch: 071, Loss: 0.7094\nEpoch: 072, Loss: 0.7238\nEpoch: 073, Loss: 0.7150\nEpoch: 074, Loss: 0.6191\nEpoch: 075, Loss: 0.6770\nEpoch: 076, Loss: 0.6487\nEpoch: 077, Loss: 0.6258\nEpoch: 078, Loss: 0.5821\nEpoch: 079, Loss: 0.5637\nEpoch: 080, Loss: 0.6368\nEpoch: 081, Loss: 0.6333\nEpoch: 082, Loss: 0.6434\nEpoch: 083, Loss: 0.5974\nEpoch: 084, Loss: 0.6176\nEpoch: 085, Loss: 0.5972\nEpoch: 086, Loss: 0.4690\nEpoch: 087, Loss: 0.6362\nEpoch: 088, Loss: 0.6118\nEpoch: 089, Loss: 0.5248\nEpoch: 090, Loss: 0.5520\nEpoch: 091, Loss: 0.6130\nEpoch: 092, Loss: 0.5361\nEpoch: 093, Loss: 0.5594\nEpoch: 094, Loss: 0.5049\nEpoch: 095, Loss: 0.5043\nEpoch: 096, Loss: 0.5235\nEpoch: 097, Loss: 0.5451\nEpoch: 098, Loss: 0.5329\nEpoch: 099, Loss: 0.5008\nEpoch: 100, Loss: 0.5350\nEpoch: 101, Loss: 0.5343\nEpoch: 102, Loss: 0.5138\nEpoch: 103, Loss: 0.5377\nEpoch: 104, Loss: 0.5353\nEpoch: 105, Loss: 0.5176\nEpoch: 106, Loss: 0.5229\nEpoch: 107, Loss: 0.4558\nEpoch: 108, Loss: 0.4883\nEpoch: 109, Loss: 0.4659\nEpoch: 110, Loss: 0.4908\nEpoch: 111, Loss: 0.4966\nEpoch: 112, Loss: 0.4725\nEpoch: 113, Loss: 0.4787\nEpoch: 114, Loss: 0.4390\nEpoch: 115, Loss: 0.4199\nEpoch: 116, Loss: 0.4810\nEpoch: 117, Loss: 0.4484\nEpoch: 118, Loss: 0.5080\nEpoch: 119, Loss: 0.4241\nEpoch: 120, Loss: 0.4745\nEpoch: 121, Loss: 0.4651\nEpoch: 122, Loss: 0.4652\nEpoch: 123, Loss: 0.5580\nEpoch: 124, Loss: 0.4861\nEpoch: 125, Loss: 0.4405\nEpoch: 126, Loss: 0.4292\nEpoch: 127, Loss: 0.4409\nEpoch: 128, Loss: 0.3575\nEpoch: 129, Loss: 0.4468\nEpoch: 130, Loss: 0.4603\nEpoch: 131, Loss: 0.4108\nEpoch: 132, Loss: 0.4601\nEpoch: 133, Loss: 0.4258\nEpoch: 134, Loss: 0.3852\nEpoch: 135, Loss: 0.4028\nEpoch: 136, Loss: 0.4245\nEpoch: 137, Loss: 0.4300\nEpoch: 138, Loss: 0.4693\nEpoch: 139, Loss: 0.4314\nEpoch: 140, Loss: 0.4031\nEpoch: 141, Loss: 0.4290\nEpoch: 142, Loss: 0.4110\nEpoch: 143, Loss: 0.3863\nEpoch: 144, Loss: 0.4215\nEpoch: 145, Loss: 0.4519\nEpoch: 146, Loss: 0.3940\nEpoch: 147, Loss: 0.4429\nEpoch: 148, Loss: 0.3527\nEpoch: 149, Loss: 0.4390\nEpoch: 150, Loss: 0.4212\nEpoch: 151, Loss: 0.4128\nEpoch: 152, Loss: 0.3779\nEpoch: 153, Loss: 0.4801\nEpoch: 154, Loss: 0.4130\nEpoch: 155, Loss: 0.3962\nEpoch: 156, Loss: 0.4262\nEpoch: 157, Loss: 0.4210\nEpoch: 158, Loss: 0.4081\nEpoch: 159, Loss: 0.4066\nEpoch: 160, Loss: 0.3782\nEpoch: 161, Loss: 0.3836\nEpoch: 162, Loss: 0.4172\nEpoch: 163, Loss: 0.3993\nEpoch: 164, Loss: 0.4477\nEpoch: 165, Loss: 0.3714\nEpoch: 166, Loss: 0.3610\nEpoch: 167, Loss: 0.4546\nEpoch: 168, Loss: 0.4387\nEpoch: 169, Loss: 0.3793\nEpoch: 170, Loss: 0.3704\nEpoch: 171, Loss: 0.4286\nEpoch: 172, Loss: 0.4131\nEpoch: 173, Loss: 0.3795\nEpoch: 174, Loss: 0.4230\nEpoch: 175, Loss: 0.4139\nEpoch: 176, Loss: 0.3586\nEpoch: 177, Loss: 0.3588\nEpoch: 178, Loss: 0.3911\nEpoch: 179, Loss: 0.3810\nEpoch: 180, Loss: 0.4203\nEpoch: 181, Loss: 0.3583\nEpoch: 182, Loss: 0.3690\nEpoch: 183, Loss: 0.4025\nEpoch: 184, Loss: 0.3920\nEpoch: 185, Loss: 0.4369\nEpoch: 186, Loss: 0.4317\nEpoch: 187, Loss: 0.4911\nEpoch: 188, Loss: 0.3369\nEpoch: 189, Loss: 0.4945\nEpoch: 190, Loss: 0.3912\nEpoch: 191, Loss: 0.3824\nEpoch: 192, Loss: 0.3479\nEpoch: 193, Loss: 0.3798\nEpoch: 194, Loss: 0.3799\nEpoch: 195, Loss: 0.4015\nEpoch: 196, Loss: 0.3615\nEpoch: 197, Loss: 0.3985\nEpoch: 198, Loss: 0.4664\nEpoch: 199, Loss: 0.3714\nEpoch: 200, Loss: 0.3810\n\n\n\n# unseen labels에 대한 성능\ntest_acc = test()\nprint(f'Test Accuracy: {test_acc:.4f}')\n\nTest Accuracy: 0.5900\n\n\n\n1/7\n\n0.14285714285714285\n\n\n\nMLP \\(\\to\\) \\(59\\%\\) test accuracy (그냥 찍는 것보다는 낫지만 성능이 별로임)\n\n- 문제1 - 심각한 오버피팅때문에 성능이 안좋게 나오는 것. - 그렇다면 왜 오버피팅이 될까? \\(\\to\\) 학습에 사용되는 training 노드수가 너무 작아 모르는 노드에 대해 일반화 하기 어렵다.\n- 문제2 - MLP 모델은 중요한 bias가 반영이 안된다. (인용된 논문은 문서의 카테고리와 관련이 있을 가능성이 매우매우 높지만 이런것들이 반영이 안된다는 점)\nGraph Neural Network를 사용해서 모델 성능을 높일수 있을 것 같다.\n\n\n\nWe can easily convert our MLP to a GNN by swapping the torch.nn.Linear layers with PyG’s GNN operators.\nFollowing-up on the first part of this tutorial, we replace the linear layers by the GCNConv module. To recap, the GCN layer (Kipf et al. (2017)) is defined as\n\\[\n\\mathbf{x}_v^{(\\ell + 1)} = \\mathbf{W}^{(\\ell + 1)} \\sum_{w \\in \\mathcal{N}(v) \\, \\cup \\, \\{ v \\}} \\frac{1}{c_{w,v}} \\cdot \\mathbf{x}_w^{(\\ell)}\n\\]\n\n\\(\\bf{W}^{l+1}\\) : a trainable weight matrix of shape of shape [num_output_features, num_input_features]\n\\(c_{w,v}\\): fixed normalization coefficient for each node.\n\nin contrast, a single Linear layer is defined as\n\\[\\bf{x}_v^{l+1} = \\bf{W}^{l+1}\\bf{x}_v^{l}\\]\nwhich does not make use of neighboring node information.\n\ndataset.num_features, dataset.num_classes\n\n(1433, 7)\n\n\n\nfrom torch_geometric.nn import GCNConv\n\n\nclass GCN(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        ## 우리가 사용할 레이어 정의\n        torch.manual_seed(1234567)\n        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n        ## 레이어 정의 끝!\n        \n    def forward(self, x, edge_index):\n        ## yhat을 어떻게 구할것인지 정의\n        x = self.conv1(x, edge_index)\n        x = x.relu()\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.conv2(x, edge_index)\n        ## 정의 끝!\n        return x\n\nmodel = GCN(hidden_channels=16)\nprint(model)\n\nGCN(\n  (conv1): GCNConv(1433, 16)\n  (conv2): GCNConv(16, 7)\n)\n\n\n\n\nwe make use of TSNE to embed our 7-dimensional node embeddings onto a 2D plane.\n\nmodel = GCN(hidden_channels=16)\nmodel.eval()\n\nout = model(data.x, data.edge_index)\nvisualize(out, color=data.y)\n\n\n\n\nWe certainly can do better by training our model. The training and testing procedure is once again the same, but this time we make use of the node features x and the graph connectivity edge_index as input to our GCN model.\n\nmodel = GCN(hidden_channels=16)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\ndef train():\n      model.train()\n      optimizr.zero_grad()  # Clear gradients.\n      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n      loss = loss_fn(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n      loss.backward()  # Derive gradients.\n      optimizr.step()  # Update parameters based on gradients.\n      return loss\n\ndef test():\n      model.eval()\n      out = model(data.x, data.edge_index)\n      pred = out.argmax(dim=1)  # Use the class with highest probability.\n      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n      return test_acc\n\n\nfor epoch in range(1, 101):\n    loss = train()\n    test_acc = test()\n    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test: {test_acc:.4f}')\n\nEpoch: 001, Loss: 1.9463, Test: 0.2700\nEpoch: 002, Loss: 1.9409, Test: 0.2910\nEpoch: 003, Loss: 1.9343, Test: 0.2910\nEpoch: 004, Loss: 1.9275, Test: 0.3210\nEpoch: 005, Loss: 1.9181, Test: 0.3630\nEpoch: 006, Loss: 1.9086, Test: 0.4120\nEpoch: 007, Loss: 1.9015, Test: 0.4010\nEpoch: 008, Loss: 1.8933, Test: 0.4020\nEpoch: 009, Loss: 1.8808, Test: 0.4180\nEpoch: 010, Loss: 1.8685, Test: 0.4470\nEpoch: 011, Loss: 1.8598, Test: 0.4680\nEpoch: 012, Loss: 1.8482, Test: 0.5180\nEpoch: 013, Loss: 1.8290, Test: 0.5440\nEpoch: 014, Loss: 1.8233, Test: 0.5720\nEpoch: 015, Loss: 1.8057, Test: 0.5910\nEpoch: 016, Loss: 1.7966, Test: 0.6080\nEpoch: 017, Loss: 1.7825, Test: 0.6300\nEpoch: 018, Loss: 1.7617, Test: 0.6450\nEpoch: 019, Loss: 1.7491, Test: 0.6520\nEpoch: 020, Loss: 1.7310, Test: 0.6560\nEpoch: 021, Loss: 1.7147, Test: 0.6570\nEpoch: 022, Loss: 1.7056, Test: 0.6640\nEpoch: 023, Loss: 1.6954, Test: 0.6770\nEpoch: 024, Loss: 1.6697, Test: 0.6950\nEpoch: 025, Loss: 1.6538, Test: 0.7140\nEpoch: 026, Loss: 1.6312, Test: 0.7150\nEpoch: 027, Loss: 1.6161, Test: 0.7170\nEpoch: 028, Loss: 1.5899, Test: 0.7230\nEpoch: 029, Loss: 1.5711, Test: 0.7220\nEpoch: 030, Loss: 1.5576, Test: 0.7210\nEpoch: 031, Loss: 1.5393, Test: 0.7280\nEpoch: 032, Loss: 1.5137, Test: 0.7370\nEpoch: 033, Loss: 1.4948, Test: 0.7380\nEpoch: 034, Loss: 1.4913, Test: 0.7430\nEpoch: 035, Loss: 1.4698, Test: 0.7510\nEpoch: 036, Loss: 1.3998, Test: 0.7570\nEpoch: 037, Loss: 1.4041, Test: 0.7600\nEpoch: 038, Loss: 1.3761, Test: 0.7640\nEpoch: 039, Loss: 1.3631, Test: 0.7700\nEpoch: 040, Loss: 1.3258, Test: 0.7800\nEpoch: 041, Loss: 1.3030, Test: 0.7810\nEpoch: 042, Loss: 1.3119, Test: 0.7760\nEpoch: 043, Loss: 1.2519, Test: 0.7760\nEpoch: 044, Loss: 1.2530, Test: 0.7790\nEpoch: 045, Loss: 1.2492, Test: 0.7800\nEpoch: 046, Loss: 1.2205, Test: 0.7790\nEpoch: 047, Loss: 1.2037, Test: 0.7850\nEpoch: 048, Loss: 1.1571, Test: 0.7900\nEpoch: 049, Loss: 1.1700, Test: 0.7920\nEpoch: 050, Loss: 1.1296, Test: 0.7940\nEpoch: 051, Loss: 1.0860, Test: 0.7930\nEpoch: 052, Loss: 1.1080, Test: 0.7910\nEpoch: 053, Loss: 1.0564, Test: 0.7930\nEpoch: 054, Loss: 1.0157, Test: 0.7930\nEpoch: 055, Loss: 1.0362, Test: 0.7920\nEpoch: 056, Loss: 1.0328, Test: 0.7980\nEpoch: 057, Loss: 1.0058, Test: 0.8000\nEpoch: 058, Loss: 0.9865, Test: 0.7970\nEpoch: 059, Loss: 0.9667, Test: 0.8010\nEpoch: 060, Loss: 0.9741, Test: 0.8000\nEpoch: 061, Loss: 0.9769, Test: 0.8030\nEpoch: 062, Loss: 0.9122, Test: 0.8040\nEpoch: 063, Loss: 0.8993, Test: 0.8050\nEpoch: 064, Loss: 0.8769, Test: 0.8050\nEpoch: 065, Loss: 0.8575, Test: 0.8060\nEpoch: 066, Loss: 0.8897, Test: 0.8030\nEpoch: 067, Loss: 0.8312, Test: 0.8060\nEpoch: 068, Loss: 0.8262, Test: 0.8030\nEpoch: 069, Loss: 0.8511, Test: 0.8070\nEpoch: 070, Loss: 0.7711, Test: 0.8070\nEpoch: 071, Loss: 0.8012, Test: 0.8080\nEpoch: 072, Loss: 0.7529, Test: 0.8080\nEpoch: 073, Loss: 0.7525, Test: 0.8070\nEpoch: 074, Loss: 0.7689, Test: 0.8110\nEpoch: 075, Loss: 0.7553, Test: 0.8140\nEpoch: 076, Loss: 0.7032, Test: 0.8120\nEpoch: 077, Loss: 0.7326, Test: 0.8110\nEpoch: 078, Loss: 0.7122, Test: 0.8120\nEpoch: 079, Loss: 0.7090, Test: 0.8110\nEpoch: 080, Loss: 0.6755, Test: 0.8130\nEpoch: 081, Loss: 0.6666, Test: 0.8070\nEpoch: 082, Loss: 0.6679, Test: 0.8080\nEpoch: 083, Loss: 0.7037, Test: 0.8100\nEpoch: 084, Loss: 0.6752, Test: 0.8070\nEpoch: 085, Loss: 0.6266, Test: 0.8100\nEpoch: 086, Loss: 0.6564, Test: 0.8080\nEpoch: 087, Loss: 0.6266, Test: 0.8090\nEpoch: 088, Loss: 0.6411, Test: 0.8080\nEpoch: 089, Loss: 0.6226, Test: 0.8100\nEpoch: 090, Loss: 0.6535, Test: 0.8130\nEpoch: 091, Loss: 0.6317, Test: 0.8140\nEpoch: 092, Loss: 0.5741, Test: 0.8120\nEpoch: 093, Loss: 0.5572, Test: 0.8140\nEpoch: 094, Loss: 0.5710, Test: 0.8120\nEpoch: 095, Loss: 0.5816, Test: 0.8140\nEpoch: 096, Loss: 0.5745, Test: 0.8140\nEpoch: 097, Loss: 0.5547, Test: 0.8150\nEpoch: 098, Loss: 0.5989, Test: 0.8160\nEpoch: 099, Loss: 0.6021, Test: 0.8160\nEpoch: 100, Loss: 0.5799, Test: 0.8150\n\n\n\ntest_acc = test()\nprint(f'Test Accuracy: {test_acc:.4f}')\n\nTest Accuracy: 0.8150\n\n\n\nGNN \\(\\to 81.5\\%\\) test accuracy!!!\n\nThere it is! By simply swapping the linear layers with GNN layers, we can reach 81.5% of test accuracy!\n\n\n\n\nmodel.eval()\n\nout = model(data.x, data.edge_index)\nvisualize(out, color=data.y)\n\n\n\n\n\n카테고리별로 군집이 어느정도 잘 나눠진 느낌\n\n\n\n\n\n\nmodel = GCN(hidden_channels=64)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\ndef val():\n      model.eval()\n      out = model(data.x, data.edge_index)\n      pred = out.argmax(dim=1)  # Use the class with highest probability.\n      val_correct = pred[data.val_mask] == data.y[data.val_mask]  # Check against ground-truth labels.\n      val_acc = int(val_correct.sum()) / int(data.val_mask.sum())  # Derive ratio of correct predictions.\n      return val_acc\n\n# 임지윤수정\n# def test(mask):\n#       model.eval()\n#       out = model(data.x, data.edge_index)\n#       pred = out.argmax(dim=1)  # Use the class with highest probability.\n#       correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n#       acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n#       return acc\n\n\nfor epoch in range(1, 101):\n    loss = train()\n    val_acc = val()\n    test_acc = test()\n    print(f'에폭: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n\n에폭: 001, Loss: 1.9461, Val: 0.2280, Test: 0.2530\n에폭: 002, Loss: 1.9347, Val: 0.3720, Test: 0.3930\n에폭: 003, Loss: 1.9207, Val: 0.6560, Test: 0.6540\n에폭: 004, Loss: 1.9041, Val: 0.7480, Test: 0.7320\n에폭: 005, Loss: 1.8870, Val: 0.7380, Test: 0.7490\n에폭: 006, Loss: 1.8686, Val: 0.7600, Test: 0.7750\n에폭: 007, Loss: 1.8476, Val: 0.7760, Test: 0.7890\n에폭: 008, Loss: 1.8169, Val: 0.7800, Test: 0.7860\n에폭: 009, Loss: 1.7975, Val: 0.7720, Test: 0.7830\n에폭: 010, Loss: 1.7649, Val: 0.7700, Test: 0.7740\n에폭: 011, Loss: 1.7330, Val: 0.7560, Test: 0.7750\n에폭: 012, Loss: 1.7101, Val: 0.7640, Test: 0.7780\n에폭: 013, Loss: 1.6784, Val: 0.7680, Test: 0.7790\n에폭: 014, Loss: 1.6361, Val: 0.7720, Test: 0.7800\n에폭: 015, Loss: 1.6086, Val: 0.7780, Test: 0.7840\n에폭: 016, Loss: 1.5724, Val: 0.7820, Test: 0.7930\n에폭: 017, Loss: 1.5306, Val: 0.7840, Test: 0.8000\n에폭: 018, Loss: 1.4846, Val: 0.7900, Test: 0.8000\n에폭: 019, Loss: 1.4324, Val: 0.8000, Test: 0.8030\n에폭: 020, Loss: 1.4128, Val: 0.8020, Test: 0.8010\n에폭: 021, Loss: 1.3664, Val: 0.7960, Test: 0.8020\n에폭: 022, Loss: 1.3191, Val: 0.7980, Test: 0.7990\n에폭: 023, Loss: 1.2794, Val: 0.7980, Test: 0.8010\n에폭: 024, Loss: 1.2395, Val: 0.7900, Test: 0.8020\n에폭: 025, Loss: 1.2056, Val: 0.7940, Test: 0.8000\n에폭: 026, Loss: 1.1459, Val: 0.7900, Test: 0.7970\n에폭: 027, Loss: 1.1225, Val: 0.7900, Test: 0.7970\n에폭: 028, Loss: 1.0561, Val: 0.7940, Test: 0.8030\n에폭: 029, Loss: 1.0305, Val: 0.7980, Test: 0.8080\n에폭: 030, Loss: 0.9678, Val: 0.8000, Test: 0.8110\n에폭: 031, Loss: 0.9440, Val: 0.7960, Test: 0.8110\n에폭: 032, Loss: 0.9190, Val: 0.7940, Test: 0.8140\n에폭: 033, Loss: 0.8733, Val: 0.7980, Test: 0.8120\n에폭: 034, Loss: 0.8455, Val: 0.8020, Test: 0.8170\n에폭: 035, Loss: 0.7919, Val: 0.8020, Test: 0.8170\n에폭: 036, Loss: 0.7638, Val: 0.8000, Test: 0.8160\n에폭: 037, Loss: 0.7554, Val: 0.8020, Test: 0.8140\n에폭: 038, Loss: 0.7256, Val: 0.8040, Test: 0.8220\n에폭: 039, Loss: 0.6891, Val: 0.8040, Test: 0.8190\n에폭: 040, Loss: 0.6443, Val: 0.7980, Test: 0.8190\n에폭: 041, Loss: 0.6405, Val: 0.8020, Test: 0.8230\n에폭: 042, Loss: 0.6302, Val: 0.7980, Test: 0.8200\n에폭: 043, Loss: 0.5836, Val: 0.7980, Test: 0.8130\n에폭: 044, Loss: 0.5620, Val: 0.7920, Test: 0.8140\n에폭: 045, Loss: 0.5484, Val: 0.8000, Test: 0.8170\n에폭: 046, Loss: 0.5387, Val: 0.8000, Test: 0.8200\n에폭: 047, Loss: 0.5254, Val: 0.8040, Test: 0.8250\n에폭: 048, Loss: 0.5036, Val: 0.8020, Test: 0.8230\n에폭: 049, Loss: 0.4968, Val: 0.8020, Test: 0.8270\n에폭: 050, Loss: 0.5090, Val: 0.7980, Test: 0.8280\n에폭: 051, Loss: 0.4719, Val: 0.7960, Test: 0.8250\n에폭: 052, Loss: 0.4537, Val: 0.7940, Test: 0.8260\n에폭: 053, Loss: 0.4421, Val: 0.7860, Test: 0.8200\n에폭: 054, Loss: 0.4380, Val: 0.7940, Test: 0.8190\n에폭: 055, Loss: 0.4082, Val: 0.8000, Test: 0.8160\n에폭: 056, Loss: 0.3956, Val: 0.8040, Test: 0.8210\n에폭: 057, Loss: 0.4172, Val: 0.8000, Test: 0.8220\n에폭: 058, Loss: 0.4053, Val: 0.7960, Test: 0.8250\n에폭: 059, Loss: 0.4049, Val: 0.7980, Test: 0.8250\n에폭: 060, Loss: 0.4005, Val: 0.7940, Test: 0.8170\n에폭: 061, Loss: 0.3776, Val: 0.7880, Test: 0.8150\n에폭: 062, Loss: 0.3655, Val: 0.7840, Test: 0.8100\n에폭: 063, Loss: 0.3504, Val: 0.7840, Test: 0.8090\n에폭: 064, Loss: 0.3473, Val: 0.7880, Test: 0.8110\n에폭: 065, Loss: 0.3726, Val: 0.7880, Test: 0.8140\n에폭: 066, Loss: 0.3532, Val: 0.7860, Test: 0.8150\n에폭: 067, Loss: 0.3520, Val: 0.7900, Test: 0.8200\n에폭: 068, Loss: 0.3481, Val: 0.7900, Test: 0.8210\n에폭: 069, Loss: 0.3543, Val: 0.7940, Test: 0.8180\n에폭: 070, Loss: 0.3482, Val: 0.7920, Test: 0.8230\n에폭: 071, Loss: 0.3228, Val: 0.7980, Test: 0.8170\n에폭: 072, Loss: 0.3726, Val: 0.7940, Test: 0.8130\n에폭: 073, Loss: 0.3259, Val: 0.8000, Test: 0.8080\n에폭: 074, Loss: 0.3051, Val: 0.8020, Test: 0.8070\n에폭: 075, Loss: 0.3152, Val: 0.7980, Test: 0.8090\n에폭: 076, Loss: 0.3163, Val: 0.7960, Test: 0.8140\n에폭: 077, Loss: 0.3005, Val: 0.7900, Test: 0.8140\n에폭: 078, Loss: 0.3089, Val: 0.7900, Test: 0.8180\n에폭: 079, Loss: 0.3017, Val: 0.7920, Test: 0.8150\n에폭: 080, Loss: 0.2835, Val: 0.7880, Test: 0.8190\n에폭: 081, Loss: 0.2895, Val: 0.7940, Test: 0.8170\n에폭: 082, Loss: 0.2775, Val: 0.7940, Test: 0.8120\n에폭: 083, Loss: 0.2926, Val: 0.7960, Test: 0.8110\n에폭: 084, Loss: 0.2832, Val: 0.7940, Test: 0.8070\n에폭: 085, Loss: 0.2879, Val: 0.7900, Test: 0.8060\n에폭: 086, Loss: 0.2579, Val: 0.7940, Test: 0.8070\n에폭: 087, Loss: 0.2768, Val: 0.7880, Test: 0.8070\n에폭: 088, Loss: 0.2832, Val: 0.7920, Test: 0.8060\n에폭: 089, Loss: 0.2625, Val: 0.7940, Test: 0.8090\n에폭: 090, Loss: 0.2670, Val: 0.7920, Test: 0.8140\n에폭: 091, Loss: 0.2810, Val: 0.7920, Test: 0.8110\n에폭: 092, Loss: 0.2622, Val: 0.7920, Test: 0.8140\n에폭: 093, Loss: 0.2512, Val: 0.7920, Test: 0.8130\n에폭: 094, Loss: 0.2469, Val: 0.7920, Test: 0.8130\n에폭: 095, Loss: 0.2359, Val: 0.7920, Test: 0.8110\n에폭: 096, Loss: 0.2657, Val: 0.7900, Test: 0.8090\n에폭: 097, Loss: 0.2554, Val: 0.7900, Test: 0.8090\n에폭: 098, Loss: 0.2496, Val: 0.7920, Test: 0.8080\n에폭: 099, Loss: 0.2493, Val: 0.7960, Test: 0.8100\n에폭: 100, Loss: 0.2593, Val: 0.7960, Test: 0.8130\n\n\n\n\nmodel = GCN(hidden_channels=256)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\nfor epoch in range(1, 101):\n    loss = train()\n    val_acc = val()\n    test_acc = test()\n    print(f'에폭: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n\n에폭: 001, Loss: 1.9448, Val: 0.2460, Test: 0.2360\n에폭: 002, Loss: 1.9221, Val: 0.3020, Test: 0.3060\n에폭: 003, Loss: 1.8922, Val: 0.3200, Test: 0.3270\n에폭: 004, Loss: 1.8556, Val: 0.3940, Test: 0.4060\n에폭: 005, Loss: 1.8123, Val: 0.4800, Test: 0.4960\n에폭: 006, Loss: 1.7614, Val: 0.5400, Test: 0.5510\n에폭: 007, Loss: 1.7012, Val: 0.5900, Test: 0.6140\n에폭: 008, Loss: 1.6528, Val: 0.6440, Test: 0.6740\n에폭: 009, Loss: 1.5808, Val: 0.6740, Test: 0.7130\n에폭: 010, Loss: 1.5118, Val: 0.7080, Test: 0.7390\n에폭: 011, Loss: 1.4335, Val: 0.7220, Test: 0.7500\n에폭: 012, Loss: 1.3561, Val: 0.7400, Test: 0.7590\n에폭: 013, Loss: 1.2777, Val: 0.7500, Test: 0.7660\n에폭: 014, Loss: 1.2094, Val: 0.7560, Test: 0.7750\n에폭: 015, Loss: 1.1225, Val: 0.7680, Test: 0.7820\n에폭: 016, Loss: 1.0417, Val: 0.7720, Test: 0.7920\n에폭: 017, Loss: 0.9676, Val: 0.7800, Test: 0.7990\n에폭: 018, Loss: 0.9025, Val: 0.7900, Test: 0.8060\n에폭: 019, Loss: 0.8258, Val: 0.7920, Test: 0.8100\n에폭: 020, Loss: 0.7598, Val: 0.7940, Test: 0.8150\n에폭: 021, Loss: 0.7166, Val: 0.7920, Test: 0.8140\n에폭: 022, Loss: 0.6533, Val: 0.7920, Test: 0.8130\n에폭: 023, Loss: 0.6075, Val: 0.7880, Test: 0.8100\n에폭: 024, Loss: 0.5647, Val: 0.7900, Test: 0.8140\n에폭: 025, Loss: 0.5216, Val: 0.7940, Test: 0.8160\n에폭: 026, Loss: 0.4843, Val: 0.7960, Test: 0.8170\n에폭: 027, Loss: 0.4597, Val: 0.7960, Test: 0.8210\n에폭: 028, Loss: 0.4341, Val: 0.8040, Test: 0.8240\n에폭: 029, Loss: 0.3999, Val: 0.8040, Test: 0.8310\n에폭: 030, Loss: 0.3885, Val: 0.8000, Test: 0.8310\n에폭: 031, Loss: 0.3755, Val: 0.7980, Test: 0.8290\n에폭: 032, Loss: 0.3532, Val: 0.7960, Test: 0.8240\n에폭: 033, Loss: 0.3327, Val: 0.7940, Test: 0.8220\n에폭: 034, Loss: 0.3176, Val: 0.7960, Test: 0.8180\n에폭: 035, Loss: 0.3280, Val: 0.7960, Test: 0.8190\n에폭: 036, Loss: 0.3020, Val: 0.7980, Test: 0.8200\n에폭: 037, Loss: 0.3077, Val: 0.7960, Test: 0.8140\n에폭: 038, Loss: 0.3007, Val: 0.7980, Test: 0.8140\n에폭: 039, Loss: 0.2771, Val: 0.8000, Test: 0.8190\n에폭: 040, Loss: 0.2912, Val: 0.8020, Test: 0.8190\n에폭: 041, Loss: 0.2674, Val: 0.8020, Test: 0.8170\n에폭: 042, Loss: 0.2737, Val: 0.7920, Test: 0.8110\n에폭: 043, Loss: 0.2506, Val: 0.7960, Test: 0.8070\n에폭: 044, Loss: 0.2429, Val: 0.7960, Test: 0.8070\n에폭: 045, Loss: 0.2518, Val: 0.7940, Test: 0.8110\n에폭: 046, Loss: 0.2412, Val: 0.7880, Test: 0.8090\n에폭: 047, Loss: 0.2537, Val: 0.7980, Test: 0.8010\n에폭: 048, Loss: 0.2303, Val: 0.7960, Test: 0.8030\n에폭: 049, Loss: 0.2341, Val: 0.7900, Test: 0.8090\n에폭: 050, Loss: 0.2295, Val: 0.7960, Test: 0.8050\n에폭: 051, Loss: 0.2180, Val: 0.7940, Test: 0.8060\n에폭: 052, Loss: 0.2149, Val: 0.7940, Test: 0.8040\n에폭: 053, Loss: 0.2350, Val: 0.7920, Test: 0.8040\n에폭: 054, Loss: 0.2234, Val: 0.7980, Test: 0.7990\n에폭: 055, Loss: 0.2126, Val: 0.7940, Test: 0.8040\n에폭: 056, Loss: 0.2107, Val: 0.7920, Test: 0.8120\n에폭: 057, Loss: 0.2117, Val: 0.7940, Test: 0.8080\n에폭: 058, Loss: 0.2034, Val: 0.7920, Test: 0.8110\n에폭: 059, Loss: 0.2032, Val: 0.7940, Test: 0.8080\n에폭: 060, Loss: 0.2053, Val: 0.8000, Test: 0.8030\n에폭: 061, Loss: 0.2004, Val: 0.7980, Test: 0.7990\n에폭: 062, Loss: 0.1933, Val: 0.7980, Test: 0.8050\n에폭: 063, Loss: 0.1882, Val: 0.7960, Test: 0.8120\n에폭: 064, Loss: 0.1891, Val: 0.7960, Test: 0.8150\n에폭: 065, Loss: 0.1982, Val: 0.7960, Test: 0.8080\n에폭: 066, Loss: 0.1794, Val: 0.7900, Test: 0.8050\n에폭: 067, Loss: 0.1883, Val: 0.7940, Test: 0.8010\n에폭: 068, Loss: 0.1840, Val: 0.7900, Test: 0.8010\n에폭: 069, Loss: 0.1801, Val: 0.7900, Test: 0.8030\n에폭: 070, Loss: 0.1845, Val: 0.7960, Test: 0.8070\n에폭: 071, Loss: 0.1839, Val: 0.7920, Test: 0.8120\n에폭: 072, Loss: 0.1820, Val: 0.7980, Test: 0.8080\n에폭: 073, Loss: 0.1787, Val: 0.7940, Test: 0.8000\n에폭: 074, Loss: 0.1813, Val: 0.7920, Test: 0.8060\n에폭: 075, Loss: 0.1793, Val: 0.7860, Test: 0.8050\n에폭: 076, Loss: 0.1785, Val: 0.7960, Test: 0.8070\n에폭: 077, Loss: 0.1644, Val: 0.7980, Test: 0.8090\n에폭: 078, Loss: 0.1687, Val: 0.7940, Test: 0.8090\n에폭: 079, Loss: 0.1673, Val: 0.7880, Test: 0.8080\n에폭: 080, Loss: 0.1705, Val: 0.7960, Test: 0.8140\n에폭: 081, Loss: 0.1713, Val: 0.7900, Test: 0.8070\n에폭: 082, Loss: 0.1720, Val: 0.7940, Test: 0.8080\n에폭: 083, Loss: 0.1683, Val: 0.7940, Test: 0.8040\n에폭: 084, Loss: 0.1672, Val: 0.7880, Test: 0.8080\n에폭: 085, Loss: 0.1657, Val: 0.7900, Test: 0.8140\n에폭: 086, Loss: 0.1592, Val: 0.7940, Test: 0.8060\n에폭: 087, Loss: 0.1635, Val: 0.8000, Test: 0.8100\n에폭: 088, Loss: 0.1593, Val: 0.7920, Test: 0.8090\n에폭: 089, Loss: 0.1666, Val: 0.7900, Test: 0.8040\n에폭: 090, Loss: 0.1593, Val: 0.7940, Test: 0.7980\n에폭: 091, Loss: 0.1669, Val: 0.7940, Test: 0.8010\n에폭: 092, Loss: 0.1540, Val: 0.7900, Test: 0.8010\n에폭: 093, Loss: 0.1513, Val: 0.7940, Test: 0.8100\n에폭: 094, Loss: 0.1569, Val: 0.7940, Test: 0.8150\n에폭: 095, Loss: 0.1561, Val: 0.7880, Test: 0.8080\n에폭: 096, Loss: 0.1497, Val: 0.7840, Test: 0.8020\n에폭: 097, Loss: 0.1497, Val: 0.7880, Test: 0.8000\n에폭: 098, Loss: 0.1559, Val: 0.7920, Test: 0.8020\n에폭: 099, Loss: 0.1493, Val: 0.7940, Test: 0.8090\n에폭: 100, Loss: 0.1488, Val: 0.8000, Test: 0.8090\n\n\n\nmodel A: filter = 64\n에폭: 097, Loss: 0.2554, Val: 0.7900, Test: 0.8090\n에폭: 098, Loss: 0.2496, Val: 0.7920, Test: 0.8080\n에폭: 099, Loss: 0.2493, Val: 0.7960, Test: 0.8100\n에폭: 100, Loss: 0.2593, Val: 0.7960, Test: 0.8130\nmodel B: flter = 256\n에폭: 097, Loss: 0.1497, Val: 0.7880, Test: 0.8000\n에폭: 098, Loss: 0.1559, Val: 0.7920, Test: 0.8020\n에폭: 099, Loss: 0.1493, Val: 0.7940, Test: 0.8090\n에폭: 100, Loss: 0.1488, Val: 0.8000, Test: 0.8090\ntrain loss 기준: model B가 우수함\nval loss 기준: model A가 우수함\n실제test 데이터에 넣었을 경우: 모델 A가 우수함\n\n\n#test_acc = test(data.test_mask)\ntest_acc\n\n0.813\n\n\n\n#test(data.val_mask)\n\n\n올라가야하는데 오히려 떨어졌는데?? (에폭수 늘려봐도 똑같다..)\n\n\n\n\n\n\n\nmodel = GCN(hidden_channels=32)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\ndef train():\n      model.train()\n      optimizr.zero_grad()  # Clear gradients.\n      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n      loss = loss_fn(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n      loss.backward()  # Derive gradients.\n      optimizr.step()  # Update parameters based on gradients.\n\ndef test(mask):\n      model.eval()\n      out = model(data.x, data.edge_index)\n      pred = out.argmax(dim=1)  # Use the class with highest probability.\n      correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n      acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n      return acc\n\n\nmodel.eval()\n\nGCN(\n  (conv1): GCNConv(1433, 32)\n  (conv2): GCNConv(32, 32)\n  (conv3): GCNConv(32, 7)\n)\n\n\n\n_out = model(data.x, data.edge_index)\n\n\n_pred = _out.argmax(dim=1) \n\n\n(_pred[data.test_mask] == data.y[data.test_mask]).sum() / int(data.test_mask.sum())  #\n\ntensor(0.0830)\n\n\n\ndata.test_mask.sum()\n\ntensor(1000)\n\n\n\nfor epoch in range(1, 101):\n    loss = train()\n    val_acc = test(data.val_mask)\n    test_acc = test(data.test_mask)\n    print(f'에폭: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n\n에폭: 001, Loss: 1.9455, Val: 0.2040, Test: 0.2490\n에폭: 002, Loss: 1.9400, Val: 0.4880, Test: 0.4600\n에폭: 003, Loss: 1.9309, Val: 0.4900, Test: 0.4740\n에폭: 004, Loss: 1.9180, Val: 0.4220, Test: 0.4570\n에폭: 005, Loss: 1.9058, Val: 0.3940, Test: 0.4240\n에폭: 006, Loss: 1.8934, Val: 0.3840, Test: 0.4230\n에폭: 007, Loss: 1.8779, Val: 0.4000, Test: 0.4390\n에폭: 008, Loss: 1.8592, Val: 0.4200, Test: 0.4470\n에폭: 009, Loss: 1.8494, Val: 0.4120, Test: 0.4300\n에폭: 010, Loss: 1.8245, Val: 0.4220, Test: 0.4290\n에폭: 011, Loss: 1.8075, Val: 0.4180, Test: 0.4250\n에폭: 012, Loss: 1.7893, Val: 0.4440, Test: 0.4480\n에폭: 013, Loss: 1.7692, Val: 0.4700, Test: 0.4770\n에폭: 014, Loss: 1.7412, Val: 0.4940, Test: 0.4980\n에폭: 015, Loss: 1.7192, Val: 0.5360, Test: 0.5290\n에폭: 016, Loss: 1.6908, Val: 0.5800, Test: 0.5700\n에폭: 017, Loss: 1.6828, Val: 0.6000, Test: 0.6080\n에폭: 018, Loss: 1.6326, Val: 0.6220, Test: 0.6360\n에폭: 019, Loss: 1.6089, Val: 0.6500, Test: 0.6640\n에폭: 020, Loss: 1.5959, Val: 0.6840, Test: 0.6810\n에폭: 021, Loss: 1.5634, Val: 0.7060, Test: 0.7000\n에폭: 022, Loss: 1.5426, Val: 0.7140, Test: 0.7090\n에폭: 023, Loss: 1.4932, Val: 0.7220, Test: 0.7160\n에폭: 024, Loss: 1.4759, Val: 0.7300, Test: 0.7190\n에폭: 025, Loss: 1.4473, Val: 0.7360, Test: 0.7320\n에폭: 026, Loss: 1.4263, Val: 0.7360, Test: 0.7430\n에폭: 027, Loss: 1.3863, Val: 0.7360, Test: 0.7450\n에폭: 028, Loss: 1.3437, Val: 0.7400, Test: 0.7480\n에폭: 029, Loss: 1.3084, Val: 0.7460, Test: 0.7570\n에폭: 030, Loss: 1.2828, Val: 0.7500, Test: 0.7610\n에폭: 031, Loss: 1.2385, Val: 0.7600, Test: 0.7620\n에폭: 032, Loss: 1.2029, Val: 0.7660, Test: 0.7680\n에폭: 033, Loss: 1.1789, Val: 0.7660, Test: 0.7720\n에폭: 034, Loss: 1.1715, Val: 0.7680, Test: 0.7770\n에폭: 035, Loss: 1.1197, Val: 0.7660, Test: 0.7790\n에폭: 036, Loss: 1.0807, Val: 0.7680, Test: 0.7810\n에폭: 037, Loss: 1.0921, Val: 0.7700, Test: 0.7870\n에폭: 038, Loss: 1.0493, Val: 0.7760, Test: 0.7920\n에폭: 039, Loss: 1.0141, Val: 0.7760, Test: 0.7940\n에폭: 040, Loss: 0.9605, Val: 0.7780, Test: 0.7970\n에폭: 041, Loss: 0.9411, Val: 0.7800, Test: 0.8010\n에폭: 042, Loss: 0.9093, Val: 0.7780, Test: 0.8000\n에폭: 043, Loss: 0.8912, Val: 0.7780, Test: 0.8030\n에폭: 044, Loss: 0.8661, Val: 0.7780, Test: 0.8010\n에폭: 045, Loss: 0.8743, Val: 0.7760, Test: 0.7990\n에폭: 046, Loss: 0.7827, Val: 0.7740, Test: 0.8000\n에폭: 047, Loss: 0.8070, Val: 0.7740, Test: 0.7990\n에폭: 048, Loss: 0.7631, Val: 0.7760, Test: 0.7980\n에폭: 049, Loss: 0.7676, Val: 0.7760, Test: 0.7930\n에폭: 050, Loss: 0.7429, Val: 0.7740, Test: 0.7960\n에폭: 051, Loss: 0.7164, Val: 0.7800, Test: 0.7960\n에폭: 052, Loss: 0.7005, Val: 0.7820, Test: 0.8010\n에폭: 053, Loss: 0.6526, Val: 0.7840, Test: 0.8040\n에폭: 054, Loss: 0.6508, Val: 0.7840, Test: 0.8070\n에폭: 055, Loss: 0.6600, Val: 0.7860, Test: 0.8080\n에폭: 056, Loss: 0.6504, Val: 0.7800, Test: 0.8090\n에폭: 057, Loss: 0.6144, Val: 0.7820, Test: 0.8130\n에폭: 058, Loss: 0.5991, Val: 0.7880, Test: 0.8150\n에폭: 059, Loss: 0.5760, Val: 0.7900, Test: 0.8150\n에폭: 060, Loss: 0.5802, Val: 0.7840, Test: 0.8190\n에폭: 061, Loss: 0.5780, Val: 0.7840, Test: 0.8170\n에폭: 062, Loss: 0.5314, Val: 0.7820, Test: 0.8170\n에폭: 063, Loss: 0.5477, Val: 0.7800, Test: 0.8140\n에폭: 064, Loss: 0.5201, Val: 0.7800, Test: 0.8140\n에폭: 065, Loss: 0.5152, Val: 0.7780, Test: 0.8170\n에폭: 066, Loss: 0.5426, Val: 0.7820, Test: 0.8150\n에폭: 067, Loss: 0.5077, Val: 0.7820, Test: 0.8090\n에폭: 068, Loss: 0.4977, Val: 0.7840, Test: 0.8080\n에폭: 069, Loss: 0.4940, Val: 0.7860, Test: 0.8100\n에폭: 070, Loss: 0.4645, Val: 0.7840, Test: 0.8070\n에폭: 071, Loss: 0.4631, Val: 0.7860, Test: 0.8080\n에폭: 072, Loss: 0.4483, Val: 0.7820, Test: 0.8130\n에폭: 073, Loss: 0.4633, Val: 0.7820, Test: 0.8140\n에폭: 074, Loss: 0.4798, Val: 0.7840, Test: 0.8130\n에폭: 075, Loss: 0.4621, Val: 0.7840, Test: 0.8120\n에폭: 076, Loss: 0.4268, Val: 0.7840, Test: 0.8130\n에폭: 077, Loss: 0.4374, Val: 0.7840, Test: 0.8160\n에폭: 078, Loss: 0.4206, Val: 0.7860, Test: 0.8160\n에폭: 079, Loss: 0.4502, Val: 0.7840, Test: 0.8140\n에폭: 080, Loss: 0.4283, Val: 0.7840, Test: 0.8120\n에폭: 081, Loss: 0.4543, Val: 0.7860, Test: 0.8140\n에폭: 082, Loss: 0.4022, Val: 0.7860, Test: 0.8130\n에폭: 083, Loss: 0.3963, Val: 0.7900, Test: 0.8120\n에폭: 084, Loss: 0.4181, Val: 0.7900, Test: 0.8100\n에폭: 085, Loss: 0.4002, Val: 0.7860, Test: 0.8080\n에폭: 086, Loss: 0.3945, Val: 0.7880, Test: 0.8090\n에폭: 087, Loss: 0.3902, Val: 0.7860, Test: 0.8100\n에폭: 088, Loss: 0.3878, Val: 0.7880, Test: 0.8090\n에폭: 089, Loss: 0.3852, Val: 0.7880, Test: 0.8100\n에폭: 090, Loss: 0.3613, Val: 0.7840, Test: 0.8110\n에폭: 091, Loss: 0.3955, Val: 0.7920, Test: 0.8120\n에폭: 092, Loss: 0.3529, Val: 0.7880, Test: 0.8120\n에폭: 093, Loss: 0.3688, Val: 0.7900, Test: 0.8110\n에폭: 094, Loss: 0.3735, Val: 0.7900, Test: 0.8080\n에폭: 095, Loss: 0.3563, Val: 0.7860, Test: 0.8070\n에폭: 096, Loss: 0.3598, Val: 0.7860, Test: 0.8090\n에폭: 097, Loss: 0.3641, Val: 0.7840, Test: 0.8090\n에폭: 098, Loss: 0.3614, Val: 0.7860, Test: 0.8100\n에폭: 099, Loss: 0.3512, Val: 0.7860, Test: 0.8110\n에폭: 100, Loss: 0.3392, Val: 0.7800, Test: 0.8110\n\n\n\ntest_acc = test(data.test_mask)\ntest_acc\n\n0.811\n\n\n\n\n\n\nmodel = GCN(hidden_channels=64)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\ndef train():\n      model.train()\n      optimizr.zero_grad()  # Clear gradients.\n      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n      loss = loss_fn(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n      loss.backward()  # Derive gradients.\n      optimizr.step()  # Update parameters based on gradients.\n      return loss\n\ndef test(mask):\n      model.eval()\n      out = model(data.x, data.edge_index)\n      pred = out.argmax(dim=1)  # Use the class with highest probability.\n      correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n      acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n      return acc\n\n\nfor epoch in range(1, 101):\n    loss = train()\n    val_acc = test(data.val_mask)\n    test_acc = test(data.test_mask)\n    print(f'에폭: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n\n에폭: 001, Loss: 1.9461, Val: 0.2280, Test: 0.2530\n에폭: 002, Loss: 1.9347, Val: 0.3720, Test: 0.3930\n에폭: 003, Loss: 1.9207, Val: 0.6560, Test: 0.6540\n에폭: 004, Loss: 1.9041, Val: 0.7480, Test: 0.7320\n에폭: 005, Loss: 1.8870, Val: 0.7380, Test: 0.7490\n에폭: 006, Loss: 1.8686, Val: 0.7600, Test: 0.7750\n에폭: 007, Loss: 1.8476, Val: 0.7760, Test: 0.7890\n에폭: 008, Loss: 1.8169, Val: 0.7800, Test: 0.7860\n에폭: 009, Loss: 1.7975, Val: 0.7720, Test: 0.7830\n에폭: 010, Loss: 1.7649, Val: 0.7700, Test: 0.7740\n에폭: 011, Loss: 1.7330, Val: 0.7560, Test: 0.7750\n에폭: 012, Loss: 1.7101, Val: 0.7640, Test: 0.7780\n에폭: 013, Loss: 1.6784, Val: 0.7680, Test: 0.7790\n에폭: 014, Loss: 1.6361, Val: 0.7720, Test: 0.7800\n에폭: 015, Loss: 1.6086, Val: 0.7780, Test: 0.7840\n에폭: 016, Loss: 1.5724, Val: 0.7820, Test: 0.7930\n에폭: 017, Loss: 1.5306, Val: 0.7840, Test: 0.8000\n에폭: 018, Loss: 1.4846, Val: 0.7900, Test: 0.8000\n에폭: 019, Loss: 1.4324, Val: 0.8000, Test: 0.8030\n에폭: 020, Loss: 1.4128, Val: 0.8020, Test: 0.8010\n에폭: 021, Loss: 1.3664, Val: 0.7960, Test: 0.8020\n에폭: 022, Loss: 1.3191, Val: 0.7980, Test: 0.7990\n에폭: 023, Loss: 1.2794, Val: 0.7980, Test: 0.8010\n에폭: 024, Loss: 1.2395, Val: 0.7900, Test: 0.8020\n에폭: 025, Loss: 1.2056, Val: 0.7940, Test: 0.8000\n에폭: 026, Loss: 1.1459, Val: 0.7900, Test: 0.7970\n에폭: 027, Loss: 1.1225, Val: 0.7900, Test: 0.7970\n에폭: 028, Loss: 1.0561, Val: 0.7940, Test: 0.8030\n에폭: 029, Loss: 1.0305, Val: 0.7980, Test: 0.8080\n에폭: 030, Loss: 0.9678, Val: 0.8000, Test: 0.8110\n에폭: 031, Loss: 0.9440, Val: 0.7960, Test: 0.8110\n에폭: 032, Loss: 0.9190, Val: 0.7940, Test: 0.8140\n에폭: 033, Loss: 0.8733, Val: 0.7980, Test: 0.8120\n에폭: 034, Loss: 0.8455, Val: 0.8020, Test: 0.8170\n에폭: 035, Loss: 0.7919, Val: 0.8020, Test: 0.8170\n에폭: 036, Loss: 0.7638, Val: 0.8000, Test: 0.8160\n에폭: 037, Loss: 0.7554, Val: 0.8020, Test: 0.8140\n에폭: 038, Loss: 0.7256, Val: 0.8040, Test: 0.8220\n에폭: 039, Loss: 0.6891, Val: 0.8040, Test: 0.8190\n에폭: 040, Loss: 0.6443, Val: 0.7980, Test: 0.8190\n에폭: 041, Loss: 0.6405, Val: 0.8020, Test: 0.8230\n에폭: 042, Loss: 0.6302, Val: 0.7980, Test: 0.8200\n에폭: 043, Loss: 0.5836, Val: 0.7980, Test: 0.8130\n에폭: 044, Loss: 0.5620, Val: 0.7920, Test: 0.8140\n에폭: 045, Loss: 0.5484, Val: 0.8000, Test: 0.8170\n에폭: 046, Loss: 0.5387, Val: 0.8000, Test: 0.8200\n에폭: 047, Loss: 0.5254, Val: 0.8040, Test: 0.8250\n에폭: 048, Loss: 0.5036, Val: 0.8020, Test: 0.8230\n에폭: 049, Loss: 0.4968, Val: 0.8020, Test: 0.8270\n에폭: 050, Loss: 0.5090, Val: 0.7980, Test: 0.8280\n에폭: 051, Loss: 0.4719, Val: 0.7960, Test: 0.8250\n에폭: 052, Loss: 0.4537, Val: 0.7940, Test: 0.8260\n에폭: 053, Loss: 0.4421, Val: 0.7860, Test: 0.8200\n에폭: 054, Loss: 0.4380, Val: 0.7940, Test: 0.8190\n에폭: 055, Loss: 0.4082, Val: 0.8000, Test: 0.8160\n에폭: 056, Loss: 0.3956, Val: 0.8040, Test: 0.8210\n에폭: 057, Loss: 0.4172, Val: 0.8000, Test: 0.8220\n에폭: 058, Loss: 0.4053, Val: 0.7960, Test: 0.8250\n에폭: 059, Loss: 0.4049, Val: 0.7980, Test: 0.8250\n에폭: 060, Loss: 0.4005, Val: 0.7940, Test: 0.8170\n에폭: 061, Loss: 0.3776, Val: 0.7880, Test: 0.8150\n에폭: 062, Loss: 0.3655, Val: 0.7840, Test: 0.8100\n에폭: 063, Loss: 0.3504, Val: 0.7840, Test: 0.8090\n에폭: 064, Loss: 0.3473, Val: 0.7880, Test: 0.8110\n에폭: 065, Loss: 0.3726, Val: 0.7880, Test: 0.8140\n에폭: 066, Loss: 0.3532, Val: 0.7860, Test: 0.8150\n에폭: 067, Loss: 0.3520, Val: 0.7900, Test: 0.8200\n에폭: 068, Loss: 0.3481, Val: 0.7900, Test: 0.8210\n에폭: 069, Loss: 0.3543, Val: 0.7940, Test: 0.8180\n에폭: 070, Loss: 0.3482, Val: 0.7920, Test: 0.8230\n에폭: 071, Loss: 0.3228, Val: 0.7980, Test: 0.8170\n에폭: 072, Loss: 0.3726, Val: 0.7940, Test: 0.8130\n에폭: 073, Loss: 0.3259, Val: 0.8000, Test: 0.8080\n에폭: 074, Loss: 0.3051, Val: 0.8020, Test: 0.8070\n에폭: 075, Loss: 0.3152, Val: 0.7980, Test: 0.8090\n에폭: 076, Loss: 0.3163, Val: 0.7960, Test: 0.8140\n에폭: 077, Loss: 0.3005, Val: 0.7900, Test: 0.8140\n에폭: 078, Loss: 0.3089, Val: 0.7900, Test: 0.8180\n에폭: 079, Loss: 0.3017, Val: 0.7920, Test: 0.8150\n에폭: 080, Loss: 0.2835, Val: 0.7880, Test: 0.8190\n에폭: 081, Loss: 0.2895, Val: 0.7940, Test: 0.8170\n에폭: 082, Loss: 0.2775, Val: 0.7940, Test: 0.8120\n에폭: 083, Loss: 0.2926, Val: 0.7960, Test: 0.8110\n에폭: 084, Loss: 0.2832, Val: 0.7940, Test: 0.8070\n에폭: 085, Loss: 0.2879, Val: 0.7900, Test: 0.8060\n에폭: 086, Loss: 0.2579, Val: 0.7940, Test: 0.8070\n에폭: 087, Loss: 0.2768, Val: 0.7880, Test: 0.8070\n에폭: 088, Loss: 0.2832, Val: 0.7920, Test: 0.8060\n에폭: 089, Loss: 0.2625, Val: 0.7940, Test: 0.8090\n에폭: 090, Loss: 0.2670, Val: 0.7920, Test: 0.8140\n에폭: 091, Loss: 0.2810, Val: 0.7920, Test: 0.8110\n에폭: 092, Loss: 0.2622, Val: 0.7920, Test: 0.8140\n에폭: 093, Loss: 0.2512, Val: 0.7920, Test: 0.8130\n에폭: 094, Loss: 0.2469, Val: 0.7920, Test: 0.8130\n에폭: 095, Loss: 0.2359, Val: 0.7920, Test: 0.8110\n에폭: 096, Loss: 0.2657, Val: 0.7900, Test: 0.8090\n에폭: 097, Loss: 0.2554, Val: 0.7900, Test: 0.8090\n에폭: 098, Loss: 0.2496, Val: 0.7920, Test: 0.8080\n에폭: 099, Loss: 0.2493, Val: 0.7960, Test: 0.8100\n에폭: 100, Loss: 0.2593, Val: 0.7960, Test: 0.8130\n\n\n\ntest_acc = test(data.test_mask)\ntest_acc\n\n0.813\n\n\n진짜 마지막\n\n\n\n\nmodel = GCN(hidden_channels=128)\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\ndef train():\n      model.train()\n      optimizr.zero_grad()  # Clear gradients.\n      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n      loss = loss_fn(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n      loss.backward()  # Derive gradients.\n      optimizr.step()  # Update parameters based on gradients.\n      return loss\n\ndef test(mask):\n      model.eval()\n      out = model(data.x, data.edge_index)\n      pred = out.argmax(dim=1)  # Use the class with highest probability.\n      correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n      acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n      return acc\n\n\nfor epoch in range(1, 101):\n    loss = train()\n    val_acc = test(data.val_mask)\n    test_acc = test(data.test_mask)\n    print(f'에폭: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n\n에폭: 001, Loss: 1.9459, Val: 0.2920, Test: 0.3330\n에폭: 002, Loss: 1.9297, Val: 0.2880, Test: 0.3140\n에폭: 003, Loss: 1.9134, Val: 0.3860, Test: 0.3930\n에폭: 004, Loss: 1.8888, Val: 0.4760, Test: 0.4990\n에폭: 005, Loss: 1.8626, Val: 0.5580, Test: 0.5820\n에폭: 006, Loss: 1.8336, Val: 0.6280, Test: 0.6420\n에폭: 007, Loss: 1.7979, Val: 0.6580, Test: 0.6730\n에폭: 008, Loss: 1.7657, Val: 0.6700, Test: 0.6910\n에폭: 009, Loss: 1.7229, Val: 0.6840, Test: 0.7180\n에폭: 010, Loss: 1.6762, Val: 0.7000, Test: 0.7250\n에폭: 011, Loss: 1.6376, Val: 0.7080, Test: 0.7370\n에폭: 012, Loss: 1.5870, Val: 0.7300, Test: 0.7650\n에폭: 013, Loss: 1.5326, Val: 0.7380, Test: 0.7740\n에폭: 014, Loss: 1.4731, Val: 0.7520, Test: 0.7770\n에폭: 015, Loss: 1.4370, Val: 0.7560, Test: 0.7840\n에폭: 016, Loss: 1.3767, Val: 0.7660, Test: 0.7910\n에폭: 017, Loss: 1.3069, Val: 0.7800, Test: 0.7910\n에폭: 018, Loss: 1.2643, Val: 0.7820, Test: 0.8020\n에폭: 019, Loss: 1.1892, Val: 0.7820, Test: 0.8040\n에폭: 020, Loss: 1.1427, Val: 0.7860, Test: 0.8080\n에폭: 021, Loss: 1.0830, Val: 0.7840, Test: 0.8090\n에폭: 022, Loss: 1.0314, Val: 0.7840, Test: 0.8080\n에폭: 023, Loss: 0.9648, Val: 0.7840, Test: 0.8100\n에폭: 024, Loss: 0.9281, Val: 0.7840, Test: 0.8110\n에폭: 025, Loss: 0.8805, Val: 0.7880, Test: 0.8120\n에폭: 026, Loss: 0.8167, Val: 0.7940, Test: 0.8150\n에폭: 027, Loss: 0.8019, Val: 0.7940, Test: 0.8140\n에폭: 028, Loss: 0.7399, Val: 0.7940, Test: 0.8160\n에폭: 029, Loss: 0.7001, Val: 0.7940, Test: 0.8180\n에폭: 030, Loss: 0.6684, Val: 0.7980, Test: 0.8230\n에폭: 031, Loss: 0.6249, Val: 0.8020, Test: 0.8230\n에폭: 032, Loss: 0.5802, Val: 0.8000, Test: 0.8220\n에폭: 033, Loss: 0.5604, Val: 0.8020, Test: 0.8250\n에폭: 034, Loss: 0.5569, Val: 0.8000, Test: 0.8280\n에폭: 035, Loss: 0.4827, Val: 0.7980, Test: 0.8270\n에폭: 036, Loss: 0.4973, Val: 0.7960, Test: 0.8250\n에폭: 037, Loss: 0.4821, Val: 0.7980, Test: 0.8280\n에폭: 038, Loss: 0.4444, Val: 0.7960, Test: 0.8290\n에폭: 039, Loss: 0.4423, Val: 0.7940, Test: 0.8280\n에폭: 040, Loss: 0.4391, Val: 0.7940, Test: 0.8220\n에폭: 041, Loss: 0.4209, Val: 0.7940, Test: 0.8200\n에폭: 042, Loss: 0.4060, Val: 0.7920, Test: 0.8210\n에폭: 043, Loss: 0.3860, Val: 0.7940, Test: 0.8210\n에폭: 044, Loss: 0.3712, Val: 0.7900, Test: 0.8230\n에폭: 045, Loss: 0.3680, Val: 0.7920, Test: 0.8240\n에폭: 046, Loss: 0.3541, Val: 0.7940, Test: 0.8200\n에폭: 047, Loss: 0.3426, Val: 0.7960, Test: 0.8220\n에폭: 048, Loss: 0.3309, Val: 0.7940, Test: 0.8190\n에폭: 049, Loss: 0.3434, Val: 0.7920, Test: 0.8230\n에폭: 050, Loss: 0.3195, Val: 0.7880, Test: 0.8190\n에폭: 051, Loss: 0.3153, Val: 0.7900, Test: 0.8220\n에폭: 052, Loss: 0.3199, Val: 0.7920, Test: 0.8230\n에폭: 053, Loss: 0.3043, Val: 0.7920, Test: 0.8210\n에폭: 054, Loss: 0.3003, Val: 0.7960, Test: 0.8170\n에폭: 055, Loss: 0.3075, Val: 0.7940, Test: 0.8160\n에폭: 056, Loss: 0.2846, Val: 0.7940, Test: 0.8160\n에폭: 057, Loss: 0.2740, Val: 0.7940, Test: 0.8150\n에폭: 058, Loss: 0.2864, Val: 0.7980, Test: 0.8100\n에폭: 059, Loss: 0.2695, Val: 0.7960, Test: 0.8110\n에폭: 060, Loss: 0.2758, Val: 0.7960, Test: 0.8130\n에폭: 061, Loss: 0.2689, Val: 0.7920, Test: 0.8110\n에폭: 062, Loss: 0.2551, Val: 0.7940, Test: 0.8100\n에폭: 063, Loss: 0.2599, Val: 0.7940, Test: 0.8040\n에폭: 064, Loss: 0.2571, Val: 0.7940, Test: 0.8030\n에폭: 065, Loss: 0.2597, Val: 0.7880, Test: 0.8010\n에폭: 066, Loss: 0.2536, Val: 0.7900, Test: 0.8000\n에폭: 067, Loss: 0.2444, Val: 0.8000, Test: 0.8070\n에폭: 068, Loss: 0.2524, Val: 0.7940, Test: 0.8080\n에폭: 069, Loss: 0.2539, Val: 0.7940, Test: 0.8090\n에폭: 070, Loss: 0.2463, Val: 0.7900, Test: 0.8130\n에폭: 071, Loss: 0.2359, Val: 0.7940, Test: 0.8080\n에폭: 072, Loss: 0.2504, Val: 0.7960, Test: 0.8020\n에폭: 073, Loss: 0.2226, Val: 0.7960, Test: 0.7970\n에폭: 074, Loss: 0.2196, Val: 0.7980, Test: 0.8000\n에폭: 075, Loss: 0.2296, Val: 0.8020, Test: 0.8010\n에폭: 076, Loss: 0.2369, Val: 0.8020, Test: 0.8020\n에폭: 077, Loss: 0.2375, Val: 0.7980, Test: 0.8070\n에폭: 078, Loss: 0.2348, Val: 0.7940, Test: 0.8030\n에폭: 079, Loss: 0.2251, Val: 0.7860, Test: 0.8090\n에폭: 080, Loss: 0.2125, Val: 0.7840, Test: 0.8070\n에폭: 081, Loss: 0.2132, Val: 0.7900, Test: 0.8050\n에폭: 082, Loss: 0.2095, Val: 0.7940, Test: 0.8060\n에폭: 083, Loss: 0.2157, Val: 0.7940, Test: 0.8060\n에폭: 084, Loss: 0.2067, Val: 0.7960, Test: 0.8040\n에폭: 085, Loss: 0.2076, Val: 0.7980, Test: 0.8050\n에폭: 086, Loss: 0.2017, Val: 0.7980, Test: 0.8050\n에폭: 087, Loss: 0.2083, Val: 0.8000, Test: 0.8050\n에폭: 088, Loss: 0.1889, Val: 0.8000, Test: 0.8070\n에폭: 089, Loss: 0.2043, Val: 0.7960, Test: 0.8070\n에폭: 090, Loss: 0.2090, Val: 0.7920, Test: 0.8080\n에폭: 091, Loss: 0.1975, Val: 0.7940, Test: 0.8030\n에폭: 092, Loss: 0.1983, Val: 0.7920, Test: 0.8020\n에폭: 093, Loss: 0.2047, Val: 0.7900, Test: 0.8080\n에폭: 094, Loss: 0.2028, Val: 0.7940, Test: 0.8040\n에폭: 095, Loss: 0.1916, Val: 0.7940, Test: 0.8050\n에폭: 096, Loss: 0.1996, Val: 0.7960, Test: 0.8060\n에폭: 097, Loss: 0.1867, Val: 0.7920, Test: 0.8030\n에폭: 098, Loss: 0.1803, Val: 0.7960, Test: 0.8030\n에폭: 099, Loss: 0.1878, Val: 0.7960, Test: 0.8000\n에폭: 100, Loss: 0.1855, Val: 0.7960, Test: 0.8020\n\n\n\ntest_acc = test(data.test_mask)\ntest_acc\n\n0.802\n\n\n실패: hidden channels=16일때가 제일 좋았다..\n\n\n\n\n\nfrom torch_geometric.nn import GCNConv\n\n\nclass GCN(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        ## 우리가 사용할 레이어 정의\n        torch.manual_seed(1234567)\n        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, 32)\n        self.conv3 = GCNConv(32, dataset.num_classes)\n        ## 레이어 정의 끝!\n        \n    def forward(self, x, edge_index):\n        ## yhat을 어떻게 구할것인지 정의\n        x = self.conv1(x, edge_index)\n        x = x.relu()\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.conv2(x, edge_index)\n        x = x.relu()\n        x = F.dropout(x, p = 0.5, training=self.training)\n        x = self.conv3(x, edge_index)\n        ## 정의 끝!\n        return x\n\nmodel = GCN(hidden_channels=16)\nprint(model)\n\nGCN(\n  (conv1): GCNConv(1433, 16)\n  (conv2): GCNConv(16, 32)\n  (conv3): GCNConv(32, 7)\n)\n\n\n\nmodel = GCN(hidden_channels=16)  ## 다시 처음처럼\noptimizr = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\nloss_fn = torch.nn.CrossEntropyLoss()\n\ndef train():\n      model.train()\n      optimizr.zero_grad()  # Clear gradients.\n      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n      loss = loss_fn(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n      loss.backward()  # Derive gradients.\n      optimizr.step()  # Update parameters based on gradients.\n      return loss\n\ndef test(mask):\n      model.eval()\n      out = model(data.x, data.edge_index)\n      pred = out.argmax(dim=1)  # Use the class with highest probability.\n      correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n      acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n      return acc\n\n\nfor epoch in range(1, 101):\n    loss = train()\n    val_acc = test(data.val_mask)\n    test_acc = test(data.test_mask)\n    print(f'에폭: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n\n에폭: 001, Loss: 1.9463, Val: 0.0600, Test: 0.0680\n에폭: 002, Loss: 1.9436, Val: 0.0960, Test: 0.1230\n에폭: 003, Loss: 1.9410, Val: 0.1840, Test: 0.1940\n에폭: 004, Loss: 1.9393, Val: 0.1920, Test: 0.2000\n에폭: 005, Loss: 1.9353, Val: 0.2100, Test: 0.2140\n에폭: 006, Loss: 1.9314, Val: 0.2380, Test: 0.2490\n에폭: 007, Loss: 1.9273, Val: 0.2720, Test: 0.2650\n에폭: 008, Loss: 1.9238, Val: 0.2940, Test: 0.2740\n에폭: 009, Loss: 1.9072, Val: 0.3440, Test: 0.3270\n에폭: 010, Loss: 1.9020, Val: 0.4120, Test: 0.4070\n에폭: 011, Loss: 1.8989, Val: 0.4620, Test: 0.4510\n에폭: 012, Loss: 1.8787, Val: 0.5180, Test: 0.5020\n에폭: 013, Loss: 1.8766, Val: 0.5260, Test: 0.5140\n에폭: 014, Loss: 1.8677, Val: 0.4820, Test: 0.4820\n에폭: 015, Loss: 1.8441, Val: 0.4420, Test: 0.4530\n에폭: 016, Loss: 1.8193, Val: 0.4100, Test: 0.4130\n에폭: 017, Loss: 1.8285, Val: 0.4140, Test: 0.4190\n에폭: 018, Loss: 1.7950, Val: 0.4480, Test: 0.4840\n에폭: 019, Loss: 1.7566, Val: 0.5000, Test: 0.5160\n에폭: 020, Loss: 1.7496, Val: 0.5560, Test: 0.5420\n에폭: 021, Loss: 1.7091, Val: 0.5600, Test: 0.5580\n에폭: 022, Loss: 1.6968, Val: 0.5760, Test: 0.5710\n에폭: 023, Loss: 1.6870, Val: 0.5600, Test: 0.5620\n에폭: 024, Loss: 1.6368, Val: 0.5660, Test: 0.5620\n에폭: 025, Loss: 1.6025, Val: 0.5720, Test: 0.5690\n에폭: 026, Loss: 1.5775, Val: 0.5700, Test: 0.5680\n에폭: 027, Loss: 1.5343, Val: 0.5720, Test: 0.5700\n에폭: 028, Loss: 1.4857, Val: 0.6200, Test: 0.5940\n에폭: 029, Loss: 1.4279, Val: 0.6340, Test: 0.6280\n에폭: 030, Loss: 1.4115, Val: 0.6720, Test: 0.6680\n에폭: 031, Loss: 1.3927, Val: 0.7060, Test: 0.7100\n에폭: 032, Loss: 1.3441, Val: 0.7160, Test: 0.7300\n에폭: 033, Loss: 1.3032, Val: 0.7220, Test: 0.7410\n에폭: 034, Loss: 1.2482, Val: 0.7320, Test: 0.7390\n에폭: 035, Loss: 1.1926, Val: 0.7320, Test: 0.7280\n에폭: 036, Loss: 1.1531, Val: 0.7400, Test: 0.7300\n에폭: 037, Loss: 1.1780, Val: 0.7440, Test: 0.7370\n에폭: 038, Loss: 1.0796, Val: 0.7520, Test: 0.7440\n에폭: 039, Loss: 1.0631, Val: 0.7540, Test: 0.7510\n에폭: 040, Loss: 0.9750, Val: 0.7540, Test: 0.7520\n에폭: 041, Loss: 0.9219, Val: 0.7500, Test: 0.7530\n에폭: 042, Loss: 0.9419, Val: 0.7640, Test: 0.7520\n에폭: 043, Loss: 0.8603, Val: 0.7680, Test: 0.7540\n에폭: 044, Loss: 0.8931, Val: 0.7640, Test: 0.7500\n에폭: 045, Loss: 0.7922, Val: 0.7660, Test: 0.7490\n에폭: 046, Loss: 0.8802, Val: 0.7740, Test: 0.7590\n에폭: 047, Loss: 0.8179, Val: 0.7500, Test: 0.7700\n에폭: 048, Loss: 0.7274, Val: 0.7340, Test: 0.7650\n에폭: 049, Loss: 0.7752, Val: 0.7460, Test: 0.7660\n에폭: 050, Loss: 0.6349, Val: 0.7700, Test: 0.7740\n에폭: 051, Loss: 0.6551, Val: 0.7640, Test: 0.7660\n에폭: 052, Loss: 0.7158, Val: 0.7560, Test: 0.7620\n에폭: 053, Loss: 0.5738, Val: 0.7500, Test: 0.7640\n에폭: 054, Loss: 0.5982, Val: 0.7520, Test: 0.7670\n에폭: 055, Loss: 0.5448, Val: 0.7620, Test: 0.7680\n에폭: 056, Loss: 0.5286, Val: 0.7600, Test: 0.7630\n에폭: 057, Loss: 0.5853, Val: 0.7560, Test: 0.7600\n에폭: 058, Loss: 0.5214, Val: 0.7560, Test: 0.7590\n에폭: 059, Loss: 0.5056, Val: 0.7620, Test: 0.7560\n에폭: 060, Loss: 0.4689, Val: 0.7620, Test: 0.7680\n에폭: 061, Loss: 0.5076, Val: 0.7600, Test: 0.7740\n에폭: 062, Loss: 0.4237, Val: 0.7580, Test: 0.7780\n에폭: 063, Loss: 0.4444, Val: 0.7540, Test: 0.7780\n에폭: 064, Loss: 0.4448, Val: 0.7620, Test: 0.7800\n에폭: 065, Loss: 0.4126, Val: 0.7640, Test: 0.7730\n에폭: 066, Loss: 0.4183, Val: 0.7620, Test: 0.7660\n에폭: 067, Loss: 0.3891, Val: 0.7560, Test: 0.7550\n에폭: 068, Loss: 0.3522, Val: 0.7480, Test: 0.7500\n에폭: 069, Loss: 0.3471, Val: 0.7520, Test: 0.7510\n에폭: 070, Loss: 0.4018, Val: 0.7440, Test: 0.7540\n에폭: 071, Loss: 0.3704, Val: 0.7480, Test: 0.7570\n에폭: 072, Loss: 0.3627, Val: 0.7540, Test: 0.7580\n에폭: 073, Loss: 0.3264, Val: 0.7440, Test: 0.7660\n에폭: 074, Loss: 0.3125, Val: 0.7580, Test: 0.7730\n에폭: 075, Loss: 0.3847, Val: 0.7580, Test: 0.7770\n에폭: 076, Loss: 0.3563, Val: 0.7640, Test: 0.7810\n에폭: 077, Loss: 0.3036, Val: 0.7560, Test: 0.7780\n에폭: 078, Loss: 0.3413, Val: 0.7560, Test: 0.7770\n에폭: 079, Loss: 0.2660, Val: 0.7560, Test: 0.7700\n에폭: 080, Loss: 0.2901, Val: 0.7520, Test: 0.7610\n에폭: 081, Loss: 0.3114, Val: 0.7540, Test: 0.7580\n에폭: 082, Loss: 0.2800, Val: 0.7560, Test: 0.7710\n에폭: 083, Loss: 0.3129, Val: 0.7520, Test: 0.7750\n에폭: 084, Loss: 0.2437, Val: 0.7540, Test: 0.7770\n에폭: 085, Loss: 0.2357, Val: 0.7580, Test: 0.7820\n에폭: 086, Loss: 0.2883, Val: 0.7620, Test: 0.7830\n에폭: 087, Loss: 0.2879, Val: 0.7600, Test: 0.7810\n에폭: 088, Loss: 0.2974, Val: 0.7540, Test: 0.7800\n에폭: 089, Loss: 0.2173, Val: 0.7560, Test: 0.7780\n에폭: 090, Loss: 0.3087, Val: 0.7620, Test: 0.7800\n에폭: 091, Loss: 0.2438, Val: 0.7560, Test: 0.7790\n에폭: 092, Loss: 0.2548, Val: 0.7600, Test: 0.7790\n에폭: 093, Loss: 0.2634, Val: 0.7560, Test: 0.7780\n에폭: 094, Loss: 0.2814, Val: 0.7580, Test: 0.7780\n에폭: 095, Loss: 0.2191, Val: 0.7600, Test: 0.7790\n에폭: 096, Loss: 0.2393, Val: 0.7740, Test: 0.7770\n에폭: 097, Loss: 0.2537, Val: 0.7680, Test: 0.7780\n에폭: 098, Loss: 0.2113, Val: 0.7660, Test: 0.7810\n에폭: 099, Loss: 0.2402, Val: 0.7700, Test: 0.7790\n에폭: 100, Loss: 0.2013, Val: 0.7660, Test: 0.7770\n\n\n\ntest_acc = test(data.test_mask)\ntest_acc\n\n0.777\n\n\n층을 늘려봐도 test accuracy가 더 떨어진다.\n\n\n\nGCNConv 인스턴스를 attention을 이용한 GATConv로 바꿔보자.\n\nfrom torch_geometric.nn import GATConv\n\n\nclass GAT(torch.nn.Module):\n    def __init__(self, hidden_channels, heads):\n        super().__init__()\n        torch.manual_seed(1234567)\n        self.conv1 = GATConv(...)  # TODO\n        self.conv2 = GATConv(...)  # TODO\n\n    def forward(self, x, edge_index):\n        x = F.dropout(x, p=0.6, training=self.training)\n        x = self.conv1(x, edge_index)\n        x = F.elu(x)\n        x = F.dropout(x, p=0.6, training=self.training)\n        x = self.conv2(x, edge_index)\n        return x\n\n\n관련논문3\n\n\n\n\nIn this chapter, you have seen how to apply GNNs to real-world problems, and, in particular, how they can effectively be used for boosting a model’s performance. In the next section, we will look into how GNNs can be used for the task of graph classification."
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn2.html",
    "href": "posts/DNN/2023-03-01-dnn2.html",
    "title": "딥러닝 기초 (2)",
    "section": "",
    "text": "회귀분석(2)– SSE와 MSE, step1의 다른버전 (torch.nn.Linear)"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn2.html#ver1-loss-sum-of-squares-error",
    "href": "posts/DNN/2023-03-01-dnn2.html#ver1-loss-sum-of-squares-error",
    "title": "딥러닝 기초 (2)",
    "section": "ver1: loss = sum of squares error",
    "text": "ver1: loss = sum of squares error\n\nalpha = 1/1000\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nfor epoc in range(30): \n    # step1: yhat \n    yhat = X@What \n    # step2: loss \n    loss = torch.sum((y-yhat)**2)\n    # step3: 미분 \n    loss.backward()\n    # step4: update \n    What.data = What.data - alpha * What.grad  # 가중치 업데이트 // # What.grad: 미분계수값 저장되어 있음.\n    What.grad = None # 가중치 초기화 (깨끗하게!)\n\n\nWhat\n\ntensor([[2.4290],\n        [4.0144]], requires_grad=True)\n\n\n\nplt.plot(x,y,'o') \nplt.plot(x,X@What.data,'--')\n\n\n\n\n\nnote: 왜 What = What - alpha*What.grad 는 안되는지?"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn2.html#ver2-loss-mean-squared-error-mse",
    "href": "posts/DNN/2023-03-01-dnn2.html#ver2-loss-mean-squared-error-mse",
    "title": "딥러닝 기초 (2)",
    "section": "ver2: loss = mean squared error = MSE",
    "text": "ver2: loss = mean squared error = MSE\n\nalpha = 1/10\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nfor epoc in range(30): \n    # step1: yhat \n    yhat = X@What \n    # step2: loss \n    loss = torch.mean((y-yhat)**2)\n    # step3: 미분 \n    loss.backward()\n    # step4: update \n    What.data = What.data - alpha * What.grad \n    What.grad = None \n\n\nWhat\n\ntensor([[2.4290],\n        [4.0144]], requires_grad=True)"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn2.html#ver1-biastrue",
    "href": "posts/DNN/2023-03-01-dnn2.html#ver1-biastrue",
    "title": "딥러닝 기초 (2)",
    "section": "ver1: bias=True",
    "text": "ver1: bias=True\n\nnet = torch.nn.Linear(1,1,bias=True)\n\n\\(X\\)가 수식적이 변환을 거처서 \\(\\hat{y}\\)라는게 나오게 될텐데 그것을 네트워크라고 정의한다.\nX -> yhat\nyhat = w0 + w1*x\nnet(x) = yhat ## 이런 구조로 만들 것임.\nw0 + w1*x같은 수식을 매번 안쳐도 됨!! \\(\\to\\) 파이토치에서 구현이 되어있음!\n\n# torch.nn.Linear?\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=1, out_features=1, bias=True) \n\n\nnet\n\nLinear(in_features=1, out_features=1, bias=True)\n\n\n- 초기 plot1 (네트워크로 만듦)\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n- 초기 plot2 (수식으로 만듦: yhat = w0+w1*x)\n\nnet.bias, net.weight\n\n(Parameter containing:\n tensor([-0.8470], requires_grad=True),\n Parameter containing:\n tensor([[-0.3467]], requires_grad=True))\n\n\n\n네트워크가 만들어질 때 net.bias, net.weight에 아무값이나 들어있음..\n\n\n# 위의 그래프와 똑같음.\nplt.plot(x,y,'o')\nplt.plot(x,-0.8470-0.3467*x,'--')\n\n\n\n\n- net에서 \\(\\hat{w}_0, \\hat{w}_1\\) 의 값은?\n\nnet.weight # w1 \n\nParameter containing:\ntensor([[-0.3467]], requires_grad=True)\n\n\n\nnet.bias # w0 \n\nParameter containing:\ntensor([-0.8470], requires_grad=True)\n\n\n\n_yhat = -0.8470 + -0.3467*x \n\n\nplt.plot(x,y,'o')\nplt.plot(x, _yhat,'--')\nplt.plot(x,net(x).data,'-.')\n\n\n\n\n- 수식표현: \\(\\hat{y}_i = \\hat{w}_0 + \\hat{w}_1 x_i = \\hat{b} + \\hat{w}x_i = -0.8470 + -0.3467 x_i\\) for all \\(i=1,2,\\dots,100\\)."
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn2.html#ver2",
    "href": "posts/DNN/2023-03-01-dnn2.html#ver2",
    "title": "딥러닝 기초 (2)",
    "section": "ver2",
    "text": "ver2\n- 입력이 x가 아닌 X를 넣고 싶다면? (보통 잘 안하긴 해요, 왜? bias=False로 주는게 귀찮거든요) - X는 바이어스가 고려된 상황\n\nnet(X) ## 그대로 쓰면 당연히 에러\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (100x2 and 1x1)\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=2, out_features=1, bias=False) \n\n\nnet.weight\n\nParameter containing:\ntensor([[-0.2451, -0.5989]], requires_grad=True)\n\n\n\\(w_0 = -0.2451, \\quad w_1 = -0.5989\\)\n\nnet.bias # bias=False로 했기때문에 아무것도 없음.\n\n\nplt.plot(x,y,'o') \nplt.plot(x,net(X).data, '--')\nplt.plot(x,X@torch.tensor([[-0.2451],[-0.5989]]), '-.')\n\n\n\n\n- 수식표현: \\(\\hat{\\bf y} = {\\bf X} {\\bf \\hat W} = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots & \\dots \\\\ 1 & x_{100} \\end{bmatrix} \\begin{bmatrix} -0.2451 \\\\ -0.5989 \\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn2.html#잘못된사용1",
    "href": "posts/DNN/2023-03-01-dnn2.html#잘못된사용1",
    "title": "딥러닝 기초 (2)",
    "section": "잘못된사용1",
    "text": "잘못된사용1\n\n_x = x.reshape(-1) # length=100인 벡터.\n\n\n_x\n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632])\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=1,out_features=1) \n\n\nnet(_x)\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (1x100 and 1x1)"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn2.html#잘못된사용2",
    "href": "posts/DNN/2023-03-01-dnn2.html#잘못된사용2",
    "title": "딥러닝 기초 (2)",
    "section": "잘못된사용2",
    "text": "잘못된사용2\n\n이건 에러메세지는 안나지만 틀림.\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=2,out_features=1) # bias=False를 깜빡..\n\n\nnet.weight\n\nParameter containing:\ntensor([[-0.2451, -0.5989]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([0.2549], requires_grad=True)\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\nplt.plot(x,X@torch.tensor([[-0.2451],[-0.5989]])+0.2549,'-.')\n\n\n\n\n\n수식표현: \\(\\hat{\\bf y} = {\\bf X} {\\bf \\hat W} + \\hat{b}= \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots & \\dots \\\\ 1 & x_{100} \\end{bmatrix} \\begin{bmatrix} -0.2451 \\\\ -0.5989 \\end{bmatrix} + 0.2549\\)"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn2.html#ver1.-biastrue",
    "href": "posts/DNN/2023-03-01-dnn2.html#ver1.-biastrue",
    "title": "딥러닝 기초 (2)",
    "section": "ver1. bias=True",
    "text": "ver1. bias=True\n\nnet1 = torch.nn.Linear(in_features=1, out_features=1,bias=True)\nnet1.weight.data, net1.bias.data # 네트워크에 들어있는 초기값.\n\n(tensor([[0.1441]]), tensor([-0.8133]))\n\n\n\nnet1.weight.data = torch.tensor([[2.5]]) # dim 맞춰주기위한 작업 // torch.tensor([2.5]).reshape(-1,1).shape -> torch.Size([1,1])\nnet1.bias.data = torch.tensor([-7.0]) # 얜 스칼라니까..\nnet1.weight.data.shape, net1.bias.shape\n\n(torch.Size([1, 1]), torch.Size([1]))\n\n\n\nnet1(x), 2.5*x-7.0\n\n(tensor([[-6.8399],\n         [-6.2981],\n         [-6.2541],\n         [-5.9748],\n         [-5.7316]], grad_fn=<AddmmBackward0>),\n tensor([[-6.8399],\n         [-6.2981],\n         [-6.2541],\n         [-5.9748],\n         [-5.7316]]))"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn2.html#ver2.-biasfalse",
    "href": "posts/DNN/2023-03-01-dnn2.html#ver2.-biasfalse",
    "title": "딥러닝 기초 (2)",
    "section": "ver2. bias=False",
    "text": "ver2. bias=False\n\nnet2 = torch.nn.Linear(in_features=1, out_features=2, bias=False)\nnet2.weight.data, net2.bias\n\n(tensor([[-0.2855],\n         [-0.4631]]),\n None)\n\n\n\nnet2.weight.data = torch.tensor([[-7.0, 2.5]])\nnet2.weight.data.shape\n\ntorch.Size([1, 2])\n\n\n\nnet2(X), 2.5*x-7.0\n\n(tensor([[-6.8399],\n         [-6.2981],\n         [-6.2541],\n         [-5.9748],\n         [-5.7316]], grad_fn=<MmBackward0>),\n tensor([[-6.8399],\n         [-6.2981],\n         [-6.2541],\n         [-5.9748],\n         [-5.7316]]))\n\n\n\n(모범답안)\n\ntorch.manual_seed(202043052) \nx,_ = torch.randn(5).sort()\nx = x.reshape(-1,1)\nX = torch.concat([torch.ones(5).reshape(-1,1),x],axis=1)\n\n\nx,X\n\n(tensor([[-2.9777],\n         [-0.2220],\n         [-0.1181],\n         [ 0.1084],\n         [ 1.7688]]),\n tensor([[ 1.0000, -2.9777],\n         [ 1.0000, -0.2220],\n         [ 1.0000, -0.1181],\n         [ 1.0000,  0.1084],\n         [ 1.0000,  1.7688]]))\n\n\n(ver1) bias를 넣음\n\nnet1=torch.nn.Linear(in_features=1,out_features=1,bias=True) \nnet1.weight.data, net1.bias.data\n\n(tensor([[0.0092]]), tensor([0.1899]))\n\n\n\nnet1.weight.data = torch.tensor([[2.5]])\nnet1.bias.data = torch.tensor([-7.0])\nnet1.weight.data, net1.bias.data\n\n(tensor([[2.5000]]), tensor([-7.]))\n\n\n\nnet1(x), 2.5*x-7\n\n(tensor([[-14.4443],\n         [ -7.5551],\n         [ -7.2952],\n         [ -6.7290],\n         [ -2.5781]], grad_fn=<AddmmBackward0>),\n tensor([[-14.4443],\n         [ -7.5551],\n         [ -7.2952],\n         [ -6.7290],\n         [ -2.5781]]))\n\n\n(ver2) bias를 넣지 않음\n\nnet2=torch.nn.Linear(in_features=2,out_features=1,bias=False) \nnet2.weight.data, net2.bias\n\n(tensor([[-0.6152, -0.6372]]), None)\n\n\n\nnet2.weight.data = torch.tensor([[-7.0, 2.5]])\nnet2.weight.data\n\ntensor([[-7.0000,  2.5000]])\n\n\n\nnet2(X), 2.5*x-7\n\n(tensor([[-14.4443],\n         [ -7.5551],\n         [ -7.2952],\n         [ -6.7290],\n         [ -2.5781]], grad_fn=<MmBackward0>),\n tensor([[-14.4443],\n         [ -7.5551],\n         [ -7.2952],\n         [ -6.7290],\n         [ -2.5781]]))"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn1.html",
    "href": "posts/DNN/2023-03-01-dnn1.html",
    "title": "딥러닝 기초 (1)",
    "section": "",
    "text": "회귀분석(1)– 회귀모형의 소개, 회귀모형에서 데이터생성, 회귀모형에서 학습이란? 파라메터를 학습하는 방법, 파라메터의 학습과정 음미, 학습률"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn1.html#stage1-첫번째-점선-임의의-선을-일단-그어보자",
    "href": "posts/DNN/2023-03-01-dnn1.html#stage1-첫번째-점선-임의의-선을-일단-그어보자",
    "title": "딥러닝 기초 (1)",
    "section": "Stage1: 첫번째 점선 – 임의의 선을 일단 그어보자",
    "text": "Stage1: 첫번째 점선 – 임의의 선을 일단 그어보자\n- \\(\\hat{w}_0=-5, \\hat{w}_1 = 10\\) 으로 설정하고 (왜? 그냥) 임의의 선을 그어보자.\n\nWhat = torch.tensor([-5.0,10.0],requires_grad=True)\nWhat\n\ntensor([-5., 10.], requires_grad=True)\n\n\n\n처음에는 \\({\\bf \\hat{W}}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}=\\begin{bmatrix} -5 \\\\ 10 \\end{bmatrix}\\) 를 대입해서 주황색 점선을 적당히 그려보자는 의미\n끝에 requires_grad=True는 나중에 미분을 위한 것 (미분꼬리표라고 하자..)\n\n“나중에 What이라는 변수를 미분할거야” 라는 의미.\n\nyhat = X@What \n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--') # 그림을 그리기 위해서 yhat의 미분꼬리표를 제거\n\n\n\n\n## 미분꼬리표 떼는 법\nyhat.detach() # 방법1\nyhat.data # 방법2"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn1.html#stage2-첫번째-수정-최초의-점선에-대한-적당한-정도를-판단하고-더-적당한-점선으로-업데이트-한다.",
    "href": "posts/DNN/2023-03-01-dnn1.html#stage2-첫번째-수정-최초의-점선에-대한-적당한-정도를-판단하고-더-적당한-점선으로-업데이트-한다.",
    "title": "딥러닝 기초 (1)",
    "section": "Stage2: 첫번째 수정 – 최초의 점선에 대한 ‘적당한 정도’를 판단하고 더 ’적당한’ 점선으로 업데이트 한다.",
    "text": "Stage2: 첫번째 수정 – 최초의 점선에 대한 ‘적당한 정도’를 판단하고 더 ’적당한’ 점선으로 업데이트 한다.\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\(loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2\\)\n\\(=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\)\n- loss 함수의 특징 - \\(y_i \\approx \\hat{y}_i\\) 일수록 loss값이 작다. - \\(y_i \\approx \\hat{y}_i\\) 이 되도록 \\((\\hat{w}_0,\\hat{w}_1)\\)을 잘 찍으면 loss값이 작다. - (중요) 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875, grad_fn=<SumBackward0>)\n\n\n- 우리의 목표: 이 loss(=8587.6875)을 더 줄이자. - 궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다. (stage2에서 할일은 아님)\n- 문제의 치환: 생각해보니까 우리의 문제는 아래와 같이 수학적으로 단순화 되었다. - 적당해보이는 주황색 선을 찾자 \\(\\to\\) \\(loss(w_0,w_1)\\)를 최소로하는 \\((w_0,w_1)\\)의 값을 찾자.\n- 수정된 목표: \\(loss(w_0,w_1)\\)를 최소로 하는 \\((w_0,w_1)\\)을 구하라. - 단순한 수학문제가 되었다. 마치 \\(loss(w)=w^2-2w+3\\) 을 최소화하는 \\(w\\)를 찾으라는 것과 같음. - 즉 “적당한 선으로 업데이트 하라 = 파라메터를 학습 하라 = 손실함수를 최소화 하라”\n- 우리의 무기: 경사하강법, 벡터미분\n\n\n# Stage2를 위한 경사하강법 복습\n경사하강법 아이디어 (1차원)\n(step 1) 임의의 점을 찍는다.\n(step 2) 그 점에서 순간기울기를 구한다. (접선) <– 미분\n(step 3) 순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다.\n(팁) 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절한다.\n경사하강법 아이디어 (2차원)\n(step 1) 임의의 점을 찍는다.\n(step 2) 그 점에서 순간기울기를 구한다. (접평면) <– 편미분\n(step 3) 순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다.\n(팁) 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다.\nloss를 줄이도록 \\({\\bf W}\\)를 개선하는 방법\n- $수정값 원래값 - 기울어진크기(=미분계수) $\n\n여기에서 \\(\\alpha\\)는 전체적인 보폭의 크기를 결정한다. 즉 \\(\\alpha\\)값이 클수록 한번의 update에 움직이는 양이 크다.\n\n- \\({\\bf W} \\leftarrow {\\bf W} - \\alpha \\times \\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1)\\)\n\n마이너스의 의미: 기울기의 부호를 보고 반대방향으로 움직여라.\n\\(\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1):\\) 기울기의 절대값 크기와 비례하여 움직이는 정도를 조정하라.\n\\(\\alpha\\)의 의미: 전체적인 보폭의 속도를 조절, \\(\\alpha\\)가 크면 전체적으로 빠르게 움직인다. 다리의 길이로 비유할 수 있다.\n\n\n- 우리의 목표: loss=8587.6875 인데, 이걸 줄이는 것이 목표라고 했었음. 이것을 줄이는 방법이 경사하강법이다.\n- 경사하강법으로 loss를 줄이기 위해서는 \\(\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1)\\)의 계산이 필요한데, 이를 위해서 벡터미분이 필요하다. (loss.backward()로 하면된다)\n\nloss\n\ntensor(8587.6875, grad_fn=<SumBackward0>)\n\n\n\nloss.backward() \n\n\nloss.backward()의 의미: loss를 미분해라! 뭘로? requires_grad=True를 가진 텐서로!!\n\nloss=torch.sum((y-yhat)**2)= torch.sum((y-X@What)**2)\n# 이었고 \nWhat=torch.tensor([-5.0,10.0],requires_grad=True)\n# 이므로 결국 What으로 미분하라는 의미. \n# 미분한 식이 나오는 것이 아니고, \n# 그 식에 (-5.0, 10.0)을 대입한 계수값이 계산됨. \n- 위에서 loss.backward()의 과정은 미분을 활용하여 \\((-5,10)\\)에서의 순간기울기를 구했다는 의미임.\n- (-5,10)에서 loss의 순간기울기 값은 What.grad로 확인가능하다.\n\nWhat,What.grad\n\n(tensor([-5., 10.], requires_grad=True), tensor([-1342.2522,  1188.9305]))\n\n\n\n이것이 의미하는건 \\((-5,10)\\)에서의 \\(loss(w_0,w_1)\\)의 순간기울기가 \\((-1342.2523, 1188.9307)\\) 이라는 의미\n\n- (확인1) loss.backward()가 미분을 잘 계산해 주는 것이 맞는가? 손계산으로 검증하여 보자.\n\n\\(loss(w_0,w_1)=({\\bf y}-\\hat{\\bf y})^\\top ({\\bf y}-\\hat{\\bf y})=({\\bf y}-{\\bf XW})^\\top ({\\bf y}-{\\bf XW})\\)\n\\(\\frac{\\partial}{\\partial {\\bf W} }loss(w_0,w_1)=-2{\\bf X}^\\top {\\bf y}+2{\\bf X}^\\top {\\bf X W}\\)\n\n\n# 손계산으로 검증\n- 2 * X.T @ y + 2 * X.T @ X @ What\n\ntensor([-1342.2522,  1188.9308], grad_fn=<AddBackward0>)\n\n\n- (확인2) loss.backward()가 미분을 잘 계산해 주는 것이 맞는가? 편미분을 간단히 구현하여 검증하여 보자.\n\n\\(\\frac{\\partial}{\\partial {\\bf W} } loss(w_0,w_1)=\\begin{bmatrix}\\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1} \\end{bmatrix}loss(w_0,w_1) =\\begin{bmatrix}\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\end{bmatrix}\\)\n\\(\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\)\n\\(\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\)\n\n\n_lossfn = lambda w0,w1: torch.sum((y-w0-w1*x)**2)\n_lossfn(-5,10)\n\ntensor(8587.6875)\n\n\n\nh=0.001\n(_lossfn(-5+h,10) - _lossfn(-5,10))/h,  (_lossfn(-5,10+h) - _lossfn(-5,10))/h\n\n(tensor(-1341.7968), tensor(1190.4297))\n\n\n\n약간 오차가 있지만 얼추비슷 \\(\\to\\) 잘 계산했다는 소리임\n\n- 수정전, 수정하는폭, 수정후의 값은 차례로 아래와 같다.\n\nalpha=0.001 \nprint('수정전: ' + str(What.data)) # What 에서 미분꼬리표를 떼고 싶다면? What.data or What.detach()\nprint('수정하는폭: ' +str(-alpha * What.grad))\nprint('수정후: ' +str(What.data-alpha * What.grad))\nprint('*참값: (2.5,4)' )\n\n수정전: tensor([-5., 10.])\n수정하는폭: tensor([ 1.3423, -1.1889])\n수정후: tensor([-3.6577,  8.8111])\n*참값: (2.5,4)\n\n\n- Wbefore, Wafter 계산\n\nWbefore = What.data\nWafter = What.data- alpha * What.grad\nWbefore, Wafter\n\n(tensor([-5., 10.]), tensor([-3.6577,  8.8111]))\n\n\n- Wbefore, Wafter의 시각화\n\nplt.plot(x,y,'o')\nplt.plot(x,X@Wbefore,'--')\nplt.plot(x,X@Wafter,'--')"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn1.html#stage3-learn-estimate-bfhatw",
    "href": "posts/DNN/2023-03-01-dnn1.html#stage3-learn-estimate-bfhatw",
    "title": "딥러닝 기초 (1)",
    "section": "Stage3: Learn (=estimate \\(\\bf\\hat{W})\\)",
    "text": "Stage3: Learn (=estimate \\(\\bf\\hat{W})\\)\n- 이 과정은 Stage1,2를 반복하면 된다.\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True) #\n\n\nalpha=0.001 \nfor epoc in range(30): ## 30번 반복합니다!! \n    yhat=X@What \n    loss=torch.sum((y-yhat)**2)\n    loss.backward() \n    What.data = What.data-alpha * What.grad\n    What.grad=None # 미분값 초기화 (초기화 하지 않으면 누적됨.)\n\n\n원래 철자는 epoch이 맞아요\n\n- 반복결과는?! (최종적으로 구해지는 What의 값은?!) - 참고로 true\n\nWhat.data ## true인 (2.5,4)와 상당히 비슷함\n\ntensor([2.4290, 4.0144])\n\n\n- 반복결과를 시각화하면?\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn1.html#학습과정의-기록",
    "href": "posts/DNN/2023-03-01-dnn1.html#학습과정의-기록",
    "title": "딥러닝 기초 (1)",
    "section": "학습과정의 기록",
    "text": "학습과정의 기록\n- 기록을 해보자.\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.001 \nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n- \\(\\hat{y}\\) 관찰 (epoch=3, epoch=10, epoch=15)\n\n## epoch=3\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[2],'--')\n\n\n\n\n\n## epoch=10\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[9],'--')\n\n\n\n\n\n# epoch=15\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[14],'--')\n\n\n\n\n- \\(\\hat{\\bf W}\\) 관찰\n\nWhat_history\n\n[[-3.657747745513916, 8.81106948852539],\n [-2.554811477661133, 7.861191749572754],\n [-1.649186134338379, 7.101552963256836],\n [-0.9060712456703186, 6.49347448348999],\n [-0.2966785430908203, 6.006272315979004],\n [0.20277434587478638, 5.615575313568115],\n [0.6119105815887451, 5.302003383636475],\n [0.9469034671783447, 5.050129413604736],\n [1.2210699319839478, 4.847657680511475],\n [1.4453645944595337, 4.684779167175293],\n [1.6287915706634521, 4.553659439086914],\n [1.778746247291565, 4.448036193847656],\n [1.90129816532135, 4.3628973960876465],\n [2.0014259815216064, 4.294229507446289],\n [2.0832109451293945, 4.238814353942871],\n [2.149996757507324, 4.194070339202881],\n [2.204521894454956, 4.157923698425293],\n [2.249027729034424, 4.128708839416504],\n [2.285348415374756, 4.105085849761963],\n [2.31498384475708, 4.0859761238098145],\n [2.339160442352295, 4.070511341094971],\n [2.3588807582855225, 4.057991027832031],\n [2.3749637603759766, 4.0478515625],\n [2.3880786895751953, 4.039637088775635],\n [2.3987717628479004, 4.032979965209961],\n [2.40748929977417, 4.027583599090576],\n [2.414595603942871, 4.023208141326904],\n [2.4203879833221436, 4.019659042358398],\n [2.4251089096069336, 4.016779899597168],\n [2.4289560317993164, 4.014443874359131]]\n\n\n- loss 관찰\n\nplt.plot(loss_history)"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn1.html#학습과정을-animation으로-시각화",
    "href": "posts/DNN/2023-03-01-dnn1.html#학습과정을-animation으로-시각화",
    "title": "딥러닝 기초 (1)",
    "section": "학습과정을 animation으로 시각화",
    "text": "학습과정을 animation으로 시각화\n\nfrom matplotlib import animation\n\n\nplt.rcParams['figure.figsize'] = (7.5,2.5)\nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n- 왼쪽에는 \\((x_i,y_i)\\) and \\((x_i,\\hat{y}_i)\\) 을 그리고 오른쪽에는 \\(loss(w_0,w_1)\\) 을 그릴것임\n\nfig = plt.figure()\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n\n\n\n- 왼쪽그림!\n\nax1.plot(x,y,'o')\nline, = ax1.plot(x,yhat_history[0]) # 나중에 애니메이션 할때 필요해요..\n\n\nfig\n\n\n\n\n- 오른쪽 그림1: \\(loss(w_0,w_1)\\)\n\n_w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) \n_w1 = np.arange(-6, 11, 0.5)\nw1,w0 = np.meshgrid(_w1,_w0)\nlss=w0*0\nfor i in range(len(_w0)):\n    for j in range(len(_w1)):\n        lss[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2)\nax2.plot_surface(w0, w1, lss, rstride=1, cstride=1, color='b',alpha=0.35) ## 파란색곡면을 그리는 코드(끝) \nax2.azim = 40  ## 3d plot의 view 조절 \nax2.dist = 8   ## 3d plot의 view 조절 \nax2.elev = 5   ## 3d plot의 view 조절 \n\nMatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\nfig\n\n\n\n\n- 오른쪽 그림2: \\((w_0,w_1)=(2.5,4)\\) 와 \\(loss(2.5,4)\\) 값 <- loss 함수가 최소가 되는 값 (이거 진짜야? ㅋㅋ)\n\nax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color='red',marker='*') ## 최소점을 표시하는 코드 (붉은색 별) \n\n<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fc11ff14fa0>\n\n\n\nfig\n\n\n\n\n- 오른쪽 그림3: \\((w_0,w_1)=(-3.66, 8.81)\\) 와 \\(loss(-3.66,8.81)\\) 값\n\nWhat_history[0]\n\n[-3.657747745513916, 8.81106948852539]\n\n\n\nax2.scatter(What_history[0][0],What_history[0][1],loss_history[0],color='grey') ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) \n\n<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fc1379569d0>\n\n\n\nfig\n\n\n\n\n- 애니메이션\n\ndef animate(epoc):\n    line.set_ydata(yhat_history[epoc])\n    ax2.scatter(What_history[epoc][0],What_history[epoc][1],loss_history[epoc],color='grey')\n    return line\n\nani = animation.FuncAnimation(fig, animate, frames=30)\nplt.close()\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 함수로 만들자..\n\ndef show_lrpr(data,history):\n    x,y = data \n    loss_history,yhat_history,What_history = history \n    \n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n    ## ax1: 왼쪽그림 \n    ax1.plot(x,y,'o')\n    line, = ax1.plot(x,yhat_history[0]) \n    ## ax2: 오른쪽그림 \n    _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) \n    _w1 = np.arange(-6, 11, 0.5)\n    w1,w0 = np.meshgrid(_w1,_w0)\n    lss=w0*0\n    for i in range(len(_w0)):\n        for j in range(len(_w1)):\n            lss[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2)\n    ax2.plot_surface(w0, w1, lss, rstride=1, cstride=1, color='b',alpha=0.35) ## 파란색곡면을 그리는 코드(끝) \n    ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color='red',marker='*') ## 최소점을 표시하는 코드 (붉은색 별) \n    ax2.scatter(What_history[0][0],What_history[0][1],loss_history[0],color='b') ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) \n    ax2.azim = 40  ## 3d plot의 view 조절 \n    ax2.dist = 8   ## 3d plot의 view 조절 \n    ax2.elev = 5   ## 3d plot의 view 조절 \n\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(What_history)[epoc,0],np.array(What_history)[epoc,1],loss_history[epoc],color='grey')\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\nMatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn1.html#alpha0.0001-alpha-가-너무-작다면-to-비효율적이다.",
    "href": "posts/DNN/2023-03-01-dnn1.html#alpha0.0001-alpha-가-너무-작다면-to-비효율적이다.",
    "title": "딥러닝 기초 (1)",
    "section": "(1) \\(\\alpha=0.0001\\): \\(\\alpha\\) 가 너무 작다면? \\(\\to\\) 비효율적이다.",
    "text": "(1) \\(\\alpha=0.0001\\): \\(\\alpha\\) 가 너무 작다면? \\(\\to\\) 비효율적이다.\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0001 \nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\nMatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn1.html#alpha0.0083-alpha가-너무-크다면-to-다른의미에서-비효율적이다-위험하다..",
    "href": "posts/DNN/2023-03-01-dnn1.html#alpha0.0083-alpha가-너무-크다면-to-다른의미에서-비효율적이다-위험하다..",
    "title": "딥러닝 기초 (1)",
    "section": "(2) \\(\\alpha=0.0083\\): \\(\\alpha\\)가 너무 크다면? \\(\\to\\) 다른의미에서 비효율적이다 + 위험하다..",
    "text": "(2) \\(\\alpha=0.0083\\): \\(\\alpha\\)가 너무 크다면? \\(\\to\\) 다른의미에서 비효율적이다 + 위험하다..\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0083\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\nMatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn1.html#alpha0.0085-to-다른의미에서-비효율적이다.-위험하다.",
    "href": "posts/DNN/2023-03-01-dnn1.html#alpha0.0085-to-다른의미에서-비효율적이다.-위험하다.",
    "title": "딥러닝 기초 (1)",
    "section": "(3) \\(\\alpha=0.0085\\) \\(\\to\\) 다른의미에서 비효율적이다. + 위험하다.",
    "text": "(3) \\(\\alpha=0.0085\\) \\(\\to\\) 다른의미에서 비효율적이다. + 위험하다.\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0085\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad.data; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\nMatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\nstepsize가 너무 크면 터질 수 있다."
  },
  {
    "objectID": "posts/DNN/2023-03-01-dnn1.html#alpha0.01",
    "href": "posts/DNN/2023-03-01-dnn1.html#alpha0.01",
    "title": "딥러닝 기초 (1)",
    "section": "(4) \\(\\alpha=0.01\\)",
    "text": "(4) \\(\\alpha=0.01\\)\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.01\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\nMatplotlibDeprecationWarning: The dist attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.\n  ax2.dist = 8   ## 3d plot의 view 조절\n\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/GCN/2023-02-21-gcn1.html",
    "href": "posts/GCN/2023-02-21-gcn1.html",
    "title": "Graph Convolutional Network",
    "section": "",
    "text": "GCN의 개념에 대해 학습해보자.\n\n\n\n\n\nMany important real-world datasets come in the form of graphs or networks: social networks, knowledge graphs, protein-interaction networks, the World Wide Web, etc. (just to name a few).\n\n대부분의 머신러닝 알고리즘은 입력 데이터가 유클리디안 공간 (Euclidean space)에 존재함을 가정하고 있다. 즉, 통계 데이터나 이미지처럼 입력 데이터가 벡터의 형태로 표현될 수 있어야 한다. 그러나 소셜 네트워크, 관계형 데이터베이스, 분자 구조 등과 같이 객체들과 그 객체들 간의 관계로 표현되는 데이터는 기본적으로 위와 같은 그래프로 표현된다.\n또한, 만약 사용자나 원자의 속성, 연결의 종류 등을 고려해야하는 경우에는 단순히 node와 edge로 이루어진 그래프가 아니라, node feature matrix와 edge feature matrix가 추가된 속성 그래프 (attributed graph)로 데이터를 표현해야 한다. 이러한 형태의 그래프 데이터는 유클리드 공간에 존재하지 않으며, 직접적인 방식으로 벡터의 형태로 변환하는 것 또한 불가능하다. 따라서, 벡터 형태의 입력 데이터를 가정하는 기존의 인공신경망 (Artificial Neural Network, ANN)으로는 분자 구조와 같은 그래프 형태의 데이터를 처리할 수 없다는 문제점이 존재한다.\n(+) 행동 인식 분야에서 가장 핫하게 등장하는 네트워크가 바로 GCN(Graph Convolutional Networks)이다. GCN은 쉽게 설명하자면, 어떤 그래프 구조를 이미지 convolution과 유사한 방식으로 연산해서 특징점을 추출하는 네트워크라고 보면 될 것 같다. 사람의 몸도 어떻게 보면 각 관절과 그 관절들이 연결되어있는 구조로 그래프 구조라고 볼 수 있다. 그렇기 때문에 GCN을 사용한 논문들에서도 좋은 성능을 보이고 있다.\n\nref: (AAAI-2018) Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition\n\n\n\n\n\n\nGraph는 vertex(node)와 edge로 이루어져있다. 이 때 node는 한 input data를 의미하고 edge는 두 데이터 간의 relationship을 의미한다. (어차피 같은 의미이지만 앞으로는 vertex 대신 node라는 표현을 많이 사용할 것이다.)\n\n소셜 그래프에서 node는 사람, edge는 두 사람 사이의 관계를 의미한다.\nWeighted Grapgh vs. Unweighted Graph\nDirected Graph vs. Undirected Graph\n(참고) 위의 그래프의 경우 방향성이 존재하지 않는 undirected Graph이다.\n\n\n\n\n모든 노드간의 relationship 정보를 담고있도록 data를 표현해야하므로 이 정보들은 1. Adgacency matrix로 나타낼 수 있다. 또한 노드간의 relationship정보 말고도 node 자체가 가지고 있는 feature 정보가 있으므로 이는 2. Feature matrix로 나타낸다.\n\n1 Network(Graph data) \\(\\to\\) Adjacency matrix\n\n\\(n\\) 개의 노드가 있다면 Adjacency matrix는 \\(n\\times n\\) 크기를 갖게 된다.\n\n5개의 노드가 있으므로 \\(5\\times 5\\) Adjacency matrix\n\n\\(\\bf{A}_{ij}\\) : Adjacency matrix의 \\(i\\)번째 row와 \\(j\\)번째 컬럼에 있는 값을 나타내며, \\(i\\)번째 노드와 \\(j\\)번째 노드가 서로 연결이 되어 있는지를 나타낸다.\n\n노드 사이에 엣지가 있는지? (있으면 \\(1\\), 없으면 \\(0\\))\n\n\n2 Feature matrix\n\nFeature matirx로 각 노드의 정보를 나타낸다.\n\nFeature matrix의 크기는 \\(n(\\text{노드의 수}) \\times f(\\text{feature 개수})\\) 이며, \\(f\\)는 설정함에 따라서 많아질 수도 있고 적어질 수도 있는 값이다.\nfeature matrix를 \\(\\bf{X}\\) 라고 하자, 이 때 \\(\\bf{X}_{ij}\\) 가 의미하는 것은 i번째 노드에 j번째 feature가 무엇인지 나타내는 것이다.\n\n\n\n\n\n\n\n데이터의 구조를 고려해야 한다는 점은 이미지뿐만 아니라 그래프 데이터에서도 매우 중요하기 때문에 이미지에 대한 convolution을 일반화하여 그래프 데이터에 적용하기 위한 연구가 머신러닝 분야에서 활발히 진행되었다. 그래프 합성곱 신경망 (Graph Convolutional Network, GCN)은 이미지에 대한 convolution을 그래프 데이터로 확장한 머신러닝 알고리즘이다.\n이부분에 대해 이해를 하려면 먼저 CNN에 이해가 필요할 것 같다.\n\n\n\n\n\nStanford, cs231n 2017\n\n\n\n\n\nReduce the number of parameters \\(\\to\\) less overfitting, low computational cost\nLearn local features\nTranslation invariance\n\n\n\n\n\n어쨌든 얘도 convolutional network니까 CNN을 보고 이것을 이미지가 아닌 그래프에 적용시켜본다면 구조를 어떻게 바꿔야 할지지 생각해보자.\n\nCNN updates values in activation map in each layer. Values of activation map determine the state of image.\nValues of each node feature determine the state of graph. \\(\\to\\) Make each layer of network update values of each node feature\n\n그래프의 정보를 결정하는 것은 무엇일까? 이미지는 activation map에 있는 value들이 그 이미지에 담긴 상태가 뭔지, 이미지에 담긴 정보가 뭔지를 결정을 하는 값들이었는데 그래프 같은 경우에는 각 노드에 담긴 value 즉, node feature matrix 안에 담긴 정보가 업데이트 되도록 하면 되겠다.\n결국 중요한 것은 Graph Convolutional Layer를 거치게 되면 노드 피처에 담긴 값이 업데이트가 되어야 한다는 것을 convolutional network를 통해 알 수 있었다.\n그렇다면 어떤 방식으로 업데이트를 해야 타당할까?\n어쨌든 이것도 컨볼루션이니까 컨볼루션은 어떤 작은 웨이트를 쭉 이동시키는 연산이었는데 중요한 특성은 Weight sharing을 한다는 것이었고, 어떤 로컬한 이 값 근처에 있는 값들만 weight에 들어가서 로컬한 피처를 배운다는 것이 또 하나의 특징이었다. 그래서 그 뉴런이 receptive field를 갖게 된다. (어떤 전체의 데이터에 정보를 하나의 뉴런이 다 받는게 아니라 어떤 로컬한 부분에 있는 정보를 이제 뉴런이 받게 되고 이를 receptive field 라고 한다.)\n그런 특성을 그럼 그래프에는 어떻게 적용시켜야 될까? 노드의 피처를 계쏙 업데이트 한다는 것은 각 노드의 정보를 업데이트 하는 것 그래서 노드 피처 매트릭스를 다시 그려보면 \\(n\\)개의 노드가 있는 그래프일 때 \\(n\\times f\\text{(feature 개수)}\\)의 shape을 갖고 이 matrix의 i번째 row가 의미하는 것은 i번째 노드의 피처/상태/정보를 담고있다고 앞에서 배웠다.\n아까 말했듯이 layer를 하나 거쳐서 이 node feature matrix를 업데이트 한다는 것은 이 각각의 row를 즉, 각각의 노드의 정보를 업데이트 해주면 될 것 같다.\n그럼 어떤 방식으로 업데이트를 할 거냐? convolution network 같이 그 주변에 있는 애들의 정보만 받아서 업데이트를 하자 이런식으로 생각해 볼 수 있을 것 같다.\n\n\n\n\n\n\nimage.png\n\n\n\\[H_1^{(l+1)} = \\sigma(H_1^{(l)}W^{(l)} + H_2^{(l)}W^{(l)} + H_3^{(l)}W^{(l)} + H_4^{(l)}W^{(l)} + b^{(l)})\\]\n\\[\\Rightarrow H_i^{(l+1)} = \\sigma\\Big(\\sum_{j\\in N(i)} H_j^{(l)}W^{(l)} + b^{(l)} \\Big)\\]\n\\[W: \\text{weight},\\quad W^{(l)}: l\\text{번째 layer의 weight},\\quad H:\\text{hidden state}, \\quad \\sigma: \\text{activation function}\\]\n(참고) 여기서는 node feature matrix를 hidden state라고 부를 것임\n위의 그림과 같은 그래프가 있다고 가정해보자. 그래프의 번호가 1번, 2번, 3번, 4번 이런식으로 붙여졌다고 할 때 \\(H_1^{(l+1)}\\), 즉 하나의 \\((l+1)\\)번 째 layer를 통과하게 되면 \\(H_1\\)의 정보는 자기 자신의 웨이트를 더하고, 그 다음에 연결되어 있는 \\(H_2\\)의 hidden state에 weight를 곱하고, \\(H_3\\)의 hidden state에 weight를 곱하고 \\(H_4\\)의 hidden state에 weight를 곱하고 bias를 더해서 activation을 거쳐서 다음 layer의 값을 업데이트 하면 되겠다.\n이렇게 되면 이제 convolutional layer처럼 어떤 local한 feature를 뽑아낼 수 있고, 그럼 이 다음 노드가 받은 것은 1번, 2번, 3번, 4번 노드의 정보만 받아서 다음 뉴런에 전달을 해주는 것이고, 연결되지 않은 5번, 6번, 7번에 대해서는 들어가지 않았으니까 1번 노드의 정보는 1번 노드의 근처에 있는 로컬한 정보를 뽑아냈다라고 볼 수 있다.\n또한 이 weight가 다 똑같기 때문에 weight sharing을 한다. 즉, 전체가 다 연결되어 있는게 아니라 어쨌든 얘도 어떤 노드의 정보는 그 구조가 다 비슷할 것이다. 왜냐하면 처음에 같은 이 feature의 순서가 똑같았으니까 거기에 어차피 얘들도 다 비슷한 애들이니까 같은 weight를 곱해서 general한 정보를 뽑아낼 수 있게 마치 LSTM에서 각각의 워드에 다 똑같은 weight를 곱해줬던 것 처럼(왜냐하면 이 word는 다 비슷한 특성을 가지고 있기 때문에) 얘들도 각각의 노드에 피처가 비슷한 성격을 띄고 있을 거니까 같은 weight를 sharing해서 곱해줘서 computational cost도 낮추고 efficiency도 높일 수 있겠다.\n그래서 이런식으로 업데이트 하면 아까 convolutional layer의 두 가지 특성이였던 weight sharing과 local feature를 뽑아낸다는 것 둘 다 가지고 있게 됐다.\n실질적으로 구현할 때 1번 노드에 연결되었는지 다 보고, 1번노드와 연결되어 있는 애들을 weight 타고 다 더한다음에 2번노드로 가서 2번노드에 뭐가 연결되어있는지 다 보고, 그 다음에 종합해서 업데이트 하고, 3번노드 뭐랑 연결되어있는지 다 보고,,이렇게 할 수는 없겠죠.(for문을 엄청나게 많이 사용해서 속도가 느려질 것이다.)\n그러면 우리가 graph structure를 adjacency matrix로 나타내는데 그럼 이 adjacency matrix가 결국은 connectivity를 담고있는 매트릭스이다. 그럼 이것을 어떻게 잘 활용하면 한번에 행렬연산으로 할 수 있을 것 같다. (행렬 연산은 gpu가 빠르게 잘함)\n- 예제\n자기자신과 연결되어있다고 가정, feature의 개수도 임의로 10으로 지정\n보기 쉽게 node feature matrix를 H라고 놓자. (오른쪽 matrix가 H임)\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n그 새로운 값은 각각의 노드의 근처에 있는 값들만 받아들여서 convolution 연산을 한 효과를 냈고, 그리고 그 weight들은 다 똑같다. 그 weight를 곱할때 filter마다는 다르지만 동인한 하나의 필터 내에서는 같은 weight들이 서로 다른 노드에 곱해진다.\n그래서 이런식으로 하면 weight sharing을 하고, local feature를 뽑아내는 convolutional layer의 특성을 가지면서도 for문을 돌고 하는게 아니라 행렬연산을 통해 이것을 구현 함으로써 GPU에 넣었을 때 훨씬 빠르고 gradient 계산하는 것도 병렬화되서 훨씬 빠르게 할 수 있기 떄문에 이렇게 구현하면 쓸 수 있겠다고 생각해볼 수 있다.\n타당한 structure인 것 같다.\n\\[H^{(l+1)} = \\sigma(AH^{(l)}W^{(l)}+b^{(l)})\\]\n다음 layer의 hidden state는 이전 layer의 hidden stat에 weight를 곱하고 여기에 adjacency matrix를 곱하면 그 connectivity에 들어가는 정보가 들어가서 각각의 노드가 연결되어 있는 애들의 정보만 받게되고, 이것도 어쨌든 컨볼루션을 했으니까 activation을 씌워주면 update된 값을 얻을 수 있다.\n\n\n\n\nPermutation invariance는 adjency matrix의 순서가 바뀌더라도 그 output이 변하지 않는 함수의 특성을 말한다.\n\n\\[f(PAP^{T}) = f(A)\\]\n(참고) 위 식에서 \\(\\bf{A}\\)는 adjacency matrix, \\(\\bf{P}\\)는 행과 열의 순서를 바꾸는 permutation matrix이다. 위 식은 위에서 설명한 것처럼 adjacency matrix 내의 노드의 순서가 바뀌어도 함수의 결과는 바뀌지 않는다.\n\n\n\nimage.png\n\n\n그래프를 adjacency matrix와 node feature matrix로 표현을 했는데 node feature matrix에 순서가 있다. 노드의 순서가 바뀐다고 해서 그래프가 달라지지는 않는다. 노드의 배치만 바뀌었을 뿐 노드의 특성과 엣지는 다 똑같이 연결되어 있으니까 같은 그래프이다.그런데 우리가 표현하는 node feature matrix는 바뀌게 될것이다. (row의 순서가 뒤죽박죽..)근데 결국 얘네들은 같은 그래프이니까 feature를 뽑아낼 때 같은 값이 나와야 된다. (순서가 다르게되어 있다고 다른값이 나오면 안되겠죠) 따라서 이걸 하기 위해서 Readout layer를 거치게 된다.\n이 Readout layer의 역할은 permutation invariance를 준다. 즉, permutation이 어떻게 되어있든 관계없이 invariance하게 하는 역할을 수행해준다. 다양한 방법이 있지만 가장 간단한 방법은 위와 같다.\n\n\n\n\n\n\n\nimage.png\n\n\nGCN을 거친 후 마지막에 Readout layer를 통해 최종적으로 classification 혹은 value를 regression한다. CNN에서 Conv-pool layer들을 거친 후 마지막에 모든 node들 정보를 취합하기 위해 FC-layer를 거친 후 softmax를 통해 classification작업을 수행한다.\n마찬가지로 Graph Neural Network에서도 graph convolution layer들을 거친 후 MLP로 모든 node 정보를 취합하고 최종적으로 regression 혹은 classification을 위해 어떤 값을 결정짓는 작업이 필요하다. 이를 GCN에서 readout-layer라고 한다\n\n\n\nimage.png\n\n\n\n\n\nGCN을 비롯한 graph neural network (GNN)을 직접 구현하는 것은 인접 행렬과 node feature matrix를 추출하는 것부터 여러 그래프의 batch를 만드는 것 까지 많은 어려움이 따른다. PyTorch를 기준으로는 Deep Graph Library (DGL)와 PyTorch Geometric이라는 라이브러리가 GNN과 이를 이용한 딥 러닝에 관한 여러 구현을 제공하고 있다.\n\n\n\n\nhttps://tkipf.github.io/graph-convolutional-networks/\nhttps://untitledtblog.tistory.com/152"
  },
  {
    "objectID": "posts/GCN/2023-02-27-gcn-prac.html",
    "href": "posts/GCN/2023-02-27-gcn-prac.html",
    "title": "GCN Implementation",
    "section": "",
    "text": "cora dataset\n\n\nimport torch_geometric\n\n\nfrom typing import Callable, List, Optional, Tuple\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport torch_geometric.transforms as T\nfrom torch import Tensor\nfrom torch.optim import Optimizer\nfrom torch_geometric.data import Data\nfrom torch_geometric.datasets import Planetoid\nfrom torch_geometric.nn import GCNConv\n# from torch_geometric.utils import accuracy\nfrom typing_extensions import Literal, TypedDict\n\nThe Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words.\n\ndataset = Planetoid('./cora', name='Cora')\n\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\nDownloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\nProcessing...\nDone!\n\n\n\nnum_nodes = dataset.data.num_nodes\nnum_edges = dataset.data.num_edges // 2\ntrain_len = dataset[0].train_mask.sum()\nval_len = dataset[0].val_mask.sum()\ntest_len = dataset[0].test_mask.sum()\nother_len = num_nodes - train_len - val_len - test_len\nprint(f'Dataset: {dataset.name}')\nprint(f'Num. nodes: {num_nodes}(train={train_len},val={val_len}, test={test_len}, other={other_len})')\nprint(f'Num. edges: {num_edges}')\nprint(f'Num. node features: {dataset.num_node_features}')\nprint(f'Num. classes: {dataset.num_classes}')\nprint(f'Dataaset len.: {dataset.len()}')\n\nDataset: Cora\nNum. nodes: 2708(train=140,val=500, test=1000, other=1068)\nNum. edges: 5278\nNum. node features: 1433\nNum. classes: 7\nDataaset len.: 1\n\n\n\nclass GCN(torch.nn.Module):\n    def __init__(\n        self,\n        num_node_features: int,\n        num_classes: int,\n        hidden_dim: int = 16,\n        dropout_rate: float = 0.5,\n    ) -> None:\n        super().__init__()\n        self.dropout1 = torch.nn.Dropout(dropout_rate)\n        self.conv1 = GCNConv(num_node_features, hidden_dim)\n        self.relu = torch.nn.ReLU(inplace=True)\n        self.dropout2 = torch.nn.Dropout(dropout_rate)\n        self.conv2 = GCNConv(hidden_dim, num_classes)\n        \n    def forward(self, x: Tensor, edge_index: Tensor) -> torch.Tensor:\n        x = self.dropout1(x)\n        x = self.conv1(x, edge_index)\n        x = self.relu(x)\n        x = self.dropout2(x)\n        x = self.conv2(x, edge_index)\n        return x\n\n\nGCN(dataset.num_node_features, dataset.num_classes, 16, 0.5)\n\nGCN(\n  (dropout1): Dropout(p=0.5, inplace=False)\n  (conv1): GCNConv(1433, 16)\n  (relu): ReLU(inplace=True)\n  (dropout2): Dropout(p=0.5, inplace=False)\n  (conv2): GCNConv(16, 7)\n)\n\n\n\ndataset = Planetoid('./cora', name='Cora')\nprint(f'Sum of row values without normalization: {dataset[0].x.sum(dim=-1)}')\n\ndataset = Planetoid('./cora', name='Cora', transform=T.NormalizeFeatures())\nprint(f'Sum of row values with normalization: {dataset[0].x.sum(dim=-1)}')\n\nSum of row values without normalization: tensor([ 9., 23., 19.,  ..., 18., 14., 13.])\nSum of row values with normalization: tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000])\n\n\n\n\n\nLossFn = Callable[[Tensor, Tensor], Tensor]\nStage  = Literal['train','val','test']\n\ndef train_step(\n    model: torch.nn.Module, date: Data, optimizer: torch.optim.Optimizer, loss_fn:LossFn\n) -> Tuple[float, float]:\n    model.train()\n    optimizer.zero_grad()\n    mask = data.train_mask\n    logits = model(data.x, data.edge_index)[mask]\n    preds = logits.argmax(dim=1)\n    y = data.y[mask]\n    loss = loss_fn(logits, y)\n    # L2 regularization to the first layer only\n    \n    acc = accuracy(preds, y)\n    loss.backward()\n    optimizer.step()\n    return loss.item(), acc\n\n@torch.no_grad()\ndef eval_step(model: torch.nn.Module, data: Data, loss_fn:LossFn, stage: Stage) -> Tuple[float,float]:\n    model.eval()\n    mask = getattr(data, f'{stage}_mask')\n    logits = model(data.x, data.edge_index)[mask]\n    preds = logits.argmax(dim=1)\n    y = data.y[mask]\n    loss = loss_fn(logits, y)\n    \n    acc = accuracy(preds, y)\n    return loss.item(), acc\n\n\nclass HistoryDict(TypedDict):\n    loss: List[float]\n    acc: List[float]\n    val_loss: List[float]\n    val_acc: List[float]\n    \ndef train(\n    model: torch.nn.Module,\n    date: Data,\n    optimizer: torch.optim.Optimizer,\n    loss_fn: LossFn = torch.nn.CrossEntropyLoss(),\n    max_epochs: int=200,\n    early_stopping: int=10,\n    print_interval: int=20,\n    verbose: bool=True,\n) -> HistoryDict:\n    history = {'loss':[], 'val_loss':[], 'acc_loss':[], 'val_acc':[]}\n    for epoch in range(max_epochs):\n        loss, acc = train_step(model, data, optimizer, loss_fn)\n        val_loss, val_acc = eval_step(model, data, loss_fn, 'val')\n        history['loss'].append(loss)\n        history['acc'].append(acc)\n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        \n        if epoch > early_stopping and val_loss > np.mean(history['val_loss'][-(early_stopping + 1):-1]):\n            if verbose:\n                print('\\nEarly stopping...')\n            break\n            \n        if verbose and epoch % print_interval == 0:\n            print(f'nEpoch: {epoch}\\n--------------')\n            print(f'Train loss: {loss:.4f} | Train acc: {acc:.4f}')\n            print(f' Val loss: {loss:.4f} | Val acc: {val_acc:.4f}')\n    \n    test_loss, test_acc = eval_step(model, data, loss_fn, 'test')\n    if verbose:\n        print(f'nEpoch: {epoch}\\n--------------')\n        print(f'Train loss: {loss:.4f} | Train acc: {acc:.4f}')\n        print(f' Val loss: {loss:.4f} | Val acc: {val_acc:.4f}')\n    return history\n        \n\n\nSEED = 42\nMAX_EPOCHS = 200\nLEARNING_RATE = 0.01\nWEIGHT_DECAY = 5e-4\nEARLY_STOPPING = 10\n\n\ntorch.manual_seed(SEED)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = GCN(dataset.num_node_features, dataset.num_classes).to(device)\ndata = dataset[0].to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\nhistory = train(model, data, optimizer, max_epochs=MAX_EPOCHS, early_stopping=EARLY_STOPPING)\n\nIndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)\n\n\n\n뭐가 문제지? ㅠㅠㅠ"
  },
  {
    "objectID": "posts/study/2023-03-05-test27.html",
    "href": "posts/study/2023-03-05-test27.html",
    "title": "27_test",
    "section": "",
    "text": "library(tidyverse)\nlibrary(recipes)\nlibrary(caret)\nlibrary(rsample)\n\n\ndat <- read_csv('fraud.csv')\n\nRows: 1234 Columns: 20\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (20): v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13, v14, v15, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndat %>% head()\n\n# A tibble: 6 × 20\n      v1      v2      v3     v4     v5      v6      v7      v8     v9    v10\n   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>\n1  1.92   0.0541 -1.65    1.44   0.373 -1.13    0.721  -0.436   0.191  0.231\n2  0.327  0.164  -2.82   -2.70   3.11   2.75    0.517   0.523  -1.49  -0.114\n3 -0.348  0.648   0.545  -2.53   1.17   0.0920  1.03   -0.126   0.515 -1.05 \n4  1.39  -0.250  -0.0641 -0.733 -0.576 -1.17   -0.0445 -0.344  -1.60   0.820\n5  1.54  -1.19    0.586  -1.42  -1.75  -0.568  -1.38   -0.0151 -1.31   1.48 \n6 -0.419  0.687   1.49   -0.109  0.519 -0.129   0.523  -0.0507  1.13  -0.245\n# … with 10 more variables: v11 <dbl>, v12 <dbl>, v13 <dbl>, v14 <dbl>,\n#   v15 <dbl>, v16 <dbl>, v17 <dbl>, time <dbl>, amount <dbl>, class <dbl>"
  },
  {
    "objectID": "posts/study/2023-02-25-chap12.2.html",
    "href": "posts/study/2023-02-25-chap12.2.html",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "",
    "text": "using LinearAlgebra, DSP"
  },
  {
    "objectID": "posts/study/2023-02-25-chap12.2.html#simultaneously-diagonalizable",
    "href": "posts/study/2023-02-25-chap12.2.html#simultaneously-diagonalizable",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "Simultaneously Diagonalizable",
    "text": "Simultaneously Diagonalizable\n매트릭스 \\(\\bf{A}\\)와 \\(\\bf{B}\\)가 대각화 가능하다는 것은 아래의 표현을 만족한 적당한 invertible matrix와 \\({\\bf \\Psi}_A,{\\bf \\Psi}_B\\)와 대각행렬 \\({\\bf \\Lambda}_A,{\\bf \\Lambda}_B\\)가 존재한다는 의미가 된다.\n\\[{\\bf A} = {\\bf V}_{A} {\\bf \\Lambda}_A {\\bf V}_{A}^{-1}\\]\n\\[{\\bf B} = {\\bf V}_{B} {\\bf \\Lambda}_B {\\bf V}_{B}^{-1}\\]\n그리고 만약에 \\({\\bf V}_{A}={\\bf V}_{B}\\)이라면 즉,\n\\[{\\bf A} = {\\bf V} {\\bf \\Lambda}_A {\\bf V}^{-1}\\]\n\\[{\\bf B} = {\\bf V} {\\bf \\Lambda}_B {\\bf V}^{-1}\\]\n이라면 \\(\\{{\\bf A},{\\bf B}\\}\\)가 simultaneosuly diagonalizable 하다고 표현한다."
  },
  {
    "objectID": "posts/study/2023-02-25-chap12.2.html#commute",
    "href": "posts/study/2023-02-25-chap12.2.html#commute",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "Commute",
    "text": "Commute\n두 matrix \\(\\bf{A}\\) 와 \\(\\bf{B}\\)에 대하여\n\\[{\\bf A}{\\bf B}= {\\bf B}{\\bf A}\\]\n인 관계가 성립하면 두 매트릭스가 commute한다고 표현한다. 그런데 \\({\\bf A}{\\bf B}= {\\bf B}{\\bf A}\\)의 조건은 \\(\\bf{A}, \\bf{B}\\)가 동시대각화가능할(simultaneously diagonalizable) 조건과 같다. 따라서 simultaneously diagonalizable는 commute와 같은 말이라 생각해도 무방하다."
  },
  {
    "objectID": "posts/study/2023-02-25-chap12.2.html#shift-invariant-filter",
    "href": "posts/study/2023-02-25-chap12.2.html#shift-invariant-filter",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "Shift Invariant Filter",
    "text": "Shift Invariant Filter\nDefine the matrix \\({\\bf B}\\) as periodic shift matrix such that\n\\[\n{\\bf B} = \\begin{bmatrix}\n0 & 0 & 0 & \\dots  & 0 & 1 \\\\\n1 & 0 & 0 & \\dots & 0 & 0 \\\\\n0 & 1 & 0 & \\dots & 0 & 0 \\\\\n\\dots & \\dots & \\dots & \\dots & \\dots & \\dots\\\\\n0 & 0 & \\dots & 1 & 0 & 0 \\\\\n0 & 0 & \\dots & 0 & 1 & 0 \\\\\n\\end{bmatrix}.\\]\nA generic filter \\({\\boldsymbol h}\\) is given by its \\(z\\)-transform\n\\[h(z)=h_0z^0+h_1z^{-1}+\\cdots +h_{N-1}z^{-(N-1)}\\]\nwhere \\(s_{n-1}=z^{-1}s_n\\). In vector notation, and with respect to the standard basis \\({\\bf I}\\), the filter is represented by the matrix \\({\\bf H}\\), a polynomial in the cyclic shift\n\\[{\\bf H}=h({\\bf B})=h_0{\\bf B}^0+h_1{\\bf B}^1+\\cdots+h_{N-1}{\\bf B}^{N-1}.\\]\nFilters are shift invariant iff\n\\[z\\cdot h(z) = h(z) \\cdot z\\]\nor from the matrix representation\n\\[\\bf{B}h(\\bf{B}) = h(\\bf{B})\\bf{B}.\\]\n\nExample\nLet \\(\\bf{B}\\) as\n\nB= [0 1 0 0 0 0 0\n    0 0 1 0 0 0 0 \n    0 0 0 1 0 0 0 \n    0 0 0 0 1 0 0 \n    0 0 0 0 0 1 0 \n    0 0 0 0 0 0 1 \n    1 0 0 0 0 0 0]\n\n7×7 Matrix{Int64}:\n 0  1  0  0  0  0  0\n 0  0  1  0  0  0  0\n 0  0  0  1  0  0  0\n 0  0  0  0  1  0  0\n 0  0  0  0  0  1  0\n 0  0  0  0  0  0  1\n 1  0  0  0  0  0  0\n\n\nDefine \\(h\\) as\n\nh = [1/3,1/3,1/3]\n\n3-element Vector{Float64}:\n 0.3333333333333333\n 0.3333333333333333\n 0.3333333333333333\n\n\nFurthermore define \\({\\bf H}=h({\\bf B})=h_0{\\bf B}^0+h_1{\\bf B}^1+h_2{\\bf B}^2\\)\n\nB^0\n\n7×7 Matrix{Int64}:\n 1  0  0  0  0  0  0\n 0  1  0  0  0  0  0\n 0  0  1  0  0  0  0\n 0  0  0  1  0  0  0\n 0  0  0  0  1  0  0\n 0  0  0  0  0  1  0\n 0  0  0  0  0  0  1\n\n\n\nB^1\n\n7×7 Matrix{Int64}:\n 0  1  0  0  0  0  0\n 0  0  1  0  0  0  0\n 0  0  0  1  0  0  0\n 0  0  0  0  1  0  0\n 0  0  0  0  0  1  0\n 0  0  0  0  0  0  1\n 1  0  0  0  0  0  0\n\n\n\nB^2\n\n7×7 Matrix{Int64}:\n 0  0  1  0  0  0  0\n 0  0  0  1  0  0  0\n 0  0  0  0  1  0  0\n 0  0  0  0  0  1  0\n 0  0  0  0  0  0  1\n 1  0  0  0  0  0  0\n 0  1  0  0  0  0  0\n\n\n\nH = (1/3)*B^0 + (1/3)*B^1 + (1/3)*B^2\n\n7×7 Matrix{Float64}:\n 0.333333  0.333333  0.333333  0.0       0.0       0.0       0.0\n 0.0       0.333333  0.333333  0.333333  0.0       0.0       0.0\n 0.0       0.0       0.333333  0.333333  0.333333  0.0       0.0\n 0.0       0.0       0.0       0.333333  0.333333  0.333333  0.0\n 0.0       0.0       0.0       0.0       0.333333  0.333333  0.333333\n 0.333333  0.0       0.0       0.0       0.0       0.333333  0.333333\n 0.333333  0.333333  0.0       0.0       0.0       0.0       0.333333\n\n\nObserve following\n\nB*H == H*B\n\ntrue\n\n\n\nB*H\n\n7×7 Matrix{Float64}:\n 0.0       0.333333  0.333333  0.333333  0.0       0.0       0.0\n 0.0       0.0       0.333333  0.333333  0.333333  0.0       0.0\n 0.0       0.0       0.0       0.333333  0.333333  0.333333  0.0\n 0.0       0.0       0.0       0.0       0.333333  0.333333  0.333333\n 0.333333  0.0       0.0       0.0       0.0       0.333333  0.333333\n 0.333333  0.333333  0.0       0.0       0.0       0.0       0.333333\n 0.333333  0.333333  0.333333  0.0       0.0       0.0       0.0\n\n\n\nH*B\n\n7×7 Matrix{Float64}:\n 0.0       0.333333  0.333333  0.333333  0.0       0.0       0.0\n 0.0       0.0       0.333333  0.333333  0.333333  0.0       0.0\n 0.0       0.0       0.0       0.333333  0.333333  0.333333  0.0\n 0.0       0.0       0.0       0.0       0.333333  0.333333  0.333333\n 0.333333  0.0       0.0       0.0       0.0       0.333333  0.333333\n 0.333333  0.333333  0.0       0.0       0.0       0.0       0.333333\n 0.333333  0.333333  0.333333  0.0       0.0       0.0       0.0\n\n\n따라서 filter \\(h\\)는 invariant filter이고, matrix \\(\\bf{H}\\)는 shift invariant operator이다.\nnote: \\(h\\) 는 moving average filter1.\nnote: for any \\(\\bf{x}, \\bf{Hx}\\) is definded by\n\\[\\left[\\frac{x_{n-1}+x_n+x_1}{3},\\frac{x_n+x_1+x_2}{3},\\dots,\\frac{x_{n-3}+x_{n-2}+x_n}{3}\\right].\\]\n\nx = [1,1,1,1,2,2,2]\nH*x\n\n7-element Vector{Float64}:\n 1.0\n 1.0\n 1.3333333333333333\n 1.6666666666666665\n 2.0\n 1.6666666666666665\n 1.3333333333333333\n\n\nnote: In some sense, the matrix \\({\\bf H}{\\bf x}\\) can be thought as generalized version of \\({\\boldsymbol h}\\star {\\bf x}\\) where \\(\\star\\) is convolution up to shift\n\nconv(h, x)\n\n9-element Vector{Float64}:\n 0.3333333333333334\n 0.6666666666666667\n 1.0\n 1.0\n 1.3333333333333333\n 1.6666666666666667\n 2.0\n 1.3333333333333333\n 0.6666666666666667"
  },
  {
    "objectID": "posts/study/2023-02-25-chap12.2.html#weakly-stationary-graph-processes",
    "href": "posts/study/2023-02-25-chap12.2.html#weakly-stationary-graph-processes",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "Weakly Stationary Graph Processes",
    "text": "Weakly Stationary Graph Processes\nWe extend three equivalent definitions of weak stationary in time to the graph domain, the most common being the invariance of the first and second moments to time shifts.\nDefinition 12.1. Given a normal shift operator \\({\\bf S}\\), a zero-mean random process \\({\\bf x}\\) is weakly stationary with respect to \\({\\bf S}\\) if it can be written as the response of a linear shift-invariant graph filter \\({\\bf H}=\\sum_{l=0}^{N-1}h_l{\\bf S}^l\\) to a zero-mean white input \\({\\bf n}\\).\nDefinition 12.2. Given a normal shift operator \\({\\bf S}\\), a zero-mean random process \\({\\bf x}\\) is weakly stationary with respect to \\({\\bf S}\\) is the following two equivalent properties hold\n(a) For any set of nonnegative integers \\(a\\),\\(b\\), and \\(c\\leq b\\) it holds that\n\\[\\mathbb{E} \\bigg[ \\big({\\bf S}^a{\\bf x}\\big)\\Big(\\big({\\bf S}^H)^b {\\bf x}\\Big)^H  \\bigg]=\\mathbb{E}\\bigg[\\big({\\bf S}^{a+c}{\\bf x}\\big)\\Big(\\big({\\bf S}^H\\big)^{b-c}{\\bf x} \\Big)^H \\bigg]\\]\n(b) Matrices \\({\\bf C}_{\\bf x}\\) and \\({\\bf S}\\) are simultaneously diagonalizable."
  },
  {
    "objectID": "posts/study/2023-03-05-survey-review.html",
    "href": "posts/study/2023-03-05-survey-review.html",
    "title": "A Comprehensive Survey on Geometric Deep Learning",
    "section": "",
    "text": "Convolutional neural networks, geometric deep learnig, graph, manifold\n\nThe deep Learning [1] technologies, for example, the con\u0002volutional neural networks [2], have achieved unprecedented good results in some machine learning applications such as object detection [3]–[5], image classification [6], speech recognition [7], and machine translation [8]. Different from traditional neural networks, the deep neural networks, espe\u0002cially convolutional neural networks, make use of the basic statistical characteristics of data including local stationarity and multi-scale component structure to capture deeper local information and features. Although deep learning technology is very successful in processing traditional signals such as image, sound, video or text, the current research on deep learning still mainly focuses on the data mentioned above which are defined in the Euclidean domain, namely grid-like data. With the emergence of larger data scale and more powerful GPU computing ability, people begin to be more and more interested in processing data in non-Euclidean domain, such as graphs and manifolds. This type of data is ubiquitous in real life. It is of great significance to study deep learning techniques in non-Euclidean domains. This is called geometric deep learning.\nThe geometric deep learning mainly study graph and man\u0002ifold data. The graph is composed of nodes and edges of the network structure data. For instance, in social network, each node represent a person’s information and the edge represent the relationship between people. The edges can be directed or undirected depending on the relationship of the connecting vertices. The Manifold data are usually used to describe geometric shapes, such as surface of objects returned by radar scanning. These geometric data are irregularly arranged and randomly distributed, which makes it difficult for people to find out the underlying pattern. Specifically, it is difficult to find the neighbor nodes of a certain point in the data, or the number of a node’s neighbor is different in [9]. This makes it difficult to define convolution operations like those on images. On the other hand, data like images in the Euclidean domain can be regarded as a special graph data, with vertices arranged in a regular way. Another issue is that non-Euclidean data usually has extraordinarily large scale. For example, molecular graph can have hundreds of millions of nodes. For this case, it is unlikely to use the traditional deep learning technology to carry out analysis and prediction tasks. This is why deep learning is so important in the field of geometric data. The purpose of this survey is to review and summarize the geometric deep learning frameworks and algorithms devel\u0002oped on graphs and manifolds data, and to introduce the practical difficulties and development directions in this new rising field."
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "",
    "text": "using LinearAlgebra, FFTW\n\nSyntaxError: invalid syntax (<ipython-input-9-0c475c9575f9>, line 1)"
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html#cyclic-shfit-operator-bf-b",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html#cyclic-shfit-operator-bf-b",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Cyclic shfit operator \\({\\bf B}\\)",
    "text": "Cyclic shfit operator \\({\\bf B}\\)\nThe matrix \\({\\bf B}\\) representing the periodic shift is\n\nB= [0 0 0 0 1\n    1 0 0 0 0 \n    0 1 0 0 0\n    0 0 1 0 0\n    0 0 0 1 0]\n\nSyntaxError: invalid syntax (<ipython-input-8-08cf3960a9a9>, line 1)\n\n\nThis matrix is the cyclic shift.\nnote: \\({\\bf B}\\) is orthogonal matrix.\n\nB'B\n\n5×5 Matrix{Int64}:\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n 0  0  0  0  1\n\n\n(ex1) Define \\({\\bf s}\\) as\n\ns = [1,2,3,4,5]\ns\n\n5-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n\n\nObserve that\n\nB*s\n\n5-element Vector{Int64}:\n 5\n 1\n 2\n 3\n 4\n\n\n\nB^2*s\n\n5-element Vector{Int64}:\n 4\n 5\n 1\n 2\n 3\n\n\n\nB^3*s\n\n5-element Vector{Int64}:\n 3\n 4\n 5\n 1\n 2\n\n\nThus we can interprete the matrix \\({\\bf B}\\) as cyclic shift operator such that\n\\[\n{\\bf B}s_n =s_{n-1}\n\\]\nfor \\(n=1,\\dots, N-1\\) and \\({\\bf B}s_0 =s_N\\).\nnote: \\({\\bf B}\\)는 시계열에서 다루는 backshift operator 와 비슷함."
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html#dft",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html#dft",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "DFT",
    "text": "DFT\nThe matrix \\({\\bf B}\\) can be expressed as\n\\({\\bf B}={\\bf DFT}^\\ast \\cdot {\\bf \\Lambda} \\cdot {\\bf DFT}\\)\nwhere \\({\\bf DFT}\\) is unitary and symmetric matrix and \\(\\bf \\Lambda\\) is diagonal matrix.\n\nλ, Ψ = eigen(B)\n\nEigen{ComplexF64, ComplexF64, Matrix{ComplexF64}, Vector{ComplexF64}}\nvalues:\n5-element Vector{ComplexF64}:\n -0.8090169943749472 - 0.5877852522924725im\n -0.8090169943749472 + 0.5877852522924725im\n 0.30901699437494734 - 0.9510565162951536im\n 0.30901699437494734 + 0.9510565162951536im\n  0.9999999999999998 + 0.0im\nvectors:\n5×5 Matrix{ComplexF64}:\n  0.138197+0.425325im   0.138197-0.425325im  …  0.447214+0.0im\n -0.361803-0.262866im  -0.361803+0.262866im     0.447214+0.0im\n  0.447214-0.0im        0.447214+0.0im          0.447214+0.0im\n -0.361803+0.262866im  -0.361803-0.262866im     0.447214+0.0im\n  0.138197-0.425325im   0.138197+0.425325im     0.447214+0.0im\n\n\n\nB ≈ Ψ * Diagonal(λ) * Ψ'\n\ntrue\n\n\nDefine \\({\\boldsymbol \\Psi}^\\ast={\\bf DFT}\\).\n\nDFT = Ψ'\n\n5×5 adjoint(::Matrix{ComplexF64}) with eltype ComplexF64:\n  0.138197-0.425325im  -0.361803+0.262866im  …  0.138197+0.425325im\n  0.138197+0.425325im  -0.361803-0.262866im     0.138197-0.425325im\n -0.361803-0.262866im  -0.361803+0.262866im     0.138197-0.425325im\n -0.361803+0.262866im  -0.361803-0.262866im     0.138197+0.425325im\n  0.447214-0.0im        0.447214-0.0im          0.447214-0.0im\n\n\nNote that the eigenvalues are not ordered in julia.\n\nλ[5], exp(-im* 2π/5 * 0)\n\n(0.9999999999999998 + 0.0im, 1.0 - 0.0im)\n\n\n\nλ[3], exp(-im* 2π/5 * 1)\n\n(0.30901699437494734 - 0.9510565162951536im, 0.30901699437494745 - 0.9510565162951535im)\n\n\n\nλ[1], exp(-im* 2π/5 * 2)\n\n(-0.8090169943749472 - 0.5877852522924725im, -0.8090169943749473 - 0.5877852522924732im)\n\n\n\nλ[2], exp(-im* 2π/5 * 3)\n\n(-0.8090169943749472 + 0.5877852522924725im, -0.8090169943749475 + 0.587785252292473im)"
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html#spectral-components-and-frequencies",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html#spectral-components-and-frequencies",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Spectral components and Frequencies",
    "text": "Spectral components and Frequencies\nWe remark:\n(1) Spectral components: For \\(k = 0,1,2,\\dots, N-1\\), the \\(k\\)-th column of \\({\\bf DFT}^\\ast\\) is defined by\n\\[\\Psi_k:=\\frac{1}{\\sqrt{N}}\\begin{bmatrix} 1 \\\\ e^{j\\frac{2\\pi}{N}k} \\\\ e^{j\\frac{2\\pi}{N}2k} \\\\ e^{j\\frac{2\\pi}{N}3k} \\\\  \\dots \\\\ e^{j\\frac{2\\pi}{N}(N-1)k} \\end{bmatrix}.\\]\nNote that \\(\\Psi_k\\) can be also interpreted as \\(\\ell\\)-th eigenvector of \\({\\bf A}\\) correspoding \\(\\lambda_\\ell = e^{-j\\frac{2\\pi}{N}k}\\). Those eigenvectors\n\\[\\big\\{{\\bf 1},\\Psi_1,\\Psi_2, \\dots, \\Psi_{N-1}\\big\\}\\]\nform a complete orthonomal basis of \\(\\mathbb{C}^N\\). These vectors are called spectral components.\n(2) Frequencies: The diagonal entries of \\({\\bf \\Lambda}\\) are the eigenvalues of the time shift \\({\\bf B}\\). In Physics and in operator theory, these eigenvalues are the frequencies of the signal. In DSP it is more common to call frequencies\n\\[\\Omega_k=\\frac{-1}{2\\pi j}\\ln\\lambda_k=\\frac{-1}{2\\pi j}\\ln e^{-j \\frac{2\\pi}{N}k}=\\frac{k}{N}, \\quad k=0,1,2,\\dots,N-1.\\]\n\nThe \\(N\\) (time) frequencies \\(\\Omega_k\\) are all distinct, positive, equally spaced, and increasing from \\(0\\) to \\(\\frac{N-1}{N}\\). The spectral components are the complex exponential sinusiodal functions. For example, corresponding to the zero frequency is the DC spectral component (a vector whose entries are constant and all equal to \\(\\frac{1}{\\sqrt{N}}\\))."
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html#dft-1",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html#dft-1",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "DFT",
    "text": "DFT\n일반적으로 우리가 알고있는 DFT1는 아래와 같다. (이 그림은 위키피디아에서 캡쳐한 것이다)\n\n즉 DFT는 임의의 신호 \\(\\{{\\bf x}_n\\}:=x_0,x_1,\\dots,x_{N-1}\\)를 적당한 규칙2에 따라서 \\(\\{{\\bf X}_k\\}:=X_0,X_1,\\dots,X_{N-1}\\)로 바꾸는 변환을 이라고 이해할 수 있다. 이때 사용되는 적당한 규칙은 구체적으로 아래의 수식을 의미한다.\n\\[X_k = \\sum_{n=0}^{N-1}x_n\\cdot e^{-i\\frac{2\\pi}{N}kn}\\]\n그런데 매트릭스를 활용하면 위의 수식을 아래와 같이 표현할 수 있다.\n\\[\\begin{bmatrix} X_1 \\\\ X_2 \\\\ X_3 \\\\ \\dots \\\\ X_{N-1} \\end{bmatrix}\n=\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n\\end{bmatrix}\n\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ \\dots \\\\ x_{N-1} \\end{bmatrix}\\]\n편의상 \\({\\bf X}\\)와 \\({\\bf x}\\)를 \\(N \\times 1\\) col-vec이라고 생각하고 DFT를 아래와 같은 matrix로 정의하자.\n\\[{\\bf DFT} = \\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n그러면\n\\[{\\bf X} = {\\bf DFT} \\cdot {\\bf x}\\]\n와 같이 표현할 수 있고 \\({\\bf x}\\)에서 \\({\\bf X}\\)로 바꾸는 과정을 단순히 \\({\\bf DFT}\\)행렬을 \\({\\bf x}\\)의 왼쪽에 곱하는 과정으로 이해할 수 있다.\n(참고) 사실 아래와 같이 \\({\\bf DFT}\\)를 정의하는 버전도 있다. (둘이 혼용해서 쓰인다)\n\\[{\\bf DFT} = \\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n\n예제1 아래는 위키에서 긁어온 예제이다. 이 예제를 따라가보자.\n\n\n\n그림2: 위키에서 긁어온 예제이미지\n\n\n예제를 풀기위해서 우선 아래와 같은 벡터를 선언하다.\n\nx = [1, 2-im, -im, -1+2im]\n\n4-element Vector{Complex{Int64}}:\n  1 + 0im\n  2 - 1im\n  0 - 1im\n -1 + 2im\n\n\n(풀이1)\n\\(4\\times 4\\)의 크기를 가지는 DFT행렬을 선언한다.\n(step1) 아래의 매트릭스 생성\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\n_DFT\n\n4×4 Matrix{Int64}:\n 0  0  0  0\n 0  1  2  3\n 0  2  4  6\n 0  3  6  9\n\n\n(step2) _DFT의 각 원소에 함수 \\(f: x \\to \\exp(-i\\frac{2\\pi}{4}x)\\)를 취함\n\nf = x -> exp(-im * (2π/4) * x)\nDFT = _DFT .|> f\n\n4×4 Matrix{ComplexF64}:\n 1.0-0.0im           1.0-0.0im          …           1.0-0.0im\n 1.0-0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0-0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0-0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n\n\n이제 \\({\\bf X}\\)를 구하면 아래와 같다.\n\nDFT * x\n\n4-element Vector{ComplexF64}:\n                   2.0 + 0.0im\n   -1.9999999999999998 - 2.0000000000000004im\n 8.881784197001252e-16 - 1.9999999999999998im\n    3.9999999999999987 + 4.000000000000001im\n\n\n위키의 답이 잘 나옴\n(풀이2)\n참고로 아래와 같이 패키지를 이용하여 구할 수도 있다.\n\nfft(x)\n\n4-element Vector{ComplexF64}:\n  2.0 + 0.0im\n -2.0 - 2.0im\n  0.0 - 2.0im\n  4.0 + 4.0im"
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html#inverse-dft",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html#inverse-dft",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Inverse DFT",
    "text": "Inverse DFT\n앞으로는 \\({\\bf DFT}\\)를 아래와 같이 정의하자.\n\\[{\\bf DFT} = \\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n\\({\\bf DFT}\\)행렬에는 몇 가지 특징이 있다.\n특징1: 유니터리행렬이다. 즉 \\({\\bf DFT}^\\ast \\cdot {\\bf DFT} = {\\bf DFT}^\\ast \\cdot{\\bf DFT} = {\\bf I}\\) 이다.\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\nf = x -> exp(-im * (2π/4) * x)\nDFT = _DFT .|> f\nDFT # 아까의 예제의 DFT!\n\n4×4 Matrix{ComplexF64}:\n 1.0-0.0im           1.0-0.0im          …           1.0-0.0im\n 1.0-0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0-0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0-0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n\n\n\nDFT = (1/√4)*DFT # 새로운 DFT의 정의 \nDFT'DFT .|> round # 유니터리행렬임을 확인!\n\n4×4 Matrix{ComplexF64}:\n  1.0+0.0im  -0.0-0.0im   0.0-0.0im   0.0-0.0im\n -0.0+0.0im   1.0+0.0im  -0.0-0.0im   0.0-0.0im\n  0.0+0.0im  -0.0+0.0im   1.0+0.0im  -0.0-0.0im\n  0.0+0.0im   0.0+0.0im  -0.0+0.0im   1.0+0.0im\n\n\n특징2: \\({\\bf DFT}\\)는 대칭행렬이다. 따라서 이 행렬의 켤레전치는 DFT의 각 원소에서 단순히 \\(i=\\sqrt{-1}\\) 대신에 \\(-i\\) 를 넣은 것과 같다.\n특징1-2를 조합하면 아래와 같이 \\({\\bf DFT}\\)에서 \\(i\\) 대신에 \\(-i\\)를 넣은 행렬이 변환 DFT를 취소시킬 수 있음을 이해할 수 있다. 3\n\\[\\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot 1} & e^{i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot 2} & e^{i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n행렬 \\({\\bf DFT}\\)를 discrete Fourier transform으로 생각했듯이 위의 행렬을 inverse discrete Fourier transform으로 해석할 수 있다."
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html#dft의-또-다른-정의",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html#dft의-또-다른-정의",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "DFT의 또 다른 정의",
    "text": "DFT의 또 다른 정의\n이번에는 \\({\\bf DFT}\\)에 대한 다른 정의를 생각해보자. 우선 아래와 같은 행렬 \\({\\bf B}\\)를 고려하자.\n\nB= [0 0 0 1 \n    1 0 0 0 \n    0 1 0 0\n    0 0 1 0]\n\n4×4 Matrix{Int64}:\n 0  0  0  1\n 1  0  0  0\n 0  1  0  0\n 0  0  1  0\n\n\n이것은 길이가 4인 임의의 column vector를 아래로 한칸씩 이동시키는 매트릭스이다.\n\nx = [1, 2-im, -im, -1+2im]\n\n4-element Vector{Complex{Int64}}:\n  1 + 0im\n  2 - 1im\n  0 - 1im\n -1 + 2im\n\n\n\nB*x # 아래로 한칸이동 \n\n4-element Vector{Complex{Int64}}:\n -1 + 2im\n  1 + 0im\n  2 - 1im\n  0 - 1im\n\n\n\nB^2*x # 아래로 두칸이동, B^2*x = B*(Bx) 이므로 \n\n4-element Vector{Complex{Int64}}:\n  0 - 1im\n -1 + 2im\n  1 + 0im\n  2 - 1im\n\n\n한편 이 매트릭스 \\({\\bf B}\\)는 아래와 같이 고유분해가 가능하다.\n\\[ {\\bf B} = {\\bf \\Psi} {\\bf \\Lambda} {\\bf \\Psi}^\\ast\\]\n\n\\({\\bf \\Psi}\\): make \\(\\frac{1}{\\sqrt{N}}[e^{\\sqrt{-1} \\frac{2\\pi}{N} ij}~\\text{ for }~ i=0,1,2,\\dots,N-1~\\text{ for }~j=0,1,2,\\dots,N-1]\\) and apply reshape function with \\((N,N)\\).\n\\({\\bf \\Lambda}\\): make \\([e^{-\\sqrt{-1}\\frac{2\\pi}{N}i}~\\text{ for }~ i=0,1,2\\dots,N-1]\\) and apply Diagonal function.\n\n\nN = 4 \nλ = [exp(-im * (2π/N) *i) for i in 0:(N-1)]\nΛ = Diagonal(λ)\n_Ψ = 1/√N *[exp(im * (2π/N) * i*j) for i in 0:(N-1) for j in 0:(N-1)]\nΨ = reshape(_Ψ, (N,N))\nB ≈ Ψ * Λ * Ψ'\n\ntrue\n\n\n그런데 위에서 정의된 \\({\\bf \\Psi}^\\ast\\)는 우리가 그전에 정의하였던 \\({\\bf DFT}\\)의 행렬과 같다.\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\nDFT = _DFT .|> (x -> exp(-im * (2π/4) * x)) \nDFT = DFT * 1/√N\n\n4×4 Matrix{ComplexF64}:\n 0.5-0.0im           0.5-0.0im          …           0.5-0.0im\n 0.5-0.0im   3.06162e-17-0.5im             -9.18485e-17+0.5im\n 0.5-0.0im          -0.5-6.12323e-17im             -0.5-1.83697e-16im\n 0.5-0.0im  -9.18485e-17+0.5im              2.75546e-16-0.5im\n\n\n\nΨ' == DFT \n\ntrue\n\n\n결국 요약하면 길이가 \\(N\\)인 신호의 \\({\\bf DFT}\\)행렬은 아래의 과정으로 구할 수 있음을 알 수 있다.\n\nForward operator \\({\\bf A}\\)를 정의한다.\n\\({\\bf A}\\)의 고유벡터행렬 \\({\\bf \\Psi}\\)을 구한다. 4\n\\({\\bf \\Psi}\\)의 conjugate transpose matrix \\({\\bf \\Psi}^\\ast\\) 를 구한다. 이것이 \\({\\bf DFT}\\) matrix 이다. 5"
  },
  {
    "objectID": "posts/study/prof/2022-12-24-Chap 8.3.html#spectral-component-and-frequencies",
    "href": "posts/study/prof/2022-12-24-Chap 8.3.html#spectral-component-and-frequencies",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Spectral component and Frequencies",
    "text": "Spectral component and Frequencies\n\\({\\bf A}\\)의 고유벡터 \\({\\bf \\Psi}\\)의 각 column을 spectral component라고 부른다.\n\nψ₁ = Ψ[:,1] # ψ₁ is first spectral component \nψ₂ = Ψ[:,2] # ψ₂ is seconde spectral component \nψ₃ = Ψ[:,3] # ψ₃ is third spectral component \nψ₄ = Ψ[:,4] # ψ₄ is last spectral component\n\n그리고 아래와 같은 수열을 \\(\\Omega_{k}=\\frac{k}{N}\\)을 frequency 라고 부른다.\n\nN=4 \nΩ = [k/N for k in 0:(N-1)]\nΩ\n\n4-element Vector{Float64}:\n 0.0\n 0.25\n 0.5\n 0.75"
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "",
    "text": "using LinearAlgebra, Plots, FFTW, Statistics"
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#kronecker-product",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#kronecker-product",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "Kronecker product",
    "text": "Kronecker product\n크로네커곱의 정의는 아래와 같다.\n\\[{\\bf A} \\otimes {\\bf B}\n=\\begin{bmatrix}\na_{11}{\\bf B} & a_{12}{\\bf B} & \\dots & a_{1m}{\\bf B} \\\\\na_{21}{\\bf B} & a_{22}{\\bf B} & \\dots & a_{2m}{\\bf B} \\\\\n\\dots & \\dots & \\dots & \\dots \\\\\na_{n1}{\\bf B} & a_{n2}{\\bf B} & \\dots & a_{nm}{\\bf B} \\\\\n\\end{bmatrix}\\]\n두 행렬 \\({\\bf A}_{m\\times n}\\), \\({\\bf B}_{p\\times q}\\)의 크로네커곱 \\({\\bf A}\\otimes {\\bf B}\\)의 차원은 \\(mp \\times nq\\) 가 된다. 계산예시는 아래와 같다.\n\n\n\n위키에서 긁은 예제, 글씨가 좀 작음\n\n\n크로네커곱에 대한 성질들이 위키에 많이 있으니 참고하면 좋다.\n(예제1)\n\nA= [1 2\n    3 4]\nB= [0 5\n    6 7]\nC = kron(A, B)\n\n4×4 Matrix{Int64}:\n  0   5   0  10\n  6   7  12  14\n  0  15   0  20\n 18  21  24  28\n\n\n(예제2)\n\nA= [1 -4 7; -2 3 3]\nB= [8 -9 -6 -5; 1 -3 -4 7; 2 8 -8 -3; 1 2 -5 -1]\nC = kron(A, B)\n\n8×12 Matrix{Int64}:\n   8   -9  -6   -5  -32   36   24   20  56  -63  -42  -35\n   1   -3  -4    7   -4   12   16  -28   7  -21  -28   49\n   2    8  -8   -3   -8  -32   32   12  14   56  -56  -21\n   1    2  -5   -1   -4   -8   20    4   7   14  -35   -7\n -16   18  12   10   24  -27  -18  -15  24  -27  -18  -15\n  -2    6   8  -14    3   -9  -12   21   3   -9  -12   21\n  -4  -16  16    6    6   24  -24   -9   6   24  -24   -9\n  -2   -4  10    2    3    6  -15   -3   3    6  -15   -3"
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#khatrirao-product",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#khatrirao-product",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "Khatri–Rao product",
    "text": "Khatri–Rao product\n카트리-라오곱은 매트릭스 \\({\\bf A}\\)와 \\({\\bf B}\\)가 같은 차원의 블락매트릭스로 정의될때 각 서브매트릭스의 크로네커 곱으로 정의된다. 정의와 계산예시는 아래와 같다.\n\n\n\n예시1: 위키에서 긁은 그림\n\n\n또 다른 계산예시는 아래와 같다. 이 예제는 중요하니까 구현해보자.\n\n\n\n예시2: 위키에서 긁은 그림\n\n\n(예제1)\n\nC= [1 2 3 \n    4 5 6 \n    7 8 9] \nD= [1 4 7\n    2 5 8\n    3 6 9]\n\n3×3 Matrix{Int64}:\n 1  4  7\n 2  5  8\n 3  6  9\n\n\n\nhcat([kron(C[:,i],D[:,i]) for i in 1:3]...)\n\n9×3 Matrix{Int64}:\n  1   8  21\n  2  10  24\n  3  12  27\n  4  20  42\n  8  25  48\n 12  30  54\n  7  32  63\n 14  40  72\n 21  48  81\n\n\n이건 자주 쓸일이 있을것 같으니까 함수로 저장하자.\n\ncolumnwise_kron = \n(C,D) -> hcat([kron(C[:,i],D[:,i]) for i in 1:size(C)[2]]...)\n\n#181 (generic function with 1 method)\n\n\n\ncolumnwise_kron(C,D)\n\n9×3 Matrix{Int64}:\n  1   8  21\n  2  10  24\n  3  12  27\n  4  20  42\n  8  25  48\n 12  30  54\n  7  32  63\n 14  40  72\n 21  48  81"
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#그래프-표현",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#그래프-표현",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "그래프 표현",
    "text": "그래프 표현\n아래의 그림을 살펴보자.\n\n\n\n그래프의 개념을 이해하는 필요한 그림, 일단 오른쪽의 \\({\\bf S}\\)는 무시할 것\n\n\n오른쪽의 \\({\\bf S}\\)는 무시하고 왼쪽의 그래프만 살펴보자. 이 그림에는 6개의 노드가 있고 각각의 노드는 저 마다의 연결구조를 가진다. 이러한 연결구조는 \\({\\bf G}=({\\bf N},{\\bf E})\\) 으로 표현할 수 있는데 여기에서 \\({\\bf N}\\)은 노드들의 집합이고 \\({\\bf E}\\)는 엣지들의 집합이다.1 보통 \\({\\cal E}\\)는 복잡하므로 연결정보를 매트릭스 \\({\\bf E}\\)로 표현하는데 이러한 \\({\\bf E}\\)를 인접행렬이라고 부른다. 인접행렬의 각 원소는 \\(E_{ij}= \\begin{cases} 1 & (i,j) \\in {\\cal E} \\\\ 0 & o.w \\end{cases}\\) 와 같이 정의한다. 이 그림의 경우 \\({\\cal N}\\) 와 \\({\\cal E}\\), \\({\\bf E}\\) 는 아래와 같다.\n\n\\({\\cal N}=\\{1,2,3,4,5,6\\}\\)\n\\({\\bf E}=\\begin{bmatrix} 0 & 1 & 0 & 0 & 1 & 0 \\\\ 1 & 0 & 1 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 & 1 & 1 \\\\ 1 & 1 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 & 0 & 0 \\end{bmatrix}\\)\n\\({\\cal E} = \\{(i,j) : E_{ij}=1 \\}\\)"
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#gso",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#gso",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "GSO",
    "text": "GSO\n후에 자세히 서술하겠지만 전통적인 시계열분석기법을 그래프신호로 확장하기 위해서는 단지 퓨리에변환 대신에 그래프퓨리에 변환을 사용하면 된다. 즉 퓨리에변환을 일반화한 그래프퓨리에변환을 잘 정의하면 된다.\n전통적인 신호처리 영역에서의 퓨리에변환은 시계열자료의 인접성을 의미하는 행렬 \\({\\bf B}\\)2의 고유행렬의 켤레전치로 정의할 수 있다. 이를 이용하면 그래프 퓨리에변환은 그래프자료의 인접성을 의미하는 행렬3의 고유행렬의 켤레전치로 정의할 수 있음을 유추할 수 있다. 즉 비유클리드 자료에서도 \\({\\bf B}\\)에 대응하는 어떠한 매트릭스가 정의되어야 하는데 (그리고 이 매트릭스는 그래프자료의 인접성에 대한 정보가 있어야 한다) 이 매트릭스를 \\({\\bf S}\\)라고 정의하고 grahp shift operator (GSO) 라고 이름 붙인다.\n주어진 그래프 \\({\\cal G}=({\\cal N},{\\cal E})\\) 에 대하여 GSO \\({\\bf S}\\)는 \\({\\bf E}+{\\bf I}\\)의 값이 1인 영역에만 값이 있는 어떠한 행렬이다. 다시 아래의 그림을 생각하여 보자.\n\n\n\nGSO의 개념을 이해하는데 필요한 그림\n\n\n왼쪽그래프의 GSO는 오른쪽과 같은 행렬 \\({\\bf S}\\)가 된다. 이제 \\({\\bf S}\\) 의 고유벡터행렬을 구한 뒤에 그것의 켤레전치를 \\({\\bf GFT}\\) 행렬로 정의하면 될 것 같다. 문제는 “\\({\\bf S}\\)의 고유벡터행렬이 항상 존재하는가?” 인데, 사실 이게 항상 존재한다는 보장이 없다. 즉 \\({\\bf S}\\)의 고유벡터 행렬이 존재 안할 수도 있다. 따라서 GSO \\({\\bf S}\\)가 고유분해가능하다는 조건이 추가적으로 필요한데 이러한 조건을 만족하는 GSO를 normal GSO라고 부른다. 우리는 당연히 normal GSO에 대해서만 관심이 있으므로 앞으로 특별한 언급이 없는한 GSO는 모두 normal GSO라고 가정한다."
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#periodogram-correlogram-and-ls-estimator",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#periodogram-correlogram-and-ls-estimator",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "Periodogram, correlogram, and LS estimator",
    "text": "Periodogram, correlogram, and LS estimator\nFrom \\({\\bf C}_{\\tilde{\\bf x}}:= \\mathbb{E}\\left[\\tilde{\\bf x}\\tilde{\\bf x}^H \\right]=\\mathbb{E}\\left[({\\bf V}^H{\\bf x})({\\bf V}^H{\\bf x})^H \\right]=\\text{diag}({\\bf p})\\) it follows that one may express the PSD as \\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\). That is, the PSD is given by the expected value of the squared frequency components of the random process. This leads to a natural approach for the estimation of \\({\\bf p}\\) from a finite set of \\(R\\) realizations of the process \\({\\bf x}\\). Indeed, we compute the \\({\\bf GFT} \\tilde{\\bf x}_r = {\\bf V}^H{\\bf x}_r\\) of each observed signal \\({\\bf x}_r\\) and estimate \\({\\bf p}\\) as\n\\[\n\\hat{\\bf p}_{pg}:= \\frac{1}{R}\\sum_{r=1}^R|\\tilde{\\bf x}_r|^2=\\frac{1}{R}\\sum_{r=1}^{R}|{\\bf V}^H{\\bf x}_{r}|^2.\n\\]\nThe estimator \\(\\hat{\\bf p}_{pg}\\) is termed periodogram due to its evident similarity with its homonym5 in classical estimation. It is simple to show that \\({\\bf p}_{pg}\\) is an unbiased estimator, that is, \\(\\mathbb{E}[\\hat{\\bf p}_{pg}]= {\\bf p}\\). A more detailed analysis of the performance of \\(\\hat{\\bf p}_{pg}\\), for the case where the observations are Gaussian, is given in Proposition 12.1.6\nAn alternative nonparametric estimation scheme, denominated correlogram, can be devised by starting from the definition of \\({\\bf p}\\) in\n\\[{\\bf p}:=\\text{diag}\\big({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V} \\big).\\]\nNamely, one may substitute \\({\\bf C}_{\\bf x}\\) in above equation by the sample covariance \\(\\hat{\\bf C}_{\\bf x} = \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\) computed based on the available observations to obtain\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right].\\]\nNotice that the matrix \\({\\bf V}^H\\hat{\\bf C}_{\\bf x}{\\bf V}\\) is in general, not diagonal because the eigenbasis of \\(\\hat{\\bf C}_{\\bf x}\\) differs from \\({\\bf V}\\), the eigenbasis of \\({\\bf C}_{\\bf x}\\). Nonetheless, we keep only the diagonal elements \\({\\bf v}_i^H \\hat{\\bf C}_{\\bf x}{\\bf v}_i\\) for \\(i = 1, \\dots , N\\) as our PSD estimator. It can be shown that the correlogram \\({\\bf p}_{cg}\\) and the periodogram \\({\\bf p}_{pg}\\) lead to identical estimators, as is the case in classical signal processing.\nThe correlogram can also be interpreted as an LS estimator. The decomposition in \\({\\bf C}_{\\bf x}={\\bf V}\\text{diag}({\\bf p}){\\bf V}^H\\) allows a linear parameterization of the covariance matrix \\({\\bf C}_{\\bf x}\\) as\n\\[\n{\\bf C}_{\\bf x}({\\bf p})=\\sum_{i=1}^N p_i{\\bf v}_i{\\bf v}_i^H.\n\\]\nThis linear parametrization will also be useful for the sampling schemes developed in Section 12.4. Vectorizing \\({\\bf C}_{\\bf x}\\) in \\({\\bf C}_{\\bf x}({\\bf p})=\\sum_{i=1}^N p_i{\\bf v}_i{\\bf v}_i^H\\) results in a set of \\(N^2\\) equations in \\({\\bf p}\\)\n\\[\n{\\bf c}_{\\bf x} = \\text{vec}({\\bf C}_{\\bf x})=\\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H)={\\bf G}_{np}{\\bf p},\n\\]\nwhere \\(\\text{vec}({\\bf v}_i{\\bf v}_i^H)={\\bf v}_i^\\ast \\otimes {\\bf v}_i\\). Relying on the Khatri-Rao product, we then form the \\(N^2 \\times N\\) matrix \\({\\bf G}_{np}\\) as\n\\[\n{\\bf G}_{np}:= \\left[{\\bf v}_1^\\ast \\otimes {\\bf v}_1, \\dots, {\\bf v}_N^\\ast \\otimes {\\bf v}_N \\right] = {\\bf V}^\\ast \\odot {\\bf V}.\n\\]\n\nHere \\(\\otimes\\) denote the Kronecker matrix product and \\(\\odot\\) denote the Khatri-Rao matrix product.\n\nUsing the sample covariance matrix \\(\\hat{\\bf C}_{\\bf x}\\) as an estimate of \\({\\bf C}_{\\bf x}\\), we can match the estimated covariance vector \\(\\hat{\\bf c}_{\\bf x}=\\text{vec}(\\hat{\\bf C}_{\\bf x})\\) to the true covariance vector \\({\\bf c}_{\\bf x}\\) in the LS sense as\n\\[\n\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}.\n\\]\nIn other words, the LS estimator minimizes the squared error \\(\\text{tr}\\left[\\big(\\hat{\\bf C}_{\\bf x} − \\hat{\\bf C}_{\\bf x}({\\bf p})\\big)^T \\big(\\hat{\\bf C}_{\\bf x} − \\hat{\\bf C}_{\\bf x}({\\bf p})\\big)\\right]\\). From expression \\(\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}\\) it can be shown that the \\(i\\)th element of \\(\\hat{\\bf p}_{ls}\\) is \\({\\bf v}_i^H \\hat{\\bf C}_{\\bf x} {\\bf v}_i\\). Combining this with Eq.\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right]\\]\nwe get that the LS estimator \\(\\hat{\\bf p}_{ls}\\) and the correlogram \\(\\hat{\\bf p}_{cg}\\) —and hence the periodogram as well— are all identical estimators. The estimators derived in this subsection do not assume any data distribution and are well suited for cases where the data probability density function is not available. In what follows, we provide performance bounds for these estimators under the condition that the observed signals are Gaussian."
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#정상시계열을-분석하는-두-가지-흐름-acf와-psd",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#정상시계열을-분석하는-두-가지-흐름-acf와-psd",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "정상시계열을 분석하는 두 가지 흐름, ACF와 PSD",
    "text": "정상시계열을 분석하는 두 가지 흐름, ACF와 PSD\n\n전통적인 분석방법\n클래식한 정상시계열은 유한차수의 ARMA로 근사할 수 있음이 알려져 있다7. 유한차수의 ARMA의 계수 \\(p\\),\\(q\\)를 적절하게 추정하기 위해서는 시계열 \\({\\bf x}\\)를 SACF plot 혹은 SPACF plot 을 이용하면 된다. 이때 SACF 혹은 SPACF 의 그림을 살펴보고 적절한 모형을 선택하기 위해서는 유한차수 ARMA의 이론적 ACF의 모양을 알면 되는데,8 이를 바꾸어서 말하면 결국 정상시계열 \\({\\bf x}\\)의 모든 정보는 ACF에 들어있다는 의미가 된다. 즉 정상시계열은 ACF만 잘 추정하면 모든 것이 해결된다.\n그런데 ACF의 모든 정보는 다시 아래의 행렬에 들어있다.\n\\[{\\bf C}_{\\bf x}=\\mathbb{E}[{\\bf x}{\\bf x}^T]\\]\n여기에서 \\({\\bf x}\\)는 realization이 아니라 확률벡터를 의미함을 유의하자.9 따라서 정상시계열의 경우 \\({\\bf C}_{\\bf x}\\)를 잘 추정하면 모든것이 해결된다고 생각하면 된다.\n\n참고: 정상시계열의 경우 ACF 만 정확하게 알아도 (반대로 PACF만 정확하게 알아도) 이론상 모든 모형을 특정할 수 있다. 즉 정상시계열의 모형을 특정하기 위해서는 ACF plot, PACF plot 하나만 있어도 충분하다. (Wold’s Thm은 떠올리면 모든 정상시계열은 무한MA로 유니크하게 표현할 수 있는데, 이는 PACF plot을 가지고 모든 정상시계열을 유니크하게 특정할 수 있다는 것을 의미한다) 다만 좀 더 모형을 특정하는 과정을 용이하게 하기 위해서 실전에서는 SACF plot 과 SPACF plot 을 함께 보는 것이 유리하다.\n\n(예제) AR(1) 모형\n왜 ACF의 모든정보를 \\({\\bf C}_{\\bf x}\\)로 부터 알수 있는지 코드를 통하여 실습하여 보자. (바로 이해된다면 사실 이 예제는 스킵해도 무방함) 아래와 같은 모형을 가정하자.\n\\[x_{t} = 0.5 x_{t-1} +\\epsilon_t\\]\n여기에서 \\(\\epsilon_t\\)는 서로 독립인 표준정규분포를 따른다. 이 모형에서 길이가 100인 시계열을 임의로 발생시키자.\n\nx = zeros(100*1000)\nx[1] = randn()\nfor t in 2:100\n    x[t] = 0.5*x[t-1] + randn()\nend\n\n모형에서 생성된 하나의 시계열을 시각화 하면 아래와 같다.\n\nplot(x) # 그냥 그려본것임. 별 의미는 없음\n\n\n\n\nlag=1일 경우 이 시계열의 SACF를 계산하면 아래와 같다.\n\nx[1:99] .* x[2:100]\n\n99-element Vector{Float64}:\n  1.587897526021493\n  1.130306190921068\n  0.5698214432110668\n  0.4648189302568683\n  0.3099446153360606\n  0.36362604534744775\n  0.8191871414624922\n -0.1720390842292145\n -0.06301214708310766\n  0.026414715508855904\n -0.007988283356933327\n -0.04178812545299474\n  0.22453267567940685\n  ⋮\n  3.931333581073927\n  1.315564948810858\n  0.9096080102581454\n  0.5410986320348997\n  0.29627801400693676\n  1.0673283524686212\n -1.0394649044573636\n  2.80195248208142\n  4.152973765526384\n  2.316315764368524\n  0.978758337765867\n -0.5840281943972468\n\n\n\n이 계산결과는 각 \\(t\\)에 대하여 \\(x_{t-1}x_t\\) 를 계산한 것과 같다.\n\n이 수열들의 평균은 아래와 같다.\n\nx[1:99] .* x[2:100] |> mean\n\n0.5835563885014224\n\n\n\n이 계산결과는 \\(\\frac{1}{99}\\sum_{t=2}^{100} x_{t-1}x_t\\)를 계산한 것과 같다.\n\n이론적인 값인 0.5 근처의 값이 잘 나옴을 알 수 있다.\nlag=2일 경우도 마찬가지로 구할 수 있다.\n\nx[1:98] .* x[3:100] |> mean\n\n0.38420263596668275\n\n\n이러한 숫자들은 그런데 \\({\\bf x}{\\bf x}^T\\)를 이용하여서도 구할 수 있다.10\n\nx*x'\n\n100×100 Matrix{Float64}:\n  0.760108    1.5879      0.541064   …  -1.57394    -0.472676    0.939172\n  1.5879      3.31719     1.13031       -3.28802    -0.987441    1.96197\n  0.541064    1.13031     0.385143      -1.12037    -0.336463    0.668527\n  0.800507    1.67229     0.569821      -1.65759    -0.497799    0.989089\n  0.441361    0.922022    0.314172      -0.913915   -0.274462    0.545336\n  0.533784    1.1151      0.379961   …  -1.10529    -0.331936    0.659531\n  0.517803    1.08171     0.368586      -1.0722     -0.321998    0.639786\n  1.20252     2.51212     0.855987      -2.49003    -0.747794    1.48581\n -0.108745   -0.227173   -0.0774074      0.225175    0.0676234  -0.134363\n  0.440444    0.920106    0.313519      -0.912016   -0.273892    0.544203\n  0.0455859   0.0952309   0.0324492  …  -0.0943935  -0.0283478   0.0563249\n -0.133198   -0.278257   -0.0948139      0.27581     0.0828298  -0.164577\n  0.238468    0.498169    0.169748      -0.493789   -0.148292    0.294646\n  ⋮                                  ⋱                          \n  2.04697     4.2762      1.45708       -4.2386     -1.27291     2.52919\n  0.488514    1.02053     0.347736      -1.01155    -0.303784    0.603596\n  1.41531     2.95665     1.00746    …  -2.93065    -0.880119    1.74873\n  0.290602    0.60708     0.206858      -0.601742   -0.180712    0.359062\n  0.774954    1.61891     0.551632      -1.60468    -0.481908    0.957516\n  1.04688     2.18698     0.745197      -2.16775    -0.651007    1.2935\n -0.754723   -1.57665    -0.537231       1.56279     0.469328   -0.932519\n -2.82194    -5.89516    -2.00873    …   5.84333     1.75484    -3.48673\n -1.11863    -2.33686    -0.796269       2.31632     0.695624   -1.38215\n -1.57394    -3.28802    -1.12037        3.25911     0.978758   -1.94472\n -0.472676   -0.987441   -0.336463       0.978758    0.293936   -0.584028\n  0.939172    1.96197     0.668527      -1.94472    -0.584028    1.16042\n\n\n여기에서 각 원소들이 의미하는 바는 아래와 같다.\n\n대각선의 원소: \\(x_t^2,~ t=1,2,\\dots,100\\) 을 의미\n대각선 한칸 위, 혹은 한칸 아래: \\(x_{t-1} x_t~ t=2,3,\\dots,100\\) 을 의미\n대각선 두칸 위, 혹은 두칸 아래: \\(x_{t-2} x_t~ t=3,4,\\dots,100\\) 을 의미\n\n\n\n\nx*x'의 계산결과를 캡쳐한 그림, 이것은 \\(\\hat{\\bf C}_{\\bf x}\\)를 의미함\n\n\n확인해보자.\nlag=1, 스크린샷의 노란색\n\n(x[1:99] .* x[2:100])[1:5]\n\n5-element Vector{Float64}:\n 1.587897526021493\n 1.130306190921068\n 0.5698214432110668\n 0.4648189302568683\n 0.3099446153360606\n\n\n\nlag1에 해당하는 숫자들임. 이는 스크린샷에서 노란색으로 표현된 1.589, 1.13031, 0.569821 … 등과 일치한다.\n\nlag=2, 스크린샷의 빨간색\n\n(x[1:98] .* x[3:100])[1:5]\n\n5-element Vector{Float64}:\n 0.5410642277088621\n 1.6722932576420804\n 0.3141719983177106\n 0.5621541352252872\n 0.30066534927151267\n\n\n\nlag2에 해당하는 숫자들임. 이는 스크린샷에서 빨간색으로 표현된 숫자들인 0.54164, 1.67229, 0.31417 … 등과 일치한다.\n\n\n\n스펙트럼 방법\n지금까지는 정상시계열일 경우 ACF를 이용한 간단한 분석방법을 다시 복습했다. 그리고 \\({\\bf C}_{\\bf x}\\)가 ACF를 구함에 필요한 모든정보를 가지고 있음을 이해했다. 한편 \\({\\bf C}_{\\bf x}\\)은 positive definite matrix 이므로 아래와 같이 분해가능하다.\n\\[{\\bf C}_{\\bf x} = {\\bf V} \\text{diag}({\\bf p}) {\\bf V}^H\\]\n이 수식표현을 잘 해석하면 \\({\\bf C}_{\\bf x}\\)의 모든 정보는 \\({\\bf V}\\)와 \\({\\bf p}\\)에 담겨있다는 사실을 이해할 수 있다. 그런데 정상시계열일 경우 한정하여 \\({\\bf C}_{x}\\)의 고유벡터행렬은 \\({\\bf B}\\)의 고유벡터행렬과 일치한다는 사실을 알고 있다. 따라서 \\({\\bf V}\\)는 \\({\\bf B}\\)로 부터 그냥 알 수 있는 정보이다. 따라서 \\({\\bf C}_{\\bf x}\\)의 모든 정보는 \\({\\bf p}\\)에 담겨있다는 사실을 알 수 있다. 이는 적절한 \\({\\bf p}\\)를 추정하는 일은 적절한 \\({\\bf C}_{\\bf x}\\)를 추정하는 것과 같다는 사실을 알려준다.\n요약하면 아래와 같다.\n\n임의의 정상시계열은 이론적인 ACF (혹은 PACF)를 잘 추정하면 유니크하게 특정할 수 있다. (Wold’s Thm)\nACF를 잘 추정한다는 말은 \\({\\bf C}_{\\bf x}\\)를 잘 추정한다는 의미이다.\n그런데 \\({\\bf p}\\)를 잘 추정하면 \\({\\bf C}_{\\bf x}\\)를 잘 추정하는 일이 된다.\n따라서 임의의 정상시계열은 \\({\\bf p}\\)를 잘 추정하면 유니크하게 특정할 수 있다는 결론을 얻는다.\n\n여기에서 \\({\\bf p}\\)를 power spectral density 라고 부른다. 일반적으로 정상시계열을 분석하기 위해서는 \\({\\bf C}_{\\bf x}\\)를 특정하거나, \\({\\bf p}\\)를 특정하면 되는데 여기에서 \\({\\bf p}\\)를 특정한뒤 \\({\\bf p}\\)로 부터 \\({\\bf C}\\)를 역으로 해석하는 방법론을 spectral analysis라고 부른다. 경우에 따라서 \\({\\bf C}_{\\bf x}\\)를 특정하는 것이 용이할 수도 있지만 \\({\\bf p}\\)를 특정하고 해석하는 것이 용이할 때도 있다.\n그렇다면 주어진 시계열 \\({\\bf x}\\)에 대하여 \\({\\bf p}\\)를 어떻게 구할까? 직관적으로 생각하면 단순히 아래의 알고리즘으로 구하면 된다는 것을 알 수 있다.\n\n\\({\\bf C}_{\\bf x}\\)를 알아낸다.\n\\({\\bf C}_{\\bf x}\\)를 고유분해하여 \\({\\bf p}\\)를 구한다.\n\n또 다른 방법으로는 교재에 소개된 바 있는 아래의 수식을 이용하는 것이다.11\n\\[{\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\]\n이것을 이용하면 아래와 같은 알고리즘을 떠올릴 수 있다.\n\n\\({\\bf B}\\)의 고유벡터행렬 \\({\\bf V}\\)를 구하고 \\({\\bf V}^H{\\bf x}\\)를 계산한다.\n계산된 결과를 원소별로 제곱하여 \\({\\bf p}\\)를 얻는다.\n\n그런데 \\({\\bf V}^H{\\bf x}= {\\bf DFT} \\cdot {\\bf x}\\) 이므로 1의 과정을 아래와 같이 바꾸어 서술할 수 있다.\n\n\\({\\bf x}\\)를 퓨리에변환하여 \\(\\tilde{\\bf x} = {\\bf DFT} \\cdot {\\bf x}\\) 를 계산한다.\n\\(\\tilde{\\bf x}\\)를 원소별로 제곱하여 \\({\\bf p}\\)를 얻는다.\n\n즉 임의의 시계열을 퓨리에변환한 뒤 제곱하면 \\({\\bf p}\\)를 얻을 수 있다.\n(예제2) – 하나의 realization에서 \\(\\hat{\\bf p}\\)를 구해보자.\n(예제1에 이어서) 아래의 모형에서 생성된 \\({\\bf x}\\)를 다시 고려하자.\n\\[x_{t} = 0.5 x_{t-1} +\\epsilon_t\\]\n\nplot(x)\n\n\n\n\n이 자료의 PSD \\({\\bf p}\\)는 아래와 같이 구할 수 있다.\n단계1: \\({\\bf x}\\)의 DFT를 계산\n\nx̃ = fft(x) \n\n100-element Vector{ComplexF64}:\n  -5.756917285643583 + 0.0im\n   -19.0826720904921 - 1.0178306444775302im\n  14.230506824768984 - 11.867854578089997im\n  3.8980118254428726 + 1.2603018602424614im\n -16.157973053188194 + 27.488246322270918im\n   12.32574209329046 - 1.5134316695905219im\n    3.95421224972561 + 15.369129638224624im\n   9.516938110507798 + 19.371467179753544im\n  -19.38292930624831 + 9.49506288623419im\n  -7.853934851478428 + 4.134711886071571im\n -14.072349901900408 - 5.945064076174294im\n -14.596266922162355 + 3.447776409279256im\n   5.857720447482927 + 5.738895112838594im\n                     ⋮\n   5.857720447482924 - 5.738895112838594im\n -14.596266922162352 - 3.4477764092792564im\n -14.072349901900408 + 5.945064076174294im\n   -7.85393485147843 - 4.134711886071569im\n -19.382929306248315 - 9.49506288623419im\n   9.516938110507798 - 19.37146717975354im\n  3.9542122497256105 - 15.36912963822462im\n  12.325742093290458 + 1.5134316695905206im\n -16.157973053188194 - 27.488246322270925im\n  3.8980118254428717 - 1.260301860242461im\n  14.230506824768984 + 11.867854578089993im\n -19.082672090492103 + 1.0178306444775296im\n\n\n\n\\({\\bf B}\\)를 설정하고 고유값분해 하기 귀찮아서 그냥 DFT해주는 패키지 사용함\n\n단계2: \\(\\hat{\\bf p}\\)를 계산\n\np̂ = abs.(x̃).^2\n\n100-element Vector{Float64}:\n   33.14209663374188\n  365.18435333408365\n  343.3532967764883\n   16.782856970223087\n 1016.6837790613963\n  154.21439356883184\n  251.84594035243464\n  465.8258516955045\n  465.85416770456163\n   78.78013503208902\n  233.37481863133453\n  224.93817023139349\n   67.24780595702228\n    ⋮\n   67.24780595702225\n  224.93817023139337\n  233.37481863133453\n   78.78013503208902\n  465.8541677045618\n  465.8258516955044\n  251.84594035243452\n  154.2143935688318\n 1016.6837790613968\n   16.782856970223072\n  343.3532967764882\n  365.1843533340838\n\n\n참고\nfft(x) 대신에 아래의 코드를 이용해도 된다.\n\nN = 100 \nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |> \n    x -> reshape(x,(N,N)) .|> \n    x -> exp(im * (2π/N) * x)\nV'x\n\n100-element Vector{ComplexF64}:\n  -5.756917285643587 + 0.0im\n -19.082672090492103 - 1.0178306444775291im\n   14.23050682476898 - 11.867854578090007im\n  3.8980118254428824 + 1.2603018602424476im\n  -16.15797305318818 + 27.48824632227092im\n   12.32574209329044 - 1.5134316695905325im\n  3.9542122497256385 + 15.369129638224617im\n    9.51693811050782 + 19.371467179753516im\n  -19.38292930624826 + 9.495062886234233im\n -7.8539348514784155 + 4.134711886071595im\n -14.072349901900417 - 5.945064076174276im\n -14.596266922162371 + 3.447776409279244im\n   5.857720447482956 + 5.7388951128385735im\n                     ⋮\n   5.857720447482839 - 5.738895112838781im\n -14.596266922162307 - 3.4477764092792627im\n  -14.07234990190023 + 5.945064076174198im\n  -7.853934851478599 - 4.134711886071242im\n -19.382929306248577 - 9.49506288623372im\n   9.516938110507212 - 19.371467179753736im\n  3.9542122497250025 - 15.369129638224603im\n  12.325742093290597 + 1.5134316695903638im\n  -16.15797305318867 - 27.488246322270854im\n  3.8980118254424903 - 1.2603018602428118im\n  14.230506824769146 + 11.867854578089572im\n   -19.0826720904922 + 1.0178306444775123im\n\n\n진짜 똑같은지 확인\n\nfft(x)\n\n100-element Vector{ComplexF64}:\n  -5.756917285643583 + 0.0im\n   -19.0826720904921 - 1.0178306444775302im\n  14.230506824768984 - 11.867854578089997im\n  3.8980118254428726 + 1.2603018602424614im\n -16.157973053188194 + 27.488246322270918im\n   12.32574209329046 - 1.5134316695905219im\n    3.95421224972561 + 15.369129638224624im\n   9.516938110507798 + 19.371467179753544im\n  -19.38292930624831 + 9.49506288623419im\n  -7.853934851478428 + 4.134711886071571im\n -14.072349901900408 - 5.945064076174294im\n -14.596266922162355 + 3.447776409279256im\n   5.857720447482927 + 5.738895112838594im\n                     ⋮\n   5.857720447482924 - 5.738895112838594im\n -14.596266922162352 - 3.4477764092792564im\n -14.072349901900408 + 5.945064076174294im\n   -7.85393485147843 - 4.134711886071569im\n -19.382929306248315 - 9.49506288623419im\n   9.516938110507798 - 19.37146717975354im\n  3.9542122497256105 - 15.36912963822462im\n  12.325742093290458 + 1.5134316695905206im\n -16.157973053188194 - 27.488246322270925im\n  3.8980118254428717 - 1.260301860242461im\n  14.230506824768984 + 11.867854578089993im\n -19.082672090492103 + 1.0178306444775296im\n\n\n\n\n전통적인 방법과 스펙트럼 방법의 비교\n시계열자료의 전통적인 분석과 spectral analysis는 대충 아래의 과정으로 비교 설명할 수 있다.\n\n\n\n\n\n\n\n\n단계\n전통적인 방법\n스펙트럴 분석\n\n\n\n\n1\n\\({\\bf x}\\)의 plot을 그려봄\n\\({\\bf x}\\)의 plot을 그려봄\n\n\n2\nSACF plot, SPACF plot 을 그려봄\nPSD plot을 그려봄\n\n\n3\nACF를 추정 (=ARMA(\\(p\\),\\(q\\))에 대응하는 파라메터를 추정)\n\\({\\bf p}\\)를 추정\n\n\n4\n추정된 파라메터를 바탕으로 여러가지 분석 수행\n추정된 파라메터를 바탕으로 여러가지 분석 수행\n\n\n\n눈여겨 볼 점은 PSD plot의 존재이다. 전통적인 시계열에서 SACF plot 과 비슷하게 스펙트럼 방법에서 시계열을 분석하기 위해 필요한 매우 중요한 시각화 이다. 간단하게 비교를 하면 아래와 같다.\nSACF plot\n\nx축: lag=0, lag=1, ….\ny축: lag에 대응하는 상관계수값\n\nPSD plot\n\nx축: \\(\\Omega=\\big\\{\\frac{k}{N}:~ \\text{for}~ k=0,\\dots, N-1\\big\\}\\), 정규화된 freq를 의미함\ny축: 주파수에 대응하는 power값\n\n전통적인 방법에 비하여 스펙트럴 분석이 가지는 장점은 위의 표에서 소개한 일반적인 분석루틴이 시계열이 아닌 그래프신호로 쉽게 확장가능 하다는 점이다12. 따라서 앞으로는 전통적인 시계열 분석방법 대신 스펙트럴 분석만을 다룰 것이다. 스펙트럴 분석의 핵심적인 부분은 \\({\\bf p}\\)를 추정하는 방법과 추정량의 점근적 성질들을 파악하는 것이다. 이 포스트에서는 \\({\\bf p}\\)를 추정하는 방법만을 다룬다."
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#그래프신호에서의-psd의-추정",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#그래프신호에서의-psd의-추정",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "그래프신호에서의 PSD의 추정",
    "text": "그래프신호에서의 PSD의 추정\n이제 그래프 신호에서 \\({\\bf p}\\)를 추정하는 방법에 대하여 살펴보자. 그래프이동변환 (Graph Shift Operator, GSO)13 \\({\\bf S}={\\bf V}{\\bf \\Lambda}{\\bf V}^H\\)에 대하여 정상인 시계열 \\({\\bf x}\\)를 고려한다. 이 신호의 그래프퓨리에 변환14은 아래와 같이 구할 수 있다.\n\\[\\tilde{\\bf x}={\\bf GFT} {\\bf x} = {\\bf V}^H{\\bf x}\\]\n여기에서 \\(\\tilde{\\bf x}\\)를 \\({\\bf x}\\)의 주파수응답(frequency representation)이라고 부른다.15 우리는 아래의 수식에서 \\({\\bf p}\\)의 값에 관심이 있다.\n\\[{\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\]\n여기에서 \\({\\bf p}\\)를 PSD (power spectrum density) 라고 한다. \\({\\bf p}\\)가 포함된 표현식은 위의 수식 이외에도 2개가 더 있다. 이를 모두 요약하면 아래와 같다16\n\n\\({\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\)17\n\\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\)\n\\({\\bf c}_{\\bf x} = \\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H) = {\\bf G}_{np} {\\bf p}\\)\n\n위의 표현중 3.에서 \\({\\bf c}_{\\bf x}\\)은 \\({\\bf C}_x\\)를 벡터화한 것이며 \\({\\bf G}_{np}\\)는 \\({\\bf V}^\\ast\\) 와 \\({\\bf V}\\)를 열별-크로네커곱 (column-wise Kronecker product) 이다. 이때 \\({\\bf G}_{np}\\)의 정의가 조금 생소하니 한번 계산하여 보자.\n(예제) 아래와 같은 GSO \\({\\bf B}\\)를 고려하자.\n\nB= [0 1 0 0 \n    0 0 1 0 \n    0 0 0 1 \n    1 0 0 0]\n\n4×4 Matrix{Int64}:\n 0  1  0  0\n 0  0  1  0\n 0  0  0  1\n 1  0  0  0\n\n\n이러한 GSO에 대하여 \\({\\bf G}_{np}\\)는 아래와 같이 구할 수 있다.\n(1) \\({\\bf V}\\)를 정의\n\nV = [i*j for i in 0:3 for j in 0:3] |> \n    x -> reshape(x,(4,4)) .|> \n    x -> exp(im * (2π/4) * x) \n\n4×4 Matrix{ComplexF64}:\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im          -1.0+1.22465e-16im             -1.0+3.67394e-16im\n 1.0+0.0im  -1.83697e-16-1.0im              5.51091e-16+1.0im\n\n\n(2) \\({\\bf G}_{np}={\\bf V}^{\\ast} \\odot {\\bf V}\\), 여기에서 \\(\\odot\\)은 열별-크로네커곱을 의미한다.\n\n# columnwise_kron은 위에서 정의한적 있음~\nGₙₚ = columnwise_kron(conj(V),V)\n\n16×4 Matrix{ComplexF64}:\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im          -1.0+1.22465e-16im             -1.0+3.67394e-16im\n 1.0+0.0im  -1.83697e-16-1.0im              5.51091e-16+1.0im\n 1.0+0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im          -1.0+1.22465e-16im             -1.0+3.67394e-16im\n 1.0+0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0+0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n 1.0+0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0+0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n\n\n위에서 언급한 표현식 1,2,3 을 이용하면 \\({\\bf p}\\)를 추정하는 세 가지 방법을 각각 정의할 수 있다. 하나씩 살펴보자.\n\n1. \\({\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\)\n확률과정 \\({\\bf x}\\)에서 \\(R\\)개의 realization \\(\\{{\\bf x}_1 \\dots {\\bf x}_R\\}\\) 을 관측하였다고 하자. 수식 \\({\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\)를 적당히 변형하면 아래를 얻을 수 있다.\n\\[{\\bf p}=\\text{diag}\\big({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V} \\big)\\]\n여기에서\n\\[{\\bf C}_{\\bf x}=\\mathbb{E}[{\\bf x}{\\bf x}^H]\\approx \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_t{\\bf x}_r^H\\]\n이므로 이 수식에 근거하여 \\({\\bf p}\\)을 추정한다면 아래와 같이 할 수 있다.\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right].\\]\n만약에 확률과정 \\({\\bf x}\\)에서 관측한 시계열이 \\({\\bf x}_r\\) 하나라면18, 즉 \\(R=1\\) 이라면 단순히 아래와 같이 쓸 수 있다.\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H{\\bf x}_r{\\bf x}_r^H{\\bf V} \\right].\\]\n\n주의: 여기에서 \\({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V}\\) 는 항상 대각행렬이지만 \\({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V}\\) 은 대각행렬이 아닐수도 있음을 유의하자. 즉 이론적인 모수는 대각행렬이지만 sample version은 대각행렬이 아닐 수 있다. 대각선이 아닌 원소는 버리면 된다.)\n\n\n아이디어: 혹시 대각선이 아닌 원소들을 이용하여 오차항 \\(\\epsilon_t\\)의 분산을 추정할 수도 있지 않을까? 이미 연구가 있겠지?\n\n(예제)\n\nN = 100 \nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |> \n    x -> reshape(x,(N,N)) .|> \n    x -> exp(im * (2π/N) * x)\n\n100×100 Matrix{ComplexF64}:\n 1.0+0.0im       1.0+0.0im        …       1.0+0.0im\n 1.0+0.0im  0.998027+0.0627905im     0.998027-0.0627905im\n 1.0+0.0im  0.992115+0.125333im      0.992115-0.125333im\n 1.0+0.0im  0.982287+0.187381im      0.982287-0.187381im\n 1.0+0.0im  0.968583+0.24869im       0.968583-0.24869im\n 1.0+0.0im  0.951057+0.309017im   …  0.951057-0.309017im\n 1.0+0.0im  0.929776+0.368125im      0.929776-0.368125im\n 1.0+0.0im  0.904827+0.425779im      0.904827-0.425779im\n 1.0+0.0im  0.876307+0.481754im      0.876307-0.481754im\n 1.0+0.0im  0.844328+0.535827im      0.844328-0.535827im\n 1.0+0.0im  0.809017+0.587785im   …  0.809017-0.587785im\n 1.0+0.0im  0.770513+0.637424im      0.770513-0.637424im\n 1.0+0.0im  0.728969+0.684547im      0.728969-0.684547im\n    ⋮                             ⋱  \n 1.0+0.0im  0.728969-0.684547im      0.728969+0.684547im\n 1.0+0.0im  0.770513-0.637424im      0.770513+0.637424im\n 1.0+0.0im  0.809017-0.587785im   …  0.809017+0.587785im\n 1.0+0.0im  0.844328-0.535827im      0.844328+0.535827im\n 1.0+0.0im  0.876307-0.481754im      0.876307+0.481754im\n 1.0+0.0im  0.904827-0.425779im      0.904827+0.425779im\n 1.0+0.0im  0.929776-0.368125im      0.929776+0.368125im\n 1.0+0.0im  0.951057-0.309017im   …  0.951057+0.309017im\n 1.0+0.0im  0.968583-0.24869im       0.968583+0.24869im\n 1.0+0.0im  0.982287-0.187381im      0.982287+0.187381im\n 1.0+0.0im  0.992115-0.125333im      0.992115+0.125333im\n 1.0+0.0im  0.998027-0.0627905im     0.998027+0.0627905im\n\n\n\np̂ = diag(V' * (x*x') * V)\n\n100-element Vector{ComplexF64}:\n 33.142096633741986 + 0.0im\n 365.18435333408354 + 1.5376069362644531e-13im\n  343.3532967764883 + 6.904176529646917e-14im\n 16.782856970223083 - 3.5538396658301444e-14im\n 1016.6837790613963 + 5.475049904926759e-15im\n 154.21439356883144 + 6.4512443306088e-14im\n  251.8459403524346 + 2.1316282072803006e-14im\n 465.82585169550384 + 1.816929057526117e-13im\n 465.85416770456044 + 4.1584439183295984e-14im\n    78.780135032089 + 1.3472456770553478e-14im\n 233.37481863133462 + 6.315728724701355e-14im\n 224.93817023139385 - 3.472109560086835e-14im\n  67.24780595702241 + 7.105427357601002e-14im\n                    ⋮\n   67.2478059570233 + 6.384723798533952e-14im\n 224.93817023139195 + 1.9727655769954595e-14im\n 233.37481863132837 - 2.1872689567834747e-14im\n    78.780135032089 + 1.917599080404094e-14im\n 465.85416770456294 + 4.808950231511622e-14im\n 465.82585169550094 - 4.890486289860305e-14im\n  251.8459403524291 + 2.0146681724568905e-14im\n  154.2143935688347 - 1.0948596967617507e-13im\n 1016.6837790614081 + 1.2114814701286432e-13im\n  16.78285697022108 + 2.376159104534641e-14im\n 343.35329677648286 + 1.1310381241837407e-14im\n 365.18435333408746 + 4.574214786667376e-14im\n\n\n\n\n2. \\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\)\n확률과정 \\({\\bf x}\\)에서 \\(R\\)개의 realization \\(\\{{\\bf x}_1 \\dots {\\bf x}_R\\}\\) 을 관측하였다고 하자. 아래의 수식을 관찰하자.\n\\[{\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\approx \\frac{1}{R}\\sum_{r=1}^{R} |{\\bf V}^H {\\bf x}_r|^2 \\]\n따라서 \\(\\frac{1}{R}\\sum_{r=1}^{R} |{\\bf V}^H {\\bf x}_r|^2\\) 를 PSD \\({\\bf p}\\)에 대한 추정량이라고 생각할 수 있다. 이러한 추정량을 기호로 \\(\\hat{\\bf p}_{pg}\\)라고 정의하고 periodogram이라고 부른다. 즉\n\\[\\hat{\\bf p}_{pg}=\\frac{1}{R}\\sum_{r=1}^{R} |{\\bf V}^H {\\bf x}_r|^2 \\]\n만약에 확률과정 \\({\\bf x}\\)에서 관측한 시계열이 \\({\\bf x}_r\\) 하나라면, 즉 \\(R=1\\) 이라면 단순히 아래와 같이 쓸 수 있다.\n\\[\\hat{\\bf p}_{pg}=|{\\bf V}^H {\\bf x}_r|^2 \\]\n즉 이 경우 \\(\\hat{\\bf p}_{pg}\\)는 단순히 관측시계열 \\({\\bf x}_r\\)의 그래프 퓨리에 변환 \\(\\tilde{\\bf x}={\\bf V}^H{\\bf x}_r\\) 결과에 절대값을 취하고 제곱한 것과 같다.\n(예제)\n스펙트럼방법챕터 예제2에서 이미 보여준 적 있다. 주어진 시계열 \\({\\bf x}\\)에 대하여 \\(\\hat{\\bf p}_{pg}\\)를 구하는 방법을 요약하면 아래와 같다.\n\nx̃ = fft(x) # 단계1: GFT, 이 신호는 시계열이라서 GFT대신에 DFT를 써도 된다.\np̂ = abs.(x̃).^2 # 단계2: hat p\n\n100-element Vector{Float64}:\n   33.14209663374188\n  365.18435333408365\n  343.3532967764883\n   16.782856970223087\n 1016.6837790613963\n  154.21439356883184\n  251.84594035243464\n  465.8258516955045\n  465.85416770456163\n   78.78013503208902\n  233.37481863133453\n  224.93817023139349\n   67.24780595702228\n    ⋮\n   67.24780595702225\n  224.93817023139337\n  233.37481863133453\n   78.78013503208902\n  465.8541677045618\n  465.8258516955044\n  251.84594035243452\n  154.2143935688318\n 1016.6837790613968\n   16.782856970223072\n  343.3532967764882\n  365.1843533340838\n\n\n\n\n3. \\({\\bf c}_{\\bf x} = {\\bf G}_{np} {\\bf p}\\)\n확률과정 \\({\\bf x}\\)에서 \\(R\\)개의 realization \\(\\{{\\bf x}_1 \\dots {\\bf x}_R\\}\\) 을 관측하였다고 하자. 아래의 수식을 관찰하자.\n\\[{\\bf C}_{\\bf x} = {\\bf V} \\text{diag}({\\bf p}) {\\bf V}^H\\]\n이 수식으로부터 아래를 얻을 수 있다.\n\\[{\\bf c}_{\\bf x} = \\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H) = {\\bf G}_{np} {\\bf p}\\]\n여기에서 \\({\\bf c}_{\\bf x}\\) 대신에 \\(\\hat{\\bf c}_{\\bf x}\\) 를 대입하면 아래와 같이 생각할 수 있다.\n\\[\\hat{\\bf c}_{\\bf x} \\approx  {\\bf G}_{np} {\\bf p}\\]\n이 문제는 아래와 같은 회귀모형으로 생각할 수 있다.\n\n\n\n\n\n\n\n\n\n회귀모형\n우리의 문제\n\n\n\n\n모형\n\\({\\bf y} \\approx {\\bf X}{\\boldsymbol \\beta}\\)\n\\(\\hat{\\bf c}_{\\bf x} \\approx {\\bf G}_{np}{\\bf p}\\)\n\n\n설명변수\n\\({\\bf X}\\)19\n\\({\\bf G}_{np}\\)20\n\n\n반응변수\n\\({\\bf y}\\)21\n\\(\\hat{\\bf c}_{\\bf x}\\)22\n\n\n추정하고 싶은 파라메터\n\\({\\boldsymbol \\beta}\\)23\n\\(\\hat{\\bf p}\\)24\n\n\n오차항\n대부분 정규분포를 가정\n??? 모르겠는데??\n\n\n\n회귀분석에서 아래의 수식이 익숙하다면\n\\[\n\\hat{\\boldsymbol \\beta}_{ls} = \\underset{\\boldsymbol \\beta}{\\operatorname{argmin}} \\|{\\bf y}-{\\bf X}{\\boldsymbol \\beta}\\|_2^2=({\\bf X}^T{\\bf X})^{-1}{\\bf X}^T{\\bf y}.\n\\]\n\\({\\bf p}\\)를 추정하기 위한 아래의 수식도 쉽게 이해할 수 있다. (의문: 그런데 왜 MSE를 손실함수로 쓰고 있는 거야? 오차항이 설마 정규분포?)\n\\[\n\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}.\n\\]\n(예제)\n(1) \\({\\bf V}\\)를 정의\n\nN = 100 \nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |> \n    x -> reshape(x,(N,N)) .|> \n    x -> exp(im * (2π/N) * x)\n\n100×100 Matrix{ComplexF64}:\n 1.0+0.0im       1.0+0.0im        …       1.0+0.0im\n 1.0+0.0im  0.998027+0.0627905im     0.998027-0.0627905im\n 1.0+0.0im  0.992115+0.125333im      0.992115-0.125333im\n 1.0+0.0im  0.982287+0.187381im      0.982287-0.187381im\n 1.0+0.0im  0.968583+0.24869im       0.968583-0.24869im\n 1.0+0.0im  0.951057+0.309017im   …  0.951057-0.309017im\n 1.0+0.0im  0.929776+0.368125im      0.929776-0.368125im\n 1.0+0.0im  0.904827+0.425779im      0.904827-0.425779im\n 1.0+0.0im  0.876307+0.481754im      0.876307-0.481754im\n 1.0+0.0im  0.844328+0.535827im      0.844328-0.535827im\n 1.0+0.0im  0.809017+0.587785im   …  0.809017-0.587785im\n 1.0+0.0im  0.770513+0.637424im      0.770513-0.637424im\n 1.0+0.0im  0.728969+0.684547im      0.728969-0.684547im\n    ⋮                             ⋱  \n 1.0+0.0im  0.728969-0.684547im      0.728969+0.684547im\n 1.0+0.0im  0.770513-0.637424im      0.770513+0.637424im\n 1.0+0.0im  0.809017-0.587785im   …  0.809017+0.587785im\n 1.0+0.0im  0.844328-0.535827im      0.844328+0.535827im\n 1.0+0.0im  0.876307-0.481754im      0.876307+0.481754im\n 1.0+0.0im  0.904827-0.425779im      0.904827+0.425779im\n 1.0+0.0im  0.929776-0.368125im      0.929776+0.368125im\n 1.0+0.0im  0.951057-0.309017im   …  0.951057+0.309017im\n 1.0+0.0im  0.968583-0.24869im       0.968583+0.24869im\n 1.0+0.0im  0.982287-0.187381im      0.982287+0.187381im\n 1.0+0.0im  0.992115-0.125333im      0.992115+0.125333im\n 1.0+0.0im  0.998027-0.0627905im     0.998027+0.0627905im\n\n\n(2) \\({\\bf G}_{np}={\\bf V}^{\\ast} \\odot {\\bf V}\\), 여기에서 \\(\\odot\\)은 열별-크로네커곱을 의미한다.\n\n# columnwise_kron은 위에서 정의한적 있음~\nGₙₚ = columnwise_kron(conj(V),V)\n\n10000×100 Matrix{ComplexF64}:\n 1.0+0.0im       1.0+0.0im        …       1.0+0.0im\n 1.0+0.0im  0.998027+0.0627905im     0.998027-0.0627905im\n 1.0+0.0im  0.992115+0.125333im      0.992115-0.125333im\n 1.0+0.0im  0.982287+0.187381im      0.982287-0.187381im\n 1.0+0.0im  0.968583+0.24869im       0.968583-0.24869im\n 1.0+0.0im  0.951057+0.309017im   …  0.951057-0.309017im\n 1.0+0.0im  0.929776+0.368125im      0.929776-0.368125im\n 1.0+0.0im  0.904827+0.425779im      0.904827-0.425779im\n 1.0+0.0im  0.876307+0.481754im      0.876307-0.481754im\n 1.0+0.0im  0.844328+0.535827im      0.844328-0.535827im\n 1.0+0.0im  0.809017+0.587785im   …  0.809017-0.587785im\n 1.0+0.0im  0.770513+0.637424im      0.770513-0.637424im\n 1.0+0.0im  0.728969+0.684547im      0.728969-0.684547im\n    ⋮                             ⋱  \n 1.0+0.0im  0.770513-0.637424im      0.770513+0.637424im\n 1.0+0.0im  0.809017-0.587785im      0.809017+0.587785im\n 1.0+0.0im  0.844328-0.535827im   …  0.844328+0.535827im\n 1.0+0.0im  0.876307-0.481754im      0.876307+0.481754im\n 1.0+0.0im  0.904827-0.425779im      0.904827+0.425779im\n 1.0+0.0im  0.929776-0.368125im      0.929776+0.368125im\n 1.0+0.0im  0.951057-0.309017im      0.951057+0.309017im\n 1.0+0.0im  0.968583-0.24869im    …  0.968583+0.24869im\n 1.0+0.0im  0.982287-0.187381im      0.982287+0.187381im\n 1.0+0.0im  0.992115-0.125333im      0.992115+0.125333im\n 1.0+0.0im  0.998027-0.0627905im     0.998027+0.0627905im\n 1.0+0.0im       1.0+0.0im                1.0+0.0im\n\n\n(3) \\(\\hat{\\bf p}_{ls}=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}\\)\n\nĉₓ = vec(x*x')\np̂ = inv(Gₙₚ' * Gₙₚ) * Gₙₚ' * ĉₓ \n\n100-element Vector{ComplexF64}:\n  0.003314209663374193 - 2.7356277964988863e-19im\n   0.03651843533340838 - 4.01518191768058e-18im\n   0.03433532967764885 + 2.515448157755484e-17im\n 0.0016782856970223292 - 1.0070028487673847e-17im\n   0.10166837790613971 + 3.1129277935880596e-18im\n  0.015421439356883134 + 9.403422807142065e-18im\n  0.025184594035243472 - 3.993782799800785e-18im\n   0.04658258516955039 - 1.850761436988587e-18im\n   0.04658541677045607 + 1.1559103895961936e-17im\n  0.007878013503208905 + 3.559698092088507e-18im\n  0.023337481863133468 + 2.6204945155857973e-18im\n   0.02249381702313939 + 5.304406111488559e-18im\n  0.006724780595702225 - 1.655564138463681e-17im\n                       ⋮\n  0.006724780595702329 + 1.8121162053534517e-18im\n  0.022493817023139205 - 1.0461976779111972e-17im\n   0.02333748186313285 - 6.792203007975684e-18im\n  0.007878013503208907 - 2.3575339315335667e-18im\n  0.046585416770456294 + 1.5392042695643853e-17im\n  0.046582585169550106 - 1.123245521985718e-17im\n  0.025184594035242928 + 1.1628578774983873e-18im\n  0.015421439356883466 + 5.864828990948797e-18im\n   0.10166837790614085 + 2.2712943512935246e-17im\n 0.0016782856970221013 + 4.829637376114682e-18im\n   0.03433532967764831 + 3.3208196889839756e-19im\n  0.036518435333408754 + 1.3795822112205515e-17im\n\n\n\n?? 뭔가 스케일이 안맞음\n\n\nN^2 * p̂\n\n100-element Vector{ComplexF64}:\n  33.14209663374193 - 2.7356277964988864e-15im\n 365.18435333408377 - 4.0151819176805797e-14im\n  343.3532967764885 + 2.515448157755484e-13im\n 16.782856970223293 - 1.0070028487673847e-13im\n 1016.6837790613971 + 3.1129277935880596e-14im\n 154.21439356883135 + 9.403422807142065e-14im\n 251.84594035243472 - 3.9937827998007846e-14im\n  465.8258516955039 - 1.850761436988587e-14im\n  465.8541677045607 + 1.1559103895961937e-13im\n  78.78013503208905 + 3.559698092088507e-14im\n 233.37481863133468 + 2.6204945155857973e-14im\n 224.93817023139388 + 5.304406111488559e-14im\n  67.24780595702225 - 1.655564138463681e-13im\n                    ⋮\n  67.24780595702329 + 1.8121162053534517e-14im\n 224.93817023139206 - 1.0461976779111972e-13im\n  233.3748186313285 - 6.792203007975684e-14im\n  78.78013503208906 - 2.3575339315335666e-14im\n 465.85416770456294 + 1.5392042695643854e-13im\n 465.82585169550106 - 1.123245521985718e-13im\n 251.84594035242927 + 1.1628578774983874e-14im\n 154.21439356883465 + 5.864828990948797e-14im\n 1016.6837790614085 + 2.2712943512935246e-13im\n  16.78285697022101 + 4.8296373761146824e-14im\n  343.3532967764831 + 3.3208196889839758e-15im\n  365.1843533340875 + 1.3795822112205514e-13im\n\n\n\n\\(N^2\\)를 곱해주니까 아까부터 구하던 값이 그대로 잘 나옴. (\\({\\bf DFT}\\) 혹은 \\({\\bf GFT}\\)를 정의할때 \\(\\frac{1}{\\sqrt N}\\)으로 스케일링 하느냐 마느냐 차이때문에 생기는 현상임)"
  },
  {
    "objectID": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#의문점",
    "href": "posts/study/prof/2022-12-27-Chap-12.2.1~12.3.1.html#의문점",
    "title": "Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "의문점",
    "text": "의문점\n아래의 그림을 살펴보자.\n\n\n\n그림12.3(교재에서 긁어온 그림): Power spectral density estimation. All estimators are based on the same random process defined on the Karate club network [@zachary1977information]. (A) Periodogram estimation with different numbers of observations. (B) Windowed average periodogram from a single realization and a different number of windows. (C) Windowed average periodogram for four windows and a varying number of realizations. (D) Parametric MA estimation for 1 and 10 realizations.\n\n\n이 그림은 다양한 방법으로 true PSD \\({\\bf p}\\)를 추정한 결과를 나타내는 PSD plot 이다25. 우리가 적용한 방법은 (A)에서 \\(R=1\\)일 경우이다. 보는것 처럼 true PSD 를 놀라울 정도로 제대로 추정하지 못한다26. 만약에 우리가 모형에서 하나의 시계열이 아니라 1000개의 정도의 시계열을 관측하였다면 좀 더 합리적으로 추정할 수 있다. 그런데 사실 하나의 모형에서 1000개씩이나 되는 시계열을 관측하는 일은 현실적으로 불가능하다27 따라서 우리는 비교적 적은 \\(R\\)에서 합리적인 PSD의 추정치를 이끌어내야 한다. 그림 (B),(C)는 상대적으로 적은 \\(R\\)에 대해 \\({\\bf p}\\)를 추정하는 windowed periodogram 을 이용하여 PSD를 추정한 결과이다. (C)를 살펴보면 \\(R=1\\) 일경우 \\({\\bf p}\\)를 추정한 값들이 나와있는데 (A)와 비교하면 꽤 합리적으로 보인다.\n문제는 (A)-(C)에서 제안된 방법 모두가 (D)에 제시된 전통적인 방법에 비하여 퍼포먼스가 떨어진다는 것이다. (D)는 parametric 모형을 사용한 결과이다. 파라메트릭 방법이므로 특정 모델을 한정하고 거기에 대응하는 한두개의 모수만 추정하면 되므로 추정이 잘 된다.28 반면 (A)-(C)의 경우 한 두개의 파라메터가 아니라 \\({\\bf p}\\)의 모든 원소를 추정해야하므로 추정할 파라메터가 데이터의 수 \\(N\\)과 같다29. 따라서 추정치의 분산이 크다. 사실 이것은 파라메트릭 방법과 세미파라메트릭 방법이라는 구조적인 차이때문에 어쩔 수 없는 것 같다. 그래도 세미파라메트릭 방법은 머리아프게 모델링을 할 필요가 없고30 내가 적합한 모델이 맞는지 확인할 필요도 없다31는 장점이 있다.\n아래는 나름 PSD를 추정하는 신기술인 것 같다.\n\n\n\n그림12.4(교재에서 긁어온 그림): PSD estimation from a subset of nodes. Estimators are based on a random process defined on the Karate club network [@zachary1977information]. (A) Graph sampling for nonparametric PSD estimation. Here, 20 out of 34 nodes are observed. The sampled nodes are highlighted by the circles around the nodes. (B) Nonparametric PSD estimation based on observations from 20 nodes and 100 data snapshots. (C) Graph sampling for parametric MA PSD estimation. Here, 4 out of 34 nodes are observed. (D) Parametric MA PSD estimation based on observations from 4 nodes and 100 data snapshots.\n\n\n그래프신호의 sub-sampling을 이용하는 것 같은데 교재의 뒤쪽에 서술되어있다. \\(R=100\\)임을 고려하여도 퍼포먼스가 좋은 편인듯 하다32."
  },
  {
    "objectID": "posts/study/prof/2023-01-15-Chap-12.4.html",
    "href": "posts/study/prof/2023-01-15-Chap-12.4.html",
    "title": "Chap 12.4: Node Subsampling for PSD Estimation",
    "section": "",
    "text": "using LinearAlgebra, Plots, FFTW, Statistics\n\n\ncolumnwise_kron = \n(C,D) -> hcat([kron(C[:,i],D[:,i]) for i in 1:size(C)[2]]...)\n\n#49 (generic function with 1 method)\n\n\n\n12.4.1 The Sampling Problem\n아래와 같이 길이가 \\(N=10\\) 인 신호 \\({\\bf x}\\)를 고려하자.\n\nx = rand(10)\n\n10-element Vector{Float64}:\n 0.03235208758206609\n 0.5069925854414447\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n 0.24116013388795854\n 0.8439116925218157\n 0.6362602319916778\n 0.386069828675059\n 0.5313655894235898\n\n\n여기에서 1,3,4,5 번째 원소만 추출하여길이가 \\(K=4\\) 인 신호 \\({\\bf y}\\)를 만들고 싶다.\n\ny = x[[1,3,4,5]]\n\n4-element Vector{Float64}:\n 0.03235208758206609\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n\n\n이 과정은 아래와 같이 수행할 수도 있다.\n\nΦ= [1 0 0 0 0 0 0 0 0 0\n    0 0 1 0 0 0 0 0 0 0\n    0 0 0 1 0 0 0 0 0 0\n    0 0 0 0 1 0 0 0 0 0]\n\n4×10 Matrix{Int64}:\n 1  0  0  0  0  0  0  0  0  0\n 0  0  1  0  0  0  0  0  0  0\n 0  0  0  1  0  0  0  0  0  0\n 0  0  0  0  1  0  0  0  0  0\n\n\n\nΦ*x\n\n4-element Vector{Float64}:\n 0.03235208758206609\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n\n\n즉 적당한 \\(K\\times N\\) selection matrix를 선언하여 subsampling을 수행할 수 있다. 이때 매트릭스 \\({\\bf \\Phi}\\)를 subsampling matrix 혹은 sparse sampling matrix 라고 부른다.\n\n\n12.4.2 Compressed LS Estimator\n\nN = 10\nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |> \n    x -> reshape(x,(N,N)) .|> \n    x -> exp(im * (2π/N) * x) \n\n10×10 Matrix{ComplexF64}:\n 1.0+0.0im        1.0+0.0im          …        1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0+1.22465e-16im  …       -1.0+1.10218e-15im\n 1.0+0.0im  -0.809017-0.587785im        -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n\n\n\nG = columnwise_kron(conj(V),V)\n\n100×10 Matrix{ComplexF64}:\n 1.0+0.0im        1.0+0.0im          …        1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0+1.22465e-16im  …       -1.0+1.10218e-15im\n 1.0+0.0im  -0.809017-0.587785im        -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n 1.0+0.0im   0.809017-0.587785im     …   0.809017+0.587785im\n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n    ⋮                                ⋱  \n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.809017+0.587785im     …   0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0-1.11022e-16im          -1.0+2.27596e-15im\n 1.0+0.0im  -0.809017-0.587785im     …  -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n\n\n- 방법1\n\nĉx = vec(x*x')\np̂ = inv(G' * G) * G' * ĉx\n\n10-element Vector{ComplexF64}:\n    0.25854107856772546 + 2.245922875954761e-20im\n   0.004743491121735806 - 1.3138893409553828e-18im\n   0.006946482731189413 - 9.791191432641327e-19im\n   0.001721693617954179 - 1.9827974128203887e-18im\n   0.011344167525098774 + 2.6827005818057562e-19im\n 0.00012662617844242917 - 3.748573865136995e-20im\n   0.011344167525098762 + 2.7448152053954017e-18im\n  0.0017216936179541913 - 9.35534609073096e-19im\n   0.006946482731189404 + 1.954408900185458e-18im\n   0.004743491121735756 - 2.561030398375897e-18im\n\n\n- 방법2\n\nĉy = vec(y*y')\np̂ = (kron(Φ,Φ)*G)' * ĉy\n\n10-element Vector{ComplexF64}:\n   3.759462826821233 + 0.0im\n   2.765185174577697 - 2.0816681711721685e-17im\n   1.077337414764992 + 2.7755575615628914e-17im\n 0.11594812606807317 + 2.0816681711721685e-17im\n 0.08838298603932843 + 3.903127820947816e-17im\n 0.32863702713833354 + 4.622231866529366e-33im\n 0.08838298603932859 + 9.540979117872439e-18im\n  0.1159481260680729 - 2.0816681711721685e-17im\n  1.0773374147649915 + 0.0im\n  2.7651851745776965 - 2.0816681711721685e-17im"
  },
  {
    "objectID": "posts/study/prof/2022-12-26-Chap-12.2.html",
    "href": "posts/study/prof/2022-12-26-Chap-12.2.html",
    "title": "Chap 12.2: Weakly Stationary Graph Processes",
    "section": "",
    "text": "using LinearAlgebra, DSP"
  },
  {
    "objectID": "posts/study/prof/2022-12-26-Chap-12.2.html#simultaneously-diagonalizable",
    "href": "posts/study/prof/2022-12-26-Chap-12.2.html#simultaneously-diagonalizable",
    "title": "Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Simultaneously Diagonalizable",
    "text": "Simultaneously Diagonalizable\n매트릭스 \\({\\bf A}\\)와 \\({\\bf B}\\)가 대각화 가능하다는 것은 아래의 표현을 만족하는 적당한 invertible matrix \\({\\bf \\Psi}_A\\), \\({\\bf \\Psi}_B\\)와 대각행렬 \\({\\bf \\Lambda}_A\\), \\({\\bf \\Lambda}_B\\)가 존재한다는 의미가 된다.\n\\[{\\bf A} = {\\bf V}_{A} {\\bf \\Lambda}_A {\\bf V}_{A}^{-1}\\]\n\\[{\\bf B} = {\\bf V}_{B} {\\bf \\Lambda}_B {\\bf V}_{B}^{-1}\\]\n그리고 만약에 \\({\\bf V}_{A}={\\bf V}_{B}\\)이라면 즉\n\\[{\\bf A} = {\\bf V} {\\bf \\Lambda}_A {\\bf V}^{-1}\\]\n\\[{\\bf B} = {\\bf V} {\\bf \\Lambda}_B {\\bf V}^{-1}\\]\n이라면 \\(\\{{\\bf A},{\\bf B}\\}\\)가 simultaneously diagonalzable 하다고 표현한다."
  },
  {
    "objectID": "posts/study/prof/2022-12-26-Chap-12.2.html#commute",
    "href": "posts/study/prof/2022-12-26-Chap-12.2.html#commute",
    "title": "Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Commute",
    "text": "Commute\n두 matrix \\({\\bf A}\\)와 \\({\\bf B}\\)에 대하여\n\\[{\\bf A}{\\bf B}= {\\bf B}{\\bf A}\\]\n인 관계가 성립하면 두 매트릭스가 commute 한다고 표현한다. 그런데 \\({\\bf A}{\\bf B}={\\bf A}{\\bf B}\\)의 조건은 \\({\\bf A}, {\\bf B}\\)가 동시대각화가능할 (simultaneously diagonalzable) 조건과 같다. 1 따라서 simultaneously diagonalzable 는 commute와 같은 말이라 생각해도 무방하다.\n\n참고: 위키피디아.."
  },
  {
    "objectID": "posts/study/prof/2022-12-26-Chap-12.2.html#shift-invariant-filter",
    "href": "posts/study/prof/2022-12-26-Chap-12.2.html#shift-invariant-filter",
    "title": "Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Shift Invariant Filter",
    "text": "Shift Invariant Filter\n\nref: @djuric2018cooperative Chap 8.3 의 내용 중 일부\n\nDefine the matrix \\({\\bf B}\\) as periodic shift matrix such that\n\\[\n{\\bf B} = \\begin{bmatrix}\n0 & 0 & 0 & \\dots  & 0 & 1 \\\\\n1 & 0 & 0 & \\dots & 0 & 0 \\\\\n0 & 1 & 0 & \\dots & 0 & 0 \\\\\n\\dots & \\dots & \\dots & \\dots & \\dots & \\dots\\\\\n0 & 0 & \\dots & 1 & 0 & 0 \\\\\n0 & 0 & \\dots & 0 & 1 & 0 \\\\\n\\end{bmatrix}.\\]\nA generic filter \\({\\boldsymbol h}\\) is given by its \\(z\\)-transform\n\\[h(z)=h_0z^0+h_1z^{-1}+\\cdots +h_{N-1}z^{-(N-1)}\\]\nwhere \\(s_{n-1}=z^{-1}s_n\\). In vector notation, and with respect to the standard basis \\({\\bf I}\\), the filter is represented by the matrix \\({\\bf H}\\), a polynomial in the cyclic shift\n\\[{\\bf H}=h({\\bf B})=h_0{\\bf B}^0+h_1{\\bf B}^1+\\cdots+h_{N-1}{\\bf B}^{N-1}.\\]\nFilters are shift invariant iff\n\\[z\\cdot h(z) = h(z)\\cdot z\\]\nor from the matrix representation\n\\[{\\bf B}h({\\bf B})=h({\\bf B}){\\bf B}.\\]\nExample\nLet \\({\\bf B}\\) as\n\nB= [0 1 0 0 0 0 0\n    0 0 1 0 0 0 0 \n    0 0 0 1 0 0 0 \n    0 0 0 0 1 0 0 \n    0 0 0 0 0 1 0 \n    0 0 0 0 0 0 1 \n    1 0 0 0 0 0 0]\n\n7×7 Matrix{Int64}:\n 0  1  0  0  0  0  0\n 0  0  1  0  0  0  0\n 0  0  0  1  0  0  0\n 0  0  0  0  1  0  0\n 0  0  0  0  0  1  0\n 0  0  0  0  0  0  1\n 1  0  0  0  0  0  0\n\n\nDefine \\({\\boldsymbol h}\\) as\n\nh = [1/3,1/3,1/3]\n\n3-element Vector{Float64}:\n 0.3333333333333333\n 0.3333333333333333\n 0.3333333333333333\n\n\nFurthermore define \\({\\bf H}=h({\\bf B})=h_0{\\bf B}^0+h_1{\\bf B}^1+h_2{\\bf B}^2\\)\n\nH = (1/3)*B^0 + (1/3)*B^1 + (1/3)*B^2 \n\n7×7 Matrix{Float64}:\n 0.333333  0.333333  0.333333  0.0       0.0       0.0       0.0\n 0.0       0.333333  0.333333  0.333333  0.0       0.0       0.0\n 0.0       0.0       0.333333  0.333333  0.333333  0.0       0.0\n 0.0       0.0       0.0       0.333333  0.333333  0.333333  0.0\n 0.0       0.0       0.0       0.0       0.333333  0.333333  0.333333\n 0.333333  0.0       0.0       0.0       0.0       0.333333  0.333333\n 0.333333  0.333333  0.0       0.0       0.0       0.0       0.333333\n\n\nObserve following:\n\nB*H == H*B \n\ntrue\n\n\nThus, filter \\({\\boldsymbol h}\\) is shift invariant filter and matrix \\({\\bf H}\\) is shift invariant operator.\nnote: \\({\\boldsymbol h}\\) is moving average filter.\nnote: for any \\({\\bf x}\\), \\({\\bf H}{\\bf x}\\) is definded by\n\\[\\left[\\frac{x_{n-1}+x_n+x_1}{3},\\frac{x_n+x_1+x_2}{3},\\dots,\\frac{x_{n-3}+x_{n-2}+x_n}{3}\\right].\\]\n\nx = [1,1,1,1,2,2,2]\nH*x\n\n7-element Vector{Float64}:\n 1.0\n 1.0\n 1.3333333333333333\n 1.6666666666666665\n 2.0\n 1.6666666666666665\n 1.3333333333333333\n\n\nnote: In some sense, the matrix \\({\\bf H}{\\bf x}\\) can be thought as generalized version of \\({\\boldsymbol h}\\star {\\bf x}\\) where \\(\\star\\) is convolution up to shift\n\nconv(h,x)\n\n9-element Vector{Float64}:\n 0.3333333333333334\n 0.6666666666666667\n 1.0\n 1.0\n 1.3333333333333333\n 1.6666666666666667\n 2.0\n 1.3333333333333333\n 0.6666666666666667\n\n\nFinally, we observe that, from the Cayley-Hamilton Theorem, \\({\\bf B}\\) satisfies its characteristic polynomial \\(\\Delta({\\bf B})\\), where \\(\\Delta(\\lambda)\\) is the determinant of \\(\\lambda{\\bf I}-{\\bf B}\\). The characteristic polynomial \\(\\Delta({\\bf B})\\) has degree \\(N\\), so, in DSP, as described so far, linear filters are (matrix) polynomial with degree at most \\(N-1\\).\n\n이 부분은 책에 써있길래 가져오긴 했는데, 무슨 의미인지 모르겠음"
  },
  {
    "objectID": "posts/study/prof/2022-12-26-Chap-12.2.html#coexisting-approaches",
    "href": "posts/study/prof/2022-12-26-Chap-12.2.html#coexisting-approaches",
    "title": "Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Coexisting Approaches",
    "text": "Coexisting Approaches\nStationary graph processes were first defined and analyzed in [@girault2015stationary]. The fundamental problem identified there is that GSOs do not preserve energy in general and therefore cannot be isometric [@gavili2017shift]. This problem is addressed in [@girault2015translation] with the definition of an isometric graph shift that preserves the eigenvector space of the Laplacian GSO but modifies its eigenvalues.\nA stationary graph process is then defined as one whose probability distributions are invariant with respect to multiplications with the isometric shift. One drawback of this approach is that the isometric shift is a complex-valued operator and has a sparsity structure (if any) different from \\({\\bf S}\\). By contrast, the vertex-based definition in\n\\[\\mathbb{E} \\bigg[ \\big({\\bf S}^a{\\bf x}\\big)\\Big(\\big({\\bf S}^H)^b {\\bf x}\\Big)^H  \\bigg]=\\mathbb{E}\\bigg[\\big({\\bf S}^{a+c}{\\bf x}\\big)\\Big(\\big({\\bf S}^H\\big)^{b-c}{\\bf x} \\Big)^H \\bigg]\\]\nis based on the original GSO \\({\\bf S}\\), which is local and real-valued. As a result, above Eq. provides intuition on the relations between stationarity and locality, which can be leveraged to develop stationarity tests or estimation schemes that work with local information. Graph stationarity was also studied in [@perraudin2017stationary] where the requirement of having a covariance matrix diagonalizable by the eigenvectors of the Laplacian GSO is adopted as a definition. This condition is shown to be equivalent to statistical invariance with respect to the translation operator introduced in [@shuman2016vertex]. When the shift \\({\\bf S}\\) coincides with the Laplacian of the graph and the eigenvalues of \\({\\bf S}\\) are all distinct, Definitions 12.1 and 12.2 are equivalent to those in [@girault2015stationary,@perraudin2017stationary]. Hence, the definitions presented here differ from [@perraudin2017stationary] in that we consider general normal shifts instead of Laplacians and that we see Definition 12.1 as a definition, not a property. These are mathematically minor differences that are important in practice though; see [@marques2017stationary,@segarra2017network] for more details."
  },
  {
    "objectID": "posts/study/test-ts.html",
    "href": "posts/study/test-ts.html",
    "title": "test",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.4     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(forecast)\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\nlibrary(recipes)\n\n\nAttaching package: 'recipes'\n\nThe following object is masked from 'package:stringr':\n\n    fixed\n\nThe following object is masked from 'package:stats':\n\n    step\n\n\n\ntourist <- scan('./tourist.txt')\ntourist[10:13] <- NA\ntour <- scan('./tour.txt')\n\ntour <- c(tourist, tour)\n\n\ntour.ts <- ts(tour, start=1981, frequency=12)\n\ntour.ts %>% \n  autoplot()\n\n\n\n\n\ntour.ts %>% \n  ggtsdisplay()\n\nWarning: Removed 4 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\nggseasonplot(tour.ts)\n\nWarning: Removed 4 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\n결측치 존재\n추세존재\n계절성 존재\n\n\ntrain <- window(tour.ts, end = c(1991, 12), freq=12)\ntest <- window(tour.ts, start = c(1992, 1), freq=12)\n\n\nlibrary(imputeTS)\nimputeTS::ggplot_na_distribution(train)\n\n\n\n\n\n1981년 말부터 1982년 사이에 결측치가 존재함.\n\n\n# 평균대치\nimp_na <- na_mean(train)\nimputeTS::ggplot_na_imputations(train, imp_na)\n\n\n\n\n\n## exponential moving average\nimp_movmean <- na_ma(train, weighting='exponential', k=3)\nimputeTS::ggplot_na_imputations(train, imp_movmean)\n\n\n\n\n시계열 결측치 대치법에는 크게 평균대치와 exponential moving average 방법이 있다. exponential moving average방법은 결측치와 가까운 시점에 더 큰 가중치를 부여하므로, 시계열의 경향성을 반영할 수 있다.\n그림을 통해서도 알수있듯이, 평균대치법에 비해 exponential moving average를 이용한 방법이 시계열의 경향성을 반영하며, 적절하게 결측치를 대치해주는 것을 확인할 수 있다..\n\nforecast::BoxCox.lambda(imp_movmean)\n\n[1] 0.1401004\n\n\n\n로그변환 실시\n\n\nlntour <- log(imp_movmean)\nlntour %>% autoplot()\n\n\n\n\n\n로그변환 결과, 시간에 따라 분산이 일정하게 안정화된 것을 볼 수 있음.\n\n- 추세와 계절성이 함께 존재하므로, 일반차분과 계절차분을 고려해볼 수 있을 것 같다.\n\ntour_1 <- diff(lntour)\nggtsdisplay(tour_1, lag.max = 48)\n\n\n\n\n\n계절차분을 고려해볼 수 있을 것 같다..\n\n\ntour_12 <- diff(lntour, lag=12)\nggtsdisplay(tour_12, lag.max=48)\n\n\n\n\n\nndiffs(tour_12)\n\n[1] 1\n\n\n\n계절차분 결과, 추세그래프와 acf plot을 확인해보면 추세가 존재하고, acf가 천천히 감소하는 것을 확인할 수 있다.\n추가적인 일반차분을 고려\n\n- d=1, D=1\n\ntour_1_12 <- diff(tour_1, lag=12)\nggtsdisplay(tour_1_12, lag.max = 48)\n\n\n\n\n\n추세가 사라졌으며, 계절성 또한 사라진 것 확인할 수 있다.\n따라서 계절차분과 일반차분 (d=1, D=1)을 동시에 고려.\n\n\nAcf(tour_1_12, lag.max = 48)\n\n\n\n\n\nPacf(tour_1_12, lag.max=48)\n\n\n\n\n후보모형 - \\(ARIMA(0,1,1)(0,1,1)_{12}\\) - \\(ARIMA(0,1,1)(1,1,0)_{12}\\) - \\(ARIMA(2,1,0)(0,1,1)_{12}\\) - \\(ARIMA(2,1,0)(1,1,0)_{12}\\)\n\nfit1 <- Arima(lntour, order = c(0,1,1),\n              seasonal = list(order = c(0,1,1),period = 12))\n\nfit2 <- Arima(lntour, order = c(0,1,1),\n              seasonal = list(order = c(1,1,0), period = 12))\n\nfit3 <- Arima(lntour, order = c(2,1,0),\n              seasonal = list(order = c(0,1,1), period = 12))\n\nfit4 <- Arima(lntour, order = c(2,1,0),\n              seasonal = list(order = c(1,1,0), period = 12))\n\n\nAIC(fit1, fit2, fit3)\n\n     df       AIC\nfit1  3 -317.4803\nfit2  3 -316.1026\nfit3  4 -315.7880\n\n\n\nBIC(fit1, fit2, fit3, fit4)\n\n     df       BIC\nfit1  3 -309.1429\nfit2  3 -307.7652\nfit3  4 -304.6715\nfit4  4 -304.0030\n\n\n\n confint(fit1)\n\n          2.5 %     97.5 %\nma1  -0.7302366 -0.4346864\nsma1 -0.7575456 -0.4108497\n\n\n\ncheckresiduals(fit1)\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(0,1,1)(0,1,1)[12]\nQ* = 18.268, df = 22, p-value = 0.69\n\nModel df: 2.   Total lags used: 24\n\n\n\n오차 사이에 자기상관X"
  },
  {
    "objectID": "posts/study/2023-03-07-intro.html",
    "href": "posts/study/2023-03-07-intro.html",
    "title": "myblog",
    "section": "",
    "text": "오메가(\\(\\Omega\\)) > Sample Space 라고함..\n오메가의 부분집합은? 공집합, {H},{T}, {H,T}\n공집합이 나올확률은 0?\n공리1,2,3은 지켜야함.\n\\(\\Omega\\)\n여기서 m은 길이를 재는 함수임.\n\n\\(m(\\Omega) = m([0,2\\pi))=2\\pi\\)\n\n개구간/폐구간 똑같?\n\\(m([0,2\\pi]) = m((0,2\\pi))\\)\n유리수만! > Q(무한개)\n무리수만!\n(외통수)\n\\[P(Q_{\\sqrt{2}})\\]"
  },
  {
    "objectID": "posts/study/2023-02-24-Chap8.3.html",
    "href": "posts/study/2023-02-24-Chap8.3.html",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "",
    "text": "using LinearAlgebra, FFTW"
  },
  {
    "objectID": "posts/study/2023-02-24-Chap8.3.html#cyclic-shift-operator-bfb",
    "href": "posts/study/2023-02-24-Chap8.3.html#cyclic-shift-operator-bfb",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Cyclic shift operator \\(\\bf{B}\\)",
    "text": "Cyclic shift operator \\(\\bf{B}\\)\nThe matrix \\(\\bf{B}\\) representing the periodic shift is\n\nB= [0 0 0 0 1\n    1 0 0 0 0 \n    0 1 0 0 0\n    0 0 1 0 0\n    0 0 0 1 0]\n\n5×5 Matrix{Int64}:\n 0  0  0  0  1\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n\n\nThis matrix is cyclic shift\nnote: \\(\\bf{B}\\) is orthogonal matrix (직교행렬: 전치행렬이 역행렬인 행렬 \\(\\bf{A}\\bf{A}'=\\bf{A}'\\bf{A}=\\bf{I}\\))\n\nCyclic shift가 뭔지는 모르겠지만 뭔가 모양새가 단위행렬을 한 칸씩 뒤에서 앞으로 밀어놓은 느낌이다.\n\n\nWhat is Cyclic shift?\nref: Cyclic shift의 개념\na circular shift is the operation of rearranging the entries in a tuple, either by moving the final entry to the first position, while shifting all other entries to the next position, or by performing the inverse operation. A circular shift is a special kind of cyclic permutation, which in turn is a special kind of permutation.\n위를 요약하자면 조합론에서 순환이동이란 튜플의 항목을 재정렬하는 작업이라고 한다. 마지막 element를 첫번째 위치로 이동하고 다른 모든 element들은 다음 위치로 이동하는 것.\n\n예를들어 (a, b, c, d)에 ciclic shift를 반복적으로 적용하면 다음과 같다.\n\n0 \\((a, b, c, d)\\) # before cyclic shift (origin)\n1 \\((d, a, b, c)\\) # 1step\n2 \\((c, d, a, b)\\) # 2step\n3 \\((b, c, d, a)\\) # 3step\n4 \\((a, b, c, d)\\) # 4step –> origin\n\ncyclic shift를 4번 반복하니까 원래 변환 전 원래 튜플로 돌아왔다.\n\n\n예제\n\nB # 1 cyclic shift\n\n5×5 Matrix{Int64}:\n 0  0  0  0  1\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n\n\n\nB'B # B는 orthogonal matrix니까 B'B = I일 것.\n\n5×5 Matrix{Int64}:\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n 0  0  0  0  1\n\n\n- (ex1) Define \\(s\\) as\n\ns = [1,2,3,4,5] ## origin\ns\n\n5-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n\n\n\nB*s\n\n5-element Vector{Int64}:\n 5\n 1\n 2\n 3\n 4\n\n\n결과: \\([1,2,3,4,5] \\to [5,1,2,3,4]\\)\n\n맨 뒤에 5가 앞으로 나오고 나머지 값들은 한칸씩 뒤로 밀렸다.\n위에서 배운대로라면 5번 쉬프트되면 자기자신으로 돌아오지 않을까?\n\n- \\(\\bf{B}^2\\) 에 \\(s\\)를 곱하면?\n\nB^2  # 2 cyclic shift\n\n5×5 Matrix{Int64}:\n 0  0  0  1  0\n 0  0  0  0  1\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n\n\n\nB^2*s\n\n5-element Vector{Int64}:\n 4\n 5\n 1\n 2\n 3\n\n\n결과: \\([1,2,3,4,5] \\to [5,1,2,3,4] \\to [4,5,1,2,3]\\)\n- \\(\\bf{B}^5\\)에 \\(s\\)를 곱하면?\n예상대로라면 원래 \\(s\\)인 \\([1,2,3,4,5]\\)로 돌아올 것 같다.\n\nB^5*s\n\n5-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n\n\nThus we can interprete the matrix \\(\\bf{B}\\) as cyclic shift operator such that\n\\[\\bf{B}_n = s_{n-1}\\]\nfor \\(n = 1,\\dots,N-1\\) and \\(\\bf{B}_{s_0}=s_N\\)\nnote : \\(\\bf{B}\\)는 시계열에서 다루는 backshift operator과 비슷함.\n(참고) backshift operator(후방이동) 연산자 \\(\\bf{B}\\)는 시계열 시차를 다룰 때 유용한 표기법 장치이다. (\\(B_{y_t} = y_{t-1})\\)\n시차변수 만들 때 완전 꿀팁인듯?"
  },
  {
    "objectID": "posts/study/2023-02-24-Chap8.3.html#dft",
    "href": "posts/study/2023-02-24-Chap8.3.html#dft",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "DFT",
    "text": "DFT\nThe matrix \\(\\bf{B}\\) can be expressed as\n\\(\\bf{B} = DFT^* \\cdot \\Lambda \\cdot DFT\\)\nwhere DFT is unitary and symmetric matrix and \\(\\Lambda\\) is diagonal matrix."
  },
  {
    "objectID": "posts/study/2023-02-24-Chap8.3.html#spectral-components-and-frequencies",
    "href": "posts/study/2023-02-24-Chap8.3.html#spectral-components-and-frequencies",
    "title": "Chap 8.3: Discrete Fourier Transform",
    "section": "Spectral components and Frequencies",
    "text": "Spectral components and Frequencies\nwe remark:\n(1) Spectral components: For \\(k = 0,1,2,\\dots, N-1\\), the \\(k\\)-th column of \\({\\bf DFT}^\\ast\\) is defined by\n\\[\\Psi_k:=\\frac{1}{\\sqrt{N}}\\begin{bmatrix} 1 \\\\ e^{j\\frac{2\\pi}{N}k} \\\\ e^{j\\frac{2\\pi}{N}2k} \\\\ e^{j\\frac{2\\pi}{N}3k} \\\\  \\dots \\\\ e^{j\\frac{2\\pi}{N}(N-1)k} \\end{bmatrix}.\\]\nNote that \\(\\Psi_k\\) can be also interpreted as \\(\\ell\\)-th eigenvector of \\({\\bf A}\\) correspoding \\(\\lambda_\\ell = e^{-j\\frac{2\\pi}{N}k}\\). Those eigenvectors\n\\[\\big\\{{\\bf 1},\\Psi_1,\\Psi_2, \\dots, \\Psi_{N-1}\\big\\}\\]\nform a complete orthonomal basis of \\(\\mathbb{C}^N\\). These vectors are called spectral components.\n(2) Frequencies: The diagonal entries of \\({\\bf \\Lambda}\\) are the eigenvalues of the time shift \\({\\bf B}\\). In Physics and in operator theory, these eigenvalues are the frequencies of the signal. In DSP it is more common to call frequencies\n\\[\\Omega_k=\\frac{-1}{2\\pi j}\\ln\\lambda_k=\\frac{-1}{2\\pi j}\\ln e^{-j \\frac{2\\pi}{N}k}=\\frac{k}{N}, \\quad k=0,1,2,\\dots,N-1.\\]"
  },
  {
    "objectID": "posts/study/2023-03-05-chap-12.2.1~12.3.1.html",
    "href": "posts/study/2023-03-05-chap-12.2.1~12.3.1.html",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "",
    "text": "using LinearAlgebra, Plots, FFTW, Statistics"
  },
  {
    "objectID": "posts/study/2023-03-05-chap-12.2.1~12.3.1.html#kronecker-product",
    "href": "posts/study/2023-03-05-chap-12.2.1~12.3.1.html#kronecker-product",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "Kronecker product",
    "text": "Kronecker product\n크로네커곱의 정의는 아래와 같다.\n\\[{\\bf A} \\otimes {\\bf B}\n=\\begin{bmatrix}\na_{11}{\\bf B} & a_{12}{\\bf B} & \\dots & a_{1m}{\\bf B} \\\\\na_{21}{\\bf B} & a_{22}{\\bf B} & \\dots & a_{2m}{\\bf B} \\\\\n\\dots & \\dots & \\dots & \\dots \\\\\na_{n1}{\\bf B} & a_{n2}{\\bf B} & \\dots & a_{nm}{\\bf B} \\\\\n\\end{bmatrix}\\]\n두 행렬 \\({\\bf A}_{m\\times n}\\), \\({\\bf B}_{p\\times q}\\)의 크로네커곱 \\({\\bf A}\\otimes {\\bf B}\\)의 차원은 \\(mp \\times nq\\) 가 된다. 계산예시는 아래와 같다.\n\n\n\nimage.png\n\n\n크로네커곱에 대한 성질들이 위키에 많이 있으니 참고하면 좋다.\n(예제1)\n\nA = [1 2\n     3 4]\nB = [0 5\n     6 7]\nC = kron(A,B)\n\n4×4 Matrix{Int64}:\n  0   5   0  10\n  6   7  12  14\n  0  15   0  20\n 18  21  24  28\n\n\n(예제2)\n\nA = [1 -4 7; -2 3 3]\nB = [8 -9 -6 -5; 1 -3 -4 7; 2 8 -8 -3; 1 2 -5 -1]\nC = kron(A, B)\n\n8×12 Matrix{Int64}:\n   8   -9  -6   -5  -32   36   24   20  56  -63  -42  -35\n   1   -3  -4    7   -4   12   16  -28   7  -21  -28   49\n   2    8  -8   -3   -8  -32   32   12  14   56  -56  -21\n   1    2  -5   -1   -4   -8   20    4   7   14  -35   -7\n -16   18  12   10   24  -27  -18  -15  24  -27  -18  -15\n  -2    6   8  -14    3   -9  -12   21   3   -9  -12   21\n  -4  -16  16    6    6   24  -24   -9   6   24  -24   -9\n  -2   -4  10    2    3    6  -15   -3   3    6  -15   -3"
  },
  {
    "objectID": "posts/study/2023-03-05-chap-12.2.1~12.3.1.html#khatri-rao-product",
    "href": "posts/study/2023-03-05-chap-12.2.1~12.3.1.html#khatri-rao-product",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "Khatri-Rao product",
    "text": "Khatri-Rao product\n카트리-라오곱은 매트릭스 \\(\\bf{A}\\)와 \\(\\bf{B}\\)가 같은 차원의 블락매트릭스로 정의될 때 각 서브매트릭스의 크로네커 곱으로 정의된다. 정의와 계산예시는 아래와 같다.\n\n\n\nimage.png\n\n\n또 다른 계산예시는 아래와 같다. 이 예제는 중요하니까 직접 구현해보자."
  },
  {
    "objectID": "posts/study/2023-03-05-chap-12.2.1~12.3.1.html#column-wise-kronecker-product",
    "href": "posts/study/2023-03-05-chap-12.2.1~12.3.1.html#column-wise-kronecker-product",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "Column-Wise Kronecker product",
    "text": "Column-Wise Kronecker product\n\n\n\nimage.png\n\n\n(예제1)\n\nC = [1 2 3\n     4 5 6\n     7 8 9]\n\n3×3 Matrix{Int64}:\n 1  2  3\n 4  5  6\n 7  8  9\n\n\n\nD = [1 4 7\n     2 5 8\n     3 6 9]\n\n3×3 Matrix{Int64}:\n 1  4  7\n 2  5  8\n 3  6  9\n\n\n\nJulia 문법\n\nhcat : The hcat() is inbuilt function in julia which is used to concatenate the given arrays along dimension 2.\n\n\n# hcat exmple\na = [5; 10; 15; 20; 25]\nb = [1 2; 3 4; 5 6; 7 8; 9 10]\nhcat(a, b)\n\n5×3 Matrix{Int64}:\n  5  1   2\n 10  3   4\n 15  5   6\n 20  7   8\n 25  9  10\n\n\n\n\\(\\bf{C}*\\bf{D} = [C_1\\otimes D_1 | C_2 \\otimes D_2 | C_3 \\otimes D_3]\\)\n\nhcat([kron(C[:,i],D[:,i]) for i in 1:3]...)\n\n9×3 Matrix{Int64}:\n  1   8  21\n  2  10  24\n  3  12  27\n  4  20  42\n  8  25  48\n 12  30  54\n  7  32  63\n 14  40  72\n 21  48  81\n\n\n이건 자주 쓸일이 있을 것 같으니까 함수로 저장하자.\n\ncolumnwise_kron = \n(C,D) -> hcat([kron(C[:,i],D[:,i]) for i in 1:size(C)[2]]...)\n\n#3 (generic function with 1 method)\n\n\n\ncolumnwise_kron(C, D)\n\n9×3 Matrix{Int64}:\n  1   8  21\n  2  10  24\n  3  12  27\n  4  20  42\n  8  25  48\n 12  30  54\n  7  32  63\n 14  40  72\n 21  48  81"
  },
  {
    "objectID": "posts/study/2023-03-05-chap-12.2.1~12.3.1.html#그래프-표현",
    "href": "posts/study/2023-03-05-chap-12.2.1~12.3.1.html#그래프-표현",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "그래프 표현",
    "text": "그래프 표현\n아래의 그림을 살펴보자.\n\n\n\n그래프의 개념을 이해하는데 필요한 그림\n\n\n오른쪽 \\(\\bf S\\)는 무시하고 왼쪽의 그래프만 살펴보자. 이 그림에는 \\(6\\)개의 노드가 있고 각각의 노드에는 저 마다의 연결구조를 가진다. 이러한 연결구조는 \\(\\bf{G} = (\\bf{N},\\bf{E})\\)으로 표현할 수 있는데 여기에서 \\(\\bf{N}\\)은 노드들의 집합이고, \\(\\bf{E}\\)는 엣지1들의 집합니다. 보통 \\(\\cal E\\)는 복잡하므로 연결정보를 매트릭스 \\(\\bf{E}\\)로 표현하는데 이러한 \\(\\bf{E}\\)를 인접행렬이라고 부른다. 인접행렬의 각 원소는 \\(E_{ij}= \\begin{cases} 1 & (i,j) \\in {\\cal E} \\\\ 0 & o.w \\end{cases}\\) 와 같이 정의한다. 이 그림의 경우 \\({\\cal N}\\) 와 \\({\\cal E}\\), \\({\\bf E}\\) 는 아래와 같다.\n\n\\(\\cal N = \\{1, 2, 3, 4, 5, 6\\}\\)\n\\({\\bf E}=\\begin{bmatrix} 0 & 1 & 0 & 0 & 1 & 0 \\\\ 1 & 0 & 1 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 & 1 & 1 \\\\ 1 & 1 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 & 0 & 0 \\end{bmatrix}\\)\n\\({\\cal E} = \\{(i,j) : E_{ij}=1 \\}\\)"
  },
  {
    "objectID": "posts/study/2023-03-05-chap-12.2.1~12.3.1.html#gso-graph-shift-operator",
    "href": "posts/study/2023-03-05-chap-12.2.1~12.3.1.html#gso-graph-shift-operator",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "GSO (Graph Shift Operator)",
    "text": "GSO (Graph Shift Operator)\n후에 자세히 서술하겠지만 전통적인 시계열분석기법을 그래프신호로 확장하기 위해서는 단지 퓨리에변환 대신에 그래프퓨리에 변환을 사용하면 된다. 즉 퓨리에변환을 일반화한 그래프퓨리에 변환을 잘 정의하면 된다.\n전통적인 신호처리 영역에서의 퓨리에변환은 시계열자료의 인접성을 의미하는 행렬 \\(\\bf{B}\\)2의 고유행렬의 켤레전치로 정의할 수 있다. 이를 이용하면 그래프 퓨리에변환은 그래프자료의 인접성을 의미하는 행렬3의 고유행렬의 켤레전치로 정의할 수 있음을 유추할 수 있다. 즉, 비유클리드 자료에서도 \\(\\bf{B}\\)에 대응하는 어떠한 매트릭스가 정의되어야 하는데 (그리고 이 매트릭스는 그래프자료의 인접성에 대한 정보가 있어야 한다.) 이 매트릭스를 \\(\\bf{S}\\)라고 정의하고 graph shift operator (GSO) 라고 이름 붙인다.\n주어진 그래프 \\(\\cal{G} = (\\cal{N}, \\cal{E})\\)에 대하여 GSO \\(\\bf S\\)는 \\(\\bf{E} + \\bf{I}\\)의 값이 1인 영역에만 값이 있는 어떠한 행렬이다. 다시 아래의 그림을 생각하여 보자.\n\n\n\nGSO개념을 이해하는데 필요한 그림\n\n\n왼쪽 그래프의 GSO는 오른쪽과 같은 행렬 \\(\\bf S\\)가 된다. 이제 \\(\\bf S\\)의 고유벡터행렬을 구한 뒤에 그것의 켤레전치를 \\(\\bf{GFT}\\) 행렬로 정의하면 될 것 같다.문제는 “\\(\\bf{S}\\)의 고유벡터행렬이 항상 존재하는가?”인데, 사실 이게 항상 존재한다는 보장이 없다. 즉 \\(\\bf{S}\\)의 고유벡터 행렬이 존재 안할 수도 있다. 따라서 GSO \\(\\bf{S}\\)가 고유분해가능하다는 조건이 추가적으로 필요한데 이러한 조건을 만족하는 GSO를 normal GSO라고 부른다. 우리는 당연히 normal GSO에 대해서만 관심이 있으므로 앞으로 특별한 언급이 없는 한 GSO는 모두 normal GSO라고 가정한다."
  },
  {
    "objectID": "posts/study/2023-03-05-chap-12.2.1~12.3.1.html#정상시계열을-분석한흔-두-가지-흐름-acf와-psd",
    "href": "posts/study/2023-03-05-chap-12.2.1~12.3.1.html#정상시계열을-분석한흔-두-가지-흐름-acf와-psd",
    "title": "Chap 12.2: Weakly Stationary Graph process",
    "section": "정상시계열을 분석한흔 두 가지 흐름, ACF와 PSD",
    "text": "정상시계열을 분석한흔 두 가지 흐름, ACF와 PSD\n\n전통적인 분석방법\n클래식한 정상시계열은 유한차수의 ARMA로 근사할 수 있음이 알려져 있다. 유한차수의 ARMA의 계수 \\(p,q\\)를 적절하게 추정하기 위해서는 시계열 \\(\\bf x\\)를 SACF plot 혹은 SPACF plot을 이용하면 된다. 이때 SACF 혹은 SPACF의 그림을 살펴보고 적절한 모형을 선택하기 위해서는 유한차수 ARMA의 이론적 ACF의 모양을 알면 되는데, 이를 바꾸어서 말하면 결국 정상시계열 \\(\\bf x\\)의 모든 정보는 ACF에 들어가있다는 의미가 된다. 즉 정상시계열은 ACF만 잘 추정함녀 모든 것이 해결된다.\n그런데 ACF의 모든 정보는 다시 아래의 행렬에 들어있다.\n\\[{\\bf C}_{\\bf x}=\\mathbb{E}[{\\bf x}{\\bf x}^T]\\]\n여기에는 \\(\\bf x\\)는 relization이 아니라 확률벡터를 의미함을 유의하자. 따라서 정상시계열의 경우 \\(\\bf{C}_x\\)를 잘 추정하면 모든것이 잘 해결된다고 생각하면 된다.\n\n참고: 정상시계열의 경우 ACF 만 정확하게 알아도 (반대로 PACF만 정확하게 알아도) 이론상 모든 모형을 특정할 수 있다. 즉 정상시계열의 모형을 특정하기 위해서는 ACF plot, PACF plot 하나만 있어도 충분하다. (Wold’s Thm은 떠올리면 모든 정상시계열은 무한MA로 유니크하게 표현할 수 있는데, 이는 PACF plot을 가지고 모든 정상시계열을 유니크하게 특정할 수 있다는 것을 의미한다) 다만 좀 더 모형을 특정하는 과정을 용이하게 하기 위해서 실전에서는 SACF plot 과 SPACF plot 을 함께 보는 것이 유리하다.\n\n(예제) AR(1) 모형\n왜 ACF의 모든 정보를 \\(\\bf{C}_x\\) 로부터 알 수 있는지 코드를 통하여 실습하여 보자.\n아래의 모형을 가정하자.\n\\[x_t = 0.5x_{t-1} + \\epsilon_t\\]\n여기에서 \\(\\epsilon_t\\)는 서로 독립인 표준정규분포를 따른다. 이 모형에서 길이가 100인 시계열을 임으로 발생시키자.\n\nx = zeros(100*1)\nx[1] = randn()\nfor t in 2:100\n    x[t] = 0.5*x[t-1] + randn()\nend\n\n모형에서 생성된 하나의 시계열을 시각화하면 아래와 같다.\n\nplot(x)\n\n\n\n\nlag=1일 경우 시계열의 SACF를 계산하면 아래와 같다.\n\nx[1:99] .* x[2:100]\n\n99-element Vector{Float64}:\n  2.763927872349466\n -2.648382063879747\n  7.5560713885953215\n 14.538881990615415\n  0.520289725235592\n -0.02893028852363918\n -0.08713887236919443\n  0.664714967484797\n  1.7558767596344267\n  0.8198605801110912\n  0.03431855113914528\n -0.01819122449351602\n -0.5411309265124012\n  ⋮\n  0.8627760724036734\n  1.4665215311182225\n -0.11299501148861134\n  0.03195980896825844\n  0.0699424007664186\n  0.009424426205167391\n  0.07855903160522548\n -0.8085731251113174\n -0.17558999208627857\n -0.4339226145863137\n  3.357684099650187\n  1.4577818358298857\n\n\n\n이 계산결과는 각 \\(t\\)에 대하여 \\(x_{t-1}x_t\\)를 계산한 것과 같다.\n\n이 수열들의 평균은 아래와 같다.\n\nx[1:99] .* x[2:100] |> mean\n\n0.6460152065947437\n\n\n\n이 계산결과는 \\(\\frac{1}{99}\\sum_{t=2}^{100}x_{t-1}x_t\\)를 계산한 것과 같다.\n\n이론적인 값인 0.5 근처의 값이 잘 나옴을 알 수 있다???? 뭔가 잘못했나.. \\(0.5\\)근처라고 해도 되나..?\nlag=2일 경우도 마찬가지로 구할 수 있다.\n\nx[1:98] .* x[3:100] |> mean\n\n0.017848962875704446\n\n\n그런데 이러한 숫자들은 \\(\\bf{x}\\bf{x}^\\top\\)를 이용해서도 구할 수 있다.\n\nx*x'\n\n100×100 Matrix{Float64}:\n  4.51193    2.76393    -4.32331    …   3.01347     5.02729    1.30834\n  2.76393    1.69313    -2.64838        1.846       3.07963    0.801466\n -4.32331   -2.64838     4.14257       -2.8875     -4.81713   -1.25364\n -7.88573   -4.83066     7.55607       -5.26681    -8.78647   -2.28665\n -8.31861   -5.09584     7.97085       -5.55593    -9.26879   -2.41218\n -0.2822    -0.172871    0.270402   …  -0.188479   -0.314433  -0.0818304\n  0.46255    0.28335    -0.443213       0.308933    0.515384   0.134127\n -0.849993  -0.520691    0.814459      -0.567703   -0.947083  -0.246476\n -3.52843   -2.16146     3.38093       -2.35661    -3.93146   -1.02315\n -2.2453    -1.37543     2.15143       -1.49961    -2.50176   -0.651077\n -1.64751   -1.00924     1.57864    …  -1.10036    -1.83569   -0.477734\n -0.093986  -0.0575742   0.0900569     -0.0627724  -0.104721  -0.0272534\n  0.873295   0.534965   -0.836787       0.583266    0.973046   0.253232\n  ⋮                                 ⋱                         \n  2.12852    1.3039     -2.03954        1.42162     2.37165    0.617215\n  3.10866    1.90431    -2.9787         2.07624     3.46374    0.901428\n -0.164002  -0.100465    0.157146   …  -0.109535   -0.182735  -0.0475562\n -0.87926   -0.53862     0.842503      -0.58725    -0.979692  -0.254962\n -0.35891   -0.219862    0.343905      -0.239712   -0.399905  -0.104074\n -0.118476  -0.0725766   0.113523      -0.0791293  -0.132009  -0.034355\n -2.99176   -1.8327      2.86669       -1.99817    -3.33349   -0.86753\n  1.21942    0.746999   -1.16845    …   0.814443    1.35871    0.353601\n -0.649691  -0.397989    0.622531      -0.433923   -0.723901  -0.188393\n  3.01347    1.846      -2.8875         2.01267     3.35768    0.873828\n  5.02729    3.07963    -4.81713        3.35768     5.60153    1.45778\n  1.30834    0.801466   -1.25364        0.873828    1.45778    0.379384\n\n\n여기에서 각 원소들이 의미하는 바는 아래와 같다.\n\n대각선의 원소: \\(x_t^2, \\space t=1,2,\\dots,100\\)을 의미\n대각선 한칸 위, 혹은 한칸 아래: \\(x_{t-1}x_t,\\space t=2,3,\\dots,100\\)을 의미\n대각선 두칸 위, 혹은 두칸 아래: \\(x_{t-1}x_t, \\space t=3,4,\\dots 100\\)을 의미\n\n\nx[1:5]\n\n5-element Vector{Float64}:\n  2.1241294211140476\n  1.301205023044152\n -2.0353303414736996\n -3.712454550804897\n -3.916245112674374\n\n\n\nx'\n\n1×100 adjoint(::Vector{Float64}) with eltype Float64:\n 2.12413  1.30121  -2.03533  -3.71245  …  1.41869  2.36675  0.615941\n\n\n\\(\\begin{bmatrix} \\end{bmatrix}\\)\n\n2.1241294211140476^2, 1.301205023044152^2, (-2.0353303414736996)^2 ## 대각선 원소\n\n(4.511925797642299, 1.6931345119953323, 4.142569598923447)\n\n\nlag1\n\n(x[1:99] .* x[2:100])[1:5]\n\n5-element Vector{Float64}:\n  2.763927872349466\n -2.648382063879747\n  7.5560713885953215\n 14.538881990615415\n  0.520289725235592"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn4.html",
    "href": "posts/RNN/2023-02-28-rnn4.html",
    "title": "순환신경망 (4)",
    "section": "",
    "text": "RNN (2)-AbAcAd예제(3)"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn4.html#data",
    "href": "posts/RNN/2023-02-28-rnn4.html#data",
    "title": "순환신경망 (4)",
    "section": "data",
    "text": "data\n- 기존의 정리방식\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5], txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))).float()\n\n\nx,y\n\n(tensor([[1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         ...,\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.]]),\n tensor([[0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         ...,\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.]]))"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html",
    "href": "posts/RNN/2023-02-25-rnn2.html",
    "title": "순환신경망 (2)",
    "section": "",
    "text": "순환신경망 intro(2)- abc예제, abdc예제, AbAcAd예제(1)"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#data",
    "href": "posts/RNN/2023-02-25-rnn2.html#data",
    "title": "순환신경망 (2)",
    "section": "data",
    "text": "data\n\ntxt = list('abc')*100\ntxt[:10]\n\n['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'a']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5], txt_y[:5]\n\n(['a', 'b', 'c', 'a', 'b'], ['b', 'c', 'a', 'b', 'c'])"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#하나의-은닉노드를-이용한-풀이---억지로-성공",
    "href": "posts/RNN/2023-02-25-rnn2.html#하나의-은닉노드를-이용한-풀이---억지로-성공",
    "title": "순환신경망 (2)",
    "section": "하나의 은닉노드를 이용한 풀이 - 억지로 성공",
    "text": "하나의 은닉노드를 이용한 풀이 - 억지로 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2}\nx = torch.tensor(f(txt_x, mapping))\ny = torch.tensor(f(txt_y, mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 0, 1]), tensor([1, 2, 0, 1, 2]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=3, embedding_dim=1), # 3? -> a,b,c // 1?->은닉층의 노드개수를 1로 설정\n    torch.nn.Tanh(),\n    #==#\n    torch.nn.Linear(in_features=1, out_features=3)\n)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    ## 2\n    loss = loss_fn(net(x),y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nsoft(net(x))[:5] \n\ntensor([[7.7743e-02, 8.4444e-01, 7.7818e-02],\n        [5.2772e-05, 7.6005e-02, 9.2394e-01],\n        [9.2247e-01, 7.7472e-02, 5.5484e-05],\n        [7.7743e-02, 8.4444e-01, 7.7818e-02],\n        [5.2772e-05, 7.6005e-02, 9.2394e-01]], grad_fn=<SliceBackward0>)\n\n\n\nnet[:2]\n\nSequential(\n  (0): Embedding(3, 1)\n  (1): Tanh()\n)\n\n\n\nnet[:2](x)[:5]\n#net[:-1](x)[:5]\n#net[1](net[0](x))[:5]\n\ntensor([[-0.0147],\n        [ 0.9653],\n        [-0.9896],\n        [-0.0147],\n        [ 0.9653]], grad_fn=<SliceBackward0>)\n\n\n- 결과해석\n처음에 두 layer를 통과시킨 값들이 어떤 값을 가질지 조사해보자.\n\nhidden = net[:-1](x).data # 처음 2개의 layer 통과\nyhat = soft(net(x)).data # hidden에 softmax 취한 것.\n\n\nplt.plot(hidden[:9],'--o')\n\n\n\n\n2번째 layer(hidden layer)까지 통과하고 한번 더 linear transform을 거치게 되면 여기 있는 하나의 값이 3개로 잘라지는데 잘라진 3개를 각각 플랏하면 다음과 같다.\n\nnet(x)[:5]\n\ntensor([[-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086],\n        [ 3.0875,  0.6104, -6.6312],\n        [-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086]], grad_fn=<SliceBackward0>)\n\n\n\nplt.plot(net(x).data[:9],'--o') # 파(a)->주(b)->초(c) 순서로 값들이 나타남.\n\n\n\n\n\n\\(x= a,b,c,a,b,c\\dots\\)\n\\(y = b,c,a,b,c,a\\dots\\)\n주황색 선의 학습상태가 썩 마음에 들지 않는다. 초록색은 확실하게 초록색, 파란색은 확실하게 파란색인데 주황색은 딱히 그런게 없다.\n약간 그런느낌 파란색도 아니고 초록색도 아니니까 얘(주황)로 하지\n\n\nplt.plot(yhat[:9],'--o')\n#plt.plot(soft(net(x)).data[:9],'--o')\n\n\n\n\n\nyhat[:5] # b일확률이 84%.. (주->b일확률, 초->c일확률, 파->a일확률)\n\ntensor([[7.7743e-02, 8.4444e-01, 7.7818e-02],\n        [5.2772e-05, 7.6005e-02, 9.2394e-01],\n        [9.2247e-01, 7.7472e-02, 5.5484e-05],\n        [7.7743e-02, 8.4444e-01, 7.7818e-02],\n        [5.2772e-05, 7.6005e-02, 9.2394e-01]])\n\n\n\ny[:5]\n\ntensor([1, 2, 0, 1, 2])\n\n\n\n억지로 맞추고 있긴한데 파라메터가 부족해보인다."
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#결과시각화1-위와-똑같은-그림임",
    "href": "posts/RNN/2023-02-25-rnn2.html#결과시각화1-위와-똑같은-그림임",
    "title": "순환신경망 (2)",
    "section": "- 결과시각화1 (위와 똑같은 그림임)",
    "text": "- 결과시각화1 (위와 똑같은 그림임)\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$', size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x)(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h, net(x),\\hat{y}$\", size=20)\nplt.tight_layout()\n\n\n\n\n\nhidden[:9], (net[-1].weight).T, net[-1].bias.data\n\n(tensor([[-0.0147],\n         [ 0.9653],\n         [-0.9896],\n         [-0.0147],\n         [ 0.9653],\n         [-0.9896],\n         [-0.0147],\n         [ 0.9653],\n         [-0.9896]]),\n tensor([[-4.6804,  0.3071,  5.2894]], grad_fn=<PermuteBackward0>),\n tensor([-1.5440,  0.9143, -1.3970]))\n\n\n\n(파랑, 주황, 초록) 순서로 그려짐\n파랑 = hidden * (-4.6804) + (-1.5440)\n주황 = hidden * (0.3071) + (0.9143) ## 상대적으로 weight, bias가 어정쩡\n초록 = hidden * (5.2894) + (-1.3970)\n\n초록색과 파란색에 대한 클래스는 확실하게 특징을 파악해서 잘 학습한 것 같은데 주황색은 그냥 초록색과 파란색이 아니기 때문에 주황색인 느낌이다.\n- 내부동작을 잘 뜯어보니까 사실 엉성해. 엄청 위태위태하게 맞추고 있었음.\n\nweight: 파랑과 초록을 구분하는 역할을 함.\nweight + bias: 뭔가 교묘하게 에매한 주황값을 만들어서 에매하게 ’b’라고 나올 확률을 학습시킨다. \\(\\to\\) 사실 학습하는 것 같지 않고 때려맞추는 느낌, 쓸 수 있는 weight가 한정적이라서 생기는 현상 (양수, 음수, 0)\n\n\n참고: torch.nn.Linear()의 비밀?\n\n사실 \\(y=x\\bf{W}+b\\) 꼴에서의 \\(\\bf{W}\\)와 \\(b\\)가 저장되는게 아니다.\n\\(y =x\\bf{A}^T+b\\)꼴에서의 \\(\\bf{X}\\)와 \\(b\\)가 저장된다.\n\\(\\bf{W}=\\bf{A}^T\\) 인 관계에 있으므로 l1.weight가 우리자 생각하는 \\(\\bf{W}\\)로 해석하려면 사실 transpose를 취해줘야 한다.\n\n왜 이렇게..?\n\n계산의 효율성 때문 (numpy의 구조를 알아야함)\n\\(x,y\\)는 수학적으로는 col-vec이지만 메모리에 저장할 시에는 row-vec로 해석하는 것이 자연스럽다. (사실 메모리는 격자모양으로 되어있지 않음)"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#결과시각화2",
    "href": "posts/RNN/2023-02-25-rnn2.html#결과시각화2",
    "title": "순환신경망 (2)",
    "section": "- 결과시각화2",
    "text": "- 결과시각화2\n똑같은 내용을 다른방식으로 시각화 한 것임.\n\ncombined = torch.concat([hidden, net(x).data, yhat],axis=1)\n\n\nplt.matshow(combined[:15], vmin=-15, vmax=15, cmap='bwr')\nplt.xticks(range(7), labels=[r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$'], size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\", size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\nsoftmax를 취하기 전단계인 net(x)(2열4열)에서 가장 빨간색인 부분만 살아남아 빨간색(57열)이 되고, 나머지 부분은 흰색으로 바뀌게 된다.\n위의 그림에서 첫번째 행에서 2~4번째 열을 보면 에매한 파란색, 에매한 빨간색으로 b가 되는 느낌."
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#data-1",
    "href": "posts/RNN/2023-02-25-rnn2.html#data-1",
    "title": "순환신경망 (2)",
    "section": "data",
    "text": "data\n\ntxt = list('abcd')*100\ntxt[:10]\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'a', 'b']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5], txt_y[:5]\n\n(['a', 'b', 'c', 'd', 'a'], ['b', 'c', 'd', 'a', 'b'])"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#하나의-은닉노드를-이용한-풀이---억지로-성공-1",
    "href": "posts/RNN/2023-02-25-rnn2.html#하나의-은닉노드를-이용한-풀이---억지로-성공-1",
    "title": "순환신경망 (2)",
    "section": "하나의 은닉노드를 이용한 풀이 - 억지로 성공",
    "text": "하나의 은닉노드를 이용한 풀이 - 억지로 성공\n- 데이터 정리\n\nmapping = {'a':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))\n\n\n- 학습\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4, embedding_dim=1),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1, out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nnet[0].weight.data = torch.tensor([[-0.3333],[-2.5000],[5.0000],[0.3333]])\n\nnet[-1].weight.data = torch.tensor([[1.5000],[-6.0000],[-2.0000],[6.0000]])\nnet[-1].bias.data = torch.tensor([0.1500, -2.0000,  0.1500, -2.000])\n\n\nnet[0]\n\nEmbedding(4, 1)\n\n\n\nfor epoc in range(5000):\n    ## 1\n    ## 2\n    loss = loss_fn(net(x),y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n\n주황색과 빨간색을 특징을 잘 파악했는데 녹색과 파란색은 좀 에매하게 특징을 파악했지만 어쩌다보니 결과는 잘 나옴.\n\n\n\n- 결과시각화2\n\ncombined = torch.concat([hidden, net(x).data, yhat], axis=1)\ncombined.shape\n\ntorch.Size([399, 9])\n\n\n\nplt.matshow(combined[:15],vmin=-15,vmax=15,cmap='bwr')\nplt.xticks(range(9), labels=[r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#두개의-은닉노드를-이용한-풀이---깔끔한-성공",
    "href": "posts/RNN/2023-02-25-rnn2.html#두개의-은닉노드를-이용한-풀이---깔끔한-성공",
    "title": "순환신경망 (2)",
    "section": "두개의 은닉노드를 이용한 풀이 - 깔끔한 성공",
    "text": "두개의 은닉노드를 이용한 풀이 - 깔끔한 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=2), # 은닉노드 2개\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n(맨 왼쪽 그림) 2개의 노드를 썼으니까 파랑이와 주황색선 두개가 보인다. - h dimension \\((n,1)\\to(n,2)\\) - 주황이가 확실히 1, -1 호불호가 갈려서 학습이 된다. - 파랑이도 1, -1 두가지로 갈려서 학습이 된다.\n맨 왼쪽그림에서 적당한 선형변환을 통해 2번째 그림을 만들어야 하고, 여기서 3번째 그림을 만들어야 한다. - 가장 오른쪽 그림의 출력결과만 봐도 매우 깔끔하게 나온다! - 높은 확률로 깔끔하게 예측하고 있음을 볼 수 있다.\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([399, 10])\n\n\n\nplt.matshow(combined[:15],vmin=-7,vmax=7,cmap='bwr')\nplt.xticks(range(10), labels=[r'$h$',r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\n\nhidden layer는 \\(-1\\sim 1\\) 값을 가질 수 있다.\n\n파,빨 \\(\\to\\) b\n파,파 \\(\\to\\) c\n빨,파 \\(\\to\\) d\n빨,빨 \\(\\to\\) a\n\n\n이런식으로 hidden layer에 있는 특징들도 결과를 해석하기에 좋은 형태로 잘 학습되어 있다.\n\n빨간색일수록 근거가 뚜렷함. 특징이 그전에 비해서 굉장히 명확하게 학습이 되고 있다는 것을 알 수 있다.\n그 전에는 b와 d는 특징을 잘 파악하고 있는데 a,c는 약간 에매했지만 이번에는 a,b,c,d의 특징들을 잘 이해하고 맞추는 것처럼 느껴진다."
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#data-2",
    "href": "posts/RNN/2023-02-25-rnn2.html#data-2",
    "title": "순환신경망 (2)",
    "section": "data",
    "text": "data\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#두개의-은닉노드를-이용한-풀이---실패",
    "href": "posts/RNN/2023-02-25-rnn2.html#두개의-은닉노드를-이용한-풀이---실패",
    "title": "순환신경망 (2)",
    "section": "두개의 은닉노드를 이용한 풀이 - 실패",
    "text": "두개의 은닉노드를 이용한 풀이 - 실패\n- 데이터정리\n\nmapping = {'A':0, 'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x, mapping))\ny = torch.tensor(f(txt_y, mapping))\nx[:5], y[:5]\n\n(tensor([0, 1, 0, 2, 0]), tensor([1, 0, 2, 0, 3]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4, embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2, out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat, y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([599, 10])\n\n\n\nplt.matshow(combined[:15],vmin=-5,vmax=5,cmap='bwr')\nplt.xticks(range(10), labels=[r'$h$',r'$h$',r'$y=A?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=A)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\n\n\\(x = \\text{AbAcAd}\\dots\\)\n\\(y = \\text{bAcAdA}\\dots\\)\n\n결국 A의 자리만 잘 찾고 b,c,d끼리는 구분을 잘 못하는 느낌이다. (1/3확률로 찍는 느낌)\n히든노드를 2개로 하고 잘 한 것 같은데 왜 이런 결과가 나올까?\n\n\n\nimage.png\n\n\n데이터를 살펴보자. 보니까 A->b, A->c, A->d ??? A다음에 뭐가 나올지 맞출 수가 없다.\n\n인간은 추론해서 맞출 수 있겠지만 컴퓨터는 데이터를 바로 직전에 있는 character만 보고 다음을 예측하게끔 우리가 데이터셋을 구성해서 x,y로 줬다.\n그런데 사실은 바로 직전이 아니고 그 직전에 직전도 보고 뭔가 이렇게 좀 여러개를 이제 봐야한다는 것이다.\n해결책? 한칸을 더 보게하면 된다. but 엄밀히 말하면 해결이 아님!\n\n실패\n- 실패를 해결하는 순진한 접근방식: 위 문제를 해결하기 위해서는 아래와 같은 구조로 데이터를 다시 정리하면 될 것이다.\n\n\n\nx\ny\n\n\n\n\nA,b\nA\n\n\nb,A\nc\n\n\nA,c\nA\n\n\nc,A\nd\n\n\nA,d\nA\n\n\nd,A\nb\n\n\nA,b\nA\n\n\nb,A\nc\n\n\n\\(\\cdots\\)\n\\(\\cdots\\)\n\n\n\n- 순진한 접근방식의 비판\n\n결국 정확하게 직전 2개의 문자를 보고 다음 문제를 예측하는 구조\n만약에 직전 3개의 문자를 봐야하는 상황이 된다면 또 다시 코드를 수정해야함.\n그리고 실전에서는 직전 몇 개의 문자를 봐야하는지 모름.\n\n앞에있는 2개, 3개, 4개.. 이러한 구조를 반영할 수 있는 새로운 네트워크를 고안해냈는데 그것은 바로 순환신경망이다.\n지금까지는 순환신경망의 필요성에 대해 알아보았던 것!\n이것에 대한 해결책은 순환신경망이다.(NEXT)"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#도전1-은닉노드-2개",
    "href": "posts/RNN/2023-02-25-rnn2.html#도전1-은닉노드-2개",
    "title": "순환신경망 (2)",
    "section": "도전1 (은닉노드 2개)",
    "text": "도전1 (은닉노드 2개)\n\nmapping = {'a':0,'b':1,'c':2,'d':3,'e':4}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 4]), tensor([1, 2, 3, 4, 0]))\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=5,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=5)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([499, 12])\n\n\n\nplt.matshow(combined[:15],vmin=-7,vmax=7,cmap='bwr')\nplt.xticks(range(12), labels=[r'$h$',r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$y=d?$', r'$y=e?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$',r'$P(y=e)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\n\n실패"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn2.html#도전2-은닉노드-3개",
    "href": "posts/RNN/2023-02-25-rnn2.html#도전2-은닉노드-3개",
    "title": "순환신경망 (2)",
    "section": "도전2 ( 은닉노드 3개)",
    "text": "도전2 ( 은닉노드 3개)\n\nmapping = {'a':0,'b':1,'c':2,'d':3,'e':4}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 4]), tensor([1, 2, 3, 4, 0]))\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=5,embedding_dim=3),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=3,out_features=5)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([499, 13])\n\n\n\nplt.matshow(combined[:15],vmin=-5,vmax=5,cmap='bwr')\nplt.xticks(range(13), labels=[r'$h$',r'$h$',r'$h$',\n                              r'$y=A?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$y=e?$',\n                              r'$P(y=A)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$',r'$P(y=e)$'],size=13)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\na,b,c,d,e를 표현함에 있어서 3개의 은닉노드면 충분하다.\n\n1개의 은닉노드 \\(\\to\\) 2개의 문자를 표현할 수 있음\n2개의 은닉노드 \\(\\to\\) 4개의 문자를 표현할 수 있음\n3개의 은닉노드 \\(\\to\\) 8개의 문자를 표현할 수 있음"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn3.html",
    "href": "posts/RNN/2023-02-28-rnn3.html",
    "title": "순환신경망 (3)",
    "section": "",
    "text": "RNN1 - AbAcAd예제(2)"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn3.html#data",
    "href": "posts/RNN/2023-02-28-rnn3.html#data",
    "title": "순환신경망 (3)",
    "section": "data",
    "text": "data\n- 기존의 정리방식\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5], txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])\n\n\n\nx = torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))\n\n\nx[:8], y[:8]\n\n(tensor([0, 1, 0, 2, 0, 3, 0, 1]), tensor([1, 0, 2, 0, 3, 0, 1, 0]))\n\n\n- 이번에는 원핫인코딩 형태까지 미리 정의하자. (임베딩 레이어 안쓸예정)\n\nx= torch.nn.functional.one_hot(x).float()\ny= torch.nn.functional.one_hot(y).float()\n\n\nx, y\n\n(tensor([[1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         ...,\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.]]),\n tensor([[0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         ...,\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.]]))"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn3.html#실패했던-풀이-구현1",
    "href": "posts/RNN/2023-02-28-rnn3.html#실패했던-풀이-구현1",
    "title": "순환신경망 (3)",
    "section": "실패했던 풀이: 구현1",
    "text": "실패했던 풀이: 구현1\n- 저번시간의 실패한 풀이\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4, embedding_dim=2), ##\n    torch.nn.Tanh(), ##\n    torch.nn.Linear(in_featusre=2, out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\n네트워크 쪼개기\n- Tanh까지만 클래스로 바꾸어서 구현\n## step1. 요 두줄 따로 떼네서 요부분만 수행하는 네트워크를 따로만들고 (Hnet)\ntorch.nn.Embedding(num_embeddings=4, embedding_dim=2),\ntorch.nn.Tanh(),\n## step2. 밑에있는 linear를 수행하는 네트워크를 따로 만들 것이다.\ntorch.nn.Linear(in_featusre=2, out_features=4)\n## step3. 이렇게 2개의 네트워크를 만들고, 2개의 네트워크에 해당되는 파라미터들을 전달해서 학습을 시킬 것\n\n## + 2개의 네트워크로 쪼개서 파라미터를 각각 리스트 형태로 전달할 것이기 때문에 위에서 한 예비학습이 필요했다.\n\nclass Hnet(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의\n        self.i2h = torch.nn.Linear(in_features=4, out_features=2) # input(x) -> h\n        self.tanh = torch.nn.Tanh()\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구현할것인지 정의\n        hidden = self.tanh(self.i2h(x))\n        ## 정의 끝\n        return hidden\n\n\nhnet = Hnet()\n\n\nhnet\n\nHnet(\n  (i2h): Linear(in_features=4, out_features=2, bias=True)\n  (tanh): Tanh()\n)\n\n\n- for문 돌릴준비\n\n# 옵티마이저에 자칭 신기술 적용!!!\n\n\ntorch.manual_seed(43052) \nhnet = Hnet()\nlinr = torch.nn.Linear(in_features=2,out_features=4)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(hnet.parameters())+list(linr.parameters())) ## 학습하고 싶은 파라미터 모으기\n\n- for문 20회반복\n\nfor epoc in range(20): \n    ## 1 \n    ## 2 \n    hidden = hnet(x) \n    output = linr(hidden)\n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- linr(hnet(x)) 적합결과 <- 숫자체크\n\nlinr(hnet(x)) \n\ntensor([[-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.2912,  0.8140, -0.2032,  0.0178],\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        ...,\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.1065,  0.6307, -0.0874,  0.1821],\n        [-0.3589,  0.7921, -0.1970, -0.0302]], grad_fn=<AddmmBackward0>)"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn3.html#실패했던-풀이-구현2",
    "href": "posts/RNN/2023-02-28-rnn3.html#실패했던-풀이-구현2",
    "title": "순환신경망 (3)",
    "section": "실패했던 풀이: 구현2",
    "text": "실패했던 풀이: 구현2\n- Tanh까지 구현한 클래스\n\n# class Hnet(torch.nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.i2h = torch.nn.Linear(in_features=4,out_features=2)\n#         self.tanh = torch.nn.Tanh()\n#     def forward(self,x):\n#         hidden = self.tanh(self.i2h(x))\n#         return hidden\n\n- for문돌릴준비\n\ntorch.manual_seed(43052)\nhnet = Hnet()\nlinr = torch.nn.Linear(in_features=2, out_features=4)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(hnet.parameters()) + list(linr.parameters()))\n\n- for문: 20회반복\n\nlen(x)\n\n599\n\n\n\nhnet(x[0]), hnet(x[[0]])\n\n(tensor([-0.4504,  0.6483], grad_fn=<TanhBackward0>),\n tensor([[-0.4504,  0.6483]], grad_fn=<TanhBackward0>))\n\n\n\nT = len(x) \nfor epoc in range(20): \n    ## 1~2\n    loss = 0 \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = hnet(xt)   # hidden \n        ot = linr(ht)  # 하나의 observation에 대한 output\n        loss = loss + loss_fn(ot,yt)  # loss를 누적.\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- linr(hnet(x)) 적합결과 <- 숫자체크\n\nlinr(hnet(x))\n\ntensor([[-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.2912,  0.8140, -0.2032,  0.0178],\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        ...,\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.1065,  0.6307, -0.0874,  0.1821],\n        [-0.3589,  0.7921, -0.1970, -0.0302]], grad_fn=<AddmmBackward0>)\n\n\n\nx # n x 4\n\ntensor([[1., 0., 0., 0.],\n        [0., 1., 0., 0.],\n        [1., 0., 0., 0.],\n        ...,\n        [1., 0., 0., 0.],\n        [0., 0., 1., 0.],\n        [1., 0., 0., 0.]])"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn3.html#순환신경망의-아이디어",
    "href": "posts/RNN/2023-02-28-rnn3.html#순환신경망의-아이디어",
    "title": "순환신경망 (3)",
    "section": "순환신경망의 아이디어",
    "text": "순환신경망의 아이디어\n\n모티브\n(예비생각1) h에 대한 이해\n는 사실 문자열 ’abcd’들을 숫자로 바꾼 또 다른 형식의 숫자표현이라 해석할 수 있음. 즉 원핫인코딩과 다른 또 다른 형태의 숫자표현이라 해석할 수 있다. (사실 원핫인코딩보다 약간 더 (1) 액기스만 남은 느낌 + (2) 숙성된 느낌을 준다)\n\n(why1) h는 “학습을 용이하게 하기 위해서 x를 적당히 선형적으로 전처리한 상태”라고 이해가능\n(why2) 실제로 예시를 살펴보면 그러했다\n\n(예비생각2) 수백년전통을 이어가는 방법\n“1리터에 500만원에 낙찰된 적 있습니다.”\n“2kg에 1억원 정도 추산됩니다.”\n“20여 종 종자장을 블렌딩해 100ml에 5000만원씩 분양 예정입니다.”\n\n모두 씨간장(종자장) 가격에 관한 실제 일화다.\n\n(중략...)\n\n위스키나 와인처럼 블렌딩을 하기도 한다. \n새로 담근 간장에 씨간장을 넣거나, 씨간장독에 햇간장을 넣어 맛을 유지하기도 한다. \n이를 겹장(또는 덧장)이라 한다. \n몇몇 종갓집에선 씨간장 잇기를 몇백 년째 해오고 있다. \n매년 새로 간장을 담가야 이어갈 수 있으니 불씨 꺼트리지 않는 것처럼 굉장히 어려운 일이다.\n이렇게 하는 이유는 집집마다 내려오는 고유 장맛을 잃지 않기 위함이다. \n씨간장이란 그만큼 소중한 주방의 자산이며 정체성이다.\n덧장: 새로운 간장을 만들 때, 옛날간장을 섞어서 만듦.\n* 기존방식: \\(\\text{콩물} \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}\\)\n* 수백년 전통의 간장맛을 유지하는 방식\n\n\\(\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3\\)\n\n* 수백년 전통의 간장맛을 유지하면서 조리를 한다면?\n\n\\(\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3\\)\n\n점점 맛있는 간장계란밥이 탄생함.\n* 알고리즘 편의상 아래와 같이 생각해도 무방.\n\n\\(\\text{콩물}_1, \\text{간장}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1 ,\\quad \\text{간장}_0=\\text{맹물}\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3\\)\n\n아이디어\n* 수백년 전통의 간장맛을 유지하면서 조리하는 과정을 수식으로?\n\n\\(\\boldsymbol{x}_1, \\boldsymbol{h}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_1 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_1\\)\n\\(\\boldsymbol{x}_2, \\boldsymbol{h}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_2 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_2\\)\n\\(\\boldsymbol{x}_3, \\boldsymbol{h}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_3 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_3\\)\n\n이제 우리가 배울것은 (1)“\\(\\text{콩물}_{t}\\)”와 “\\(\\text{간장}_{t-1}\\)”로 “\\(\\text{간장}_{t}\\)”를 숙성하는 방법 (2) “\\(\\text{간장}_{t}\\)”으로 “\\(\\text{간장계란밥}_{t}\\)”을 조리하는 방법이다.\n즉 숙성담당 네트워크와 조리담당 네트워크를 각각 만들어 학습하면 된다.\n\n\n알고리즘\n세부적인 알고리즘(\\(t=0,1,2,\\dots\\)에 대하여 한줄 한줄 쓴 알고리즘)\n(1) \\(t=0\\)\n\\({\\boldsymbol h}_0=[[0,0]] \\leftarrow \\text{간장}_0\\)은 맹물로 초기화\n(2) \\(t=1\\)\n\\({\\boldsymbol h}_1= \\tanh({\\boldsymbol x}_1{\\bf W}_{ih}+{\\boldsymbol h}_0{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\)\n\n\\({\\boldsymbol x}_1: (1,4)\\)\n\\({\\bf W}_{ih}: (4,2)\\)\n\\({\\boldsymbol h}_0: (1,2)\\)\n\\({\\bf W}_hh: (2,2)\\)\n\\({\\boldsymbol b}_{ih}: (1,2)\\)\n\\({\\boldsymbol b}_{hh}: (1,2)\\)\n\n\\({\\boldsymbol o}_1= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}\\)\n\\(\\hat{\\boldsymbol y}_1 = \\text{soft}({\\boldsymbol o}_1)\\)\n\n좀 더 일반화된 알고리즘\n(ver1)\ninit \\(\\boldsymbol{h}_0\\)\nfor \\(t\\) in \\(1\\):\\(T\\)\n\n\\({\\boldsymbol h}_t= \\tanh({\\boldsymbol x}_t{\\bf W}_{ih}+{\\boldsymbol h}_{t-1}{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\)\n\\({\\boldsymbol o}_t= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}\\)\n\\(\\hat{\\boldsymbol y}_t = \\text{soft}({\\boldsymbol o}_t)\\)\n\n(ver2)\ninit hidden\n\nfor t in 1:T \n    hidden = tanh(linr(x)+linr(hidden))\n    output = linr(hidden)\n    yt_hat = soft(output)\n\n코드상으로는 \\(h_t\\)와 \\(h_{t-1}\\)의 구분이 교묘하게 사라진다. (그래서 오히려 좋아.)\n\n\n전체 알고리즘은 대충 아래와 같은 형식으로 구현될 수 있음.\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        linr1 = torch.nn.Linear(?,?) \n        linr2 = torch.nn.Linear(?,?) \n        tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = tanh(lrnr1(x)+lrnr2(hidden))\n        return hidden\n\ninit ht\nrnncell = rNNCell()\n\nfor t in 1:T \n    xt, yt = x[[t]], y[[t]] \n    ht = rnncell(xt, ht)\n    ot = linr(ht) \n    loss = loss + loss_fn(ot, yt)"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn3.html#순환신경망-구현1-with-rnncell-class-hidden-node2---성공",
    "href": "posts/RNN/2023-02-28-rnn3.html#순환신경망-구현1-with-rnncell-class-hidden-node2---성공",
    "title": "순환신경망 (3)",
    "section": "순환신경망 구현1 (with rNNCell class, hidden node2) - 성공",
    "text": "순환신경망 구현1 (with rNNCell class, hidden node2) - 성공\n(1) 숙성담당 네트워크\n\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(4,2) \n        self.h2h = torch.nn.Linear(2,2) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = self.tanh(self.i2h(x)+self.h2h(hidden))\n        return hidden\n\n\ntorch.manual_seed(43052)\nrnncell =  rNNCell() # 숙성담당 네트워크 (콩물 -> 간장), h를 만드는 네트워크.\n\n(2) 조리담당 네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수, 옵티마이저 설계\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습 (6분정도 걸림)\n\nT = len(x) \nfor epoc in range(5000): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) # 1x2 맹물벡터\n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) # 숙성된 애가 들어가서 ht가 만들어짐.\n        ot = cook(ht) # ht가 cook을 거쳐서 ot가 됨.\n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) # x에 맹물을 넣어 첫번째 간장을 만든다.\nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]]) \n\n\nyhat = soft(cook(hidden)) # 간장을 가지고 조리한 것을 softmax 취한다.\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4712e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n\nplt.matshow(yhat.data[:15]) # 앞에 15개\n\n<matplotlib.image.AxesImage at 0x7f240219a760>\n\n\n\n\n\n\n# x[:8]\ny[:8], y[-15:]\n\n(tensor([[0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.],\n         [1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.]]),\n tensor([[0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.],\n         [1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.],\n         [1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.]]))\n\n\n\nplt.matshow(yhat.data[-15:])  # 끝에 15개\n\n<matplotlib.image.AxesImage at 0x7f2401f57490>\n\n\n\n\n\n\n아주 특이한 특징: yhat[:15], yhat[-15:]의 적합결과가 다르다.\n왜? 간장계란밥은 간장이 중요한데, 간장은 시간이 갈수록 맛있어지니까..!\n\n뒤에있는 적합결과가 앞에있는 적합결과보다 더 잘맞는다.\\(\\to\\) 뒤에있는 애가 앞에있는 정보를 더 많이 활용하기 때문이다.\n\n\n첫번째 순환신경망 성공적으로 학습!!!"
  },
  {
    "objectID": "posts/RNN/2023-02-28-rnn3.html#순환신경망-구현2-with-rnncell-hidden-node-2---성공",
    "href": "posts/RNN/2023-02-28-rnn3.html#순환신경망-구현2-with-rnncell-hidden-node-2---성공",
    "title": "순환신경망 (3)",
    "section": "순환신경망 구현2 (with RNNCell, hidden node 2) - 성공",
    "text": "순환신경망 구현2 (with RNNCell, hidden node 2) - 성공\n\nref: https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.ht\n\n(1) 숙성네트워크\n선언\n\nrnncell = torch.nn.RNNCell(4,2) # x: (n,4) h:(n,2) // 콩물의 dim , 간장(hidden layer)의 dim\n\n가중치초기화 (순환신경망 구현1과 동일하도록)\n\n# 비교를 위한것.\ntorch.manual_seed(43052)\n_rnncell = rNNCell()\n\n\nrnncell.weight_ih.data = _rnncell.i2h.weight.data \nrnncell.weight_hh.data = _rnncell.h2h.weight.data \nrnncell.bias_hh.data = _rnncell.h2h.bias.data \nrnncell.bias_ih.data = _rnncell.i2h.bias.data \n\n(2) 조리담당 네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수, 옵티마이저 설계\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습 (6분정도 걸림)\n\nT = len(x) \nfor epoc in range(5000): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) \n        ot = cook(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]]) \n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4712e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n\nplt.matshow(yhat.data[-15:])\n\n<matplotlib.image.AxesImage at 0x7f2401dd61f0>"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html",
    "href": "posts/RNN/2023-03-01-rnn5.html",
    "title": "순환신경망 (5)",
    "section": "",
    "text": "LSTM (1) - GPU실험, abcabC예제, abcdabcD예제"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes",
    "href": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes",
    "title": "순환신경망 (5)",
    "section": "20000 len + 20 hidden nodes",
    "text": "20000 len + 20 hidden nodes\ncpu\n\nx = torch.randn([20000,4]) \ny = torch.randn([20000,4]) \n\n\nrnn = torch.nn.RNN(4,20)\nlinr = torch.nn.Linear(20,4)\noptimizr = torch.optim.Adam(list(rnn.parameters()) + list(linr.parameters()))\nloss_fn = torch.nn.MSELoss()\n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1\n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x, _water)\n    yhat = linr(hidden)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward() ## 사실 역전파 부분이 시간을 되게 많이 잡아먹음.\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1\n\n145.73457264900208\n\n\ngpu\n\nx = torch.randn([20000,4]).to(\"cuda:0\")\ny = torch.randn([20000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward()  ## 시간차이의 이유!\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n4.398334980010986\n\n\n\n왜 빠른지? (거의 30배정도 차이)"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes-역전파주석처리",
    "href": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes-역전파주석처리",
    "title": "순환신경망 (5)",
    "section": "20000 len + 20 hidden nodes + 역전파주석처리",
    "text": "20000 len + 20 hidden nodes + 역전파주석처리\n\nx = torch.randn([20000,4]) \ny = torch.randn([20000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n28.299692392349243\n\n\ngpu\n\nx = torch.randn([20000,4]).to(\"cuda:0\")\ny = torch.randn([20000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n1.6998937129974365\n\n\n\n미분을 진행하는 과정에서 gpu의 효율이 극대화된다."
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes-1",
    "href": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes-1",
    "title": "순환신경망 (5)",
    "section": "2000 len + 20 hidden nodes",
    "text": "2000 len + 20 hidden nodes\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n10.605574131011963\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n0.4819977283477783"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes-역전파주석처리-1",
    "href": "posts/RNN/2023-03-01-rnn5.html#len-20-hidden-nodes-역전파주석처리-1",
    "title": "순환신경망 (5)",
    "section": "2000 len + 20 hidden nodes + 역전파주석처리",
    "text": "2000 len + 20 hidden nodes + 역전파주석처리\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    # loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n3.2522189617156982\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    # loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n0.1948552131652832"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#len-1000-hidden-nodes",
    "href": "posts/RNN/2023-03-01-rnn5.html#len-1000-hidden-nodes",
    "title": "순환신경망 (5)",
    "section": "2000 len + 1000 hidden nodes",
    "text": "2000 len + 1000 hidden nodes\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,1000) \nlinr = torch.nn.Linear(1000,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n43.083815574645996\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,1000).to(\"cuda:0\")\nlinr = torch.nn.Linear(1000,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n5.486930847167969"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#len-1000-hidden-nodes-역전파주석처리",
    "href": "posts/RNN/2023-03-01-rnn5.html#len-1000-hidden-nodes-역전파주석처리",
    "title": "순환신경망 (5)",
    "section": "2000 len + 1000 hidden nodes + 역전파주석처리",
    "text": "2000 len + 1000 hidden nodes + 역전파주석처리\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,1000) \nlinr = torch.nn.Linear(1000,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    # loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n6.92149543762207\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,1000).to(\"cuda:0\")\nlinr = torch.nn.Linear(1000,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    # loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n2.9791648387908936"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#실험결과-요약",
    "href": "posts/RNN/2023-03-01-rnn5.html#실험결과-요약",
    "title": "순환신경망 (5)",
    "section": "실험결과 요약",
    "text": "실험결과 요약\n\n\n\nlen\n# of hidden ndoes\nbackward\ncpu\ngpu\nratio\n\n\n\n\n20000\n20\nO\n145.73\n4.39\n33.19\n\n\n20000\n20\nX\n28.29\n1.69\n16.73\n\n\n2000\n20\nO\n10.60\n0.48\n22.08\n\n\n2000\n20\nX\n3.25\n0.19\n17.10\n\n\n2000\n1000\nO\n43.08\n5.48\n7.86\n\n\n2000\n1000\nX\n6.92\n2.97\n2.32"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#data",
    "href": "posts/RNN/2023-03-01-rnn5.html#data",
    "title": "순환신경망 (5)",
    "section": "data",
    "text": "data\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \n\n\ntxt = list('abcabC')*100\ntxt[:8]\n\n['a', 'b', 'c', 'a', 'b', 'C', 'a', 'b']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\ntxt_x[:8], txt_y[:8]\n\n(['a', 'b', 'c', 'a', 'b', 'C', 'a', 'b'],\n ['b', 'c', 'a', 'b', 'C', 'a', 'b', 'c'])\n\n\n\nmapping = {'a':0,'b':1,'c':2,'C':3}\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx = x.to(\"cuda:0\")\ny = y.to(\"cuda:0\")\n\n- a,b,c,a,b,C - 보이는 문자수가 a,b,c,C 이므로 4개\n- a1,b1,c,a2,b2,C - 문맥까지 고려하면 6개\nhidden node의 개수를 2개로 하면 a,b,c,C 4개의 문자를 구분할 수는 있지만 문맥에 따른 차이점을 구분하기 모호할 수 있다.\n\\(\\to\\) 따라서 hidden node의 개수를 3으로 설정하자."
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#data-1",
    "href": "posts/RNN/2023-03-01-rnn5.html#data-1",
    "title": "순환신경망 (5)",
    "section": "data",
    "text": "data\n\ntxt = list('abcdabcD')*100\ntxt[:8]\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'D']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'a':0,'b':1,'c':2,'d':3,'D':4}\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx=x.to(\"cuda:0\")\ny=y.to(\"cuda:0\")"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn5.html#rnn-vs.-lstm-성능비교실헝",
    "href": "posts/RNN/2023-03-01-rnn5.html#rnn-vs.-lstm-성능비교실헝",
    "title": "순환신경망 (5)",
    "section": "RNN vs. LSTM 성능비교실헝",
    "text": "RNN vs. LSTM 성능비교실헝\n- RNN\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(5,4).to(\"cuda:0\")\n        linr = torch.nn.Linear(4,5).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,4).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-8:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$RNN$\",size=20)\nfig.tight_layout()\n\n\n\n\n성공횟수가 이전 예제보다 확실히 적어졌다.\n- LSTM\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(5,4).to(\"cuda:0\")\n        linr = torch.nn.Linear(4,5).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,4).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-8:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$LSTM$\",size=20)\nfig.tight_layout()\n\n\n\n\n\n대부분 성공\nLSTM이 해당 세팅에서도 학습이 더 잘된다는 것을 알 수 있었다.\n\n- 관찰1: LSTM이 확실히 장기기억에 강하다.\n- 관찰2: LSTM은 hidden에 0이 잘 나온다.\n\n사실 확실히 구분되는 특징을 판별할때는 -1,1로 히든레이어 값들이 설정되면 명확하다.\n히든레이어에 -1~1 사이의 값이 나온다면 애매한 판단이 내려지게 된다.\n그런데 이 애매한 판단이 어떻게 보면 문맥의 뉘앙스를 이해하는데 더 잘 맞다.\n그런데 RNN은 -1,1로 셋팅된 상황에서 -1~1로의 변화가 더디다는 것이 문제임."
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn6.html",
    "href": "posts/RNN/2023-03-01-rnn6.html",
    "title": "순환신경망 (6)",
    "section": "",
    "text": "LSTM (2) - LSTM의 계산과정, LSTM은 왜 강한가?"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn6.html#data-abab",
    "href": "posts/RNN/2023-03-01-rnn6.html#data-abab",
    "title": "순환신경망 (6)",
    "section": "data: abaB",
    "text": "data: abaB\n\ntxt = list('abaB')*100\ntxt[:5]\n\n['a', 'b', 'a', 'B', 'a']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'a':0, 'b':1, 'B':2}\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn6.html#epoch-ver1-with-torch.nn.lstmcell",
    "href": "posts/RNN/2023-03-01-rnn6.html#epoch-ver1-with-torch.nn.lstmcell",
    "title": "순환신경망 (6)",
    "section": "1 epoch ver1 (with torch.nn.LSTMCell)",
    "text": "1 epoch ver1 (with torch.nn.LSTMCell)\n\ntorch.manual_seed(43052)\nlstm_cell = torch.nn.LSTMCell(3,2) # hidden node: 2\nlinr = torch.nn.Linear(2,3)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm_cell.parameters()) + list(linr.parameters()), lr=0.1)\n\n\nT = len(x) \nfor epoc in range(1):\n    ht = torch.zeros(1,2)\n    ct = torch.zeros(1,2)\n    loss = 0 \n    ## 1~2\n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht,ct = lstm_cell(xt,(ht,ct))\n        ot = linr(ht) \n        loss = loss + loss_fn(ot,yt)\n    loss = loss / T\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nht, ct\n\n(tensor([[-0.0406,  0.2505]], grad_fn=<MulBackward0>),\n tensor([[-0.0975,  0.7134]], grad_fn=<AddBackward0>))"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn6.html#epoc-ver2-완전-손으로-구현",
    "href": "posts/RNN/2023-03-01-rnn6.html#epoc-ver2-완전-손으로-구현",
    "title": "순환신경망 (6)",
    "section": "1 epoc ver2 (완전 손으로 구현)",
    "text": "1 epoc ver2 (완전 손으로 구현)\n\n\\(t=0 \\to t=1\\)\n- lstm_cell을 이용한 계산 (결과비교용)\n\ntorch.manual_seed(43052)\nlstm_cell = torch.nn.LSTMCell(3,2)\nlinr = torch.nn.Linear(2,3)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm_cell.parameters()) + list(linr.parameters()), lr=0.1)\n\n\nT = len(x) \nfor epoc in range(1):\n    ht = torch.zeros(1,2)\n    ct = torch.zeros(1,2)\n    loss = 0 \n    ## 1~2\n    for t in range(1):\n        xt,yt = x[[t]], y[[t]]\n        ht,ct = lstm_cell(xt,(ht,ct))\n    #     ot = linr(ht) \n    #     loss = loss + loss_fn(ot,yt)\n    # loss = loss / T\n    # ## 3 \n    # loss.backward()\n    # ## 4 \n    # optimizr.step()\n    # optimizr.zero_grad()\n\n\nht, ct\n\n(tensor([[-0.0541,  0.0892]], grad_fn=<MulBackward0>),\n tensor([[-0.1347,  0.2339]], grad_fn=<AddBackward0>))\n\n\n\n이런결과를 어떻게 만드는걸가?\nhttps://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n\n\\[\\begin{align*}i_t & = \\sigma(W_{ii}x_t + b_{ii} + W_{hi}h_{t-1}+b_{hi}) \\\\\nf_t & = \\sigma(W_{if}x_t + b_{if} +W_{hf}h_{t-1}+b_{hf}) \\\\\ng_t & = \\text{tanh} (W_{ig}x_t + b_{ig} + W_{hg}h_{t-1}+b_{hg} \\\\\no_t & = \\sigma(W_{io}x_t + b_{io}+W_{ho}h_{t-1} +b_{ho}) \\\\\nc_t & = f_t\\odot c_{t-1} + i_t \\odot g_t \\\\\nh_t &= o_t \\odot \\text{tanh}(c_t)\n\\end{align*}\\]\n\n\\(h_t\\): hidden state at \\(t\\)\n\\(c_t\\): cell state at time \\(t\\)\n\\(x_t\\): the input at time \\(t\\)\n\\(h_{t-1}\\): the hidden state of the layer at time \\(t-1\\)\n\\(i_t, f_t, g_t, o_t\\): input,forget,cell,and output gates, respectively\n\\(\\sigma\\): the sigmoid function\n\\(\\odot\\): the Hadamard product\n(참고) \\(\\odot\\) : elment-wise 하게 곱하는 연산자\n\n\\((1,2) \\odot (3,0) = (3,0)\\)\n\n\n- 직접계산\n\nht = torch.zeros(1,2)\nct = torch.zeros(1,2)\n\n\\[(x_t, h_{t-1}) \\overset{lin}{\\to} [a,b,c,d] \\to [\\sigma(a), \\sigma(b),\\text{tanh}(c),\\sigma(d)] = [i_t,f_t,g_t,o_t]\\]\n\n_ifgo = xt @ lstm_cell.weight_ih.T + ht @ lstm_cell.weight_hh.T + lstm_cell.bias_ih + lstm_cell.bias_hh\n_ifgo\n\ntensor([[ 0.0728,  0.1561,  0.0693,  0.5941, -0.2661,  0.4648, -0.3884, -0.4536]],\n       grad_fn=<AddBackward0>)\n\n\n\ninput_gate = sig(_ifgo[:,0:2])\nforget_gate = sig(_ifgo[:,2:4])\ngt = tanh(_ifgo[:,4:6])\noutput_gate = sig(_ifgo[:,6:8])\n\n\nct = forget_gate * ct + input_gate * gt\nht = output_gate * tanh(ct)\n\n\nht,ct\n\n(tensor([[-0.0541,  0.0892]], grad_fn=<MulBackward0>),\n tensor([[-0.1347,  0.2339]], grad_fn=<AddBackward0>))\n\n\n\n\n\\(t=0 \\to t=T\\)\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2) \nlinr = torch.nn.Linear(2,3)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm_cell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nT = len(x) \nfor epoc in range(1):\n    ht = torch.zeros(1,2)\n    ct = torch.zeros(1,2)\n    loss = 0 \n    ## 1~2\n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        \n        ## lstm_cell step1: calculate _ifgo \n        _ifgo = xt @ lstm_cell.weight_ih.T + ht @ lstm_cell.weight_hh.T + lstm_cell.bias_ih + lstm_cell.bias_hh\n        ## lstm_cell step2: decompose _ifgo \n        input_gate = sig(_ifgo[:,0:2])\n        forget_gate = sig(_ifgo[:,2:4])\n        gt = tanh(_ifgo[:,4:6])\n        output_gate = sig(_ifgo[:,6:8])\n        ## lstm_cell step3: calculate ht,ct \n        ct = forget_gate * ct + input_gate * gt\n        ht = output_gate * tanh(ct)\n        \n    #     ot = linr(ht) \n    #     loss = loss + loss_fn(ot,yt)\n    # loss = loss / T\n    # ## 3 \n    # loss.backward()\n    # ## 4 \n    # optimizr.step()\n    # optimizr.zero_grad()\n\n\nht,ct\n\n(tensor([[-0.0406,  0.2505]], grad_fn=<MulBackward0>),\n tensor([[-0.0975,  0.7134]], grad_fn=<AddBackward0>))\n\n\n(tensor([[-0.0406,  0.2505]], grad_fn=<MulBackward0>),\n tensor([[-0.0975,  0.7134]], grad_fn=<AddBackward0>))"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn6.html#data-abab-1",
    "href": "posts/RNN/2023-03-01-rnn6.html#data-abab-1",
    "title": "순환신경망 (6)",
    "section": "data: abaB",
    "text": "data: abaB\n\ntxt = list('abaB')*100\ntxt[:5]\n\n['a', 'b', 'a', 'B', 'a']\n\n\n\nn_words = 3\n\n\nmapping = {'a':0,'b':1,'B':2}\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:10], txt_y[:10]\n\n(['a', 'b', 'a', 'B', 'a', 'b', 'a', 'B', 'a', 'b'],\n ['b', 'a', 'B', 'a', 'b', 'a', 'B', 'a', 'b', 'a'])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx,y\n\n(tensor([[1., 0., 0.],\n         [0., 1., 0.],\n         [1., 0., 0.],\n         ...,\n         [1., 0., 0.],\n         [0., 1., 0.],\n         [1., 0., 0.]]),\n tensor([[0., 1., 0.],\n         [1., 0., 0.],\n         [0., 0., 1.],\n         ...,\n         [0., 1., 0.],\n         [1., 0., 0.],\n         [0., 0., 1.]]))"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn6.html#epoch",
    "href": "posts/RNN/2023-03-01-rnn6.html#epoch",
    "title": "순환신경망 (6)",
    "section": "1000 epoch",
    "text": "1000 epoch\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(3,2) \nlinr = torch.nn.Linear(2,3) \n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+ list(linr.parameters()),lr=0.1)\n\n\n_water = torch.zeros(1,2) \nfor epoc in range(1000): \n    ## step1 \n    hidden, (ht,ct) = lstm(x,(_water,_water))\n    output = linr(hidden)\n    ## step2\n    loss = loss_fn(output,y) \n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn6.html#시각화",
    "href": "posts/RNN/2023-03-01-rnn6.html#시각화",
    "title": "순환신경망 (6)",
    "section": "시각화",
    "text": "시각화\n\nT = len(x)\ninput_gate = torch.zeros(T,2)\nforget_gate = torch.zeros(T,2)\noutput_gate = torch.zeros(T,2)\ng = torch.zeros(T,2)\ncell = torch.zeros(T,2)\nh = torch.zeros(T,2) \n\n\nfor t in range(T): \n    ## 1: calculate _ifgo \n    _ifgo = x[[t]] @ lstm.weight_ih_l0.T + h[[t]] @ lstm.weight_hh_l0.T + lstm.bias_ih_l0 + lstm.bias_hh_l0 \n    ## 2: decompose _ifgo \n    input_gate[[t]] = sig(_ifgo[:,0:2])\n    forget_gate[[t]] = sig(_ifgo[:,2:4])\n    g[[t]] = tanh(_ifgo[:,4:6])\n    output_gate[[t]] = sig(_ifgo[:,6:8])\n    ## 3: calculate ht,ct \n    cell[[t]] = forget_gate[[t]] * cell[[t]] + input_gate[[t]] * g[[t]]\n    h[[t]] = output_gate[[t]] * tanh(cell[[t]])\n\n\ncombinded1 = torch.concat([input_gate,forget_gate,output_gate],axis=1)\ncombinded2 = torch.concat([g,cell,h,soft(output)],axis=1)\n\n\nplt.matshow(combinded1[-8:].data,cmap='bwr',vmin=-1,vmax=1);\nplt.xticks(range(combinded1.shape[-1]),labels=['i']*2 + ['f']*2 + ['o']*2);\nplt.matshow(combinded2[-8:].data,cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(combinded2.shape[-1]),labels=['g']*2 + ['c']*2 + ['h']*2 + ['yhat']*3);\n\n\n\n\n\n\n\n\n상단그림은 게이트의 값들만 시각화, 하단그림은 게이트 이외의 값들을 시각화"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn6.html#시각화의-해석-i",
    "href": "posts/RNN/2023-03-01-rnn6.html#시각화의-해석-i",
    "title": "순환신경망 (6)",
    "section": "시각화의 해석 I",
    "text": "시각화의 해석 I\n\nplt.matshow(combinded1[-8:].data,cmap='bwr',vmin=-1,vmax=1);\nplt.xticks(range(combinded1.shape[-1]),labels=['i']*2 + ['f']*2 + ['o']*2);\nplt.colorbar()\n\n<matplotlib.colorbar.Colorbar at 0x7fb0131c8a60>\n\n\n\n\n\n- input gate, forget gate, output_gate는 모두 \\(0\\sim 1\\) 사이의 값을 가진다.\n\n(참고) 파:\\(-1\\), 흰:\\(0\\), 빨:\\(1\\)\n\n- 이 값들은 각각 모두 \\(g_t, c_{t-1}, \\text{tanh}(c_t)\\) 에 곱해진다. 따라서 input_gate, forget_fate, ouput_gate는 gate의 역할로 비유가능하다. (1이면 통과, 0이면 차단)\n\ninput_gate: \\(g_t\\) 의 값을 얼만큼 통과시킬지 \\(0\\sim 1\\) 사이의 숫자로 결정\nforget_gate: \\(c_{t-1}\\)의 값을 얼만큼 통과시킬지 \\(0\\sim 1\\) 사이의 숫자로 결정\noutput_gate: \\(\\text{htan}(c_t)\\) 의 값들을 얼만큼 통과시킬지 \\(0\\sim 1\\) 사이의 숫자로 결정\n\ninput/forget/output gate가 진짜 문지기 같은 역할을 함 (어떤 값을 통과시킬지 말지 0과 1사이의 숫자로 정해주는 역할을 한다.) 그렇기 때문에 gate라는 이름이 붙게 되었다."
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn6.html#시각화의-해석-ii",
    "href": "posts/RNN/2023-03-01-rnn6.html#시각화의-해석-ii",
    "title": "순환신경망 (6)",
    "section": "시각화의 해석 II",
    "text": "시각화의 해석 II\n\nplt.matshow(combinded2[-8:].data,cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(combinded2.shape[-1]),labels=['g']*2 + ['c']*2 + ['h']*2 + ['yhat']*3);\n\n\n\n\n- 결국 \\(g_t \\to c_t \\to h_t \\to \\hat{y}\\)의 느낌이다. (\\(h_t\\)를 계산하기 위해서는 \\(c_t\\)가 필요했고, \\(c_t\\)를 계산하기 위해서는 \\(c_{t-1}\\) 과 \\(g_t\\)가 필요했음)\n\n\\(h_t = \\text{tanh}(c_t) \\odot o_t\\)\n\\(c_t = c_{t-1} \\odot f_t + g_t \\odot i_t\\)\n\n\n\n\nimage.png\n\n\n- \\(g_t, c_t, h_t\\) 모두 \\(x_t\\)의 정보를 숙성시켜 가지고 있는 느낌이 든다.\n- \\(g_t\\)의 특징: 보통 -1, 1 중 하나의 값을 가지도록 학습되어 있다. (마치 RNN의 hidden node처럼!)\n\n\\(g_t = \\text{tanh}(x_t\\bf{W}_{ig}+h_{t-1}\\bf{W}_{hg}+b_{ig}+b_{hg})\\)\n\n- \\(c_t\\)의 특징: \\(g_t\\)와 매우 비슷하지만 약간 다른 값을 가진다. 그래서 \\(g_t\\)와 달리 \\(-1,1\\) 이외의 값도 종종 등장.\n\n\\(g_t, c_t, h_t\\) 모두 콩물(\\(x_t\\))를 숙성시킨 간장이지만 \\(g_t\\) 보다는 \\(c_t\\)가 더, \\(h_t\\)보다는 \\(c_t\\)가 더 숙성된 느낌이다.\n\\(g_t\\)는 진한 빨/파 였다면 \\(c_t\\)는 \\(g_t\\)와 유사하지만 좀 더 연한 빨/파, \\(h_t\\)는 \\(c_t\\)와 유사하지만 더 연한 빨/파\n\n\nprint(\"first row: gt={}, ct={}\".format(g[-8].data, cell[-8].data))\nprint(\"second row: gt={}, ct={}\".format(g[-7].data, cell[-7].data))\n#g[-7], cell[-7]\n\nfirst row: gt=tensor([ 0.9999, -0.9999]), ct=tensor([ 0.9647, -0.9984])\nsecond row: gt=tensor([ 0.9970, -0.9554]), ct=tensor([ 0.3592, -0.9373])\n\n\n- \\(h_t\\)의 특징: (1) \\(c_t\\)의 느낌이 있음 하지만 약간의 변형이 있음. (2) -1~1 사이의 값을 훨씬 다양하게 가진다. (tanh때문)\n\nprint(\"first row: gt={}, ct={}, ht={}\".format(g[-8].data, cell[-8].data,h[-8].data))\nprint(\"second row: gt={}, ct={}, ht={}\".format(g[-7].data, cell[-7].data,h[-7].data))\n#g[-7], cell[-7]\n\nfirst row: gt=tensor([ 0.9999, -0.9999]), ct=tensor([ 0.9647, -0.9984]), ht=tensor([ 0.7370, -0.3323])\nsecond row: gt=tensor([ 0.9970, -0.9554]), ct=tensor([ 0.3592, -0.9373]), ht=tensor([ 0.0604, -0.6951])\n\n\n- 예전의문 해결\n\n실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.\n그 이유: RNN은 \\(h_t\\)의 값이 \\(-1\\) 혹은 \\(1\\)로 결정되는 경우가 많았음. 그러나 경우에 따라서는 \\(h_t\\)이 -1~1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한다 LSTM이 이러한 방식으로 학습되는 경우가 많았음.\n왜 LSTM의 \\(h_t\\)은 -1,1 이외의 값을 쉽게 가질 수 있는가? (1) gate들의 역할 (2) 마지막에 취해지는 tanh때문"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn6.html#lstm의-알고리즘-리뷰-i-수식위주",
    "href": "posts/RNN/2023-03-01-rnn6.html#lstm의-알고리즘-리뷰-i-수식위주",
    "title": "순환신경망 (6)",
    "section": "LSTM의 알고리즘 리뷰 I (수식위주)",
    "text": "LSTM의 알고리즘 리뷰 I (수식위주)\n(step1) calculate \\(\\tt{ifgo}\\)\n\\({\\tt ifgo} = {\\boldsymbol x}_t \\big[{\\bf W}_{ii} | {\\bf W}_{if}| {\\bf W}_{ig} |{\\bf W}_{io}\\big] + {\\boldsymbol h}_{t-1} \\big[ {\\bf W}_{hi}|{\\bf W}_{hf} |{\\bf W}_{hg} | {\\bf W}_{ho} \\big] + bias \\\\  =\\big[{\\boldsymbol x}_t{\\bf W}_{ii} + {\\boldsymbol h}_{t-1}{\\bf W}_{hi} ~\\big|~ {\\boldsymbol x}_t{\\bf W}_{if}+ {\\boldsymbol h}_{t-1}{\\bf W}_{hf}~ \\big|~ {\\boldsymbol x}_t{\\bf W}_{ig} + {\\boldsymbol h}_{t-1}{\\bf W}_{hg} ~\\big|~ {\\boldsymbol x}_t{\\bf W}_{io} + {\\boldsymbol h}_{t-1}{\\bf W}_{ho} \\big] + bias\\)\n참고: 위의 수식은 아래코드에 해당하는 부분\n\nifgo = xt @ lstm_cell.weight_ih.T +\\\n       ht @ lstm_cell.weight_hh.T +\\\n       lstm_cell.bias_ih + lstm_cell.bias_hh\n\n(stpe2) decompose \\(\\tt{ifgo}\\) and get \\(i_t,f_t,g_t,o_t\\)\n\\({\\boldsymbol i}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{ii} + {\\boldsymbol h}_{t-1} {\\bf W}_{hi} +bias ) \\\\ {\\boldsymbol f}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{if} + {\\boldsymbol h}_{t-1} {\\bf W}_{hf} +bias ) \\\\ {\\boldsymbol g}_t = \\tanh({\\boldsymbol x}_t {\\bf W}_{ig} + {\\boldsymbol h}_{t-1} {\\bf W}_{hg} +bias ) \\\\ {\\boldsymbol o}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{io} + {\\boldsymbol h}_{t-1} {\\bf W}_{ho} +bias )\\)\n(step3) calculate \\(c_t\\) and \\(h_t\\)\n\\({\\boldsymbol c}_t = {\\boldsymbol i}_t \\odot {\\boldsymbol g}_t+ {\\boldsymbol f}_t \\odot {\\boldsymbol c}_{t-1} \\\\ {\\boldsymbol h}_t = \\tanh({\\boldsymbol o}_t \\odot {\\boldsymbol c}_t)\\)"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn6.html#lstm의-알고리즘-리뷰-ii-느낌위주",
    "href": "posts/RNN/2023-03-01-rnn6.html#lstm의-알고리즘-리뷰-ii-느낌위주",
    "title": "순환신경망 (6)",
    "section": "LSTM의 알고리즘 리뷰 II (느낌위주)",
    "text": "LSTM의 알고리즘 리뷰 II (느낌위주)\n\n이해 및 암기를 돕기위해서 비유적으로 설명한 챕터!\n\n- 느낌1: RNN이 콩물에서 간장을 한번에 숙성시키는 방법이라면 LSTM은 콩물에서 간장을 3차로 나누어 숙성하는 느낌이다.\n\n콩물: \\(\\boldsymbol x_t\\)\n1차숙성: \\(\\boldsymbol g_t\\)\n2차숙성: \\(\\boldsymbol c_t\\)\n3차숙성: \\(\\boldsymbol h_t\\)\n\n- 느낌2: \\(g_t\\) 에 대하여\n\n계산방법: \\(x_t\\)와 \\(h_{t-1}\\)를 \\(\\bf{W}_{ig},\\bf{W}_{hg}\\)를 이용해 선형결합하고 \\(\\tt{tanh}\\)를 취한결과\nRNN에서 간장을 만들던 그 수식에서 \\(h_t\\)를 \\(g_t\\) 로 바꾼것.\n크게 2가지의 의미를 가진다. (1) 과거와 현재의 결합 (2) 활성화함수 \\(\\text{tanh}\\) 를 적용\n\n- 느낌3: \\(\\boldsymbol c_t\\) 에 대하여 (1)\n\n계산방법: \\(g_t\\)와 \\(c_{t-1}\\)을 요소별로 선택하고 더하는 과정\n\\(g_t\\)는 (1) 과거와 현재의 결합 (2) 활성화함수 tanh를 적용으로 나누어지는데 이중에서 (1) 과거와 현재의 정보를 결합하는 과정만 해당한다. 차이점은 요소별 선택 후 덧셈\n이러한 결합을 쓰는 이유? 게이트를 이용하여 과거와 현재의 정보를 제어 (일반적인 설명)\n\n- 느낌4: \\(\\boldsymbol c_t\\)에 대하여 (2) // \\(\\boldsymbol c_t\\)는 왜 과거와 현재의 정보를 제어한다고 볼 수 있는가?\n\\(t=1\\) 시점 계산과정관찰\n\ninput_gate[1],g[1], forget_gate[1], cell[0]\n\n(tensor([0.9065, 0.9999], grad_fn=<SelectBackward0>),\n tensor([0.9931, 0.9999], grad_fn=<SelectBackward0>),\n tensor([0.9931, 0.0014], grad_fn=<SelectBackward0>),\n tensor([ 0.3592, -0.9373], grad_fn=<SelectBackward0>))\n\n\n\\([0.9,1.0]\\odot \\boldsymbol g_t + [1.0,0.0] \\odot \\boldsymbol c_{t-1}\\)\n\nforget_gate는 \\(c_{t-1}\\)의 첫번째 원소는 기억하고, 두번째 원소는 잊으라고 말하고 있음 // forget_gate는 과거(\\(c_{t-1})\\)의 정보를 얼마나 잊을지 (=얼마나 기억할지)를 결정한다고 해석할 수 있다.\ninput_gate는 \\(\\boldsymbol g_t\\)의 첫번째 원소와 두 번째 원소를 모두 기억하되 두번째 원소를 좀 더 중요하게 기억하라고 말하고 있음 // input_gate는 현재(\\(\\boldsymbol g_t\\))\n이 둘을 조합하면 \\(\\boldsymbol c_t\\)가 현재와 과거의 정보중 어떠한 정보를 중시하면서 기억할지 결정한다고 볼 수 있다.\n\n- 느낌5: \\(\\boldsymbol c_t\\)에 대하여 (3)\n\n사실상 LSTM 알고리즘의 꽃이라 할 수 있음.\nLSTM은 long short term memory의 약자임. 기존의 RNN은 장기기억을 활용함에 약점이 있는데 LSTM은 단기기억/장기기억 모두 잘 활용함.\nLSTM이 장기기억을 잘 활용하는 비법은 바로 \\(c_t\\)에 있다.\n\n- 느낌6: \\(\\boldsymbol h_t\\)에 대하여 - 계산방법: \\(\\text{tanh}(c_t)\\)를 요소별로 선택\n- RNN, LSTM의 변수들 비교 테이블\n\n\n\n\n\n\n\n\n\n\n\n\n\n과거정보\n현재정보\n과거와 현재의 결합방식\n활성화\n느낌\n비고\n\n\n\n\nRNN-\\({\\boldsymbol h}_t\\)\n\\({\\boldsymbol h}_{t-1}\\)\n\\({\\boldsymbol x}_t\\)\n\\(\\times\\) \\(\\to\\) \\(+\\)\n\\(\\tanh\\)\n간장\n\n\n\nLSTM-\\({\\boldsymbol g}_t\\)\n\\({\\boldsymbol h}_{t-1}\\)\n\\({\\boldsymbol x}_t\\)\n\\(\\times\\) \\(\\to\\) \\(+\\)\n\\(\\tanh\\)\n1차간장\n\n\n\nLSTM-\\({\\boldsymbol c}_t\\)\n\\({\\boldsymbol c}_{t-1}\\)\n\\({\\boldsymbol g}_t\\)\n\\(\\odot\\) \\(\\to\\) \\(+\\)\nNone\n2차간장\ngate를 열림정도를 판단할때 \\({\\boldsymbol x}_t\\)와 \\({\\boldsymbol h}_{t-1}\\)을 이용\n\n\nLSTM-\\({\\boldsymbol h}_t\\)\nNone\n\\({\\boldsymbol c}_t\\)\nNone\n\\(\\tanh\\), \\(\\odot\\)\n3차간장\ngate를 열림정도를 판단할때 \\({\\boldsymbol x}_t\\)와 \\({\\boldsymbol h}_{t-1}\\)을 이용\n\n\n\n\nRNN은 기억할 과거정보가 \\(h_{t-1}\\) 하나이지만 LSTM은 \\(\\boldsymbol c_{t-1}, \\boldsymbol h_{t-1}\\) 2개이다.\n\n- 알고리즘리뷰:\n\n콩물, 과거 3차간장 \\(\\overset{\\text{x},+,\\text{tanh}} \\longrightarrow\\) 현재1차간장\n현재1차간장, 과거2차간장 \\(\\overset{\\odot,+,\\text{tanh}} \\longrightarrow\\) 현재 2차간장\n현재2차간장 \\(\\overset{\\text{tanh},\\odot}\\longrightarrow\\) 현재 3차간장"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn6.html#lstm이-강한-이유",
    "href": "posts/RNN/2023-03-01-rnn6.html#lstm이-강한-이유",
    "title": "순환신경망 (6)",
    "section": "LSTM이 강한 이유",
    "text": "LSTM이 강한 이유\n- LSTM이 장기기억에 유리함. 그 이유는 input, forget, output gate들이 과거기억을 위한 역할을 하기 때문.\n\n비판: 아키텍처에 대한 이론적 근거는 없음. 장기기억을 위하여 꼭 LSTM같은 구조일 필요는 없음. (왜 3차간장을 만들때 tanh를 써야하는지? 게이트는 꼭 3개이어야 하는지?)\n실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.\n그 이유: RNN은 \\(\\boldsymbol h_t\\)의 값이 -1 혹은 1로 결정되는 경우가 많았음. 그러나 경우에 따라서는 \\(\\boldsymbol h_t\\)이 -1 ~ 1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한데 LSTM이 이러한 방식으로 학습되는 경우가 많았음.\n왜 LSTM은 \\(\\boldsymbol h_t\\)은 -1,1 이외의 값을 쉽게 가질 수 있는가? (1) gate들의 역할 (2) 마지막에 취해지는 tanh 때문"
  },
  {
    "objectID": "posts/RNN/2023-03-01-rnn6.html#참고자료들",
    "href": "posts/RNN/2023-03-01-rnn6.html#참고자료들",
    "title": "순환신경망 (6)",
    "section": "참고자료들",
    "text": "참고자료들\n\nhttps://colah.github.io/posts/2015-08-Understanding-LSTMs/\nhttps://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\nhttps://arxiv.org/abs/1402.1128"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn1.html",
    "href": "posts/RNN/2023-02-25-rnn1.html",
    "title": "순환신경망 (1)",
    "section": "",
    "text": "순환신경망 intro(1)- ab예제, embedding layer"
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn1.html#data",
    "href": "posts/RNN/2023-02-25-rnn1.html#data",
    "title": "순환신경망 (1)",
    "section": "data",
    "text": "data\n\ntxt = list('ab')*100\ntxt[:10]\n\n['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5], txt_y[:5]\n\n(['a', 'b', 'a', 'b', 'a'], ['b', 'a', 'b', 'a', 'b'])\n\n\nx가 네트워크의 입력이라고 생각하고 b가 네트워크의 출력이라고 생각하면 - 네트워크 입력으로 a가 들어오면 b를 뱉어내고 - 네트워크 입력으로 b가 들어오면 a를 뱉어낸다.\n\\(\\to\\) 이러한 구조를 학습하면 된다."
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn1.html#선형모형을-이용한-풀이",
    "href": "posts/RNN/2023-02-25-rnn1.html#선형모형을-이용한-풀이",
    "title": "순환신경망 (1)",
    "section": "선형모형을 이용한 풀이",
    "text": "선형모형을 이용한 풀이\n\n(풀이1) 1개의 파라메터 - 실패\n\nmapping = {'a':0, 'b':1}\nx = torch.tensor(f(txt_x, mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y, mapping)).float().reshape(-1,1)\n\n\nx[:5], y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 학습 및 결과 시각화\n\nnet = torch.nn.Linear(in_features=1, out_features=1, bias=False)\nloss_fn = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat, y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizer.step()\n    optimizer.zero_grad()\n\n\nplt.plot(y[:5], 'o')\nplt.plot(net(x).data[:5])\n\n\n\n\n\n잘 학습이 안되었다.\n\n- 학습이 잘 안된 이유\n\npd.DataFrame({'x':x[:5].reshape(-1), 'y':y[:5].reshape(-1)})\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      0.0\n      1.0\n    \n    \n      1\n      1.0\n      0.0\n    \n    \n      2\n      0.0\n      1.0\n    \n    \n      3\n      1.0\n      0.0\n    \n    \n      4\n      0.0\n      1.0\n    \n  \n\n\n\n\n현재 \\(\\hat{y}_i = \\hat{w}x_i\\) 꼴의 아키텍처이고 \\(y_i \\approx \\hat{w}x_i\\)가 되는 적당한 \\(\\hat{w}\\)를 찾아야 하는 상황 - \\((x_i, y_i) = (0, 1)\\) 이면 어떠한 \\(\\hat{w}\\) 를 선택해도 \\(y_i \\approx \\hat{w}x_i\\) 를 만드는 것이 불가능 - \\((x_i, y_i) = (1, 0)\\) 이면 \\(\\hat{w} = 0\\) 일 경우 \\(y_i \\approx \\hat{w}x_i\\)로 만드는 것이 가능\n상황을 종합해보니 \\(\\hat{w}=0\\)으로 학습되는 것이 그나마 최선\n\n\n(풀이2) 1개의 파라메터 - 성공, but 확장성이 없는 풀이\n- 0이라는 값이 문제가 되므로 인코딩방식의 변경\n\nx = torch.tensor(f(txt_x, {'a':-1,'b':1})).float().reshape(-1,1)\ny = torch.tensor(f(txt_y, {'a':-1,'b':1})).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[-1.],\n         [ 1.],\n         [-1.],\n         [ 1.],\n         [-1.]]),\n tensor([[ 1.],\n         [-1.],\n         [ 1.],\n         [-1.],\n         [ 1.]]))\n\n\n\nnet = torch.nn.Linear(in_features=1, out_features=1, bias=False)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(2000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat, y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과는 성공\n\nplt.plot(y[:5],'o')\nplt.plot(net(x).data[:5])\n\n\n\n\n딱봐도 클래스가 3개일 경우 확장이 어려워 보인다."
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn1.html#로지스틱-모형을-이용한-풀이",
    "href": "posts/RNN/2023-02-25-rnn1.html#로지스틱-모형을-이용한-풀이",
    "title": "순환신경망 (1)",
    "section": "로지스틱 모형을 이용한 풀이",
    "text": "로지스틱 모형을 이용한 풀이\n\n(풀이1) 1개의 파라메터 - 실패\n- 데이터를 다시 a=0, b=1로 정의\n\nmapping = {'a':0, 'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5], y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 학습\n\nnet = torch.nn.Linear(in_features = 1, out_features = 1, bias = False)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat, y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과\n\nplt.plot(y[:10], 'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 결과해석: 예상되었던 실패임\n\n아키텍처는 \\(\\hat{y}_i = \\text{sig}(\\hat{w}x_i)\\) 꼴이다.\n\\((x_i, y_i) = (0,1)\\) 이라면 어떠한 \\(\\hat{w}\\) 를 선택해도 \\(\\hat{w}x_i=0\\)이다. 이 경우 \\(\\hat{y}_i = sig(0) = 0.5\\) 가 된다.\n\\((x_i, y_i) = (1,0)\\) 이라면 \\(\\hat{w} = -5\\)와 같은 값으로 선택하면 \\(sig(-5)\\approx - = y_i\\)와 같이 만들 수 있다.\n상황을 종합해보면 net이 weight는 \\(sig(\\hat{w}x_i)\\approx 0\\)이 되도록 적당한 음수로 학습되는 것이 최선임을 알 수 있다.\n\n\nnet.weight # 적당한 음수값으로 학습되어있음을 확인\n\nParameter containing:\ntensor([[-2.4571]], requires_grad=True)\n\n\n\n\n(풀이2) 2개의 파라메터 + 좋은 초기값 - 성공\n2개의 파라메터를 쓴다는 것은 weight와 bias를 쓴다는 것.\n- 동일하게 a=0,b=1로 맵핑\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 네트워크에서 bias를 넣기로 결정함\n\nnet = torch.nn.Linear(in_features=1, out_features=1, bias=True)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- net의 초기값을 설정 (이것은 좋은 초기값임)\n\\(y = sig(-5x + 2.5)\\)\n\n\\(x=0 \\to sig(2.5) \\to y\\text{는 1근처}\\)\n\\(x=1 \\to sig(-2.5) \\to y\\text{는 0근처}\\)\n\n(참고) \\(sig(x) = \\frac{1}{1+e^{-x}}\\)\n\nimport numpy as np\n1/(1+np.exp(-2.5)) , 1/(1+np.exp(2.5))\n\n(0.9241418199787566, 0.07585818002124355)\n\n\n\nnet.weight.data = torch.tensor([[-5.00]])\nnet.bias.data = torch.tensor([+2.500])\n\n\nnet(x)[:10]\n\ntensor([[ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000]], grad_fn=<SliceBackward0>)\n\n\n- 학습 전 결과\n\nplt.plot(y[:10], 'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 학습 후 결과\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat, y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n\n\n(풀이3) 2개의 파라메터 + 나쁜 초기값 - 성공\n- a=0,b=1\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 이전과 동일하게 바이어스가 포함된 네트워크 설정\n\nnet = torch.nn.Linear(in_features=1, out_features=1,bias=True)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- 초기값 설정 (이 초기값은 나쁜 초기값임)\n\nnet.weight.data = torch.tensor([[+5.00]])\nnet.bias.data = torch.tensor([-2.500])\n\n\nnet(x)[:10]\n\ntensor([[-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000]], grad_fn=<SliceBackward0>)\n\n\n- 학습전상태: 반대모양으로 되어있다.\n\nplt.plot(y[:10], 'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 학습\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat, y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n\n될 것 같긴한데 느릴것 같다..결국 수렴하긴 할듯.\n\n\n\n(풀이4) 3개의 파라메터를 쓴다면?\n- a=0, b=1로 코딩\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 3개의 파라메터를 사용하기 위해서 아래와 같은 구조를 생각하자.\n## 파라메터 3개를 줄 수 있는 방법\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1, bias=True),  ## 파라메터 2개\n    torch.nn.ACTIVATION_FUNCTION(),   ## activation 걸기  ## 파라메터 0개\n    torch.nn.Linear(in_features=1, out_features=1, bias=False) ## 파라메터 1개\n)\n위와 같은 네트워크를 설정하면 3개의 파라메터를 사용할 수 있다. 적절한 ACTIVATION_FUNCTION을 골라야하는데 실험적으로 tanh가 적절하다고 알려져있다. (\\(\\to\\) 그래서 우리도 실험적으로 이해해보자.)\n순환신경망에서 activation으로 tanh를 많이 사용한다. 이를 증명하기 위해서 실험을 해보자.\n\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features = 1, out_features = 1, bias = True),  ## 2개\n    torch.nn.ReLU(), ## 0개 \n    torch.nn.Linear(in_features = 1, out_features = 1, bias = False) ## 1개\n)\n\nSequential(\n  (0): Linear(in_features=1, out_features=1, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=1, out_features=1, bias=False)\n)\n\n\n\n(예비학습1) net(x)와 사실 net.forward(x)는 같다.\n\nnet(x)[:5] # 풀이3에서 학습한 네트워크임\n\ntensor([[-0.1584],\n        [ 0.1797],\n        [-0.1584],\n        [ 0.1797],\n        [-0.1584]], grad_fn=<SliceBackward0>)\n\n\n\nnet.forward(x)[:5] # 풀이3에서 학습한 네트워크임\n\ntensor([[-0.1584],\n        [ 0.1797],\n        [-0.1584],\n        [ 0.1797],\n        [-0.1584]], grad_fn=<SliceBackward0>)\n\n\n그래서 net.forward를 재정의하면 net(x)의 기능을 재정의 할 수 있다.\n\nnet.forward = lambda x: 1\n\n\n“lambda x:1”은 입력이 x, 출력이 1인 함수를 의미한다. (즉, 입력값에 상관없이 항상 1을 출력하는 함수)\n“net.forward = lambda x:1”이라고 새롭게 선언하였으므로 앞으로는 net.forward(), net(x)도 입력값에 상관없이 항상 1을 출력하게 될 것임.\n\n\nnet(x)\n\n1\n\n\n(예비학습2) torch.nn.Module을 상속받아서 네트워크를 만들면 (=’classXXX(torch.nn.Module):“와 같은 방식으로 클래스를 선언하면) 약속된 아키텍처를 가진 네트워크를 찍어내는 함수를 만들 수 있다.\n(예시1)\n\n## 클래스는 인스턴스를 만드는 틀같은 걸로 생각.\n\n\nclass Mynet1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.Sigmoid()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\n\nnet = Mynet1()\n\n는 아래와 같은 효과를 가진다.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1, bias=True),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(in_features=1, out_features=1, bias=False)\n)\n\n(예시2)\n\nclass Mynet2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1, out_features=1, bias=True)\n        self.a1 = torch.nn.ReLU()\n        self.l2 = torch.nn.Linear(in_features=1, out_features=1, bias=False)\n    def forward(self, x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\n\nnet = Mynet2()\n\n는 아래와 같은 효과를 가진다.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1, bias=True),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=1, out_features=1, bias=False)\n)\n\n(예시3)\n\nclass Mynet3(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1, out_features=1, bias=True)\n        self.a1 = torch.nn.Tanh()\n        self.l2 = torch.nn.Linear(in_features=1, out_features=1, bias=False)\n    def forward(self, x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\n\nnet = Mynet3()\n\n는 아래와 같은 효과를 가진다.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1, bias=True),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1, out_features=1, bias=False)\n)\n\n\n클래스에 대한 이해가 부족한 학생을 위한 암기방법\nstep1: 아래의 코드를 복사하여 틀을 만든다. (무조건 고정임, XXXX자리는 원하는 이름을 넣는다.)\n\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의\n        \n        ## 레이어 정의 끝\n    def forward(self, x):\n        ## yhat을 어떻게 구할것인지 정의\n        \n        ## 정의 끝\n        return yhat\n\n\nnet(x)에 사용하는 x임, yhat은 net.forward(x)의 리턴값임.\n사실, x,yhat은 다른 변수로 써도 무방하나 (예를들어 input/output 이라든지) 설명의 편의상 x와 yhat을 고정한다.\n\nstpe2: def __init__(self)에 사용할 레이어를 정의하고 이름을 붙인다. 이름은 항상 self.xxx와 같은 식으로 정의한다.\n\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return yhat\n\nstep3: def forward:에 “x->yhat”으로 가는 과정을묘사한 코드를 작성하고 yhat을 리턴하도록 한다.\n\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        u = self.xxx1(x)\n        v = self.xxx2(u)\n        yhat = self.xxx3(v)\n        ## 정의 끝\n        return yhat\n\n예비학습 끝\n\n- 우리가 하려고 했던 것 : 아래의 아키텍처에서\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1, bias=True),\n    torch.nn.ACTIVATION_FUNCTION(),\n    torch.nn.Linear(in_features=1, out_features=1, bias=False)\n)\nACTIVATION의 자리에 tanh가 왜 적절한지 직관을 얻어보자.\n\n\n- 실험결과1(Sig): Sigmoid activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet1()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_1(x):=Sigmoid(x)$\",size=20)\nfig.tight_layout()\n\n\n\n\n\n\n- 실험결과2(ReLU): ReLU activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet2()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_2(x):=ReLU(x)$\",size=20)\nfig.tight_layout()\n\n\n\n\n\n\n- 실험결과3(Tanh): Tanh activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet3()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_2(x):=Tanh(x)$\",size=20)        \nfig.tight_layout()\n\n\n\n\n\n\n- 실험해석\n\nSig: 주항색선의 변동폭이 작음 + 항상 \\(0.5\\) 근처로 머무는 적합값이 존재\nReLU: 주황색선의 변동폭이 큼 + 항상 \\(0.5\\) 근처로 머무는 적합값이 존재\nTanh: 주황색선의 변동폭이 큼 + \\(0.5\\) 근처로 머무는 적합값이 존재X\n\n실험해보니까 Tanh가 우수한 것 같다. \\(\\to\\) 앞으로는 Tanh를 쓰자."
  },
  {
    "objectID": "posts/RNN/2023-02-25-rnn1.html#소프트맥스로-확장",
    "href": "posts/RNN/2023-02-25-rnn1.html#소프트맥스로-확장",
    "title": "순환신경망 (1)",
    "section": "소프트맥스로 확장",
    "text": "소프트맥스로 확장\n\n(풀이1) 로지스틱모형에서 3개의 파라메터 버전을 그대로 확장\n\nmapping = {'a':[1,0], 'b':[0,1]}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,2)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,2)\nx[:5], y[:5]\n\n(tensor([[1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [0., 1.],\n         [1., 0.]]),\n tensor([[0., 1.],\n         [1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [0., 1.]]))\n\n\n\n[1, 0] -> a\n[0, 1] -> b\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=2, out_features=1), # x의 shape이 2 -> in_features=2\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1, out_features=2, bias=False) # y의 shape이 2 -> out_features=2\n)    \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat, y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5][:,1]\n\ntensor([1., 0., 1., 0., 1.])\n\n\n\nsoft(net(x))[:5][:,1]\n\ntensor([0.9952, 0.0049, 0.9952, 0.0049, 0.9952], grad_fn=<SelectBackward0>)\n\n\n\nplt.plot(y[:5][:,1],'o') ## y\nplt.plot(soft(net(x[:5]))[:,1].data,'--r') ## 예측한 값.\n\n\n\n\n\nfig,ax = plt.subplots(1,2)\nax[0].imshow(y[:5])\nax[1].imshow(soft(net(x[:5])).data)\n\n<matplotlib.image.AxesImage at 0x7f66535be9a0>\n\n\n\n\n\n모양이 똑같이 나왔으니까 예측이 잘 되었다고 판단."
  },
  {
    "objectID": "etc/2023-02-28.html",
    "href": "etc/2023-02-28.html",
    "title": "클래스 암기",
    "section": "",
    "text": "클래스 헷갈리는 개념모음\n\n\n파이썬 iterable object\n\n파이썬의 모든 것은 오브젝트이다. \n함수도 오브젝트이고\n리스트도 오브젝트이다..\n\n\n\n\n\n_lst= [1,2,3]\nfor i in _lst:\n    print(i)\n\n1\n2\n3\n\n\n\n_iterator = _lst.__iter__() # __iter__()라는 함수를 쓰면 iterator가 만들어진다.\n\n\niterator에는 __next__ 라는 기능이 있다.\niterable object에는 __next__라는 기능이 없다.\n이것이 iterator(=jenerator)와 iterable object와의 차이\n\niterable object는 결국 iterator로 만들 수 있는 오브젝트라는 것\n\n_iterator.__next__()\n\n1\n\n\n\n_iterator.__next__()\n\n2\n\n\n\n_iterator.__next__()\n\n3\n\n\n\n_iterator.__next__() # 에러 나는게 당연! 다음에 꺼낼게 없으니까...\n\nStopIteration: \n\n\n\nset(dir(_lst)) & {'__next__', '__iter__'} # 얘는 iterable object\n\n{'__iter__'}\n\n\n\nset(dir(_iterator)) & {'__next__', '__iter__'} # 얘는 iterator (=generator)\n\n{'__iter__', '__next__'}\n\n\n다시 정리\n\ndir()로 확인했을 때 __iter__ 만 있으면 iterable object\n\niterable object에는 __iter__ 라는 숨겨진 기능이 있음.\n\n\n__iter__와 __next__ 둘 다 있으면 iterator!!\n\n\n\n\n\nimport torch\n\n\nnet = torch.nn.Linear(in_features = 1, out_features=1)\nnet.weight\n\nParameter containing:\ntensor([[-0.9288]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([0.1182], requires_grad=True)\n\n\n\nfor param in net.parameters():\n    print(param)\n\nParameter containing:\ntensor([[-0.9288]], requires_grad=True)\nParameter containing:\ntensor([0.1182], requires_grad=True)\n\n\nnet.parameters()는 net오브젝트에서 학습할 파라메터를 모두 모아 리스트 같은 iterable object로 만드는 함수라 이해할 수 있다.\n\n\n\n\nstep1: 아래의 코드를 복사하여 틀을 만든다. (무조건 고정임, XXXX자리는 원하는 이름을 넣는다.)\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의\n        \n        ## 레이어 정의 끝\n    def forward(self, x):\n        ## yhat을 어떻게 구할것인지 정의\n        \n        ## 정의 끝\n        return yhat\n\nnet(x)에 사용하는 x임, yhat은 net.forward(x)의 리턴값임.\n사실, x,yhat은 다른 변수로 써도 무방하나 (예를들어 input/output 이라든지) 설명의 편의상 x와 yhat을 고정한다.\n\nstpe2: def __init__(self)에 사용할 레이어를 정의하고 이름을 붙인다. 이름은 항상 self.xxx와 같은 식으로 정의한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return yhat\nstep3: def forward:에 “x->yhat”으로 가는 과정을묘사한 코드를 작성하고 yhat을 리턴하도록 한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        u = self.xxx1(x)\n        v = self.xxx2(u)\n        yhat = self.xxx3(v)\n        ## 정의 끝\n        return yhat"
  },
  {
    "objectID": "etc/2023-02-20-memo.html",
    "href": "etc/2023-02-20-memo.html",
    "title": "메모장",
    "section": "",
    "text": "temporal signal vs. static signals\nstatic graph vs. dynamic graph\nedge index? edge feature matrix (node feature matrix는 알겠는데ㅠㅠ엣지 매트릭스는 뭐야)\nGNN, Recurrent GNN, GCN, ST-GCN 순서가 어떻게 되는지 헷갈린다..\nGRU\nspectral gcn\nGNN 정리 블로그\nML with Graphs 강의영상"
  },
  {
    "objectID": "etc/2023-02-20-memo.html#lstm-참고자료들",
    "href": "etc/2023-02-20-memo.html#lstm-참고자료들",
    "title": "메모장",
    "section": "(LSTM 참고자료들)",
    "text": "(LSTM 참고자료들)\n\nhttps://colah.github.io/posts/2015-08-Understanding-LSTMs/\nhttps://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\nhttps://arxiv.org/abs/1402.1128"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "myblog",
    "section": "",
    "text": "27_test\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\ntest25\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nA Comprehensive Survey on Geometric Deep Learning\n\n\n\n\n\n\n\n논문리뷰\n\n\nstudy\n\n\n\n\n\n\n\n\n\n\n\nMar 5, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n  \n\n\n\n\nChap 12.2: Weakly Stationary Graph process\n\n\n\n\n\n\n\nCGSP\n\n\nstudy\n\n\n\n\n\n\n\n\n\n\n\nMar 5, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1 GNN tuto1\n\n\n\n\n\n\n\nGNN\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2 GNN tuto2\n\n\n\n\n\n\n\nGNN\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2 GNN tuto2\n\n\n\n\n\n\n\nGNN\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n  \n\n\n\n\n0 Introductino to GNN\n\n\n\n\n\n\n\nGNN\n\n\n\n\n\n\n\n\n\n\n\nMar 3, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n딥러닝 기초 (2)\n\n\n\n\n\n\n\nDNN\n\n\nBASIC\n\n\nDL2022\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n딥러닝 기초 (1)\n\n\n\n\n\n\n\nDNN\n\n\nBASIC\n\n\nDL2022\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n순환신경망 (5)\n\n\n\n\n\n\n\nDL2022\n\n\nRNN\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n  \n\n\n\n\n순환신경망 (6)\n\n\n\n\n\n\n\nDL2022\n\n\nRNN\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n순환신경망 (4)\n\n\n\n\n\n\n\nDL2022\n\n\nRNN\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n순환신경망 (3)\n\n\n\n\n\n\n\nDL2022\n\n\nRNN\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGCN Implementation\n\n\n\n\n\n\n\nGCN\n\n\nImplementation\n\n\n\n\n\n\n\n\n\n\n\nFeb 27, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n  \n\n\n\n\n순환신경망 (2)\n\n\n\n\n\n\n\nDL2022\n\n\nRNN\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n순환신경망 (1)\n\n\n\n\n\n\n\nDL2022\n\n\nRNN\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChap 12.2: Weakly Stationary Graph process\n\n\n\n\n\n\n\nCGSP\n\n\nstudy\n\n\n\n\n\n\n\n\n\n\n\nFeb 24, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n  \n\n\n\n\nChap 8.3: Discrete Fourier Transform\n\n\n\n\n\n\n\nCGSP\n\n\nstudy\n\n\n\n\n\n\n\n\n\n\n\nFeb 24, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n튜토리얼 따라가기2\n\n\n\n\n\n\n\nSTGCN\n\n\nBASIC\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraffic Forecasting review\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n  \n\n\n\n\nGraph Convolutional Network\n\n\n\n\n\n\n\nGCN\n\n\nBASIC\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n  \n\n\n\n\n튜토리얼 따라가기1\n\n\n\n\n\n\n\nSTGCN\n\n\nBASIC\n\n\n\n\n\n\n\n\n\n\n\nFeb 20, 2023\n\n\njiyun Lim\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChap 12.4: Node Subsampling for PSD Estimation\n\n\n\n\n\n\n\n\n\n\n\n\nJan 15, 2023\n\n\n신록예찬\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToy Example\n\n\n\n\n\n\n\nSTGCN\n\n\nPytorch\n\n\n\n\n\n\n\n\n\n\n\nDec 30, 2022\n\n\n신록예찬\n\n\n\n\n\n\n  \n\n\n\n\nSTGCN 튜토리얼\n\n\n\n\n\n\n\n\n\n\n\n\nDec 29, 2022\n\n\n신록예찬, 최서연\n\n\n\n\n\n\n  \n\n\n\n\nChap 12.2 ~ 3: Power Spectral Density and its Estimators\n\n\n\n\n\n\n\n\n\n\n\n\nDec 27, 2022\n\n\n신록예찬\n\n\n\n\n\n\n  \n\n\n\n\nChap 12.2: Weakly Stationary Graph Processes\n\n\n\n\n\n\n\n\n\n\n\n\nDec 26, 2022\n\n\n신록예찬\n\n\n\n\n\n\n  \n\n\n\n\nChap 8.3: Discrete Fourier Transform\n\n\n\n\n\n\n\n\n\n\n\n\nDec 24, 2022\n\n\n신록예찬\n\n\n\n\n\n\nNo matching items"
  }
]